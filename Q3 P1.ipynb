{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# load `.mat` file\n",
    "data = scipy.io.loadmat('face.mat')\n",
    "\n",
    "# Images\n",
    "# N: number of images\n",
    "# D: number of pixels\n",
    "X = data['X']  # shape: [D x N]\n",
    "y = data['l']  # shape: [1 x N]\n",
    "\n",
    "assert(X.shape[1] == y.shape[1])\n",
    "# Number of images\n",
    "D, N = X.shape\n",
    "\n",
    "# Fix the random seed\n",
    "np.random.seed(13)\n",
    "\n",
    "# Cardinality of labels\n",
    "_card = len(set(y.ravel()))\n",
    "\n",
    "# Step splitting of dataset\n",
    "_step = int(N / _card)\n",
    "\n",
    "# Shape boundaries\n",
    "_bounds = np.arange(0, N+1, _step)\n",
    "\n",
    "# Shapes\n",
    "shapes = list(zip(_bounds[:-1], _bounds[1:]))\n",
    "\n",
    "# Training Mask\n",
    "_mask = []\n",
    "\n",
    "for _shape in shapes:\n",
    "    _idx = np.random.choice(\n",
    "        np.arange(*_shape), int(0.8 * _step), replace=False)\n",
    "    _mask.append(_idx)\n",
    "\n",
    "mask_train = np.array(_mask).ravel()\n",
    "\n",
    "mask_test = np.array(list(set(np.arange(0, N)) - set(mask_train)))\n",
    "\n",
    "# Partition dataset to train and test sets\n",
    "X_train, X_test = X[:, mask_train], X[:, mask_test]\n",
    "y_train, y_test = y[:, mask_train], y[:, mask_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA(object):\n",
    "    \"\"\"Principle Component Analysis.\"\"\"\n",
    "\n",
    "    def __init__(self, n_comps=5, standard=True):\n",
    "        \"\"\"Contructor.\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_comps: int\n",
    "            Number of principle components\n",
    "        \"\"\"\n",
    "        self._fitted = False\n",
    "        self.n_comps = n_comps\n",
    "        self.standard = standard\n",
    "        self.mean = None\n",
    "        self.U = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"Fit PCA according to `X.cov()`.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: numpy.ndarray\n",
    "            Features matrix\n",
    "        Returns\n",
    "        -------\n",
    "        array: numpy.ndarray\n",
    "            Transformed features matrix\n",
    "        \"\"\"\n",
    "        self.D, N = X.shape\n",
    "        self.mean = X.mean(axis=1).reshape(-1, 1)\n",
    "        # center data\n",
    "        A = X - self.mean\n",
    "        # covariance matrix\n",
    "        S = (1 / N) * np.dot(A.T, A)\n",
    "        \n",
    "        _l, _v = np.linalg.eig(S)\n",
    "\n",
    "        _indexes = np.argsort(_l)[::-1]\n",
    "\n",
    "        # Sorted eigenvalues and eigenvectors\n",
    "        l, v = _l[_indexes], _v[:, _indexes]\n",
    "\n",
    "        V = v[:, :self.n_comps]\n",
    "\n",
    "        _U = np.dot(A, V)\n",
    "\n",
    "        self.U = _U / np.apply_along_axis(np.linalg.norm, 0, _U)\n",
    "\n",
    "        W = np.dot(self.U.T, A)\n",
    "\n",
    "        if self.standard:\n",
    "            self.W_mean = np.mean(W, axis=1)\n",
    "            self.W_std = np.std(W, axis=1)\n",
    "\n",
    "        self._fitted = True\n",
    "\n",
    "        if self.standard:\n",
    "            return ((W.T - self.W_mean) / self.W_std).T\n",
    "        else:\n",
    "            return W\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform `X` by projecting it to PCA feature space.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: numpy.ndarray\n",
    "            Features matrix\n",
    "        Returns\n",
    "        -------\n",
    "        array: numpy.ndarray\n",
    "            Transformed features matrix\n",
    "        \"\"\"\n",
    "\n",
    "        Phi = X - self.mean\n",
    "\n",
    "        W = np.dot(self.U.T, Phi)\n",
    "\n",
    "        if self.standard:\n",
    "            return ((W.T - self.W_mean) / self.W_std).T\n",
    "        else:\n",
    "            return W\n",
    "\n",
    "    def reconstruct(self, W):\n",
    "        \"\"\"Recontruct compressed data.\n",
    "        Parameters\n",
    "        ----------\n",
    "        W: numpy.ndarray\n",
    "            Projection coefficients matrix\n",
    "        Returns\n",
    "        -------\n",
    "        X_hat: numpy.ndarray\n",
    "            Reconstructed features matrix\n",
    "        \"\"\"\n",
    "        A_hat = np.dot(self.U, W).reshape(-1, 1)\n",
    "        A_hat = A_hat + self.mean\n",
    "        return A_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  1 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  2  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  3  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  4  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  5  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  6  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  7  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  8  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  9  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  10  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  11  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  12  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  13  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  14  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  15  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  16  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  17  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  18  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  19  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  20  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  21  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  22  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  23  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  24  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  25  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  26  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  27  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  28  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  29  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  30  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  31  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  32  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  33  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  34  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  35  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  36  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  37  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  38  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  39  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  40  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  41  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  42  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  43  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  44  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  45  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  46  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  47  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  48  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  49  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  50  --->  Accuracy = 4.81%\n",
      "M_pca =  1 , M_lda =  51  --->  Accuracy = 4.81%\n",
      "M_pca =  2 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  2 , M_lda =  2  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  3  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  4  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  5  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  6  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  7  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  8  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  9  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  10  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  11  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  12  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  13  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  14  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  15  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  16  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  17  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  18  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  19  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  20  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  21  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  22  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  23  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  24  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  25  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  26  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  27  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  28  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  29  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  30  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  31  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  32  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  33  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  34  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  35  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  36  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  37  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  38  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  39  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  40  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  41  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  42  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  43  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  44  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  45  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  46  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  47  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  48  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  49  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  50  --->  Accuracy = 9.62%\n",
      "M_pca =  2 , M_lda =  51  --->  Accuracy = 9.62%\n",
      "M_pca =  3 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  3 , M_lda =  2  --->  Accuracy = 5.77%\n",
      "M_pca =  3 , M_lda =  3  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  4  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  5  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  6  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  7  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  8  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  9  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  10  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  11  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  12  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  13  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  14  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  15  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  16  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  17  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  18  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  19  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  20  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  21  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  22  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  23  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  24  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  25  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  26  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  27  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  28  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  29  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  30  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  31  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  32  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  33  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  34  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  35  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  36  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  37  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  38  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  39  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  40  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  41  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  42  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  43  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  44  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  45  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  46  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  47  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  48  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  49  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  50  --->  Accuracy = 17.31%\n",
      "M_pca =  3 , M_lda =  51  --->  Accuracy = 17.31%\n",
      "M_pca =  4 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  4 , M_lda =  2  --->  Accuracy = 6.73%\n",
      "M_pca =  4 , M_lda =  3  --->  Accuracy = 18.27%\n",
      "M_pca =  4 , M_lda =  4  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  5  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  6  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  7  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  8  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  9  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  10  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  11  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  12  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  13  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  14  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  15  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  16  --->  Accuracy = 25.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  4 , M_lda =  17  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  18  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  19  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  20  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  21  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  22  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  23  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  24  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  25  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  26  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  27  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  28  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  29  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  30  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  31  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  32  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  33  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  34  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  35  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  36  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  37  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  38  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  39  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  40  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  41  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  42  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  43  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  44  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  45  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  46  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  47  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  48  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  49  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  50  --->  Accuracy = 25.00%\n",
      "M_pca =  4 , M_lda =  51  --->  Accuracy = 25.00%\n",
      "M_pca =  5 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  5 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  5 , M_lda =  3  --->  Accuracy = 22.12%\n",
      "M_pca =  5 , M_lda =  4  --->  Accuracy = 25.96%\n",
      "M_pca =  5 , M_lda =  5  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  6  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  7  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  8  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  9  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  10  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  11  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  12  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  13  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  14  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  15  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  16  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  17  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  18  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  19  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  20  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  21  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  22  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  23  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  24  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  25  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  26  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  27  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  28  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  29  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  30  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  31  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  32  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  33  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  34  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  35  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  36  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  37  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  38  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  39  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  40  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  41  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  42  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  43  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  44  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  45  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  46  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  47  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  48  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  49  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  50  --->  Accuracy = 35.58%\n",
      "M_pca =  5 , M_lda =  51  --->  Accuracy = 35.58%\n",
      "M_pca =  6 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  6 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  6 , M_lda =  3  --->  Accuracy = 20.19%\n",
      "M_pca =  6 , M_lda =  4  --->  Accuracy = 31.73%\n",
      "M_pca =  6 , M_lda =  5  --->  Accuracy = 35.58%\n",
      "M_pca =  6 , M_lda =  6  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  7  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  8  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  9  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  10  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  11  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  12  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  13  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  14  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  15  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  16  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  17  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  18  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  19  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  20  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  21  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  22  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  23  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  24  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  25  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  26  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  27  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  28  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  29  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  30  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  31  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  32  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  33  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  34  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  35  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  36  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  37  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  38  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  39  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  40  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  41  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  42  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  43  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  44  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  45  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  46  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  47  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  48  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  49  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  50  --->  Accuracy = 41.35%\n",
      "M_pca =  6 , M_lda =  51  --->  Accuracy = 41.35%\n",
      "M_pca =  7 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  7 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  7 , M_lda =  3  --->  Accuracy = 27.88%\n",
      "M_pca =  7 , M_lda =  4  --->  Accuracy = 29.81%\n",
      "M_pca =  7 , M_lda =  5  --->  Accuracy = 32.69%\n",
      "M_pca =  7 , M_lda =  6  --->  Accuracy = 35.58%\n",
      "M_pca =  7 , M_lda =  7  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  8  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  9  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  10  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  11  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  12  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  13  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  14  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  15  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  16  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  17  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  18  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  19  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  20  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  21  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  22  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  23  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  24  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  25  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  26  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  27  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  28  --->  Accuracy = 37.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  7 , M_lda =  29  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  30  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  31  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  32  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  33  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  34  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  35  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  36  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  37  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  38  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  39  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  40  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  41  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  42  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  43  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  44  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  45  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  46  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  47  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  48  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  49  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  50  --->  Accuracy = 37.50%\n",
      "M_pca =  7 , M_lda =  51  --->  Accuracy = 37.50%\n",
      "M_pca =  8 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  8 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  8 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  8 , M_lda =  4  --->  Accuracy = 29.81%\n",
      "M_pca =  8 , M_lda =  5  --->  Accuracy = 33.65%\n",
      "M_pca =  8 , M_lda =  6  --->  Accuracy = 35.58%\n",
      "M_pca =  8 , M_lda =  7  --->  Accuracy = 44.23%\n",
      "M_pca =  8 , M_lda =  8  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  9  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  10  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  11  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  12  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  13  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  14  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  15  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  16  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  17  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  18  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  19  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  20  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  21  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  22  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  23  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  24  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  25  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  26  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  27  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  28  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  29  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  30  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  31  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  32  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  33  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  34  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  35  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  36  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  37  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  38  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  39  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  40  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  41  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  42  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  43  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  44  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  45  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  46  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  47  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  48  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  49  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  50  --->  Accuracy = 42.31%\n",
      "M_pca =  8 , M_lda =  51  --->  Accuracy = 42.31%\n",
      "M_pca =  9 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  9 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  9 , M_lda =  3  --->  Accuracy = 25.96%\n",
      "M_pca =  9 , M_lda =  4  --->  Accuracy = 31.73%\n",
      "M_pca =  9 , M_lda =  5  --->  Accuracy = 36.54%\n",
      "M_pca =  9 , M_lda =  6  --->  Accuracy = 38.46%\n",
      "M_pca =  9 , M_lda =  7  --->  Accuracy = 40.38%\n",
      "M_pca =  9 , M_lda =  8  --->  Accuracy = 44.23%\n",
      "M_pca =  9 , M_lda =  9  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  10  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  11  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  12  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  13  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  14  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  15  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  16  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  17  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  18  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  19  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  20  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  21  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  22  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  23  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  24  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  25  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  26  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  27  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  28  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  29  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  30  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  31  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  32  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  33  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  34  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  35  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  36  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  37  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  38  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  39  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  40  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  41  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  42  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  43  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  44  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  45  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  46  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  47  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  48  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  49  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  50  --->  Accuracy = 48.08%\n",
      "M_pca =  9 , M_lda =  51  --->  Accuracy = 48.08%\n",
      "M_pca =  10 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  10 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  10 , M_lda =  3  --->  Accuracy = 23.08%\n",
      "M_pca =  10 , M_lda =  4  --->  Accuracy = 32.69%\n",
      "M_pca =  10 , M_lda =  5  --->  Accuracy = 38.46%\n",
      "M_pca =  10 , M_lda =  6  --->  Accuracy = 42.31%\n",
      "M_pca =  10 , M_lda =  7  --->  Accuracy = 45.19%\n",
      "M_pca =  10 , M_lda =  8  --->  Accuracy = 50.96%\n",
      "M_pca =  10 , M_lda =  9  --->  Accuracy = 49.04%\n",
      "M_pca =  10 , M_lda =  10  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  11  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  12  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  13  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  14  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  15  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  16  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  17  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  18  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  19  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  20  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  21  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  22  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  23  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  24  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  25  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  26  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  27  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  28  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  29  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  30  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  31  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  32  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  33  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  34  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  35  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  36  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  37  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  38  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  39  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  40  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  41  --->  Accuracy = 52.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  10 , M_lda =  42  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  43  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  44  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  45  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  46  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  47  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  48  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  49  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  50  --->  Accuracy = 52.88%\n",
      "M_pca =  10 , M_lda =  51  --->  Accuracy = 52.88%\n",
      "M_pca =  11 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  11 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  11 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  11 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  11 , M_lda =  5  --->  Accuracy = 37.50%\n",
      "M_pca =  11 , M_lda =  6  --->  Accuracy = 39.42%\n",
      "M_pca =  11 , M_lda =  7  --->  Accuracy = 47.12%\n",
      "M_pca =  11 , M_lda =  8  --->  Accuracy = 51.92%\n",
      "M_pca =  11 , M_lda =  9  --->  Accuracy = 50.96%\n",
      "M_pca =  11 , M_lda =  10  --->  Accuracy = 51.92%\n",
      "M_pca =  11 , M_lda =  11  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  12  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  13  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  14  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  15  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  16  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  17  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  18  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  19  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  20  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  21  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  22  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  23  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  24  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  25  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  26  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  27  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  28  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  29  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  30  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  31  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  32  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  33  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  34  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  35  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  36  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  37  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  38  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  39  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  40  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  41  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  42  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  43  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  44  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  45  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  46  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  47  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  48  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  49  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  50  --->  Accuracy = 56.73%\n",
      "M_pca =  11 , M_lda =  51  --->  Accuracy = 56.73%\n",
      "M_pca =  12 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  12 , M_lda =  2  --->  Accuracy = 23.08%\n",
      "M_pca =  12 , M_lda =  3  --->  Accuracy = 35.58%\n",
      "M_pca =  12 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  12 , M_lda =  5  --->  Accuracy = 44.23%\n",
      "M_pca =  12 , M_lda =  6  --->  Accuracy = 50.96%\n",
      "M_pca =  12 , M_lda =  7  --->  Accuracy = 53.85%\n",
      "M_pca =  12 , M_lda =  8  --->  Accuracy = 54.81%\n",
      "M_pca =  12 , M_lda =  9  --->  Accuracy = 57.69%\n",
      "M_pca =  12 , M_lda =  10  --->  Accuracy = 60.58%\n",
      "M_pca =  12 , M_lda =  11  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  12  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  13  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  14  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  15  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  16  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  17  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  18  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  19  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  20  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  21  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  22  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  23  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  24  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  25  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  26  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  27  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  28  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  29  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  30  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  31  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  32  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  33  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  34  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  35  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  36  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  37  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  38  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  39  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  40  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  41  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  42  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  43  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  44  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  45  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  46  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  47  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  48  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  49  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  50  --->  Accuracy = 59.62%\n",
      "M_pca =  12 , M_lda =  51  --->  Accuracy = 59.62%\n",
      "M_pca =  13 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  13 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  13 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  13 , M_lda =  4  --->  Accuracy = 40.38%\n",
      "M_pca =  13 , M_lda =  5  --->  Accuracy = 41.35%\n",
      "M_pca =  13 , M_lda =  6  --->  Accuracy = 50.00%\n",
      "M_pca =  13 , M_lda =  7  --->  Accuracy = 54.81%\n",
      "M_pca =  13 , M_lda =  8  --->  Accuracy = 53.85%\n",
      "M_pca =  13 , M_lda =  9  --->  Accuracy = 53.85%\n",
      "M_pca =  13 , M_lda =  10  --->  Accuracy = 55.77%\n",
      "M_pca =  13 , M_lda =  11  --->  Accuracy = 57.69%\n",
      "M_pca =  13 , M_lda =  12  --->  Accuracy = 58.65%\n",
      "M_pca =  13 , M_lda =  13  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  14  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  15  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  16  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  17  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  18  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  19  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  20  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  21  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  22  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  23  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  24  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  25  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  26  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  27  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  28  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  29  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  30  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  31  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  32  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  33  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  34  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  35  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  36  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  37  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  38  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  39  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  40  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  41  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  42  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  43  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  44  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  45  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  46  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  47  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  48  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  49  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  50  --->  Accuracy = 63.46%\n",
      "M_pca =  13 , M_lda =  51  --->  Accuracy = 63.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  14 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  14 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  14 , M_lda =  3  --->  Accuracy = 33.65%\n",
      "M_pca =  14 , M_lda =  4  --->  Accuracy = 41.35%\n",
      "M_pca =  14 , M_lda =  5  --->  Accuracy = 40.38%\n",
      "M_pca =  14 , M_lda =  6  --->  Accuracy = 43.27%\n",
      "M_pca =  14 , M_lda =  7  --->  Accuracy = 49.04%\n",
      "M_pca =  14 , M_lda =  8  --->  Accuracy = 48.08%\n",
      "M_pca =  14 , M_lda =  9  --->  Accuracy = 51.92%\n",
      "M_pca =  14 , M_lda =  10  --->  Accuracy = 57.69%\n",
      "M_pca =  14 , M_lda =  11  --->  Accuracy = 61.54%\n",
      "M_pca =  14 , M_lda =  12  --->  Accuracy = 62.50%\n",
      "M_pca =  14 , M_lda =  13  --->  Accuracy = 63.46%\n",
      "M_pca =  14 , M_lda =  14  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  15  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  16  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  17  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  18  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  19  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  20  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  21  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  22  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  23  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  24  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  25  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  26  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  27  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  28  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  29  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  30  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  31  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  32  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  33  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  34  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  35  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  36  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  37  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  38  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  39  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  40  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  41  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  42  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  43  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  44  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  45  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  46  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  47  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  48  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  49  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  50  --->  Accuracy = 64.42%\n",
      "M_pca =  14 , M_lda =  51  --->  Accuracy = 64.42%\n",
      "M_pca =  15 , M_lda =  1  --->  Accuracy = 10.58%\n",
      "M_pca =  15 , M_lda =  2  --->  Accuracy = 22.12%\n",
      "M_pca =  15 , M_lda =  3  --->  Accuracy = 33.65%\n",
      "M_pca =  15 , M_lda =  4  --->  Accuracy = 38.46%\n",
      "M_pca =  15 , M_lda =  5  --->  Accuracy = 39.42%\n",
      "M_pca =  15 , M_lda =  6  --->  Accuracy = 46.15%\n",
      "M_pca =  15 , M_lda =  7  --->  Accuracy = 50.96%\n",
      "M_pca =  15 , M_lda =  8  --->  Accuracy = 54.81%\n",
      "M_pca =  15 , M_lda =  9  --->  Accuracy = 53.85%\n",
      "M_pca =  15 , M_lda =  10  --->  Accuracy = 55.77%\n",
      "M_pca =  15 , M_lda =  11  --->  Accuracy = 56.73%\n",
      "M_pca =  15 , M_lda =  12  --->  Accuracy = 60.58%\n",
      "M_pca =  15 , M_lda =  13  --->  Accuracy = 67.31%\n",
      "M_pca =  15 , M_lda =  14  --->  Accuracy = 66.35%\n",
      "M_pca =  15 , M_lda =  15  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  16  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  17  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  18  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  19  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  20  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  21  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  22  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  23  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  24  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  25  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  26  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  27  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  28  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  29  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  30  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  31  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  32  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  33  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  34  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  35  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  36  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  37  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  38  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  39  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  40  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  41  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  42  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  43  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  44  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  45  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  46  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  47  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  48  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  49  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  50  --->  Accuracy = 65.38%\n",
      "M_pca =  15 , M_lda =  51  --->  Accuracy = 65.38%\n",
      "M_pca =  16 , M_lda =  1  --->  Accuracy = 2.88%\n",
      "M_pca =  16 , M_lda =  2  --->  Accuracy = 11.54%\n",
      "M_pca =  16 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  16 , M_lda =  4  --->  Accuracy = 39.42%\n",
      "M_pca =  16 , M_lda =  5  --->  Accuracy = 41.35%\n",
      "M_pca =  16 , M_lda =  6  --->  Accuracy = 50.00%\n",
      "M_pca =  16 , M_lda =  7  --->  Accuracy = 52.88%\n",
      "M_pca =  16 , M_lda =  8  --->  Accuracy = 56.73%\n",
      "M_pca =  16 , M_lda =  9  --->  Accuracy = 54.81%\n",
      "M_pca =  16 , M_lda =  10  --->  Accuracy = 54.81%\n",
      "M_pca =  16 , M_lda =  11  --->  Accuracy = 58.65%\n",
      "M_pca =  16 , M_lda =  12  --->  Accuracy = 57.69%\n",
      "M_pca =  16 , M_lda =  13  --->  Accuracy = 61.54%\n",
      "M_pca =  16 , M_lda =  14  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  15  --->  Accuracy = 67.31%\n",
      "M_pca =  16 , M_lda =  16  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  17  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  18  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  19  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  20  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  21  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  22  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  23  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  24  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  25  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  26  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  27  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  28  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  29  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  30  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  31  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  32  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  33  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  34  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  35  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  36  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  37  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  38  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  39  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  40  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  41  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  42  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  43  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  44  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  45  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  46  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  47  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  48  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  49  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  50  --->  Accuracy = 66.35%\n",
      "M_pca =  16 , M_lda =  51  --->  Accuracy = 66.35%\n",
      "M_pca =  17 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  17 , M_lda =  2  --->  Accuracy = 11.54%\n",
      "M_pca =  17 , M_lda =  3  --->  Accuracy = 33.65%\n",
      "M_pca =  17 , M_lda =  4  --->  Accuracy = 41.35%\n",
      "M_pca =  17 , M_lda =  5  --->  Accuracy = 41.35%\n",
      "M_pca =  17 , M_lda =  6  --->  Accuracy = 47.12%\n",
      "M_pca =  17 , M_lda =  7  --->  Accuracy = 52.88%\n",
      "M_pca =  17 , M_lda =  8  --->  Accuracy = 54.81%\n",
      "M_pca =  17 , M_lda =  9  --->  Accuracy = 56.73%\n",
      "M_pca =  17 , M_lda =  10  --->  Accuracy = 56.73%\n",
      "M_pca =  17 , M_lda =  11  --->  Accuracy = 56.73%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  17 , M_lda =  12  --->  Accuracy = 62.50%\n",
      "M_pca =  17 , M_lda =  13  --->  Accuracy = 62.50%\n",
      "M_pca =  17 , M_lda =  14  --->  Accuracy = 65.38%\n",
      "M_pca =  17 , M_lda =  15  --->  Accuracy = 66.35%\n",
      "M_pca =  17 , M_lda =  16  --->  Accuracy = 65.38%\n",
      "M_pca =  17 , M_lda =  17  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  18  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  19  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  20  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  21  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  22  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  23  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  24  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  25  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  26  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  27  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  28  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  29  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  30  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  31  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  32  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  33  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  34  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  35  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  36  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  37  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  38  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  39  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  40  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  41  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  42  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  43  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  44  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  45  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  46  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  47  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  48  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  49  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  50  --->  Accuracy = 67.31%\n",
      "M_pca =  17 , M_lda =  51  --->  Accuracy = 67.31%\n",
      "M_pca =  18 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  18 , M_lda =  2  --->  Accuracy = 12.50%\n",
      "M_pca =  18 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  18 , M_lda =  4  --->  Accuracy = 41.35%\n",
      "M_pca =  18 , M_lda =  5  --->  Accuracy = 45.19%\n",
      "M_pca =  18 , M_lda =  6  --->  Accuracy = 50.96%\n",
      "M_pca =  18 , M_lda =  7  --->  Accuracy = 49.04%\n",
      "M_pca =  18 , M_lda =  8  --->  Accuracy = 56.73%\n",
      "M_pca =  18 , M_lda =  9  --->  Accuracy = 55.77%\n",
      "M_pca =  18 , M_lda =  10  --->  Accuracy = 61.54%\n",
      "M_pca =  18 , M_lda =  11  --->  Accuracy = 57.69%\n",
      "M_pca =  18 , M_lda =  12  --->  Accuracy = 61.54%\n",
      "M_pca =  18 , M_lda =  13  --->  Accuracy = 63.46%\n",
      "M_pca =  18 , M_lda =  14  --->  Accuracy = 61.54%\n",
      "M_pca =  18 , M_lda =  15  --->  Accuracy = 61.54%\n",
      "M_pca =  18 , M_lda =  16  --->  Accuracy = 67.31%\n",
      "M_pca =  18 , M_lda =  17  --->  Accuracy = 68.27%\n",
      "M_pca =  18 , M_lda =  18  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  19  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  20  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  21  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  22  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  23  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  24  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  25  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  26  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  27  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  28  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  29  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  30  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  31  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  32  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  33  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  34  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  35  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  36  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  37  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  38  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  39  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  40  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  41  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  42  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  43  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  44  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  45  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  46  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  47  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  48  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  49  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  50  --->  Accuracy = 70.19%\n",
      "M_pca =  18 , M_lda =  51  --->  Accuracy = 70.19%\n",
      "M_pca =  19 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  19 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  19 , M_lda =  3  --->  Accuracy = 25.00%\n",
      "M_pca =  19 , M_lda =  4  --->  Accuracy = 38.46%\n",
      "M_pca =  19 , M_lda =  5  --->  Accuracy = 44.23%\n",
      "M_pca =  19 , M_lda =  6  --->  Accuracy = 48.08%\n",
      "M_pca =  19 , M_lda =  7  --->  Accuracy = 50.00%\n",
      "M_pca =  19 , M_lda =  8  --->  Accuracy = 58.65%\n",
      "M_pca =  19 , M_lda =  9  --->  Accuracy = 62.50%\n",
      "M_pca =  19 , M_lda =  10  --->  Accuracy = 61.54%\n",
      "M_pca =  19 , M_lda =  11  --->  Accuracy = 61.54%\n",
      "M_pca =  19 , M_lda =  12  --->  Accuracy = 63.46%\n",
      "M_pca =  19 , M_lda =  13  --->  Accuracy = 67.31%\n",
      "M_pca =  19 , M_lda =  14  --->  Accuracy = 65.38%\n",
      "M_pca =  19 , M_lda =  15  --->  Accuracy = 64.42%\n",
      "M_pca =  19 , M_lda =  16  --->  Accuracy = 66.35%\n",
      "M_pca =  19 , M_lda =  17  --->  Accuracy = 68.27%\n",
      "M_pca =  19 , M_lda =  18  --->  Accuracy = 71.15%\n",
      "M_pca =  19 , M_lda =  19  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  20  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  21  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  22  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  23  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  24  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  25  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  26  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  27  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  28  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  29  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  30  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  31  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  32  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  33  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  34  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  35  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  36  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  37  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  38  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  39  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  40  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  41  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  42  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  43  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  44  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  45  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  46  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  47  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  48  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  49  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  50  --->  Accuracy = 72.12%\n",
      "M_pca =  19 , M_lda =  51  --->  Accuracy = 72.12%\n",
      "M_pca =  20 , M_lda =  1  --->  Accuracy = 2.88%\n",
      "M_pca =  20 , M_lda =  2  --->  Accuracy = 10.58%\n",
      "M_pca =  20 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  20 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  20 , M_lda =  5  --->  Accuracy = 42.31%\n",
      "M_pca =  20 , M_lda =  6  --->  Accuracy = 50.96%\n",
      "M_pca =  20 , M_lda =  7  --->  Accuracy = 58.65%\n",
      "M_pca =  20 , M_lda =  8  --->  Accuracy = 58.65%\n",
      "M_pca =  20 , M_lda =  9  --->  Accuracy = 60.58%\n",
      "M_pca =  20 , M_lda =  10  --->  Accuracy = 67.31%\n",
      "M_pca =  20 , M_lda =  11  --->  Accuracy = 67.31%\n",
      "M_pca =  20 , M_lda =  12  --->  Accuracy = 66.35%\n",
      "M_pca =  20 , M_lda =  13  --->  Accuracy = 70.19%\n",
      "M_pca =  20 , M_lda =  14  --->  Accuracy = 68.27%\n",
      "M_pca =  20 , M_lda =  15  --->  Accuracy = 69.23%\n",
      "M_pca =  20 , M_lda =  16  --->  Accuracy = 71.15%\n",
      "M_pca =  20 , M_lda =  17  --->  Accuracy = 72.12%\n",
      "M_pca =  20 , M_lda =  18  --->  Accuracy = 71.15%\n",
      "M_pca =  20 , M_lda =  19  --->  Accuracy = 71.15%\n",
      "M_pca =  20 , M_lda =  20  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  21  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  22  --->  Accuracy = 75.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  20 , M_lda =  23  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  24  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  25  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  26  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  27  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  28  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  29  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  30  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  31  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  32  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  33  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  34  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  35  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  36  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  37  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  38  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  39  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  40  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  41  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  42  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  43  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  44  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  45  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  46  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  47  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  48  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  49  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  50  --->  Accuracy = 75.00%\n",
      "M_pca =  20 , M_lda =  51  --->  Accuracy = 75.00%\n",
      "M_pca =  21 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  21 , M_lda =  2  --->  Accuracy = 12.50%\n",
      "M_pca =  21 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  21 , M_lda =  4  --->  Accuracy = 40.38%\n",
      "M_pca =  21 , M_lda =  5  --->  Accuracy = 50.96%\n",
      "M_pca =  21 , M_lda =  6  --->  Accuracy = 50.96%\n",
      "M_pca =  21 , M_lda =  7  --->  Accuracy = 52.88%\n",
      "M_pca =  21 , M_lda =  8  --->  Accuracy = 60.58%\n",
      "M_pca =  21 , M_lda =  9  --->  Accuracy = 63.46%\n",
      "M_pca =  21 , M_lda =  10  --->  Accuracy = 63.46%\n",
      "M_pca =  21 , M_lda =  11  --->  Accuracy = 63.46%\n",
      "M_pca =  21 , M_lda =  12  --->  Accuracy = 62.50%\n",
      "M_pca =  21 , M_lda =  13  --->  Accuracy = 67.31%\n",
      "M_pca =  21 , M_lda =  14  --->  Accuracy = 64.42%\n",
      "M_pca =  21 , M_lda =  15  --->  Accuracy = 65.38%\n",
      "M_pca =  21 , M_lda =  16  --->  Accuracy = 68.27%\n",
      "M_pca =  21 , M_lda =  17  --->  Accuracy = 68.27%\n",
      "M_pca =  21 , M_lda =  18  --->  Accuracy = 70.19%\n",
      "M_pca =  21 , M_lda =  19  --->  Accuracy = 69.23%\n",
      "M_pca =  21 , M_lda =  20  --->  Accuracy = 70.19%\n",
      "M_pca =  21 , M_lda =  21  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  22  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  23  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  24  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  25  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  26  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  27  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  28  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  29  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  30  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  31  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  32  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  33  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  34  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  35  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  36  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  37  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  38  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  39  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  40  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  41  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  42  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  43  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  44  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  45  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  46  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  47  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  48  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  49  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  50  --->  Accuracy = 72.12%\n",
      "M_pca =  21 , M_lda =  51  --->  Accuracy = 72.12%\n",
      "M_pca =  22 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  22 , M_lda =  2  --->  Accuracy = 12.50%\n",
      "M_pca =  22 , M_lda =  3  --->  Accuracy = 27.88%\n",
      "M_pca =  22 , M_lda =  4  --->  Accuracy = 38.46%\n",
      "M_pca =  22 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  22 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  22 , M_lda =  7  --->  Accuracy = 57.69%\n",
      "M_pca =  22 , M_lda =  8  --->  Accuracy = 61.54%\n",
      "M_pca =  22 , M_lda =  9  --->  Accuracy = 64.42%\n",
      "M_pca =  22 , M_lda =  10  --->  Accuracy = 65.38%\n",
      "M_pca =  22 , M_lda =  11  --->  Accuracy = 66.35%\n",
      "M_pca =  22 , M_lda =  12  --->  Accuracy = 65.38%\n",
      "M_pca =  22 , M_lda =  13  --->  Accuracy = 65.38%\n",
      "M_pca =  22 , M_lda =  14  --->  Accuracy = 66.35%\n",
      "M_pca =  22 , M_lda =  15  --->  Accuracy = 67.31%\n",
      "M_pca =  22 , M_lda =  16  --->  Accuracy = 68.27%\n",
      "M_pca =  22 , M_lda =  17  --->  Accuracy = 70.19%\n",
      "M_pca =  22 , M_lda =  18  --->  Accuracy = 71.15%\n",
      "M_pca =  22 , M_lda =  19  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  20  --->  Accuracy = 71.15%\n",
      "M_pca =  22 , M_lda =  21  --->  Accuracy = 72.12%\n",
      "M_pca =  22 , M_lda =  22  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  23  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  24  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  25  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  26  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  27  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  28  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  29  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  30  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  31  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  32  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  33  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  34  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  35  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  36  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  37  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  38  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  39  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  40  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  41  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  42  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  43  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  44  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  45  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  46  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  47  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  48  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  49  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  50  --->  Accuracy = 73.08%\n",
      "M_pca =  22 , M_lda =  51  --->  Accuracy = 73.08%\n",
      "M_pca =  23 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  23 , M_lda =  2  --->  Accuracy = 12.50%\n",
      "M_pca =  23 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  23 , M_lda =  4  --->  Accuracy = 40.38%\n",
      "M_pca =  23 , M_lda =  5  --->  Accuracy = 52.88%\n",
      "M_pca =  23 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  23 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  23 , M_lda =  8  --->  Accuracy = 69.23%\n",
      "M_pca =  23 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  23 , M_lda =  10  --->  Accuracy = 69.23%\n",
      "M_pca =  23 , M_lda =  11  --->  Accuracy = 72.12%\n",
      "M_pca =  23 , M_lda =  12  --->  Accuracy = 70.19%\n",
      "M_pca =  23 , M_lda =  13  --->  Accuracy = 72.12%\n",
      "M_pca =  23 , M_lda =  14  --->  Accuracy = 70.19%\n",
      "M_pca =  23 , M_lda =  15  --->  Accuracy = 71.15%\n",
      "M_pca =  23 , M_lda =  16  --->  Accuracy = 71.15%\n",
      "M_pca =  23 , M_lda =  17  --->  Accuracy = 72.12%\n",
      "M_pca =  23 , M_lda =  18  --->  Accuracy = 73.08%\n",
      "M_pca =  23 , M_lda =  19  --->  Accuracy = 71.15%\n",
      "M_pca =  23 , M_lda =  20  --->  Accuracy = 72.12%\n",
      "M_pca =  23 , M_lda =  21  --->  Accuracy = 73.08%\n",
      "M_pca =  23 , M_lda =  22  --->  Accuracy = 73.08%\n",
      "M_pca =  23 , M_lda =  23  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  24  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  25  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  26  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  27  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  28  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  29  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  30  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  31  --->  Accuracy = 74.04%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  23 , M_lda =  32  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  33  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  34  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  35  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  36  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  37  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  38  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  39  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  40  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  41  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  42  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  43  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  44  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  45  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  46  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  47  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  48  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  49  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  50  --->  Accuracy = 74.04%\n",
      "M_pca =  23 , M_lda =  51  --->  Accuracy = 74.04%\n",
      "M_pca =  24 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  24 , M_lda =  2  --->  Accuracy = 12.50%\n",
      "M_pca =  24 , M_lda =  3  --->  Accuracy = 25.96%\n",
      "M_pca =  24 , M_lda =  4  --->  Accuracy = 33.65%\n",
      "M_pca =  24 , M_lda =  5  --->  Accuracy = 53.85%\n",
      "M_pca =  24 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  24 , M_lda =  7  --->  Accuracy = 61.54%\n",
      "M_pca =  24 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  24 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  24 , M_lda =  10  --->  Accuracy = 70.19%\n",
      "M_pca =  24 , M_lda =  11  --->  Accuracy = 72.12%\n",
      "M_pca =  24 , M_lda =  12  --->  Accuracy = 71.15%\n",
      "M_pca =  24 , M_lda =  13  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  14  --->  Accuracy = 72.12%\n",
      "M_pca =  24 , M_lda =  15  --->  Accuracy = 68.27%\n",
      "M_pca =  24 , M_lda =  16  --->  Accuracy = 70.19%\n",
      "M_pca =  24 , M_lda =  17  --->  Accuracy = 69.23%\n",
      "M_pca =  24 , M_lda =  18  --->  Accuracy = 70.19%\n",
      "M_pca =  24 , M_lda =  19  --->  Accuracy = 71.15%\n",
      "M_pca =  24 , M_lda =  20  --->  Accuracy = 70.19%\n",
      "M_pca =  24 , M_lda =  21  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  22  --->  Accuracy = 71.15%\n",
      "M_pca =  24 , M_lda =  23  --->  Accuracy = 70.19%\n",
      "M_pca =  24 , M_lda =  24  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  25  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  26  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  27  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  28  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  29  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  30  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  31  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  32  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  33  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  34  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  35  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  36  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  37  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  38  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  39  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  40  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  41  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  42  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  43  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  44  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  45  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  46  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  47  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  48  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  49  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  50  --->  Accuracy = 73.08%\n",
      "M_pca =  24 , M_lda =  51  --->  Accuracy = 73.08%\n",
      "M_pca =  25 , M_lda =  1  --->  Accuracy = 10.58%\n",
      "M_pca =  25 , M_lda =  2  --->  Accuracy = 11.54%\n",
      "M_pca =  25 , M_lda =  3  --->  Accuracy = 24.04%\n",
      "M_pca =  25 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  25 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  25 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  25 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  25 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  25 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  25 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  25 , M_lda =  11  --->  Accuracy = 72.12%\n",
      "M_pca =  25 , M_lda =  12  --->  Accuracy = 68.27%\n",
      "M_pca =  25 , M_lda =  13  --->  Accuracy = 70.19%\n",
      "M_pca =  25 , M_lda =  14  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  15  --->  Accuracy = 72.12%\n",
      "M_pca =  25 , M_lda =  16  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  17  --->  Accuracy = 70.19%\n",
      "M_pca =  25 , M_lda =  18  --->  Accuracy = 69.23%\n",
      "M_pca =  25 , M_lda =  19  --->  Accuracy = 69.23%\n",
      "M_pca =  25 , M_lda =  20  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  21  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  22  --->  Accuracy = 69.23%\n",
      "M_pca =  25 , M_lda =  23  --->  Accuracy = 68.27%\n",
      "M_pca =  25 , M_lda =  24  --->  Accuracy = 66.35%\n",
      "M_pca =  25 , M_lda =  25  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  26  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  27  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  28  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  29  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  30  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  31  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  32  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  33  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  34  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  35  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  36  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  37  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  38  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  39  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  40  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  41  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  42  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  43  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  44  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  45  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  46  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  47  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  48  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  49  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  50  --->  Accuracy = 71.15%\n",
      "M_pca =  25 , M_lda =  51  --->  Accuracy = 71.15%\n",
      "M_pca =  26 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  26 , M_lda =  2  --->  Accuracy = 11.54%\n",
      "M_pca =  26 , M_lda =  3  --->  Accuracy = 20.19%\n",
      "M_pca =  26 , M_lda =  4  --->  Accuracy = 32.69%\n",
      "M_pca =  26 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  26 , M_lda =  6  --->  Accuracy = 52.88%\n",
      "M_pca =  26 , M_lda =  7  --->  Accuracy = 59.62%\n",
      "M_pca =  26 , M_lda =  8  --->  Accuracy = 63.46%\n",
      "M_pca =  26 , M_lda =  9  --->  Accuracy = 68.27%\n",
      "M_pca =  26 , M_lda =  10  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  11  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  12  --->  Accuracy = 68.27%\n",
      "M_pca =  26 , M_lda =  13  --->  Accuracy = 68.27%\n",
      "M_pca =  26 , M_lda =  14  --->  Accuracy = 67.31%\n",
      "M_pca =  26 , M_lda =  15  --->  Accuracy = 71.15%\n",
      "M_pca =  26 , M_lda =  16  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  17  --->  Accuracy = 73.08%\n",
      "M_pca =  26 , M_lda =  18  --->  Accuracy = 71.15%\n",
      "M_pca =  26 , M_lda =  19  --->  Accuracy = 70.19%\n",
      "M_pca =  26 , M_lda =  20  --->  Accuracy = 73.08%\n",
      "M_pca =  26 , M_lda =  21  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  22  --->  Accuracy = 71.15%\n",
      "M_pca =  26 , M_lda =  23  --->  Accuracy = 69.23%\n",
      "M_pca =  26 , M_lda =  24  --->  Accuracy = 70.19%\n",
      "M_pca =  26 , M_lda =  25  --->  Accuracy = 70.19%\n",
      "M_pca =  26 , M_lda =  26  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  27  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  28  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  29  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  30  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  31  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  32  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  33  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  34  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  35  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  36  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  37  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  38  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  39  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  40  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  41  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  42  --->  Accuracy = 72.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  26 , M_lda =  43  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  44  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  45  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  46  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  47  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  48  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  49  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  50  --->  Accuracy = 72.12%\n",
      "M_pca =  26 , M_lda =  51  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  27 , M_lda =  2  --->  Accuracy = 12.50%\n",
      "M_pca =  27 , M_lda =  3  --->  Accuracy = 25.00%\n",
      "M_pca =  27 , M_lda =  4  --->  Accuracy = 37.50%\n",
      "M_pca =  27 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  27 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  27 , M_lda =  7  --->  Accuracy = 60.58%\n",
      "M_pca =  27 , M_lda =  8  --->  Accuracy = 61.54%\n",
      "M_pca =  27 , M_lda =  9  --->  Accuracy = 66.35%\n",
      "M_pca =  27 , M_lda =  10  --->  Accuracy = 69.23%\n",
      "M_pca =  27 , M_lda =  11  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  12  --->  Accuracy = 69.23%\n",
      "M_pca =  27 , M_lda =  13  --->  Accuracy = 69.23%\n",
      "M_pca =  27 , M_lda =  14  --->  Accuracy = 71.15%\n",
      "M_pca =  27 , M_lda =  15  --->  Accuracy = 71.15%\n",
      "M_pca =  27 , M_lda =  16  --->  Accuracy = 73.08%\n",
      "M_pca =  27 , M_lda =  17  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  18  --->  Accuracy = 74.04%\n",
      "M_pca =  27 , M_lda =  19  --->  Accuracy = 74.04%\n",
      "M_pca =  27 , M_lda =  20  --->  Accuracy = 75.00%\n",
      "M_pca =  27 , M_lda =  21  --->  Accuracy = 75.00%\n",
      "M_pca =  27 , M_lda =  22  --->  Accuracy = 73.08%\n",
      "M_pca =  27 , M_lda =  23  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  24  --->  Accuracy = 70.19%\n",
      "M_pca =  27 , M_lda =  25  --->  Accuracy = 70.19%\n",
      "M_pca =  27 , M_lda =  26  --->  Accuracy = 71.15%\n",
      "M_pca =  27 , M_lda =  27  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  28  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  29  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  30  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  31  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  32  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  33  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  34  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  35  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  36  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  37  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  38  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  39  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  40  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  41  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  42  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  43  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  44  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  45  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  46  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  47  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  48  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  49  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  50  --->  Accuracy = 72.12%\n",
      "M_pca =  27 , M_lda =  51  --->  Accuracy = 72.12%\n",
      "M_pca =  28 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  28 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  28 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  28 , M_lda =  4  --->  Accuracy = 42.31%\n",
      "M_pca =  28 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  28 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  28 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  28 , M_lda =  8  --->  Accuracy = 65.38%\n",
      "M_pca =  28 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  28 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  28 , M_lda =  11  --->  Accuracy = 74.04%\n",
      "M_pca =  28 , M_lda =  12  --->  Accuracy = 74.04%\n",
      "M_pca =  28 , M_lda =  13  --->  Accuracy = 71.15%\n",
      "M_pca =  28 , M_lda =  14  --->  Accuracy = 74.04%\n",
      "M_pca =  28 , M_lda =  15  --->  Accuracy = 75.00%\n",
      "M_pca =  28 , M_lda =  16  --->  Accuracy = 73.08%\n",
      "M_pca =  28 , M_lda =  17  --->  Accuracy = 74.04%\n",
      "M_pca =  28 , M_lda =  18  --->  Accuracy = 73.08%\n",
      "M_pca =  28 , M_lda =  19  --->  Accuracy = 72.12%\n",
      "M_pca =  28 , M_lda =  20  --->  Accuracy = 72.12%\n",
      "M_pca =  28 , M_lda =  21  --->  Accuracy = 73.08%\n",
      "M_pca =  28 , M_lda =  22  --->  Accuracy = 72.12%\n",
      "M_pca =  28 , M_lda =  23  --->  Accuracy = 71.15%\n",
      "M_pca =  28 , M_lda =  24  --->  Accuracy = 69.23%\n",
      "M_pca =  28 , M_lda =  25  --->  Accuracy = 68.27%\n",
      "M_pca =  28 , M_lda =  26  --->  Accuracy = 67.31%\n",
      "M_pca =  28 , M_lda =  27  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  28  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  29  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  30  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  31  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  32  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  33  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  34  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  35  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  36  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  37  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  38  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  39  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  40  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  41  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  42  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  43  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  44  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  45  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  46  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  47  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  48  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  49  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  50  --->  Accuracy = 70.19%\n",
      "M_pca =  28 , M_lda =  51  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  1  --->  Accuracy = 2.88%\n",
      "M_pca =  29 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  29 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  29 , M_lda =  4  --->  Accuracy = 47.12%\n",
      "M_pca =  29 , M_lda =  5  --->  Accuracy = 52.88%\n",
      "M_pca =  29 , M_lda =  6  --->  Accuracy = 61.54%\n",
      "M_pca =  29 , M_lda =  7  --->  Accuracy = 67.31%\n",
      "M_pca =  29 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  29 , M_lda =  9  --->  Accuracy = 67.31%\n",
      "M_pca =  29 , M_lda =  10  --->  Accuracy = 67.31%\n",
      "M_pca =  29 , M_lda =  11  --->  Accuracy = 75.00%\n",
      "M_pca =  29 , M_lda =  12  --->  Accuracy = 74.04%\n",
      "M_pca =  29 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  29 , M_lda =  14  --->  Accuracy = 75.96%\n",
      "M_pca =  29 , M_lda =  15  --->  Accuracy = 75.96%\n",
      "M_pca =  29 , M_lda =  16  --->  Accuracy = 74.04%\n",
      "M_pca =  29 , M_lda =  17  --->  Accuracy = 73.08%\n",
      "M_pca =  29 , M_lda =  18  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  19  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  20  --->  Accuracy = 75.00%\n",
      "M_pca =  29 , M_lda =  21  --->  Accuracy = 74.04%\n",
      "M_pca =  29 , M_lda =  22  --->  Accuracy = 73.08%\n",
      "M_pca =  29 , M_lda =  23  --->  Accuracy = 73.08%\n",
      "M_pca =  29 , M_lda =  24  --->  Accuracy = 72.12%\n",
      "M_pca =  29 , M_lda =  25  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  26  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  27  --->  Accuracy = 68.27%\n",
      "M_pca =  29 , M_lda =  28  --->  Accuracy = 69.23%\n",
      "M_pca =  29 , M_lda =  29  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  30  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  31  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  32  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  33  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  34  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  35  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  36  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  37  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  38  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  39  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  40  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  41  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  42  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  43  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  44  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  45  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  46  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  47  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  48  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  49  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  50  --->  Accuracy = 70.19%\n",
      "M_pca =  29 , M_lda =  51  --->  Accuracy = 70.19%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  30 , M_lda =  1  --->  Accuracy = 13.46%\n",
      "M_pca =  30 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  30 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  30 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  30 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  30 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  30 , M_lda =  7  --->  Accuracy = 60.58%\n",
      "M_pca =  30 , M_lda =  8  --->  Accuracy = 63.46%\n",
      "M_pca =  30 , M_lda =  9  --->  Accuracy = 63.46%\n",
      "M_pca =  30 , M_lda =  10  --->  Accuracy = 68.27%\n",
      "M_pca =  30 , M_lda =  11  --->  Accuracy = 75.00%\n",
      "M_pca =  30 , M_lda =  12  --->  Accuracy = 75.96%\n",
      "M_pca =  30 , M_lda =  13  --->  Accuracy = 75.96%\n",
      "M_pca =  30 , M_lda =  14  --->  Accuracy = 74.04%\n",
      "M_pca =  30 , M_lda =  15  --->  Accuracy = 74.04%\n",
      "M_pca =  30 , M_lda =  16  --->  Accuracy = 71.15%\n",
      "M_pca =  30 , M_lda =  17  --->  Accuracy = 70.19%\n",
      "M_pca =  30 , M_lda =  18  --->  Accuracy = 72.12%\n",
      "M_pca =  30 , M_lda =  19  --->  Accuracy = 71.15%\n",
      "M_pca =  30 , M_lda =  20  --->  Accuracy = 73.08%\n",
      "M_pca =  30 , M_lda =  21  --->  Accuracy = 74.04%\n",
      "M_pca =  30 , M_lda =  22  --->  Accuracy = 74.04%\n",
      "M_pca =  30 , M_lda =  23  --->  Accuracy = 72.12%\n",
      "M_pca =  30 , M_lda =  24  --->  Accuracy = 71.15%\n",
      "M_pca =  30 , M_lda =  25  --->  Accuracy = 71.15%\n",
      "M_pca =  30 , M_lda =  26  --->  Accuracy = 70.19%\n",
      "M_pca =  30 , M_lda =  27  --->  Accuracy = 70.19%\n",
      "M_pca =  30 , M_lda =  28  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  29  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  30  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  31  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  32  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  33  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  34  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  35  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  36  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  37  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  38  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  39  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  40  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  41  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  42  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  43  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  44  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  45  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  46  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  47  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  48  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  49  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  50  --->  Accuracy = 67.31%\n",
      "M_pca =  30 , M_lda =  51  --->  Accuracy = 67.31%\n",
      "M_pca =  31 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  31 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  31 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  31 , M_lda =  4  --->  Accuracy = 40.38%\n",
      "M_pca =  31 , M_lda =  5  --->  Accuracy = 47.12%\n",
      "M_pca =  31 , M_lda =  6  --->  Accuracy = 54.81%\n",
      "M_pca =  31 , M_lda =  7  --->  Accuracy = 60.58%\n",
      "M_pca =  31 , M_lda =  8  --->  Accuracy = 64.42%\n",
      "M_pca =  31 , M_lda =  9  --->  Accuracy = 63.46%\n",
      "M_pca =  31 , M_lda =  10  --->  Accuracy = 71.15%\n",
      "M_pca =  31 , M_lda =  11  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  31 , M_lda =  13  --->  Accuracy = 74.04%\n",
      "M_pca =  31 , M_lda =  14  --->  Accuracy = 71.15%\n",
      "M_pca =  31 , M_lda =  15  --->  Accuracy = 72.12%\n",
      "M_pca =  31 , M_lda =  16  --->  Accuracy = 72.12%\n",
      "M_pca =  31 , M_lda =  17  --->  Accuracy = 73.08%\n",
      "M_pca =  31 , M_lda =  18  --->  Accuracy = 74.04%\n",
      "M_pca =  31 , M_lda =  19  --->  Accuracy = 74.04%\n",
      "M_pca =  31 , M_lda =  20  --->  Accuracy = 72.12%\n",
      "M_pca =  31 , M_lda =  21  --->  Accuracy = 74.04%\n",
      "M_pca =  31 , M_lda =  22  --->  Accuracy = 73.08%\n",
      "M_pca =  31 , M_lda =  23  --->  Accuracy = 75.00%\n",
      "M_pca =  31 , M_lda =  24  --->  Accuracy = 75.96%\n",
      "M_pca =  31 , M_lda =  25  --->  Accuracy = 74.04%\n",
      "M_pca =  31 , M_lda =  26  --->  Accuracy = 74.04%\n",
      "M_pca =  31 , M_lda =  27  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  28  --->  Accuracy = 73.08%\n",
      "M_pca =  31 , M_lda =  29  --->  Accuracy = 71.15%\n",
      "M_pca =  31 , M_lda =  30  --->  Accuracy = 69.23%\n",
      "M_pca =  31 , M_lda =  31  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  32  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  33  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  34  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  35  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  36  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  37  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  38  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  39  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  40  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  41  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  42  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  43  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  44  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  45  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  46  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  47  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  48  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  49  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  50  --->  Accuracy = 70.19%\n",
      "M_pca =  31 , M_lda =  51  --->  Accuracy = 70.19%\n",
      "M_pca =  32 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  32 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  32 , M_lda =  3  --->  Accuracy = 24.04%\n",
      "M_pca =  32 , M_lda =  4  --->  Accuracy = 39.42%\n",
      "M_pca =  32 , M_lda =  5  --->  Accuracy = 46.15%\n",
      "M_pca =  32 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  32 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  32 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  32 , M_lda =  9  --->  Accuracy = 66.35%\n",
      "M_pca =  32 , M_lda =  10  --->  Accuracy = 67.31%\n",
      "M_pca =  32 , M_lda =  11  --->  Accuracy = 68.27%\n",
      "M_pca =  32 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  32 , M_lda =  13  --->  Accuracy = 73.08%\n",
      "M_pca =  32 , M_lda =  14  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  15  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  16  --->  Accuracy = 72.12%\n",
      "M_pca =  32 , M_lda =  17  --->  Accuracy = 72.12%\n",
      "M_pca =  32 , M_lda =  18  --->  Accuracy = 75.00%\n",
      "M_pca =  32 , M_lda =  19  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  20  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  21  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  22  --->  Accuracy = 75.00%\n",
      "M_pca =  32 , M_lda =  23  --->  Accuracy = 75.00%\n",
      "M_pca =  32 , M_lda =  24  --->  Accuracy = 75.00%\n",
      "M_pca =  32 , M_lda =  25  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  26  --->  Accuracy = 75.00%\n",
      "M_pca =  32 , M_lda =  27  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  28  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  29  --->  Accuracy = 73.08%\n",
      "M_pca =  32 , M_lda =  30  --->  Accuracy = 73.08%\n",
      "M_pca =  32 , M_lda =  31  --->  Accuracy = 72.12%\n",
      "M_pca =  32 , M_lda =  32  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  33  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  34  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  35  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  36  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  37  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  38  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  39  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  40  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  41  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  42  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  43  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  44  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  45  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  46  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  47  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  48  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  49  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  50  --->  Accuracy = 74.04%\n",
      "M_pca =  32 , M_lda =  51  --->  Accuracy = 74.04%\n",
      "M_pca =  33 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  33 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  33 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  33 , M_lda =  4  --->  Accuracy = 41.35%\n",
      "M_pca =  33 , M_lda =  5  --->  Accuracy = 51.92%\n",
      "M_pca =  33 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  33 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  33 , M_lda =  8  --->  Accuracy = 64.42%\n",
      "M_pca =  33 , M_lda =  9  --->  Accuracy = 66.35%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  33 , M_lda =  10  --->  Accuracy = 67.31%\n",
      "M_pca =  33 , M_lda =  11  --->  Accuracy = 70.19%\n",
      "M_pca =  33 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  33 , M_lda =  13  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  14  --->  Accuracy = 75.00%\n",
      "M_pca =  33 , M_lda =  15  --->  Accuracy = 75.00%\n",
      "M_pca =  33 , M_lda =  16  --->  Accuracy = 73.08%\n",
      "M_pca =  33 , M_lda =  17  --->  Accuracy = 74.04%\n",
      "M_pca =  33 , M_lda =  18  --->  Accuracy = 75.00%\n",
      "M_pca =  33 , M_lda =  19  --->  Accuracy = 75.00%\n",
      "M_pca =  33 , M_lda =  20  --->  Accuracy = 75.00%\n",
      "M_pca =  33 , M_lda =  21  --->  Accuracy = 75.00%\n",
      "M_pca =  33 , M_lda =  22  --->  Accuracy = 75.96%\n",
      "M_pca =  33 , M_lda =  23  --->  Accuracy = 76.92%\n",
      "M_pca =  33 , M_lda =  24  --->  Accuracy = 75.96%\n",
      "M_pca =  33 , M_lda =  25  --->  Accuracy = 75.96%\n",
      "M_pca =  33 , M_lda =  26  --->  Accuracy = 75.96%\n",
      "M_pca =  33 , M_lda =  27  --->  Accuracy = 75.96%\n",
      "M_pca =  33 , M_lda =  28  --->  Accuracy = 75.00%\n",
      "M_pca =  33 , M_lda =  29  --->  Accuracy = 74.04%\n",
      "M_pca =  33 , M_lda =  30  --->  Accuracy = 73.08%\n",
      "M_pca =  33 , M_lda =  31  --->  Accuracy = 72.12%\n",
      "M_pca =  33 , M_lda =  32  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  33  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  34  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  35  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  36  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  37  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  38  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  39  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  40  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  41  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  42  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  43  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  44  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  45  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  46  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  47  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  48  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  49  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  50  --->  Accuracy = 71.15%\n",
      "M_pca =  33 , M_lda =  51  --->  Accuracy = 71.15%\n",
      "M_pca =  34 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  34 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  34 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  34 , M_lda =  4  --->  Accuracy = 41.35%\n",
      "M_pca =  34 , M_lda =  5  --->  Accuracy = 53.85%\n",
      "M_pca =  34 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  34 , M_lda =  7  --->  Accuracy = 60.58%\n",
      "M_pca =  34 , M_lda =  8  --->  Accuracy = 63.46%\n",
      "M_pca =  34 , M_lda =  9  --->  Accuracy = 63.46%\n",
      "M_pca =  34 , M_lda =  10  --->  Accuracy = 68.27%\n",
      "M_pca =  34 , M_lda =  11  --->  Accuracy = 73.08%\n",
      "M_pca =  34 , M_lda =  12  --->  Accuracy = 73.08%\n",
      "M_pca =  34 , M_lda =  13  --->  Accuracy = 74.04%\n",
      "M_pca =  34 , M_lda =  14  --->  Accuracy = 75.96%\n",
      "M_pca =  34 , M_lda =  15  --->  Accuracy = 75.96%\n",
      "M_pca =  34 , M_lda =  16  --->  Accuracy = 73.08%\n",
      "M_pca =  34 , M_lda =  17  --->  Accuracy = 74.04%\n",
      "M_pca =  34 , M_lda =  18  --->  Accuracy = 74.04%\n",
      "M_pca =  34 , M_lda =  19  --->  Accuracy = 74.04%\n",
      "M_pca =  34 , M_lda =  20  --->  Accuracy = 76.92%\n",
      "M_pca =  34 , M_lda =  21  --->  Accuracy = 74.04%\n",
      "M_pca =  34 , M_lda =  22  --->  Accuracy = 75.96%\n",
      "M_pca =  34 , M_lda =  23  --->  Accuracy = 76.92%\n",
      "M_pca =  34 , M_lda =  24  --->  Accuracy = 77.88%\n",
      "M_pca =  34 , M_lda =  25  --->  Accuracy = 77.88%\n",
      "M_pca =  34 , M_lda =  26  --->  Accuracy = 77.88%\n",
      "M_pca =  34 , M_lda =  27  --->  Accuracy = 75.96%\n",
      "M_pca =  34 , M_lda =  28  --->  Accuracy = 75.96%\n",
      "M_pca =  34 , M_lda =  29  --->  Accuracy = 74.04%\n",
      "M_pca =  34 , M_lda =  30  --->  Accuracy = 74.04%\n",
      "M_pca =  34 , M_lda =  31  --->  Accuracy = 74.04%\n",
      "M_pca =  34 , M_lda =  32  --->  Accuracy = 73.08%\n",
      "M_pca =  34 , M_lda =  33  --->  Accuracy = 74.04%\n",
      "M_pca =  34 , M_lda =  34  --->  Accuracy = 75.00%\n",
      "M_pca =  34 , M_lda =  35  --->  Accuracy = 75.00%\n",
      "M_pca =  34 , M_lda =  36  --->  Accuracy = 75.00%\n",
      "M_pca =  34 , M_lda =  37  --->  Accuracy = 75.00%\n",
      "M_pca =  34 , M_lda =  38  --->  Accuracy = 75.00%\n",
      "M_pca =  34 , M_lda =  39  --->  Accuracy = 75.00%\n",
      "M_pca =  34 , M_lda =  40  --->  Accuracy = 75.00%\n",
      "M_pca =  34 , M_lda =  41  --->  Accuracy = 75.00%\n",
      "M_pca =  34 , M_lda =  42  --->  Accuracy = 75.00%\n",
      "M_pca =  34 , M_lda =  43  --->  Accuracy = 75.00%\n",
      "M_pca =  34 , M_lda =  44  --->  Accuracy = 75.00%\n",
      "M_pca =  34 , M_lda =  45  --->  Accuracy = 75.00%\n",
      "M_pca =  34 , M_lda =  46  --->  Accuracy = 75.00%\n",
      "M_pca =  34 , M_lda =  47  --->  Accuracy = 75.00%\n",
      "M_pca =  34 , M_lda =  48  --->  Accuracy = 75.00%\n",
      "M_pca =  34 , M_lda =  49  --->  Accuracy = 75.00%\n",
      "M_pca =  34 , M_lda =  50  --->  Accuracy = 75.00%\n",
      "M_pca =  34 , M_lda =  51  --->  Accuracy = 75.00%\n",
      "M_pca =  35 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  35 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  35 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  35 , M_lda =  4  --->  Accuracy = 39.42%\n",
      "M_pca =  35 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  35 , M_lda =  6  --->  Accuracy = 54.81%\n",
      "M_pca =  35 , M_lda =  7  --->  Accuracy = 60.58%\n",
      "M_pca =  35 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  35 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  35 , M_lda =  10  --->  Accuracy = 71.15%\n",
      "M_pca =  35 , M_lda =  11  --->  Accuracy = 72.12%\n",
      "M_pca =  35 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  35 , M_lda =  13  --->  Accuracy = 75.96%\n",
      "M_pca =  35 , M_lda =  14  --->  Accuracy = 76.92%\n",
      "M_pca =  35 , M_lda =  15  --->  Accuracy = 75.00%\n",
      "M_pca =  35 , M_lda =  16  --->  Accuracy = 76.92%\n",
      "M_pca =  35 , M_lda =  17  --->  Accuracy = 75.00%\n",
      "M_pca =  35 , M_lda =  18  --->  Accuracy = 75.96%\n",
      "M_pca =  35 , M_lda =  19  --->  Accuracy = 75.00%\n",
      "M_pca =  35 , M_lda =  20  --->  Accuracy = 75.00%\n",
      "M_pca =  35 , M_lda =  21  --->  Accuracy = 76.92%\n",
      "M_pca =  35 , M_lda =  22  --->  Accuracy = 77.88%\n",
      "M_pca =  35 , M_lda =  23  --->  Accuracy = 78.85%\n",
      "M_pca =  35 , M_lda =  24  --->  Accuracy = 78.85%\n",
      "M_pca =  35 , M_lda =  25  --->  Accuracy = 78.85%\n",
      "M_pca =  35 , M_lda =  26  --->  Accuracy = 78.85%\n",
      "M_pca =  35 , M_lda =  27  --->  Accuracy = 77.88%\n",
      "M_pca =  35 , M_lda =  28  --->  Accuracy = 74.04%\n",
      "M_pca =  35 , M_lda =  29  --->  Accuracy = 75.00%\n",
      "M_pca =  35 , M_lda =  30  --->  Accuracy = 74.04%\n",
      "M_pca =  35 , M_lda =  31  --->  Accuracy = 74.04%\n",
      "M_pca =  35 , M_lda =  32  --->  Accuracy = 74.04%\n",
      "M_pca =  35 , M_lda =  33  --->  Accuracy = 73.08%\n",
      "M_pca =  35 , M_lda =  34  --->  Accuracy = 75.00%\n",
      "M_pca =  35 , M_lda =  35  --->  Accuracy = 75.96%\n",
      "M_pca =  35 , M_lda =  36  --->  Accuracy = 75.96%\n",
      "M_pca =  35 , M_lda =  37  --->  Accuracy = 75.96%\n",
      "M_pca =  35 , M_lda =  38  --->  Accuracy = 75.96%\n",
      "M_pca =  35 , M_lda =  39  --->  Accuracy = 75.96%\n",
      "M_pca =  35 , M_lda =  40  --->  Accuracy = 75.96%\n",
      "M_pca =  35 , M_lda =  41  --->  Accuracy = 75.96%\n",
      "M_pca =  35 , M_lda =  42  --->  Accuracy = 75.96%\n",
      "M_pca =  35 , M_lda =  43  --->  Accuracy = 75.96%\n",
      "M_pca =  35 , M_lda =  44  --->  Accuracy = 75.96%\n",
      "M_pca =  35 , M_lda =  45  --->  Accuracy = 75.96%\n",
      "M_pca =  35 , M_lda =  46  --->  Accuracy = 75.96%\n",
      "M_pca =  35 , M_lda =  47  --->  Accuracy = 75.96%\n",
      "M_pca =  35 , M_lda =  48  --->  Accuracy = 75.96%\n",
      "M_pca =  35 , M_lda =  49  --->  Accuracy = 75.96%\n",
      "M_pca =  35 , M_lda =  50  --->  Accuracy = 75.96%\n",
      "M_pca =  35 , M_lda =  51  --->  Accuracy = 75.96%\n",
      "M_pca =  36 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  36 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  36 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  36 , M_lda =  4  --->  Accuracy = 42.31%\n",
      "M_pca =  36 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  36 , M_lda =  6  --->  Accuracy = 50.96%\n",
      "M_pca =  36 , M_lda =  7  --->  Accuracy = 61.54%\n",
      "M_pca =  36 , M_lda =  8  --->  Accuracy = 63.46%\n",
      "M_pca =  36 , M_lda =  9  --->  Accuracy = 68.27%\n",
      "M_pca =  36 , M_lda =  10  --->  Accuracy = 72.12%\n",
      "M_pca =  36 , M_lda =  11  --->  Accuracy = 72.12%\n",
      "M_pca =  36 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  36 , M_lda =  13  --->  Accuracy = 73.08%\n",
      "M_pca =  36 , M_lda =  14  --->  Accuracy = 75.96%\n",
      "M_pca =  36 , M_lda =  15  --->  Accuracy = 75.96%\n",
      "M_pca =  36 , M_lda =  16  --->  Accuracy = 75.96%\n",
      "M_pca =  36 , M_lda =  17  --->  Accuracy = 76.92%\n",
      "M_pca =  36 , M_lda =  18  --->  Accuracy = 76.92%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  36 , M_lda =  19  --->  Accuracy = 76.92%\n",
      "M_pca =  36 , M_lda =  20  --->  Accuracy = 75.96%\n",
      "M_pca =  36 , M_lda =  21  --->  Accuracy = 78.85%\n",
      "M_pca =  36 , M_lda =  22  --->  Accuracy = 78.85%\n",
      "M_pca =  36 , M_lda =  23  --->  Accuracy = 77.88%\n",
      "M_pca =  36 , M_lda =  24  --->  Accuracy = 78.85%\n",
      "M_pca =  36 , M_lda =  25  --->  Accuracy = 78.85%\n",
      "M_pca =  36 , M_lda =  26  --->  Accuracy = 78.85%\n",
      "M_pca =  36 , M_lda =  27  --->  Accuracy = 77.88%\n",
      "M_pca =  36 , M_lda =  28  --->  Accuracy = 76.92%\n",
      "M_pca =  36 , M_lda =  29  --->  Accuracy = 75.00%\n",
      "M_pca =  36 , M_lda =  30  --->  Accuracy = 74.04%\n",
      "M_pca =  36 , M_lda =  31  --->  Accuracy = 74.04%\n",
      "M_pca =  36 , M_lda =  32  --->  Accuracy = 75.00%\n",
      "M_pca =  36 , M_lda =  33  --->  Accuracy = 75.00%\n",
      "M_pca =  36 , M_lda =  34  --->  Accuracy = 75.00%\n",
      "M_pca =  36 , M_lda =  35  --->  Accuracy = 74.04%\n",
      "M_pca =  36 , M_lda =  36  --->  Accuracy = 76.92%\n",
      "M_pca =  36 , M_lda =  37  --->  Accuracy = 76.92%\n",
      "M_pca =  36 , M_lda =  38  --->  Accuracy = 76.92%\n",
      "M_pca =  36 , M_lda =  39  --->  Accuracy = 76.92%\n",
      "M_pca =  36 , M_lda =  40  --->  Accuracy = 76.92%\n",
      "M_pca =  36 , M_lda =  41  --->  Accuracy = 76.92%\n",
      "M_pca =  36 , M_lda =  42  --->  Accuracy = 76.92%\n",
      "M_pca =  36 , M_lda =  43  --->  Accuracy = 76.92%\n",
      "M_pca =  36 , M_lda =  44  --->  Accuracy = 76.92%\n",
      "M_pca =  36 , M_lda =  45  --->  Accuracy = 76.92%\n",
      "M_pca =  36 , M_lda =  46  --->  Accuracy = 76.92%\n",
      "M_pca =  36 , M_lda =  47  --->  Accuracy = 76.92%\n",
      "M_pca =  36 , M_lda =  48  --->  Accuracy = 76.92%\n",
      "M_pca =  36 , M_lda =  49  --->  Accuracy = 76.92%\n",
      "M_pca =  36 , M_lda =  50  --->  Accuracy = 76.92%\n",
      "M_pca =  36 , M_lda =  51  --->  Accuracy = 76.92%\n",
      "M_pca =  37 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  37 , M_lda =  2  --->  Accuracy = 13.46%\n",
      "M_pca =  37 , M_lda =  3  --->  Accuracy = 20.19%\n",
      "M_pca =  37 , M_lda =  4  --->  Accuracy = 40.38%\n",
      "M_pca =  37 , M_lda =  5  --->  Accuracy = 51.92%\n",
      "M_pca =  37 , M_lda =  6  --->  Accuracy = 50.96%\n",
      "M_pca =  37 , M_lda =  7  --->  Accuracy = 60.58%\n",
      "M_pca =  37 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  37 , M_lda =  9  --->  Accuracy = 69.23%\n",
      "M_pca =  37 , M_lda =  10  --->  Accuracy = 73.08%\n",
      "M_pca =  37 , M_lda =  11  --->  Accuracy = 75.96%\n",
      "M_pca =  37 , M_lda =  12  --->  Accuracy = 74.04%\n",
      "M_pca =  37 , M_lda =  13  --->  Accuracy = 75.96%\n",
      "M_pca =  37 , M_lda =  14  --->  Accuracy = 75.96%\n",
      "M_pca =  37 , M_lda =  15  --->  Accuracy = 75.96%\n",
      "M_pca =  37 , M_lda =  16  --->  Accuracy = 75.00%\n",
      "M_pca =  37 , M_lda =  17  --->  Accuracy = 75.96%\n",
      "M_pca =  37 , M_lda =  18  --->  Accuracy = 76.92%\n",
      "M_pca =  37 , M_lda =  19  --->  Accuracy = 76.92%\n",
      "M_pca =  37 , M_lda =  20  --->  Accuracy = 76.92%\n",
      "M_pca =  37 , M_lda =  21  --->  Accuracy = 75.96%\n",
      "M_pca =  37 , M_lda =  22  --->  Accuracy = 75.96%\n",
      "M_pca =  37 , M_lda =  23  --->  Accuracy = 75.96%\n",
      "M_pca =  37 , M_lda =  24  --->  Accuracy = 78.85%\n",
      "M_pca =  37 , M_lda =  25  --->  Accuracy = 77.88%\n",
      "M_pca =  37 , M_lda =  26  --->  Accuracy = 76.92%\n",
      "M_pca =  37 , M_lda =  27  --->  Accuracy = 76.92%\n",
      "M_pca =  37 , M_lda =  28  --->  Accuracy = 77.88%\n",
      "M_pca =  37 , M_lda =  29  --->  Accuracy = 77.88%\n",
      "M_pca =  37 , M_lda =  30  --->  Accuracy = 75.00%\n",
      "M_pca =  37 , M_lda =  31  --->  Accuracy = 74.04%\n",
      "M_pca =  37 , M_lda =  32  --->  Accuracy = 74.04%\n",
      "M_pca =  37 , M_lda =  33  --->  Accuracy = 74.04%\n",
      "M_pca =  37 , M_lda =  34  --->  Accuracy = 73.08%\n",
      "M_pca =  37 , M_lda =  35  --->  Accuracy = 72.12%\n",
      "M_pca =  37 , M_lda =  36  --->  Accuracy = 74.04%\n",
      "M_pca =  37 , M_lda =  37  --->  Accuracy = 75.00%\n",
      "M_pca =  37 , M_lda =  38  --->  Accuracy = 75.00%\n",
      "M_pca =  37 , M_lda =  39  --->  Accuracy = 75.00%\n",
      "M_pca =  37 , M_lda =  40  --->  Accuracy = 75.00%\n",
      "M_pca =  37 , M_lda =  41  --->  Accuracy = 75.00%\n",
      "M_pca =  37 , M_lda =  42  --->  Accuracy = 75.00%\n",
      "M_pca =  37 , M_lda =  43  --->  Accuracy = 75.00%\n",
      "M_pca =  37 , M_lda =  44  --->  Accuracy = 75.00%\n",
      "M_pca =  37 , M_lda =  45  --->  Accuracy = 75.00%\n",
      "M_pca =  37 , M_lda =  46  --->  Accuracy = 75.00%\n",
      "M_pca =  37 , M_lda =  47  --->  Accuracy = 75.00%\n",
      "M_pca =  37 , M_lda =  48  --->  Accuracy = 75.00%\n",
      "M_pca =  37 , M_lda =  49  --->  Accuracy = 75.00%\n",
      "M_pca =  37 , M_lda =  50  --->  Accuracy = 75.00%\n",
      "M_pca =  37 , M_lda =  51  --->  Accuracy = 75.00%\n",
      "M_pca =  38 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  38 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  38 , M_lda =  3  --->  Accuracy = 25.96%\n",
      "M_pca =  38 , M_lda =  4  --->  Accuracy = 38.46%\n",
      "M_pca =  38 , M_lda =  5  --->  Accuracy = 47.12%\n",
      "M_pca =  38 , M_lda =  6  --->  Accuracy = 50.96%\n",
      "M_pca =  38 , M_lda =  7  --->  Accuracy = 59.62%\n",
      "M_pca =  38 , M_lda =  8  --->  Accuracy = 65.38%\n",
      "M_pca =  38 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  38 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  38 , M_lda =  11  --->  Accuracy = 75.00%\n",
      "M_pca =  38 , M_lda =  12  --->  Accuracy = 75.96%\n",
      "M_pca =  38 , M_lda =  13  --->  Accuracy = 73.08%\n",
      "M_pca =  38 , M_lda =  14  --->  Accuracy = 76.92%\n",
      "M_pca =  38 , M_lda =  15  --->  Accuracy = 75.00%\n",
      "M_pca =  38 , M_lda =  16  --->  Accuracy = 75.96%\n",
      "M_pca =  38 , M_lda =  17  --->  Accuracy = 72.12%\n",
      "M_pca =  38 , M_lda =  18  --->  Accuracy = 75.00%\n",
      "M_pca =  38 , M_lda =  19  --->  Accuracy = 74.04%\n",
      "M_pca =  38 , M_lda =  20  --->  Accuracy = 76.92%\n",
      "M_pca =  38 , M_lda =  21  --->  Accuracy = 77.88%\n",
      "M_pca =  38 , M_lda =  22  --->  Accuracy = 77.88%\n",
      "M_pca =  38 , M_lda =  23  --->  Accuracy = 76.92%\n",
      "M_pca =  38 , M_lda =  24  --->  Accuracy = 78.85%\n",
      "M_pca =  38 , M_lda =  25  --->  Accuracy = 76.92%\n",
      "M_pca =  38 , M_lda =  26  --->  Accuracy = 79.81%\n",
      "M_pca =  38 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  38 , M_lda =  28  --->  Accuracy = 76.92%\n",
      "M_pca =  38 , M_lda =  29  --->  Accuracy = 75.00%\n",
      "M_pca =  38 , M_lda =  30  --->  Accuracy = 73.08%\n",
      "M_pca =  38 , M_lda =  31  --->  Accuracy = 74.04%\n",
      "M_pca =  38 , M_lda =  32  --->  Accuracy = 74.04%\n",
      "M_pca =  38 , M_lda =  33  --->  Accuracy = 73.08%\n",
      "M_pca =  38 , M_lda =  34  --->  Accuracy = 72.12%\n",
      "M_pca =  38 , M_lda =  35  --->  Accuracy = 75.00%\n",
      "M_pca =  38 , M_lda =  36  --->  Accuracy = 75.00%\n",
      "M_pca =  38 , M_lda =  37  --->  Accuracy = 76.92%\n",
      "M_pca =  38 , M_lda =  38  --->  Accuracy = 75.96%\n",
      "M_pca =  38 , M_lda =  39  --->  Accuracy = 75.96%\n",
      "M_pca =  38 , M_lda =  40  --->  Accuracy = 75.96%\n",
      "M_pca =  38 , M_lda =  41  --->  Accuracy = 75.96%\n",
      "M_pca =  38 , M_lda =  42  --->  Accuracy = 75.96%\n",
      "M_pca =  38 , M_lda =  43  --->  Accuracy = 75.96%\n",
      "M_pca =  38 , M_lda =  44  --->  Accuracy = 75.96%\n",
      "M_pca =  38 , M_lda =  45  --->  Accuracy = 75.96%\n",
      "M_pca =  38 , M_lda =  46  --->  Accuracy = 75.96%\n",
      "M_pca =  38 , M_lda =  47  --->  Accuracy = 75.96%\n",
      "M_pca =  38 , M_lda =  48  --->  Accuracy = 75.96%\n",
      "M_pca =  38 , M_lda =  49  --->  Accuracy = 75.96%\n",
      "M_pca =  38 , M_lda =  50  --->  Accuracy = 75.96%\n",
      "M_pca =  38 , M_lda =  51  --->  Accuracy = 75.96%\n",
      "M_pca =  39 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  39 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  39 , M_lda =  3  --->  Accuracy = 25.00%\n",
      "M_pca =  39 , M_lda =  4  --->  Accuracy = 37.50%\n",
      "M_pca =  39 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  39 , M_lda =  6  --->  Accuracy = 51.92%\n",
      "M_pca =  39 , M_lda =  7  --->  Accuracy = 59.62%\n",
      "M_pca =  39 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  39 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  39 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  39 , M_lda =  11  --->  Accuracy = 72.12%\n",
      "M_pca =  39 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  39 , M_lda =  13  --->  Accuracy = 74.04%\n",
      "M_pca =  39 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  39 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  39 , M_lda =  16  --->  Accuracy = 75.96%\n",
      "M_pca =  39 , M_lda =  17  --->  Accuracy = 75.00%\n",
      "M_pca =  39 , M_lda =  18  --->  Accuracy = 76.92%\n",
      "M_pca =  39 , M_lda =  19  --->  Accuracy = 75.96%\n",
      "M_pca =  39 , M_lda =  20  --->  Accuracy = 76.92%\n",
      "M_pca =  39 , M_lda =  21  --->  Accuracy = 78.85%\n",
      "M_pca =  39 , M_lda =  22  --->  Accuracy = 78.85%\n",
      "M_pca =  39 , M_lda =  23  --->  Accuracy = 77.88%\n",
      "M_pca =  39 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  39 , M_lda =  25  --->  Accuracy = 78.85%\n",
      "M_pca =  39 , M_lda =  26  --->  Accuracy = 78.85%\n",
      "M_pca =  39 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  39 , M_lda =  28  --->  Accuracy = 78.85%\n",
      "M_pca =  39 , M_lda =  29  --->  Accuracy = 75.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  39 , M_lda =  30  --->  Accuracy = 73.08%\n",
      "M_pca =  39 , M_lda =  31  --->  Accuracy = 73.08%\n",
      "M_pca =  39 , M_lda =  32  --->  Accuracy = 74.04%\n",
      "M_pca =  39 , M_lda =  33  --->  Accuracy = 74.04%\n",
      "M_pca =  39 , M_lda =  34  --->  Accuracy = 72.12%\n",
      "M_pca =  39 , M_lda =  35  --->  Accuracy = 73.08%\n",
      "M_pca =  39 , M_lda =  36  --->  Accuracy = 75.96%\n",
      "M_pca =  39 , M_lda =  37  --->  Accuracy = 74.04%\n",
      "M_pca =  39 , M_lda =  38  --->  Accuracy = 74.04%\n",
      "M_pca =  39 , M_lda =  39  --->  Accuracy = 75.96%\n",
      "M_pca =  39 , M_lda =  40  --->  Accuracy = 75.96%\n",
      "M_pca =  39 , M_lda =  41  --->  Accuracy = 75.96%\n",
      "M_pca =  39 , M_lda =  42  --->  Accuracy = 75.96%\n",
      "M_pca =  39 , M_lda =  43  --->  Accuracy = 75.96%\n",
      "M_pca =  39 , M_lda =  44  --->  Accuracy = 75.96%\n",
      "M_pca =  39 , M_lda =  45  --->  Accuracy = 75.96%\n",
      "M_pca =  39 , M_lda =  46  --->  Accuracy = 75.96%\n",
      "M_pca =  39 , M_lda =  47  --->  Accuracy = 75.96%\n",
      "M_pca =  39 , M_lda =  48  --->  Accuracy = 75.96%\n",
      "M_pca =  39 , M_lda =  49  --->  Accuracy = 75.96%\n",
      "M_pca =  39 , M_lda =  50  --->  Accuracy = 75.96%\n",
      "M_pca =  39 , M_lda =  51  --->  Accuracy = 75.96%\n",
      "M_pca =  40 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  40 , M_lda =  2  --->  Accuracy = 12.50%\n",
      "M_pca =  40 , M_lda =  3  --->  Accuracy = 21.15%\n",
      "M_pca =  40 , M_lda =  4  --->  Accuracy = 40.38%\n",
      "M_pca =  40 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  40 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  40 , M_lda =  7  --->  Accuracy = 58.65%\n",
      "M_pca =  40 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  40 , M_lda =  9  --->  Accuracy = 73.08%\n",
      "M_pca =  40 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  40 , M_lda =  11  --->  Accuracy = 74.04%\n",
      "M_pca =  40 , M_lda =  12  --->  Accuracy = 73.08%\n",
      "M_pca =  40 , M_lda =  13  --->  Accuracy = 76.92%\n",
      "M_pca =  40 , M_lda =  14  --->  Accuracy = 75.96%\n",
      "M_pca =  40 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  40 , M_lda =  16  --->  Accuracy = 77.88%\n",
      "M_pca =  40 , M_lda =  17  --->  Accuracy = 75.96%\n",
      "M_pca =  40 , M_lda =  18  --->  Accuracy = 76.92%\n",
      "M_pca =  40 , M_lda =  19  --->  Accuracy = 76.92%\n",
      "M_pca =  40 , M_lda =  20  --->  Accuracy = 75.96%\n",
      "M_pca =  40 , M_lda =  21  --->  Accuracy = 77.88%\n",
      "M_pca =  40 , M_lda =  22  --->  Accuracy = 76.92%\n",
      "M_pca =  40 , M_lda =  23  --->  Accuracy = 77.88%\n",
      "M_pca =  40 , M_lda =  24  --->  Accuracy = 77.88%\n",
      "M_pca =  40 , M_lda =  25  --->  Accuracy = 77.88%\n",
      "M_pca =  40 , M_lda =  26  --->  Accuracy = 78.85%\n",
      "M_pca =  40 , M_lda =  27  --->  Accuracy = 78.85%\n",
      "M_pca =  40 , M_lda =  28  --->  Accuracy = 75.96%\n",
      "M_pca =  40 , M_lda =  29  --->  Accuracy = 75.00%\n",
      "M_pca =  40 , M_lda =  30  --->  Accuracy = 75.00%\n",
      "M_pca =  40 , M_lda =  31  --->  Accuracy = 73.08%\n",
      "M_pca =  40 , M_lda =  32  --->  Accuracy = 72.12%\n",
      "M_pca =  40 , M_lda =  33  --->  Accuracy = 74.04%\n",
      "M_pca =  40 , M_lda =  34  --->  Accuracy = 72.12%\n",
      "M_pca =  40 , M_lda =  35  --->  Accuracy = 73.08%\n",
      "M_pca =  40 , M_lda =  36  --->  Accuracy = 75.96%\n",
      "M_pca =  40 , M_lda =  37  --->  Accuracy = 75.00%\n",
      "M_pca =  40 , M_lda =  38  --->  Accuracy = 74.04%\n",
      "M_pca =  40 , M_lda =  39  --->  Accuracy = 74.04%\n",
      "M_pca =  40 , M_lda =  40  --->  Accuracy = 72.12%\n",
      "M_pca =  40 , M_lda =  41  --->  Accuracy = 72.12%\n",
      "M_pca =  40 , M_lda =  42  --->  Accuracy = 72.12%\n",
      "M_pca =  40 , M_lda =  43  --->  Accuracy = 72.12%\n",
      "M_pca =  40 , M_lda =  44  --->  Accuracy = 72.12%\n",
      "M_pca =  40 , M_lda =  45  --->  Accuracy = 72.12%\n",
      "M_pca =  40 , M_lda =  46  --->  Accuracy = 72.12%\n",
      "M_pca =  40 , M_lda =  47  --->  Accuracy = 72.12%\n",
      "M_pca =  40 , M_lda =  48  --->  Accuracy = 72.12%\n",
      "M_pca =  40 , M_lda =  49  --->  Accuracy = 72.12%\n",
      "M_pca =  40 , M_lda =  50  --->  Accuracy = 72.12%\n",
      "M_pca =  40 , M_lda =  51  --->  Accuracy = 72.12%\n",
      "M_pca =  41 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  41 , M_lda =  2  --->  Accuracy = 23.08%\n",
      "M_pca =  41 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  41 , M_lda =  4  --->  Accuracy = 38.46%\n",
      "M_pca =  41 , M_lda =  5  --->  Accuracy = 45.19%\n",
      "M_pca =  41 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  41 , M_lda =  7  --->  Accuracy = 60.58%\n",
      "M_pca =  41 , M_lda =  8  --->  Accuracy = 74.04%\n",
      "M_pca =  41 , M_lda =  9  --->  Accuracy = 67.31%\n",
      "M_pca =  41 , M_lda =  10  --->  Accuracy = 67.31%\n",
      "M_pca =  41 , M_lda =  11  --->  Accuracy = 75.00%\n",
      "M_pca =  41 , M_lda =  12  --->  Accuracy = 78.85%\n",
      "M_pca =  41 , M_lda =  13  --->  Accuracy = 76.92%\n",
      "M_pca =  41 , M_lda =  14  --->  Accuracy = 74.04%\n",
      "M_pca =  41 , M_lda =  15  --->  Accuracy = 76.92%\n",
      "M_pca =  41 , M_lda =  16  --->  Accuracy = 76.92%\n",
      "M_pca =  41 , M_lda =  17  --->  Accuracy = 75.00%\n",
      "M_pca =  41 , M_lda =  18  --->  Accuracy = 74.04%\n",
      "M_pca =  41 , M_lda =  19  --->  Accuracy = 76.92%\n",
      "M_pca =  41 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  41 , M_lda =  21  --->  Accuracy = 77.88%\n",
      "M_pca =  41 , M_lda =  22  --->  Accuracy = 78.85%\n",
      "M_pca =  41 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  41 , M_lda =  24  --->  Accuracy = 81.73%\n",
      "M_pca =  41 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  41 , M_lda =  26  --->  Accuracy = 79.81%\n",
      "M_pca =  41 , M_lda =  27  --->  Accuracy = 80.77%\n",
      "M_pca =  41 , M_lda =  28  --->  Accuracy = 79.81%\n",
      "M_pca =  41 , M_lda =  29  --->  Accuracy = 78.85%\n",
      "M_pca =  41 , M_lda =  30  --->  Accuracy = 77.88%\n",
      "M_pca =  41 , M_lda =  31  --->  Accuracy = 80.77%\n",
      "M_pca =  41 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  41 , M_lda =  33  --->  Accuracy = 77.88%\n",
      "M_pca =  41 , M_lda =  34  --->  Accuracy = 76.92%\n",
      "M_pca =  41 , M_lda =  35  --->  Accuracy = 75.96%\n",
      "M_pca =  41 , M_lda =  36  --->  Accuracy = 76.92%\n",
      "M_pca =  41 , M_lda =  37  --->  Accuracy = 76.92%\n",
      "M_pca =  41 , M_lda =  38  --->  Accuracy = 76.92%\n",
      "M_pca =  41 , M_lda =  39  --->  Accuracy = 75.96%\n",
      "M_pca =  41 , M_lda =  40  --->  Accuracy = 74.04%\n",
      "M_pca =  41 , M_lda =  41  --->  Accuracy = 74.04%\n",
      "M_pca =  41 , M_lda =  42  --->  Accuracy = 74.04%\n",
      "M_pca =  41 , M_lda =  43  --->  Accuracy = 74.04%\n",
      "M_pca =  41 , M_lda =  44  --->  Accuracy = 74.04%\n",
      "M_pca =  41 , M_lda =  45  --->  Accuracy = 74.04%\n",
      "M_pca =  41 , M_lda =  46  --->  Accuracy = 74.04%\n",
      "M_pca =  41 , M_lda =  47  --->  Accuracy = 74.04%\n",
      "M_pca =  41 , M_lda =  48  --->  Accuracy = 74.04%\n",
      "M_pca =  41 , M_lda =  49  --->  Accuracy = 74.04%\n",
      "M_pca =  41 , M_lda =  50  --->  Accuracy = 74.04%\n",
      "M_pca =  41 , M_lda =  51  --->  Accuracy = 74.04%\n",
      "M_pca =  42 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  42 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  42 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  42 , M_lda =  4  --->  Accuracy = 42.31%\n",
      "M_pca =  42 , M_lda =  5  --->  Accuracy = 51.92%\n",
      "M_pca =  42 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  42 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  42 , M_lda =  8  --->  Accuracy = 76.92%\n",
      "M_pca =  42 , M_lda =  9  --->  Accuracy = 73.08%\n",
      "M_pca =  42 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  42 , M_lda =  11  --->  Accuracy = 74.04%\n",
      "M_pca =  42 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  42 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  42 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  42 , M_lda =  15  --->  Accuracy = 78.85%\n",
      "M_pca =  42 , M_lda =  16  --->  Accuracy = 79.81%\n",
      "M_pca =  42 , M_lda =  17  --->  Accuracy = 75.96%\n",
      "M_pca =  42 , M_lda =  18  --->  Accuracy = 76.92%\n",
      "M_pca =  42 , M_lda =  19  --->  Accuracy = 77.88%\n",
      "M_pca =  42 , M_lda =  20  --->  Accuracy = 76.92%\n",
      "M_pca =  42 , M_lda =  21  --->  Accuracy = 76.92%\n",
      "M_pca =  42 , M_lda =  22  --->  Accuracy = 78.85%\n",
      "M_pca =  42 , M_lda =  23  --->  Accuracy = 79.81%\n",
      "M_pca =  42 , M_lda =  24  --->  Accuracy = 81.73%\n",
      "M_pca =  42 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  42 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  42 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  42 , M_lda =  28  --->  Accuracy = 80.77%\n",
      "M_pca =  42 , M_lda =  29  --->  Accuracy = 77.88%\n",
      "M_pca =  42 , M_lda =  30  --->  Accuracy = 76.92%\n",
      "M_pca =  42 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  42 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  42 , M_lda =  33  --->  Accuracy = 79.81%\n",
      "M_pca =  42 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  42 , M_lda =  35  --->  Accuracy = 77.88%\n",
      "M_pca =  42 , M_lda =  36  --->  Accuracy = 78.85%\n",
      "M_pca =  42 , M_lda =  37  --->  Accuracy = 77.88%\n",
      "M_pca =  42 , M_lda =  38  --->  Accuracy = 77.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  42 , M_lda =  39  --->  Accuracy = 77.88%\n",
      "M_pca =  42 , M_lda =  40  --->  Accuracy = 76.92%\n",
      "M_pca =  42 , M_lda =  41  --->  Accuracy = 74.04%\n",
      "M_pca =  42 , M_lda =  42  --->  Accuracy = 75.00%\n",
      "M_pca =  42 , M_lda =  43  --->  Accuracy = 75.00%\n",
      "M_pca =  42 , M_lda =  44  --->  Accuracy = 75.00%\n",
      "M_pca =  42 , M_lda =  45  --->  Accuracy = 75.00%\n",
      "M_pca =  42 , M_lda =  46  --->  Accuracy = 75.00%\n",
      "M_pca =  42 , M_lda =  47  --->  Accuracy = 75.00%\n",
      "M_pca =  42 , M_lda =  48  --->  Accuracy = 75.00%\n",
      "M_pca =  42 , M_lda =  49  --->  Accuracy = 75.00%\n",
      "M_pca =  42 , M_lda =  50  --->  Accuracy = 75.00%\n",
      "M_pca =  42 , M_lda =  51  --->  Accuracy = 75.00%\n",
      "M_pca =  43 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  43 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  43 , M_lda =  3  --->  Accuracy = 27.88%\n",
      "M_pca =  43 , M_lda =  4  --->  Accuracy = 41.35%\n",
      "M_pca =  43 , M_lda =  5  --->  Accuracy = 54.81%\n",
      "M_pca =  43 , M_lda =  6  --->  Accuracy = 52.88%\n",
      "M_pca =  43 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  43 , M_lda =  8  --->  Accuracy = 77.88%\n",
      "M_pca =  43 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  43 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  43 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  43 , M_lda =  12  --->  Accuracy = 79.81%\n",
      "M_pca =  43 , M_lda =  13  --->  Accuracy = 80.77%\n",
      "M_pca =  43 , M_lda =  14  --->  Accuracy = 79.81%\n",
      "M_pca =  43 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  43 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  43 , M_lda =  17  --->  Accuracy = 77.88%\n",
      "M_pca =  43 , M_lda =  18  --->  Accuracy = 76.92%\n",
      "M_pca =  43 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  43 , M_lda =  20  --->  Accuracy = 76.92%\n",
      "M_pca =  43 , M_lda =  21  --->  Accuracy = 75.00%\n",
      "M_pca =  43 , M_lda =  22  --->  Accuracy = 75.96%\n",
      "M_pca =  43 , M_lda =  23  --->  Accuracy = 79.81%\n",
      "M_pca =  43 , M_lda =  24  --->  Accuracy = 78.85%\n",
      "M_pca =  43 , M_lda =  25  --->  Accuracy = 80.77%\n",
      "M_pca =  43 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  43 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  43 , M_lda =  28  --->  Accuracy = 77.88%\n",
      "M_pca =  43 , M_lda =  29  --->  Accuracy = 78.85%\n",
      "M_pca =  43 , M_lda =  30  --->  Accuracy = 77.88%\n",
      "M_pca =  43 , M_lda =  31  --->  Accuracy = 78.85%\n",
      "M_pca =  43 , M_lda =  32  --->  Accuracy = 76.92%\n",
      "M_pca =  43 , M_lda =  33  --->  Accuracy = 78.85%\n",
      "M_pca =  43 , M_lda =  34  --->  Accuracy = 77.88%\n",
      "M_pca =  43 , M_lda =  35  --->  Accuracy = 77.88%\n",
      "M_pca =  43 , M_lda =  36  --->  Accuracy = 78.85%\n",
      "M_pca =  43 , M_lda =  37  --->  Accuracy = 78.85%\n",
      "M_pca =  43 , M_lda =  38  --->  Accuracy = 76.92%\n",
      "M_pca =  43 , M_lda =  39  --->  Accuracy = 76.92%\n",
      "M_pca =  43 , M_lda =  40  --->  Accuracy = 77.88%\n",
      "M_pca =  43 , M_lda =  41  --->  Accuracy = 76.92%\n",
      "M_pca =  43 , M_lda =  42  --->  Accuracy = 74.04%\n",
      "M_pca =  43 , M_lda =  43  --->  Accuracy = 75.96%\n",
      "M_pca =  43 , M_lda =  44  --->  Accuracy = 75.96%\n",
      "M_pca =  43 , M_lda =  45  --->  Accuracy = 75.96%\n",
      "M_pca =  43 , M_lda =  46  --->  Accuracy = 75.96%\n",
      "M_pca =  43 , M_lda =  47  --->  Accuracy = 75.96%\n",
      "M_pca =  43 , M_lda =  48  --->  Accuracy = 75.96%\n",
      "M_pca =  43 , M_lda =  49  --->  Accuracy = 75.96%\n",
      "M_pca =  43 , M_lda =  50  --->  Accuracy = 75.96%\n",
      "M_pca =  43 , M_lda =  51  --->  Accuracy = 75.96%\n",
      "M_pca =  44 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  44 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  44 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  44 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  44 , M_lda =  5  --->  Accuracy = 55.77%\n",
      "M_pca =  44 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  44 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  44 , M_lda =  8  --->  Accuracy = 75.96%\n",
      "M_pca =  44 , M_lda =  9  --->  Accuracy = 73.08%\n",
      "M_pca =  44 , M_lda =  10  --->  Accuracy = 73.08%\n",
      "M_pca =  44 , M_lda =  11  --->  Accuracy = 74.04%\n",
      "M_pca =  44 , M_lda =  12  --->  Accuracy = 77.88%\n",
      "M_pca =  44 , M_lda =  13  --->  Accuracy = 80.77%\n",
      "M_pca =  44 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  44 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  44 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  44 , M_lda =  17  --->  Accuracy = 78.85%\n",
      "M_pca =  44 , M_lda =  18  --->  Accuracy = 79.81%\n",
      "M_pca =  44 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  44 , M_lda =  20  --->  Accuracy = 79.81%\n",
      "M_pca =  44 , M_lda =  21  --->  Accuracy = 77.88%\n",
      "M_pca =  44 , M_lda =  22  --->  Accuracy = 79.81%\n",
      "M_pca =  44 , M_lda =  23  --->  Accuracy = 78.85%\n",
      "M_pca =  44 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  44 , M_lda =  25  --->  Accuracy = 80.77%\n",
      "M_pca =  44 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  44 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  44 , M_lda =  28  --->  Accuracy = 78.85%\n",
      "M_pca =  44 , M_lda =  29  --->  Accuracy = 78.85%\n",
      "M_pca =  44 , M_lda =  30  --->  Accuracy = 79.81%\n",
      "M_pca =  44 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  44 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  44 , M_lda =  33  --->  Accuracy = 78.85%\n",
      "M_pca =  44 , M_lda =  34  --->  Accuracy = 78.85%\n",
      "M_pca =  44 , M_lda =  35  --->  Accuracy = 78.85%\n",
      "M_pca =  44 , M_lda =  36  --->  Accuracy = 77.88%\n",
      "M_pca =  44 , M_lda =  37  --->  Accuracy = 77.88%\n",
      "M_pca =  44 , M_lda =  38  --->  Accuracy = 75.96%\n",
      "M_pca =  44 , M_lda =  39  --->  Accuracy = 76.92%\n",
      "M_pca =  44 , M_lda =  40  --->  Accuracy = 76.92%\n",
      "M_pca =  44 , M_lda =  41  --->  Accuracy = 77.88%\n",
      "M_pca =  44 , M_lda =  42  --->  Accuracy = 75.00%\n",
      "M_pca =  44 , M_lda =  43  --->  Accuracy = 75.96%\n",
      "M_pca =  44 , M_lda =  44  --->  Accuracy = 74.04%\n",
      "M_pca =  44 , M_lda =  45  --->  Accuracy = 74.04%\n",
      "M_pca =  44 , M_lda =  46  --->  Accuracy = 74.04%\n",
      "M_pca =  44 , M_lda =  47  --->  Accuracy = 74.04%\n",
      "M_pca =  44 , M_lda =  48  --->  Accuracy = 74.04%\n",
      "M_pca =  44 , M_lda =  49  --->  Accuracy = 74.04%\n",
      "M_pca =  44 , M_lda =  50  --->  Accuracy = 74.04%\n",
      "M_pca =  44 , M_lda =  51  --->  Accuracy = 74.04%\n",
      "M_pca =  45 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  45 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  45 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  45 , M_lda =  4  --->  Accuracy = 39.42%\n",
      "M_pca =  45 , M_lda =  5  --->  Accuracy = 51.92%\n",
      "M_pca =  45 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  45 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  45 , M_lda =  8  --->  Accuracy = 74.04%\n",
      "M_pca =  45 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  45 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  45 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  45 , M_lda =  12  --->  Accuracy = 77.88%\n",
      "M_pca =  45 , M_lda =  13  --->  Accuracy = 77.88%\n",
      "M_pca =  45 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  45 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  45 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  45 , M_lda =  17  --->  Accuracy = 78.85%\n",
      "M_pca =  45 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  45 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  45 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  45 , M_lda =  21  --->  Accuracy = 79.81%\n",
      "M_pca =  45 , M_lda =  22  --->  Accuracy = 79.81%\n",
      "M_pca =  45 , M_lda =  23  --->  Accuracy = 79.81%\n",
      "M_pca =  45 , M_lda =  24  --->  Accuracy = 78.85%\n",
      "M_pca =  45 , M_lda =  25  --->  Accuracy = 77.88%\n",
      "M_pca =  45 , M_lda =  26  --->  Accuracy = 78.85%\n",
      "M_pca =  45 , M_lda =  27  --->  Accuracy = 78.85%\n",
      "M_pca =  45 , M_lda =  28  --->  Accuracy = 79.81%\n",
      "M_pca =  45 , M_lda =  29  --->  Accuracy = 76.92%\n",
      "M_pca =  45 , M_lda =  30  --->  Accuracy = 78.85%\n",
      "M_pca =  45 , M_lda =  31  --->  Accuracy = 78.85%\n",
      "M_pca =  45 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  45 , M_lda =  33  --->  Accuracy = 78.85%\n",
      "M_pca =  45 , M_lda =  34  --->  Accuracy = 78.85%\n",
      "M_pca =  45 , M_lda =  35  --->  Accuracy = 78.85%\n",
      "M_pca =  45 , M_lda =  36  --->  Accuracy = 78.85%\n",
      "M_pca =  45 , M_lda =  37  --->  Accuracy = 78.85%\n",
      "M_pca =  45 , M_lda =  38  --->  Accuracy = 75.96%\n",
      "M_pca =  45 , M_lda =  39  --->  Accuracy = 76.92%\n",
      "M_pca =  45 , M_lda =  40  --->  Accuracy = 76.92%\n",
      "M_pca =  45 , M_lda =  41  --->  Accuracy = 75.96%\n",
      "M_pca =  45 , M_lda =  42  --->  Accuracy = 77.88%\n",
      "M_pca =  45 , M_lda =  43  --->  Accuracy = 75.96%\n",
      "M_pca =  45 , M_lda =  44  --->  Accuracy = 75.00%\n",
      "M_pca =  45 , M_lda =  45  --->  Accuracy = 75.00%\n",
      "M_pca =  45 , M_lda =  46  --->  Accuracy = 75.00%\n",
      "M_pca =  45 , M_lda =  47  --->  Accuracy = 75.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  45 , M_lda =  48  --->  Accuracy = 75.00%\n",
      "M_pca =  45 , M_lda =  49  --->  Accuracy = 75.00%\n",
      "M_pca =  45 , M_lda =  50  --->  Accuracy = 75.00%\n",
      "M_pca =  45 , M_lda =  51  --->  Accuracy = 75.00%\n",
      "M_pca =  46 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  46 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  46 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  46 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  46 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  46 , M_lda =  6  --->  Accuracy = 61.54%\n",
      "M_pca =  46 , M_lda =  7  --->  Accuracy = 67.31%\n",
      "M_pca =  46 , M_lda =  8  --->  Accuracy = 75.00%\n",
      "M_pca =  46 , M_lda =  9  --->  Accuracy = 73.08%\n",
      "M_pca =  46 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  46 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  46 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  46 , M_lda =  13  --->  Accuracy = 79.81%\n",
      "M_pca =  46 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  46 , M_lda =  15  --->  Accuracy = 79.81%\n",
      "M_pca =  46 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  46 , M_lda =  17  --->  Accuracy = 77.88%\n",
      "M_pca =  46 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  46 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  46 , M_lda =  20  --->  Accuracy = 81.73%\n",
      "M_pca =  46 , M_lda =  21  --->  Accuracy = 80.77%\n",
      "M_pca =  46 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  46 , M_lda =  23  --->  Accuracy = 80.77%\n",
      "M_pca =  46 , M_lda =  24  --->  Accuracy = 81.73%\n",
      "M_pca =  46 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  46 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  46 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  46 , M_lda =  28  --->  Accuracy = 77.88%\n",
      "M_pca =  46 , M_lda =  29  --->  Accuracy = 79.81%\n",
      "M_pca =  46 , M_lda =  30  --->  Accuracy = 78.85%\n",
      "M_pca =  46 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  46 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  46 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  46 , M_lda =  34  --->  Accuracy = 80.77%\n",
      "M_pca =  46 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  46 , M_lda =  36  --->  Accuracy = 77.88%\n",
      "M_pca =  46 , M_lda =  37  --->  Accuracy = 77.88%\n",
      "M_pca =  46 , M_lda =  38  --->  Accuracy = 78.85%\n",
      "M_pca =  46 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  46 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  46 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  46 , M_lda =  42  --->  Accuracy = 80.77%\n",
      "M_pca =  46 , M_lda =  43  --->  Accuracy = 77.88%\n",
      "M_pca =  46 , M_lda =  44  --->  Accuracy = 75.96%\n",
      "M_pca =  46 , M_lda =  45  --->  Accuracy = 76.92%\n",
      "M_pca =  46 , M_lda =  46  --->  Accuracy = 75.96%\n",
      "M_pca =  46 , M_lda =  47  --->  Accuracy = 75.96%\n",
      "M_pca =  46 , M_lda =  48  --->  Accuracy = 75.96%\n",
      "M_pca =  46 , M_lda =  49  --->  Accuracy = 75.96%\n",
      "M_pca =  46 , M_lda =  50  --->  Accuracy = 75.96%\n",
      "M_pca =  46 , M_lda =  51  --->  Accuracy = 75.96%\n",
      "M_pca =  47 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  47 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  47 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  47 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  47 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  47 , M_lda =  6  --->  Accuracy = 61.54%\n",
      "M_pca =  47 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  47 , M_lda =  8  --->  Accuracy = 75.96%\n",
      "M_pca =  47 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  47 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  47 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  47 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  47 , M_lda =  13  --->  Accuracy = 81.73%\n",
      "M_pca =  47 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  47 , M_lda =  15  --->  Accuracy = 84.62%\n",
      "M_pca =  47 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  47 , M_lda =  17  --->  Accuracy = 75.96%\n",
      "M_pca =  47 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  47 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  47 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  47 , M_lda =  21  --->  Accuracy = 81.73%\n",
      "M_pca =  47 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  47 , M_lda =  23  --->  Accuracy = 79.81%\n",
      "M_pca =  47 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  47 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  47 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  47 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  47 , M_lda =  28  --->  Accuracy = 80.77%\n",
      "M_pca =  47 , M_lda =  29  --->  Accuracy = 80.77%\n",
      "M_pca =  47 , M_lda =  30  --->  Accuracy = 80.77%\n",
      "M_pca =  47 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  47 , M_lda =  32  --->  Accuracy = 76.92%\n",
      "M_pca =  47 , M_lda =  33  --->  Accuracy = 77.88%\n",
      "M_pca =  47 , M_lda =  34  --->  Accuracy = 76.92%\n",
      "M_pca =  47 , M_lda =  35  --->  Accuracy = 77.88%\n",
      "M_pca =  47 , M_lda =  36  --->  Accuracy = 77.88%\n",
      "M_pca =  47 , M_lda =  37  --->  Accuracy = 77.88%\n",
      "M_pca =  47 , M_lda =  38  --->  Accuracy = 77.88%\n",
      "M_pca =  47 , M_lda =  39  --->  Accuracy = 78.85%\n",
      "M_pca =  47 , M_lda =  40  --->  Accuracy = 78.85%\n",
      "M_pca =  47 , M_lda =  41  --->  Accuracy = 78.85%\n",
      "M_pca =  47 , M_lda =  42  --->  Accuracy = 78.85%\n",
      "M_pca =  47 , M_lda =  43  --->  Accuracy = 76.92%\n",
      "M_pca =  47 , M_lda =  44  --->  Accuracy = 77.88%\n",
      "M_pca =  47 , M_lda =  45  --->  Accuracy = 76.92%\n",
      "M_pca =  47 , M_lda =  46  --->  Accuracy = 78.85%\n",
      "M_pca =  47 , M_lda =  47  --->  Accuracy = 77.88%\n",
      "M_pca =  47 , M_lda =  48  --->  Accuracy = 77.88%\n",
      "M_pca =  47 , M_lda =  49  --->  Accuracy = 77.88%\n",
      "M_pca =  47 , M_lda =  50  --->  Accuracy = 77.88%\n",
      "M_pca =  47 , M_lda =  51  --->  Accuracy = 77.88%\n",
      "M_pca =  48 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  48 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  48 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  48 , M_lda =  4  --->  Accuracy = 49.04%\n",
      "M_pca =  48 , M_lda =  5  --->  Accuracy = 53.85%\n",
      "M_pca =  48 , M_lda =  6  --->  Accuracy = 61.54%\n",
      "M_pca =  48 , M_lda =  7  --->  Accuracy = 68.27%\n",
      "M_pca =  48 , M_lda =  8  --->  Accuracy = 77.88%\n",
      "M_pca =  48 , M_lda =  9  --->  Accuracy = 77.88%\n",
      "M_pca =  48 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  48 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  48 , M_lda =  12  --->  Accuracy = 74.04%\n",
      "M_pca =  48 , M_lda =  13  --->  Accuracy = 77.88%\n",
      "M_pca =  48 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  48 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  48 , M_lda =  16  --->  Accuracy = 79.81%\n",
      "M_pca =  48 , M_lda =  17  --->  Accuracy = 81.73%\n",
      "M_pca =  48 , M_lda =  18  --->  Accuracy = 77.88%\n",
      "M_pca =  48 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  48 , M_lda =  20  --->  Accuracy = 79.81%\n",
      "M_pca =  48 , M_lda =  21  --->  Accuracy = 81.73%\n",
      "M_pca =  48 , M_lda =  22  --->  Accuracy = 82.69%\n",
      "M_pca =  48 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  48 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  48 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  48 , M_lda =  26  --->  Accuracy = 78.85%\n",
      "M_pca =  48 , M_lda =  27  --->  Accuracy = 77.88%\n",
      "M_pca =  48 , M_lda =  28  --->  Accuracy = 77.88%\n",
      "M_pca =  48 , M_lda =  29  --->  Accuracy = 77.88%\n",
      "M_pca =  48 , M_lda =  30  --->  Accuracy = 80.77%\n",
      "M_pca =  48 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  48 , M_lda =  32  --->  Accuracy = 77.88%\n",
      "M_pca =  48 , M_lda =  33  --->  Accuracy = 77.88%\n",
      "M_pca =  48 , M_lda =  34  --->  Accuracy = 77.88%\n",
      "M_pca =  48 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  48 , M_lda =  36  --->  Accuracy = 76.92%\n",
      "M_pca =  48 , M_lda =  37  --->  Accuracy = 78.85%\n",
      "M_pca =  48 , M_lda =  38  --->  Accuracy = 78.85%\n",
      "M_pca =  48 , M_lda =  39  --->  Accuracy = 78.85%\n",
      "M_pca =  48 , M_lda =  40  --->  Accuracy = 79.81%\n",
      "M_pca =  48 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  48 , M_lda =  42  --->  Accuracy = 79.81%\n",
      "M_pca =  48 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  48 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  48 , M_lda =  45  --->  Accuracy = 77.88%\n",
      "M_pca =  48 , M_lda =  46  --->  Accuracy = 77.88%\n",
      "M_pca =  48 , M_lda =  47  --->  Accuracy = 76.92%\n",
      "M_pca =  48 , M_lda =  48  --->  Accuracy = 76.92%\n",
      "M_pca =  48 , M_lda =  49  --->  Accuracy = 76.92%\n",
      "M_pca =  48 , M_lda =  50  --->  Accuracy = 76.92%\n",
      "M_pca =  48 , M_lda =  51  --->  Accuracy = 76.92%\n",
      "M_pca =  49 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  49 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  49 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  49 , M_lda =  4  --->  Accuracy = 48.08%\n",
      "M_pca =  49 , M_lda =  5  --->  Accuracy = 54.81%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  49 , M_lda =  6  --->  Accuracy = 62.50%\n",
      "M_pca =  49 , M_lda =  7  --->  Accuracy = 69.23%\n",
      "M_pca =  49 , M_lda =  8  --->  Accuracy = 77.88%\n",
      "M_pca =  49 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  49 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  49 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  49 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  49 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  49 , M_lda =  14  --->  Accuracy = 83.65%\n",
      "M_pca =  49 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  49 , M_lda =  16  --->  Accuracy = 83.65%\n",
      "M_pca =  49 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  49 , M_lda =  18  --->  Accuracy = 79.81%\n",
      "M_pca =  49 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  49 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  49 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  49 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  49 , M_lda =  23  --->  Accuracy = 79.81%\n",
      "M_pca =  49 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  49 , M_lda =  25  --->  Accuracy = 78.85%\n",
      "M_pca =  49 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  49 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  49 , M_lda =  28  --->  Accuracy = 78.85%\n",
      "M_pca =  49 , M_lda =  29  --->  Accuracy = 80.77%\n",
      "M_pca =  49 , M_lda =  30  --->  Accuracy = 79.81%\n",
      "M_pca =  49 , M_lda =  31  --->  Accuracy = 78.85%\n",
      "M_pca =  49 , M_lda =  32  --->  Accuracy = 78.85%\n",
      "M_pca =  49 , M_lda =  33  --->  Accuracy = 78.85%\n",
      "M_pca =  49 , M_lda =  34  --->  Accuracy = 80.77%\n",
      "M_pca =  49 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  49 , M_lda =  36  --->  Accuracy = 78.85%\n",
      "M_pca =  49 , M_lda =  37  --->  Accuracy = 79.81%\n",
      "M_pca =  49 , M_lda =  38  --->  Accuracy = 78.85%\n",
      "M_pca =  49 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  49 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  49 , M_lda =  41  --->  Accuracy = 79.81%\n",
      "M_pca =  49 , M_lda =  42  --->  Accuracy = 80.77%\n",
      "M_pca =  49 , M_lda =  43  --->  Accuracy = 80.77%\n",
      "M_pca =  49 , M_lda =  44  --->  Accuracy = 80.77%\n",
      "M_pca =  49 , M_lda =  45  --->  Accuracy = 79.81%\n",
      "M_pca =  49 , M_lda =  46  --->  Accuracy = 79.81%\n",
      "M_pca =  49 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  49 , M_lda =  48  --->  Accuracy = 78.85%\n",
      "M_pca =  49 , M_lda =  49  --->  Accuracy = 76.92%\n",
      "M_pca =  49 , M_lda =  50  --->  Accuracy = 76.92%\n",
      "M_pca =  49 , M_lda =  51  --->  Accuracy = 76.92%\n",
      "M_pca =  50 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  50 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  50 , M_lda =  3  --->  Accuracy = 27.88%\n",
      "M_pca =  50 , M_lda =  4  --->  Accuracy = 45.19%\n",
      "M_pca =  50 , M_lda =  5  --->  Accuracy = 57.69%\n",
      "M_pca =  50 , M_lda =  6  --->  Accuracy = 62.50%\n",
      "M_pca =  50 , M_lda =  7  --->  Accuracy = 70.19%\n",
      "M_pca =  50 , M_lda =  8  --->  Accuracy = 76.92%\n",
      "M_pca =  50 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  50 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  50 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  50 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  50 , M_lda =  13  --->  Accuracy = 81.73%\n",
      "M_pca =  50 , M_lda =  14  --->  Accuracy = 82.69%\n",
      "M_pca =  50 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  50 , M_lda =  16  --->  Accuracy = 83.65%\n",
      "M_pca =  50 , M_lda =  17  --->  Accuracy = 80.77%\n",
      "M_pca =  50 , M_lda =  18  --->  Accuracy = 83.65%\n",
      "M_pca =  50 , M_lda =  19  --->  Accuracy = 82.69%\n",
      "M_pca =  50 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  50 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  50 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  50 , M_lda =  23  --->  Accuracy = 80.77%\n",
      "M_pca =  50 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  50 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  50 , M_lda =  26  --->  Accuracy = 77.88%\n",
      "M_pca =  50 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  50 , M_lda =  28  --->  Accuracy = 77.88%\n",
      "M_pca =  50 , M_lda =  29  --->  Accuracy = 80.77%\n",
      "M_pca =  50 , M_lda =  30  --->  Accuracy = 78.85%\n",
      "M_pca =  50 , M_lda =  31  --->  Accuracy = 78.85%\n",
      "M_pca =  50 , M_lda =  32  --->  Accuracy = 78.85%\n",
      "M_pca =  50 , M_lda =  33  --->  Accuracy = 77.88%\n",
      "M_pca =  50 , M_lda =  34  --->  Accuracy = 77.88%\n",
      "M_pca =  50 , M_lda =  35  --->  Accuracy = 78.85%\n",
      "M_pca =  50 , M_lda =  36  --->  Accuracy = 78.85%\n",
      "M_pca =  50 , M_lda =  37  --->  Accuracy = 78.85%\n",
      "M_pca =  50 , M_lda =  38  --->  Accuracy = 78.85%\n",
      "M_pca =  50 , M_lda =  39  --->  Accuracy = 76.92%\n",
      "M_pca =  50 , M_lda =  40  --->  Accuracy = 76.92%\n",
      "M_pca =  50 , M_lda =  41  --->  Accuracy = 78.85%\n",
      "M_pca =  50 , M_lda =  42  --->  Accuracy = 79.81%\n",
      "M_pca =  50 , M_lda =  43  --->  Accuracy = 79.81%\n",
      "M_pca =  50 , M_lda =  44  --->  Accuracy = 79.81%\n",
      "M_pca =  50 , M_lda =  45  --->  Accuracy = 77.88%\n",
      "M_pca =  50 , M_lda =  46  --->  Accuracy = 78.85%\n",
      "M_pca =  50 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  50 , M_lda =  48  --->  Accuracy = 77.88%\n",
      "M_pca =  50 , M_lda =  49  --->  Accuracy = 75.96%\n",
      "M_pca =  50 , M_lda =  50  --->  Accuracy = 75.96%\n",
      "M_pca =  50 , M_lda =  51  --->  Accuracy = 75.96%\n",
      "M_pca =  51 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  51 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  51 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  51 , M_lda =  4  --->  Accuracy = 45.19%\n",
      "M_pca =  51 , M_lda =  5  --->  Accuracy = 54.81%\n",
      "M_pca =  51 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  51 , M_lda =  7  --->  Accuracy = 68.27%\n",
      "M_pca =  51 , M_lda =  8  --->  Accuracy = 78.85%\n",
      "M_pca =  51 , M_lda =  9  --->  Accuracy = 76.92%\n",
      "M_pca =  51 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  51 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  51 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  51 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  51 , M_lda =  14  --->  Accuracy = 82.69%\n",
      "M_pca =  51 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  51 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  51 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  51 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  51 , M_lda =  19  --->  Accuracy = 82.69%\n",
      "M_pca =  51 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  51 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  51 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  51 , M_lda =  23  --->  Accuracy = 83.65%\n",
      "M_pca =  51 , M_lda =  24  --->  Accuracy = 81.73%\n",
      "M_pca =  51 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  51 , M_lda =  26  --->  Accuracy = 77.88%\n",
      "M_pca =  51 , M_lda =  27  --->  Accuracy = 78.85%\n",
      "M_pca =  51 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  51 , M_lda =  29  --->  Accuracy = 79.81%\n",
      "M_pca =  51 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  51 , M_lda =  31  --->  Accuracy = 80.77%\n",
      "M_pca =  51 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  51 , M_lda =  33  --->  Accuracy = 78.85%\n",
      "M_pca =  51 , M_lda =  34  --->  Accuracy = 77.88%\n",
      "M_pca =  51 , M_lda =  35  --->  Accuracy = 77.88%\n",
      "M_pca =  51 , M_lda =  36  --->  Accuracy = 78.85%\n",
      "M_pca =  51 , M_lda =  37  --->  Accuracy = 79.81%\n",
      "M_pca =  51 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  51 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  51 , M_lda =  40  --->  Accuracy = 79.81%\n",
      "M_pca =  51 , M_lda =  41  --->  Accuracy = 78.85%\n",
      "M_pca =  51 , M_lda =  42  --->  Accuracy = 79.81%\n",
      "M_pca =  51 , M_lda =  43  --->  Accuracy = 79.81%\n",
      "M_pca =  51 , M_lda =  44  --->  Accuracy = 79.81%\n",
      "M_pca =  51 , M_lda =  45  --->  Accuracy = 79.81%\n",
      "M_pca =  51 , M_lda =  46  --->  Accuracy = 78.85%\n",
      "M_pca =  51 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  51 , M_lda =  48  --->  Accuracy = 78.85%\n",
      "M_pca =  51 , M_lda =  49  --->  Accuracy = 77.88%\n",
      "M_pca =  51 , M_lda =  50  --->  Accuracy = 78.85%\n",
      "M_pca =  51 , M_lda =  51  --->  Accuracy = 76.92%\n",
      "M_pca =  52 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  52 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  52 , M_lda =  3  --->  Accuracy = 33.65%\n",
      "M_pca =  52 , M_lda =  4  --->  Accuracy = 47.12%\n",
      "M_pca =  52 , M_lda =  5  --->  Accuracy = 58.65%\n",
      "M_pca =  52 , M_lda =  6  --->  Accuracy = 61.54%\n",
      "M_pca =  52 , M_lda =  7  --->  Accuracy = 69.23%\n",
      "M_pca =  52 , M_lda =  8  --->  Accuracy = 75.96%\n",
      "M_pca =  52 , M_lda =  9  --->  Accuracy = 78.85%\n",
      "M_pca =  52 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  52 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  52 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  52 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  52 , M_lda =  14  --->  Accuracy = 81.73%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  52 , M_lda =  15  --->  Accuracy = 80.77%\n",
      "M_pca =  52 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  52 , M_lda =  17  --->  Accuracy = 80.77%\n",
      "M_pca =  52 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  52 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  52 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  52 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  52 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  52 , M_lda =  23  --->  Accuracy = 82.69%\n",
      "M_pca =  52 , M_lda =  24  --->  Accuracy = 81.73%\n",
      "M_pca =  52 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  52 , M_lda =  26  --->  Accuracy = 81.73%\n",
      "M_pca =  52 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  52 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  52 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  52 , M_lda =  30  --->  Accuracy = 81.73%\n",
      "M_pca =  52 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  52 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  52 , M_lda =  33  --->  Accuracy = 77.88%\n",
      "M_pca =  52 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  52 , M_lda =  35  --->  Accuracy = 79.81%\n",
      "M_pca =  52 , M_lda =  36  --->  Accuracy = 77.88%\n",
      "M_pca =  52 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  52 , M_lda =  38  --->  Accuracy = 80.77%\n",
      "M_pca =  52 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  52 , M_lda =  40  --->  Accuracy = 82.69%\n",
      "M_pca =  52 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  52 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  52 , M_lda =  43  --->  Accuracy = 80.77%\n",
      "M_pca =  52 , M_lda =  44  --->  Accuracy = 82.69%\n",
      "M_pca =  52 , M_lda =  45  --->  Accuracy = 79.81%\n",
      "M_pca =  52 , M_lda =  46  --->  Accuracy = 80.77%\n",
      "M_pca =  52 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  52 , M_lda =  48  --->  Accuracy = 78.85%\n",
      "M_pca =  52 , M_lda =  49  --->  Accuracy = 76.92%\n",
      "M_pca =  52 , M_lda =  50  --->  Accuracy = 77.88%\n",
      "M_pca =  52 , M_lda =  51  --->  Accuracy = 75.96%\n",
      "M_pca =  53 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  53 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  53 , M_lda =  3  --->  Accuracy = 25.96%\n",
      "M_pca =  53 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  53 , M_lda =  5  --->  Accuracy = 53.85%\n",
      "M_pca =  53 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  53 , M_lda =  7  --->  Accuracy = 69.23%\n",
      "M_pca =  53 , M_lda =  8  --->  Accuracy = 75.96%\n",
      "M_pca =  53 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  53 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  53 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  53 , M_lda =  12  --->  Accuracy = 77.88%\n",
      "M_pca =  53 , M_lda =  13  --->  Accuracy = 80.77%\n",
      "M_pca =  53 , M_lda =  14  --->  Accuracy = 82.69%\n",
      "M_pca =  53 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  53 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  53 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  53 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  53 , M_lda =  19  --->  Accuracy = 82.69%\n",
      "M_pca =  53 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  53 , M_lda =  21  --->  Accuracy = 82.69%\n",
      "M_pca =  53 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  53 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  53 , M_lda =  24  --->  Accuracy = 82.69%\n",
      "M_pca =  53 , M_lda =  25  --->  Accuracy = 80.77%\n",
      "M_pca =  53 , M_lda =  26  --->  Accuracy = 81.73%\n",
      "M_pca =  53 , M_lda =  27  --->  Accuracy = 84.62%\n",
      "M_pca =  53 , M_lda =  28  --->  Accuracy = 84.62%\n",
      "M_pca =  53 , M_lda =  29  --->  Accuracy = 84.62%\n",
      "M_pca =  53 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  53 , M_lda =  31  --->  Accuracy = 84.62%\n",
      "M_pca =  53 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  53 , M_lda =  33  --->  Accuracy = 79.81%\n",
      "M_pca =  53 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  53 , M_lda =  35  --->  Accuracy = 78.85%\n",
      "M_pca =  53 , M_lda =  36  --->  Accuracy = 80.77%\n",
      "M_pca =  53 , M_lda =  37  --->  Accuracy = 81.73%\n",
      "M_pca =  53 , M_lda =  38  --->  Accuracy = 82.69%\n",
      "M_pca =  53 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  53 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  53 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  53 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  53 , M_lda =  43  --->  Accuracy = 80.77%\n",
      "M_pca =  53 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  53 , M_lda =  45  --->  Accuracy = 79.81%\n",
      "M_pca =  53 , M_lda =  46  --->  Accuracy = 78.85%\n",
      "M_pca =  53 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  53 , M_lda =  48  --->  Accuracy = 78.85%\n",
      "M_pca =  53 , M_lda =  49  --->  Accuracy = 76.92%\n",
      "M_pca =  53 , M_lda =  50  --->  Accuracy = 77.88%\n",
      "M_pca =  53 , M_lda =  51  --->  Accuracy = 77.88%\n",
      "M_pca =  54 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  54 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  54 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  54 , M_lda =  4  --->  Accuracy = 42.31%\n",
      "M_pca =  54 , M_lda =  5  --->  Accuracy = 57.69%\n",
      "M_pca =  54 , M_lda =  6  --->  Accuracy = 64.42%\n",
      "M_pca =  54 , M_lda =  7  --->  Accuracy = 68.27%\n",
      "M_pca =  54 , M_lda =  8  --->  Accuracy = 76.92%\n",
      "M_pca =  54 , M_lda =  9  --->  Accuracy = 76.92%\n",
      "M_pca =  54 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  54 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  54 , M_lda =  12  --->  Accuracy = 77.88%\n",
      "M_pca =  54 , M_lda =  13  --->  Accuracy = 80.77%\n",
      "M_pca =  54 , M_lda =  14  --->  Accuracy = 79.81%\n",
      "M_pca =  54 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  54 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  54 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  54 , M_lda =  18  --->  Accuracy = 79.81%\n",
      "M_pca =  54 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  54 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  54 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  54 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  54 , M_lda =  23  --->  Accuracy = 82.69%\n",
      "M_pca =  54 , M_lda =  24  --->  Accuracy = 84.62%\n",
      "M_pca =  54 , M_lda =  25  --->  Accuracy = 80.77%\n",
      "M_pca =  54 , M_lda =  26  --->  Accuracy = 79.81%\n",
      "M_pca =  54 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  54 , M_lda =  28  --->  Accuracy = 84.62%\n",
      "M_pca =  54 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  54 , M_lda =  30  --->  Accuracy = 81.73%\n",
      "M_pca =  54 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  54 , M_lda =  32  --->  Accuracy = 81.73%\n",
      "M_pca =  54 , M_lda =  33  --->  Accuracy = 81.73%\n",
      "M_pca =  54 , M_lda =  34  --->  Accuracy = 81.73%\n",
      "M_pca =  54 , M_lda =  35  --->  Accuracy = 79.81%\n",
      "M_pca =  54 , M_lda =  36  --->  Accuracy = 80.77%\n",
      "M_pca =  54 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  54 , M_lda =  38  --->  Accuracy = 82.69%\n",
      "M_pca =  54 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  54 , M_lda =  40  --->  Accuracy = 78.85%\n",
      "M_pca =  54 , M_lda =  41  --->  Accuracy = 79.81%\n",
      "M_pca =  54 , M_lda =  42  --->  Accuracy = 80.77%\n",
      "M_pca =  54 , M_lda =  43  --->  Accuracy = 79.81%\n",
      "M_pca =  54 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  54 , M_lda =  45  --->  Accuracy = 78.85%\n",
      "M_pca =  54 , M_lda =  46  --->  Accuracy = 78.85%\n",
      "M_pca =  54 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  54 , M_lda =  48  --->  Accuracy = 78.85%\n",
      "M_pca =  54 , M_lda =  49  --->  Accuracy = 75.96%\n",
      "M_pca =  54 , M_lda =  50  --->  Accuracy = 77.88%\n",
      "M_pca =  54 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  55 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  55 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  55 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  55 , M_lda =  4  --->  Accuracy = 38.46%\n",
      "M_pca =  55 , M_lda =  5  --->  Accuracy = 55.77%\n",
      "M_pca =  55 , M_lda =  6  --->  Accuracy = 66.35%\n",
      "M_pca =  55 , M_lda =  7  --->  Accuracy = 69.23%\n",
      "M_pca =  55 , M_lda =  8  --->  Accuracy = 77.88%\n",
      "M_pca =  55 , M_lda =  9  --->  Accuracy = 77.88%\n",
      "M_pca =  55 , M_lda =  10  --->  Accuracy = 79.81%\n",
      "M_pca =  55 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  55 , M_lda =  12  --->  Accuracy = 78.85%\n",
      "M_pca =  55 , M_lda =  13  --->  Accuracy = 79.81%\n",
      "M_pca =  55 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  55 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  55 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  55 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  55 , M_lda =  18  --->  Accuracy = 78.85%\n",
      "M_pca =  55 , M_lda =  19  --->  Accuracy = 78.85%\n",
      "M_pca =  55 , M_lda =  20  --->  Accuracy = 79.81%\n",
      "M_pca =  55 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  55 , M_lda =  22  --->  Accuracy = 82.69%\n",
      "M_pca =  55 , M_lda =  23  --->  Accuracy = 83.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  55 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  55 , M_lda =  25  --->  Accuracy = 82.69%\n",
      "M_pca =  55 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  55 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  55 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  55 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  55 , M_lda =  30  --->  Accuracy = 81.73%\n",
      "M_pca =  55 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  55 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  55 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  55 , M_lda =  34  --->  Accuracy = 81.73%\n",
      "M_pca =  55 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  55 , M_lda =  36  --->  Accuracy = 79.81%\n",
      "M_pca =  55 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  55 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  55 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  55 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  55 , M_lda =  41  --->  Accuracy = 79.81%\n",
      "M_pca =  55 , M_lda =  42  --->  Accuracy = 79.81%\n",
      "M_pca =  55 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  55 , M_lda =  44  --->  Accuracy = 79.81%\n",
      "M_pca =  55 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  55 , M_lda =  46  --->  Accuracy = 79.81%\n",
      "M_pca =  55 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  55 , M_lda =  48  --->  Accuracy = 78.85%\n",
      "M_pca =  55 , M_lda =  49  --->  Accuracy = 77.88%\n",
      "M_pca =  55 , M_lda =  50  --->  Accuracy = 78.85%\n",
      "M_pca =  55 , M_lda =  51  --->  Accuracy = 79.81%\n",
      "M_pca =  56 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  56 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  56 , M_lda =  3  --->  Accuracy = 34.62%\n",
      "M_pca =  56 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  56 , M_lda =  5  --->  Accuracy = 56.73%\n",
      "M_pca =  56 , M_lda =  6  --->  Accuracy = 68.27%\n",
      "M_pca =  56 , M_lda =  7  --->  Accuracy = 68.27%\n",
      "M_pca =  56 , M_lda =  8  --->  Accuracy = 77.88%\n",
      "M_pca =  56 , M_lda =  9  --->  Accuracy = 78.85%\n",
      "M_pca =  56 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  56 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  56 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  56 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  56 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  56 , M_lda =  15  --->  Accuracy = 79.81%\n",
      "M_pca =  56 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  56 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  56 , M_lda =  18  --->  Accuracy = 78.85%\n",
      "M_pca =  56 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  56 , M_lda =  20  --->  Accuracy = 79.81%\n",
      "M_pca =  56 , M_lda =  21  --->  Accuracy = 79.81%\n",
      "M_pca =  56 , M_lda =  22  --->  Accuracy = 81.73%\n",
      "M_pca =  56 , M_lda =  23  --->  Accuracy = 82.69%\n",
      "M_pca =  56 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  56 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  56 , M_lda =  26  --->  Accuracy = 81.73%\n",
      "M_pca =  56 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  56 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  56 , M_lda =  29  --->  Accuracy = 81.73%\n",
      "M_pca =  56 , M_lda =  30  --->  Accuracy = 79.81%\n",
      "M_pca =  56 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  56 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  56 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  56 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  56 , M_lda =  35  --->  Accuracy = 79.81%\n",
      "M_pca =  56 , M_lda =  36  --->  Accuracy = 79.81%\n",
      "M_pca =  56 , M_lda =  37  --->  Accuracy = 79.81%\n",
      "M_pca =  56 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  56 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  56 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  56 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  56 , M_lda =  42  --->  Accuracy = 77.88%\n",
      "M_pca =  56 , M_lda =  43  --->  Accuracy = 77.88%\n",
      "M_pca =  56 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  56 , M_lda =  45  --->  Accuracy = 78.85%\n",
      "M_pca =  56 , M_lda =  46  --->  Accuracy = 79.81%\n",
      "M_pca =  56 , M_lda =  47  --->  Accuracy = 80.77%\n",
      "M_pca =  56 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  56 , M_lda =  49  --->  Accuracy = 79.81%\n",
      "M_pca =  56 , M_lda =  50  --->  Accuracy = 76.92%\n",
      "M_pca =  56 , M_lda =  51  --->  Accuracy = 77.88%\n",
      "M_pca =  57 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  57 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  57 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  57 , M_lda =  4  --->  Accuracy = 41.35%\n",
      "M_pca =  57 , M_lda =  5  --->  Accuracy = 57.69%\n",
      "M_pca =  57 , M_lda =  6  --->  Accuracy = 69.23%\n",
      "M_pca =  57 , M_lda =  7  --->  Accuracy = 71.15%\n",
      "M_pca =  57 , M_lda =  8  --->  Accuracy = 76.92%\n",
      "M_pca =  57 , M_lda =  9  --->  Accuracy = 78.85%\n",
      "M_pca =  57 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  57 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  57 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  57 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  57 , M_lda =  14  --->  Accuracy = 83.65%\n",
      "M_pca =  57 , M_lda =  15  --->  Accuracy = 80.77%\n",
      "M_pca =  57 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  57 , M_lda =  17  --->  Accuracy = 78.85%\n",
      "M_pca =  57 , M_lda =  18  --->  Accuracy = 78.85%\n",
      "M_pca =  57 , M_lda =  19  --->  Accuracy = 78.85%\n",
      "M_pca =  57 , M_lda =  20  --->  Accuracy = 81.73%\n",
      "M_pca =  57 , M_lda =  21  --->  Accuracy = 82.69%\n",
      "M_pca =  57 , M_lda =  22  --->  Accuracy = 81.73%\n",
      "M_pca =  57 , M_lda =  23  --->  Accuracy = 83.65%\n",
      "M_pca =  57 , M_lda =  24  --->  Accuracy = 84.62%\n",
      "M_pca =  57 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  57 , M_lda =  26  --->  Accuracy = 79.81%\n",
      "M_pca =  57 , M_lda =  27  --->  Accuracy = 80.77%\n",
      "M_pca =  57 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  57 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  57 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  57 , M_lda =  31  --->  Accuracy = 81.73%\n",
      "M_pca =  57 , M_lda =  32  --->  Accuracy = 81.73%\n",
      "M_pca =  57 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  57 , M_lda =  34  --->  Accuracy = 80.77%\n",
      "M_pca =  57 , M_lda =  35  --->  Accuracy = 79.81%\n",
      "M_pca =  57 , M_lda =  36  --->  Accuracy = 79.81%\n",
      "M_pca =  57 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  57 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  57 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  57 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  57 , M_lda =  41  --->  Accuracy = 79.81%\n",
      "M_pca =  57 , M_lda =  42  --->  Accuracy = 79.81%\n",
      "M_pca =  57 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  57 , M_lda =  44  --->  Accuracy = 80.77%\n",
      "M_pca =  57 , M_lda =  45  --->  Accuracy = 77.88%\n",
      "M_pca =  57 , M_lda =  46  --->  Accuracy = 78.85%\n",
      "M_pca =  57 , M_lda =  47  --->  Accuracy = 77.88%\n",
      "M_pca =  57 , M_lda =  48  --->  Accuracy = 77.88%\n",
      "M_pca =  57 , M_lda =  49  --->  Accuracy = 78.85%\n",
      "M_pca =  57 , M_lda =  50  --->  Accuracy = 76.92%\n",
      "M_pca =  57 , M_lda =  51  --->  Accuracy = 76.92%\n",
      "M_pca =  58 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  58 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  58 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  58 , M_lda =  4  --->  Accuracy = 39.42%\n",
      "M_pca =  58 , M_lda =  5  --->  Accuracy = 52.88%\n",
      "M_pca =  58 , M_lda =  6  --->  Accuracy = 64.42%\n",
      "M_pca =  58 , M_lda =  7  --->  Accuracy = 69.23%\n",
      "M_pca =  58 , M_lda =  8  --->  Accuracy = 73.08%\n",
      "M_pca =  58 , M_lda =  9  --->  Accuracy = 76.92%\n",
      "M_pca =  58 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  58 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  58 , M_lda =  12  --->  Accuracy = 79.81%\n",
      "M_pca =  58 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  58 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  58 , M_lda =  15  --->  Accuracy = 78.85%\n",
      "M_pca =  58 , M_lda =  16  --->  Accuracy = 79.81%\n",
      "M_pca =  58 , M_lda =  17  --->  Accuracy = 80.77%\n",
      "M_pca =  58 , M_lda =  18  --->  Accuracy = 79.81%\n",
      "M_pca =  58 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  58 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  58 , M_lda =  21  --->  Accuracy = 80.77%\n",
      "M_pca =  58 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  58 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  58 , M_lda =  24  --->  Accuracy = 83.65%\n",
      "M_pca =  58 , M_lda =  25  --->  Accuracy = 83.65%\n",
      "M_pca =  58 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  58 , M_lda =  27  --->  Accuracy = 78.85%\n",
      "M_pca =  58 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  58 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  58 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  58 , M_lda =  31  --->  Accuracy = 83.65%\n",
      "M_pca =  58 , M_lda =  32  --->  Accuracy = 84.62%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  58 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  58 , M_lda =  34  --->  Accuracy = 81.73%\n",
      "M_pca =  58 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  58 , M_lda =  36  --->  Accuracy = 80.77%\n",
      "M_pca =  58 , M_lda =  37  --->  Accuracy = 79.81%\n",
      "M_pca =  58 , M_lda =  38  --->  Accuracy = 78.85%\n",
      "M_pca =  58 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  58 , M_lda =  40  --->  Accuracy = 78.85%\n",
      "M_pca =  58 , M_lda =  41  --->  Accuracy = 78.85%\n",
      "M_pca =  58 , M_lda =  42  --->  Accuracy = 78.85%\n",
      "M_pca =  58 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  58 , M_lda =  44  --->  Accuracy = 79.81%\n",
      "M_pca =  58 , M_lda =  45  --->  Accuracy = 79.81%\n",
      "M_pca =  58 , M_lda =  46  --->  Accuracy = 78.85%\n",
      "M_pca =  58 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  58 , M_lda =  48  --->  Accuracy = 77.88%\n",
      "M_pca =  58 , M_lda =  49  --->  Accuracy = 78.85%\n",
      "M_pca =  58 , M_lda =  50  --->  Accuracy = 78.85%\n",
      "M_pca =  58 , M_lda =  51  --->  Accuracy = 79.81%\n",
      "M_pca =  59 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  59 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  59 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  59 , M_lda =  4  --->  Accuracy = 45.19%\n",
      "M_pca =  59 , M_lda =  5  --->  Accuracy = 55.77%\n",
      "M_pca =  59 , M_lda =  6  --->  Accuracy = 65.38%\n",
      "M_pca =  59 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  59 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  59 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  59 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  59 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  59 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  59 , M_lda =  13  --->  Accuracy = 79.81%\n",
      "M_pca =  59 , M_lda =  14  --->  Accuracy = 79.81%\n",
      "M_pca =  59 , M_lda =  15  --->  Accuracy = 78.85%\n",
      "M_pca =  59 , M_lda =  16  --->  Accuracy = 77.88%\n",
      "M_pca =  59 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  59 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  59 , M_lda =  19  --->  Accuracy = 78.85%\n",
      "M_pca =  59 , M_lda =  20  --->  Accuracy = 79.81%\n",
      "M_pca =  59 , M_lda =  21  --->  Accuracy = 81.73%\n",
      "M_pca =  59 , M_lda =  22  --->  Accuracy = 82.69%\n",
      "M_pca =  59 , M_lda =  23  --->  Accuracy = 82.69%\n",
      "M_pca =  59 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  59 , M_lda =  25  --->  Accuracy = 83.65%\n",
      "M_pca =  59 , M_lda =  26  --->  Accuracy = 83.65%\n",
      "M_pca =  59 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  59 , M_lda =  28  --->  Accuracy = 84.62%\n",
      "M_pca =  59 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  59 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  59 , M_lda =  31  --->  Accuracy = 84.62%\n",
      "M_pca =  59 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  59 , M_lda =  33  --->  Accuracy = 81.73%\n",
      "M_pca =  59 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  59 , M_lda =  35  --->  Accuracy = 79.81%\n",
      "M_pca =  59 , M_lda =  36  --->  Accuracy = 77.88%\n",
      "M_pca =  59 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  59 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  59 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  59 , M_lda =  40  --->  Accuracy = 79.81%\n",
      "M_pca =  59 , M_lda =  41  --->  Accuracy = 78.85%\n",
      "M_pca =  59 , M_lda =  42  --->  Accuracy = 78.85%\n",
      "M_pca =  59 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  59 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  59 , M_lda =  45  --->  Accuracy = 76.92%\n",
      "M_pca =  59 , M_lda =  46  --->  Accuracy = 76.92%\n",
      "M_pca =  59 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  59 , M_lda =  48  --->  Accuracy = 78.85%\n",
      "M_pca =  59 , M_lda =  49  --->  Accuracy = 79.81%\n",
      "M_pca =  59 , M_lda =  50  --->  Accuracy = 78.85%\n",
      "M_pca =  59 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  60 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  60 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  60 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  60 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  60 , M_lda =  5  --->  Accuracy = 55.77%\n",
      "M_pca =  60 , M_lda =  6  --->  Accuracy = 68.27%\n",
      "M_pca =  60 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  60 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  60 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  60 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  60 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  60 , M_lda =  12  --->  Accuracy = 79.81%\n",
      "M_pca =  60 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  60 , M_lda =  14  --->  Accuracy = 82.69%\n",
      "M_pca =  60 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  60 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  60 , M_lda =  17  --->  Accuracy = 80.77%\n",
      "M_pca =  60 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  60 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  60 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  60 , M_lda =  21  --->  Accuracy = 79.81%\n",
      "M_pca =  60 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  60 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  60 , M_lda =  24  --->  Accuracy = 81.73%\n",
      "M_pca =  60 , M_lda =  25  --->  Accuracy = 80.77%\n",
      "M_pca =  60 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  60 , M_lda =  27  --->  Accuracy = 80.77%\n",
      "M_pca =  60 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  60 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  60 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  60 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  60 , M_lda =  32  --->  Accuracy = 81.73%\n",
      "M_pca =  60 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  60 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  60 , M_lda =  35  --->  Accuracy = 77.88%\n",
      "M_pca =  60 , M_lda =  36  --->  Accuracy = 77.88%\n",
      "M_pca =  60 , M_lda =  37  --->  Accuracy = 78.85%\n",
      "M_pca =  60 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  60 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  60 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  60 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  60 , M_lda =  42  --->  Accuracy = 79.81%\n",
      "M_pca =  60 , M_lda =  43  --->  Accuracy = 79.81%\n",
      "M_pca =  60 , M_lda =  44  --->  Accuracy = 79.81%\n",
      "M_pca =  60 , M_lda =  45  --->  Accuracy = 78.85%\n",
      "M_pca =  60 , M_lda =  46  --->  Accuracy = 79.81%\n",
      "M_pca =  60 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  60 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  60 , M_lda =  49  --->  Accuracy = 78.85%\n",
      "M_pca =  60 , M_lda =  50  --->  Accuracy = 78.85%\n",
      "M_pca =  60 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  61 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  61 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  61 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  61 , M_lda =  4  --->  Accuracy = 48.08%\n",
      "M_pca =  61 , M_lda =  5  --->  Accuracy = 64.42%\n",
      "M_pca =  61 , M_lda =  6  --->  Accuracy = 68.27%\n",
      "M_pca =  61 , M_lda =  7  --->  Accuracy = 69.23%\n",
      "M_pca =  61 , M_lda =  8  --->  Accuracy = 71.15%\n",
      "M_pca =  61 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  61 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  61 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  61 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  61 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  61 , M_lda =  14  --->  Accuracy = 79.81%\n",
      "M_pca =  61 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  61 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  61 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  61 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  61 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  61 , M_lda =  20  --->  Accuracy = 80.77%\n",
      "M_pca =  61 , M_lda =  21  --->  Accuracy = 79.81%\n",
      "M_pca =  61 , M_lda =  22  --->  Accuracy = 79.81%\n",
      "M_pca =  61 , M_lda =  23  --->  Accuracy = 80.77%\n",
      "M_pca =  61 , M_lda =  24  --->  Accuracy = 83.65%\n",
      "M_pca =  61 , M_lda =  25  --->  Accuracy = 82.69%\n",
      "M_pca =  61 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  61 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  61 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  61 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  61 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  61 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  61 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  61 , M_lda =  33  --->  Accuracy = 81.73%\n",
      "M_pca =  61 , M_lda =  34  --->  Accuracy = 80.77%\n",
      "M_pca =  61 , M_lda =  35  --->  Accuracy = 79.81%\n",
      "M_pca =  61 , M_lda =  36  --->  Accuracy = 78.85%\n",
      "M_pca =  61 , M_lda =  37  --->  Accuracy = 78.85%\n",
      "M_pca =  61 , M_lda =  38  --->  Accuracy = 78.85%\n",
      "M_pca =  61 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  61 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  61 , M_lda =  41  --->  Accuracy = 80.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  61 , M_lda =  42  --->  Accuracy = 78.85%\n",
      "M_pca =  61 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  61 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  61 , M_lda =  45  --->  Accuracy = 79.81%\n",
      "M_pca =  61 , M_lda =  46  --->  Accuracy = 78.85%\n",
      "M_pca =  61 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  61 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  61 , M_lda =  49  --->  Accuracy = 79.81%\n",
      "M_pca =  61 , M_lda =  50  --->  Accuracy = 78.85%\n",
      "M_pca =  61 , M_lda =  51  --->  Accuracy = 79.81%\n",
      "M_pca =  62 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  62 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  62 , M_lda =  3  --->  Accuracy = 34.62%\n",
      "M_pca =  62 , M_lda =  4  --->  Accuracy = 42.31%\n",
      "M_pca =  62 , M_lda =  5  --->  Accuracy = 64.42%\n",
      "M_pca =  62 , M_lda =  6  --->  Accuracy = 68.27%\n",
      "M_pca =  62 , M_lda =  7  --->  Accuracy = 71.15%\n",
      "M_pca =  62 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  62 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  62 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  62 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  62 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  62 , M_lda =  13  --->  Accuracy = 79.81%\n",
      "M_pca =  62 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  62 , M_lda =  15  --->  Accuracy = 80.77%\n",
      "M_pca =  62 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  62 , M_lda =  17  --->  Accuracy = 78.85%\n",
      "M_pca =  62 , M_lda =  18  --->  Accuracy = 79.81%\n",
      "M_pca =  62 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  62 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  62 , M_lda =  21  --->  Accuracy = 77.88%\n",
      "M_pca =  62 , M_lda =  22  --->  Accuracy = 78.85%\n",
      "M_pca =  62 , M_lda =  23  --->  Accuracy = 80.77%\n",
      "M_pca =  62 , M_lda =  24  --->  Accuracy = 82.69%\n",
      "M_pca =  62 , M_lda =  25  --->  Accuracy = 82.69%\n",
      "M_pca =  62 , M_lda =  26  --->  Accuracy = 83.65%\n",
      "M_pca =  62 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  62 , M_lda =  28  --->  Accuracy = 79.81%\n",
      "M_pca =  62 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  62 , M_lda =  30  --->  Accuracy = 81.73%\n",
      "M_pca =  62 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  62 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  62 , M_lda =  33  --->  Accuracy = 81.73%\n",
      "M_pca =  62 , M_lda =  34  --->  Accuracy = 81.73%\n",
      "M_pca =  62 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  62 , M_lda =  36  --->  Accuracy = 80.77%\n",
      "M_pca =  62 , M_lda =  37  --->  Accuracy = 81.73%\n",
      "M_pca =  62 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  62 , M_lda =  39  --->  Accuracy = 82.69%\n",
      "M_pca =  62 , M_lda =  40  --->  Accuracy = 82.69%\n",
      "M_pca =  62 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  62 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  62 , M_lda =  43  --->  Accuracy = 80.77%\n",
      "M_pca =  62 , M_lda =  44  --->  Accuracy = 80.77%\n",
      "M_pca =  62 , M_lda =  45  --->  Accuracy = 81.73%\n",
      "M_pca =  62 , M_lda =  46  --->  Accuracy = 80.77%\n",
      "M_pca =  62 , M_lda =  47  --->  Accuracy = 81.73%\n",
      "M_pca =  62 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  62 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  62 , M_lda =  50  --->  Accuracy = 80.77%\n",
      "M_pca =  62 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  63 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  63 , M_lda =  2  --->  Accuracy = 24.04%\n",
      "M_pca =  63 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  63 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  63 , M_lda =  5  --->  Accuracy = 63.46%\n",
      "M_pca =  63 , M_lda =  6  --->  Accuracy = 67.31%\n",
      "M_pca =  63 , M_lda =  7  --->  Accuracy = 73.08%\n",
      "M_pca =  63 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  63 , M_lda =  9  --->  Accuracy = 73.08%\n",
      "M_pca =  63 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  63 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  63 , M_lda =  12  --->  Accuracy = 79.81%\n",
      "M_pca =  63 , M_lda =  13  --->  Accuracy = 79.81%\n",
      "M_pca =  63 , M_lda =  14  --->  Accuracy = 82.69%\n",
      "M_pca =  63 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  63 , M_lda =  16  --->  Accuracy = 76.92%\n",
      "M_pca =  63 , M_lda =  17  --->  Accuracy = 78.85%\n",
      "M_pca =  63 , M_lda =  18  --->  Accuracy = 79.81%\n",
      "M_pca =  63 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  63 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  63 , M_lda =  21  --->  Accuracy = 79.81%\n",
      "M_pca =  63 , M_lda =  22  --->  Accuracy = 79.81%\n",
      "M_pca =  63 , M_lda =  23  --->  Accuracy = 80.77%\n",
      "M_pca =  63 , M_lda =  24  --->  Accuracy = 81.73%\n",
      "M_pca =  63 , M_lda =  25  --->  Accuracy = 80.77%\n",
      "M_pca =  63 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  63 , M_lda =  27  --->  Accuracy = 78.85%\n",
      "M_pca =  63 , M_lda =  28  --->  Accuracy = 78.85%\n",
      "M_pca =  63 , M_lda =  29  --->  Accuracy = 78.85%\n",
      "M_pca =  63 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  63 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  63 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  63 , M_lda =  33  --->  Accuracy = 81.73%\n",
      "M_pca =  63 , M_lda =  34  --->  Accuracy = 82.69%\n",
      "M_pca =  63 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  63 , M_lda =  36  --->  Accuracy = 82.69%\n",
      "M_pca =  63 , M_lda =  37  --->  Accuracy = 81.73%\n",
      "M_pca =  63 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  63 , M_lda =  39  --->  Accuracy = 84.62%\n",
      "M_pca =  63 , M_lda =  40  --->  Accuracy = 83.65%\n",
      "M_pca =  63 , M_lda =  41  --->  Accuracy = 82.69%\n",
      "M_pca =  63 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  63 , M_lda =  43  --->  Accuracy = 82.69%\n",
      "M_pca =  63 , M_lda =  44  --->  Accuracy = 82.69%\n",
      "M_pca =  63 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  63 , M_lda =  46  --->  Accuracy = 83.65%\n",
      "M_pca =  63 , M_lda =  47  --->  Accuracy = 82.69%\n",
      "M_pca =  63 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  63 , M_lda =  49  --->  Accuracy = 81.73%\n",
      "M_pca =  63 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  63 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  64 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  64 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  64 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  64 , M_lda =  4  --->  Accuracy = 48.08%\n",
      "M_pca =  64 , M_lda =  5  --->  Accuracy = 63.46%\n",
      "M_pca =  64 , M_lda =  6  --->  Accuracy = 66.35%\n",
      "M_pca =  64 , M_lda =  7  --->  Accuracy = 70.19%\n",
      "M_pca =  64 , M_lda =  8  --->  Accuracy = 69.23%\n",
      "M_pca =  64 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  64 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  64 , M_lda =  11  --->  Accuracy = 81.73%\n",
      "M_pca =  64 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  64 , M_lda =  13  --->  Accuracy = 80.77%\n",
      "M_pca =  64 , M_lda =  14  --->  Accuracy = 83.65%\n",
      "M_pca =  64 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  64 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  64 , M_lda =  17  --->  Accuracy = 81.73%\n",
      "M_pca =  64 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  64 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  64 , M_lda =  20  --->  Accuracy = 80.77%\n",
      "M_pca =  64 , M_lda =  21  --->  Accuracy = 79.81%\n",
      "M_pca =  64 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  64 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  64 , M_lda =  24  --->  Accuracy = 83.65%\n",
      "M_pca =  64 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  64 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  64 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  64 , M_lda =  28  --->  Accuracy = 80.77%\n",
      "M_pca =  64 , M_lda =  29  --->  Accuracy = 80.77%\n",
      "M_pca =  64 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  64 , M_lda =  31  --->  Accuracy = 84.62%\n",
      "M_pca =  64 , M_lda =  32  --->  Accuracy = 84.62%\n",
      "M_pca =  64 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  64 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  64 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  64 , M_lda =  36  --->  Accuracy = 82.69%\n",
      "M_pca =  64 , M_lda =  37  --->  Accuracy = 82.69%\n",
      "M_pca =  64 , M_lda =  38  --->  Accuracy = 83.65%\n",
      "M_pca =  64 , M_lda =  39  --->  Accuracy = 83.65%\n",
      "M_pca =  64 , M_lda =  40  --->  Accuracy = 84.62%\n",
      "M_pca =  64 , M_lda =  41  --->  Accuracy = 84.62%\n",
      "M_pca =  64 , M_lda =  42  --->  Accuracy = 83.65%\n",
      "M_pca =  64 , M_lda =  43  --->  Accuracy = 82.69%\n",
      "M_pca =  64 , M_lda =  44  --->  Accuracy = 83.65%\n",
      "M_pca =  64 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  64 , M_lda =  46  --->  Accuracy = 83.65%\n",
      "M_pca =  64 , M_lda =  47  --->  Accuracy = 83.65%\n",
      "M_pca =  64 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  64 , M_lda =  49  --->  Accuracy = 81.73%\n",
      "M_pca =  64 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  64 , M_lda =  51  --->  Accuracy = 81.73%\n",
      "M_pca =  65 , M_lda =  1  --->  Accuracy = 5.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  65 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  65 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  65 , M_lda =  4  --->  Accuracy = 45.19%\n",
      "M_pca =  65 , M_lda =  5  --->  Accuracy = 62.50%\n",
      "M_pca =  65 , M_lda =  6  --->  Accuracy = 65.38%\n",
      "M_pca =  65 , M_lda =  7  --->  Accuracy = 70.19%\n",
      "M_pca =  65 , M_lda =  8  --->  Accuracy = 72.12%\n",
      "M_pca =  65 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  65 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  65 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  65 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  65 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  65 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  65 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  65 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  65 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  65 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  65 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  65 , M_lda =  20  --->  Accuracy = 81.73%\n",
      "M_pca =  65 , M_lda =  21  --->  Accuracy = 82.69%\n",
      "M_pca =  65 , M_lda =  22  --->  Accuracy = 81.73%\n",
      "M_pca =  65 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  65 , M_lda =  24  --->  Accuracy = 82.69%\n",
      "M_pca =  65 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  65 , M_lda =  26  --->  Accuracy = 83.65%\n",
      "M_pca =  65 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  65 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  65 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  65 , M_lda =  30  --->  Accuracy = 84.62%\n",
      "M_pca =  65 , M_lda =  31  --->  Accuracy = 84.62%\n",
      "M_pca =  65 , M_lda =  32  --->  Accuracy = 83.65%\n",
      "M_pca =  65 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  65 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  65 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  65 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  65 , M_lda =  37  --->  Accuracy = 84.62%\n",
      "M_pca =  65 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  65 , M_lda =  39  --->  Accuracy = 84.62%\n",
      "M_pca =  65 , M_lda =  40  --->  Accuracy = 84.62%\n",
      "M_pca =  65 , M_lda =  41  --->  Accuracy = 83.65%\n",
      "M_pca =  65 , M_lda =  42  --->  Accuracy = 84.62%\n",
      "M_pca =  65 , M_lda =  43  --->  Accuracy = 84.62%\n",
      "M_pca =  65 , M_lda =  44  --->  Accuracy = 84.62%\n",
      "M_pca =  65 , M_lda =  45  --->  Accuracy = 84.62%\n",
      "M_pca =  65 , M_lda =  46  --->  Accuracy = 85.58%\n",
      "M_pca =  65 , M_lda =  47  --->  Accuracy = 84.62%\n",
      "M_pca =  65 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  65 , M_lda =  49  --->  Accuracy = 78.85%\n",
      "M_pca =  65 , M_lda =  50  --->  Accuracy = 78.85%\n",
      "M_pca =  65 , M_lda =  51  --->  Accuracy = 77.88%\n",
      "M_pca =  66 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  66 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  66 , M_lda =  3  --->  Accuracy = 37.50%\n",
      "M_pca =  66 , M_lda =  4  --->  Accuracy = 48.08%\n",
      "M_pca =  66 , M_lda =  5  --->  Accuracy = 59.62%\n",
      "M_pca =  66 , M_lda =  6  --->  Accuracy = 64.42%\n",
      "M_pca =  66 , M_lda =  7  --->  Accuracy = 70.19%\n",
      "M_pca =  66 , M_lda =  8  --->  Accuracy = 72.12%\n",
      "M_pca =  66 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  66 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  66 , M_lda =  11  --->  Accuracy = 75.96%\n",
      "M_pca =  66 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  66 , M_lda =  13  --->  Accuracy = 80.77%\n",
      "M_pca =  66 , M_lda =  14  --->  Accuracy = 82.69%\n",
      "M_pca =  66 , M_lda =  15  --->  Accuracy = 85.58%\n",
      "M_pca =  66 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  66 , M_lda =  17  --->  Accuracy = 80.77%\n",
      "M_pca =  66 , M_lda =  18  --->  Accuracy = 78.85%\n",
      "M_pca =  66 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  66 , M_lda =  20  --->  Accuracy = 80.77%\n",
      "M_pca =  66 , M_lda =  21  --->  Accuracy = 82.69%\n",
      "M_pca =  66 , M_lda =  22  --->  Accuracy = 82.69%\n",
      "M_pca =  66 , M_lda =  23  --->  Accuracy = 83.65%\n",
      "M_pca =  66 , M_lda =  24  --->  Accuracy = 83.65%\n",
      "M_pca =  66 , M_lda =  25  --->  Accuracy = 80.77%\n",
      "M_pca =  66 , M_lda =  26  --->  Accuracy = 81.73%\n",
      "M_pca =  66 , M_lda =  27  --->  Accuracy = 80.77%\n",
      "M_pca =  66 , M_lda =  28  --->  Accuracy = 80.77%\n",
      "M_pca =  66 , M_lda =  29  --->  Accuracy = 80.77%\n",
      "M_pca =  66 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  66 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  66 , M_lda =  32  --->  Accuracy = 81.73%\n",
      "M_pca =  66 , M_lda =  33  --->  Accuracy = 81.73%\n",
      "M_pca =  66 , M_lda =  34  --->  Accuracy = 82.69%\n",
      "M_pca =  66 , M_lda =  35  --->  Accuracy = 83.65%\n",
      "M_pca =  66 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  66 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  66 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  66 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  66 , M_lda =  40  --->  Accuracy = 82.69%\n",
      "M_pca =  66 , M_lda =  41  --->  Accuracy = 83.65%\n",
      "M_pca =  66 , M_lda =  42  --->  Accuracy = 83.65%\n",
      "M_pca =  66 , M_lda =  43  --->  Accuracy = 83.65%\n",
      "M_pca =  66 , M_lda =  44  --->  Accuracy = 82.69%\n",
      "M_pca =  66 , M_lda =  45  --->  Accuracy = 81.73%\n",
      "M_pca =  66 , M_lda =  46  --->  Accuracy = 80.77%\n",
      "M_pca =  66 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  66 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  66 , M_lda =  49  --->  Accuracy = 79.81%\n",
      "M_pca =  66 , M_lda =  50  --->  Accuracy = 80.77%\n",
      "M_pca =  66 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  67 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  67 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  67 , M_lda =  3  --->  Accuracy = 36.54%\n",
      "M_pca =  67 , M_lda =  4  --->  Accuracy = 48.08%\n",
      "M_pca =  67 , M_lda =  5  --->  Accuracy = 57.69%\n",
      "M_pca =  67 , M_lda =  6  --->  Accuracy = 62.50%\n",
      "M_pca =  67 , M_lda =  7  --->  Accuracy = 69.23%\n",
      "M_pca =  67 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  67 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  67 , M_lda =  10  --->  Accuracy = 72.12%\n",
      "M_pca =  67 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  67 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  67 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  67 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  67 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  67 , M_lda =  16  --->  Accuracy = 77.88%\n",
      "M_pca =  67 , M_lda =  17  --->  Accuracy = 77.88%\n",
      "M_pca =  67 , M_lda =  18  --->  Accuracy = 76.92%\n",
      "M_pca =  67 , M_lda =  19  --->  Accuracy = 77.88%\n",
      "M_pca =  67 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  67 , M_lda =  21  --->  Accuracy = 81.73%\n",
      "M_pca =  67 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  67 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  67 , M_lda =  24  --->  Accuracy = 82.69%\n",
      "M_pca =  67 , M_lda =  25  --->  Accuracy = 82.69%\n",
      "M_pca =  67 , M_lda =  26  --->  Accuracy = 81.73%\n",
      "M_pca =  67 , M_lda =  27  --->  Accuracy = 80.77%\n",
      "M_pca =  67 , M_lda =  28  --->  Accuracy = 80.77%\n",
      "M_pca =  67 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  67 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  67 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  67 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  67 , M_lda =  33  --->  Accuracy = 82.69%\n",
      "M_pca =  67 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  67 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  67 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  67 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  67 , M_lda =  38  --->  Accuracy = 80.77%\n",
      "M_pca =  67 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  67 , M_lda =  40  --->  Accuracy = 84.62%\n",
      "M_pca =  67 , M_lda =  41  --->  Accuracy = 84.62%\n",
      "M_pca =  67 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  67 , M_lda =  43  --->  Accuracy = 80.77%\n",
      "M_pca =  67 , M_lda =  44  --->  Accuracy = 80.77%\n",
      "M_pca =  67 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  67 , M_lda =  46  --->  Accuracy = 79.81%\n",
      "M_pca =  67 , M_lda =  47  --->  Accuracy = 80.77%\n",
      "M_pca =  67 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  67 , M_lda =  49  --->  Accuracy = 78.85%\n",
      "M_pca =  67 , M_lda =  50  --->  Accuracy = 77.88%\n",
      "M_pca =  67 , M_lda =  51  --->  Accuracy = 77.88%\n",
      "M_pca =  68 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  68 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  68 , M_lda =  3  --->  Accuracy = 36.54%\n",
      "M_pca =  68 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  68 , M_lda =  5  --->  Accuracy = 55.77%\n",
      "M_pca =  68 , M_lda =  6  --->  Accuracy = 63.46%\n",
      "M_pca =  68 , M_lda =  7  --->  Accuracy = 67.31%\n",
      "M_pca =  68 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  68 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  68 , M_lda =  10  --->  Accuracy = 75.96%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  68 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  68 , M_lda =  12  --->  Accuracy = 78.85%\n",
      "M_pca =  68 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  68 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  68 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  68 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  68 , M_lda =  17  --->  Accuracy = 78.85%\n",
      "M_pca =  68 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  68 , M_lda =  19  --->  Accuracy = 78.85%\n",
      "M_pca =  68 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  68 , M_lda =  21  --->  Accuracy = 82.69%\n",
      "M_pca =  68 , M_lda =  22  --->  Accuracy = 81.73%\n",
      "M_pca =  68 , M_lda =  23  --->  Accuracy = 80.77%\n",
      "M_pca =  68 , M_lda =  24  --->  Accuracy = 80.77%\n",
      "M_pca =  68 , M_lda =  25  --->  Accuracy = 80.77%\n",
      "M_pca =  68 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  68 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  68 , M_lda =  28  --->  Accuracy = 80.77%\n",
      "M_pca =  68 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  68 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  68 , M_lda =  31  --->  Accuracy = 83.65%\n",
      "M_pca =  68 , M_lda =  32  --->  Accuracy = 81.73%\n",
      "M_pca =  68 , M_lda =  33  --->  Accuracy = 83.65%\n",
      "M_pca =  68 , M_lda =  34  --->  Accuracy = 82.69%\n",
      "M_pca =  68 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  68 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  68 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  68 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  68 , M_lda =  39  --->  Accuracy = 83.65%\n",
      "M_pca =  68 , M_lda =  40  --->  Accuracy = 82.69%\n",
      "M_pca =  68 , M_lda =  41  --->  Accuracy = 84.62%\n",
      "M_pca =  68 , M_lda =  42  --->  Accuracy = 83.65%\n",
      "M_pca =  68 , M_lda =  43  --->  Accuracy = 83.65%\n",
      "M_pca =  68 , M_lda =  44  --->  Accuracy = 82.69%\n",
      "M_pca =  68 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  68 , M_lda =  46  --->  Accuracy = 80.77%\n",
      "M_pca =  68 , M_lda =  47  --->  Accuracy = 80.77%\n",
      "M_pca =  68 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  68 , M_lda =  49  --->  Accuracy = 79.81%\n",
      "M_pca =  68 , M_lda =  50  --->  Accuracy = 79.81%\n",
      "M_pca =  68 , M_lda =  51  --->  Accuracy = 80.77%\n",
      "M_pca =  69 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  69 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  69 , M_lda =  3  --->  Accuracy = 37.50%\n",
      "M_pca =  69 , M_lda =  4  --->  Accuracy = 40.38%\n",
      "M_pca =  69 , M_lda =  5  --->  Accuracy = 51.92%\n",
      "M_pca =  69 , M_lda =  6  --->  Accuracy = 60.58%\n",
      "M_pca =  69 , M_lda =  7  --->  Accuracy = 68.27%\n",
      "M_pca =  69 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  69 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  69 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  69 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  69 , M_lda =  12  --->  Accuracy = 77.88%\n",
      "M_pca =  69 , M_lda =  13  --->  Accuracy = 79.81%\n",
      "M_pca =  69 , M_lda =  14  --->  Accuracy = 76.92%\n",
      "M_pca =  69 , M_lda =  15  --->  Accuracy = 79.81%\n",
      "M_pca =  69 , M_lda =  16  --->  Accuracy = 77.88%\n",
      "M_pca =  69 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  69 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  69 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  69 , M_lda =  20  --->  Accuracy = 79.81%\n",
      "M_pca =  69 , M_lda =  21  --->  Accuracy = 79.81%\n",
      "M_pca =  69 , M_lda =  22  --->  Accuracy = 82.69%\n",
      "M_pca =  69 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  69 , M_lda =  24  --->  Accuracy = 82.69%\n",
      "M_pca =  69 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  69 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  69 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  69 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  69 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  69 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  69 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  69 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  69 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  69 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  69 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  69 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  69 , M_lda =  37  --->  Accuracy = 82.69%\n",
      "M_pca =  69 , M_lda =  38  --->  Accuracy = 82.69%\n",
      "M_pca =  69 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  69 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  69 , M_lda =  41  --->  Accuracy = 82.69%\n",
      "M_pca =  69 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  69 , M_lda =  43  --->  Accuracy = 80.77%\n",
      "M_pca =  69 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  69 , M_lda =  45  --->  Accuracy = 79.81%\n",
      "M_pca =  69 , M_lda =  46  --->  Accuracy = 78.85%\n",
      "M_pca =  69 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  69 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  69 , M_lda =  49  --->  Accuracy = 78.85%\n",
      "M_pca =  69 , M_lda =  50  --->  Accuracy = 78.85%\n",
      "M_pca =  69 , M_lda =  51  --->  Accuracy = 77.88%\n",
      "M_pca =  70 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  70 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  70 , M_lda =  3  --->  Accuracy = 40.38%\n",
      "M_pca =  70 , M_lda =  4  --->  Accuracy = 41.35%\n",
      "M_pca =  70 , M_lda =  5  --->  Accuracy = 51.92%\n",
      "M_pca =  70 , M_lda =  6  --->  Accuracy = 61.54%\n",
      "M_pca =  70 , M_lda =  7  --->  Accuracy = 68.27%\n",
      "M_pca =  70 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  70 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  70 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  70 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  70 , M_lda =  12  --->  Accuracy = 78.85%\n",
      "M_pca =  70 , M_lda =  13  --->  Accuracy = 79.81%\n",
      "M_pca =  70 , M_lda =  14  --->  Accuracy = 79.81%\n",
      "M_pca =  70 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  70 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  70 , M_lda =  17  --->  Accuracy = 81.73%\n",
      "M_pca =  70 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  70 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  70 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  70 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  70 , M_lda =  22  --->  Accuracy = 83.65%\n",
      "M_pca =  70 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  70 , M_lda =  24  --->  Accuracy = 81.73%\n",
      "M_pca =  70 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  70 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  70 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  70 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  70 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  70 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  70 , M_lda =  31  --->  Accuracy = 83.65%\n",
      "M_pca =  70 , M_lda =  32  --->  Accuracy = 83.65%\n",
      "M_pca =  70 , M_lda =  33  --->  Accuracy = 82.69%\n",
      "M_pca =  70 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  70 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  70 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  70 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  70 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  70 , M_lda =  39  --->  Accuracy = 82.69%\n",
      "M_pca =  70 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  70 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  70 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  70 , M_lda =  43  --->  Accuracy = 84.62%\n",
      "M_pca =  70 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  70 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  70 , M_lda =  46  --->  Accuracy = 81.73%\n",
      "M_pca =  70 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  70 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  70 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  70 , M_lda =  50  --->  Accuracy = 78.85%\n",
      "M_pca =  70 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  71 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  71 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  71 , M_lda =  3  --->  Accuracy = 37.50%\n",
      "M_pca =  71 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  71 , M_lda =  5  --->  Accuracy = 54.81%\n",
      "M_pca =  71 , M_lda =  6  --->  Accuracy = 63.46%\n",
      "M_pca =  71 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  71 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  71 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  71 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  71 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  71 , M_lda =  12  --->  Accuracy = 78.85%\n",
      "M_pca =  71 , M_lda =  13  --->  Accuracy = 80.77%\n",
      "M_pca =  71 , M_lda =  14  --->  Accuracy = 79.81%\n",
      "M_pca =  71 , M_lda =  15  --->  Accuracy = 80.77%\n",
      "M_pca =  71 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  71 , M_lda =  17  --->  Accuracy = 80.77%\n",
      "M_pca =  71 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  71 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  71 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  71 , M_lda =  21  --->  Accuracy = 84.62%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  71 , M_lda =  22  --->  Accuracy = 82.69%\n",
      "M_pca =  71 , M_lda =  23  --->  Accuracy = 80.77%\n",
      "M_pca =  71 , M_lda =  24  --->  Accuracy = 80.77%\n",
      "M_pca =  71 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  71 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  71 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  71 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  71 , M_lda =  29  --->  Accuracy = 81.73%\n",
      "M_pca =  71 , M_lda =  30  --->  Accuracy = 81.73%\n",
      "M_pca =  71 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  71 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  71 , M_lda =  33  --->  Accuracy = 82.69%\n",
      "M_pca =  71 , M_lda =  34  --->  Accuracy = 83.65%\n",
      "M_pca =  71 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  71 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  71 , M_lda =  37  --->  Accuracy = 84.62%\n",
      "M_pca =  71 , M_lda =  38  --->  Accuracy = 82.69%\n",
      "M_pca =  71 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  71 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  71 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  71 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  71 , M_lda =  43  --->  Accuracy = 84.62%\n",
      "M_pca =  71 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  71 , M_lda =  45  --->  Accuracy = 81.73%\n",
      "M_pca =  71 , M_lda =  46  --->  Accuracy = 79.81%\n",
      "M_pca =  71 , M_lda =  47  --->  Accuracy = 80.77%\n",
      "M_pca =  71 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  71 , M_lda =  49  --->  Accuracy = 81.73%\n",
      "M_pca =  71 , M_lda =  50  --->  Accuracy = 80.77%\n",
      "M_pca =  71 , M_lda =  51  --->  Accuracy = 79.81%\n",
      "M_pca =  72 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  72 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  72 , M_lda =  3  --->  Accuracy = 42.31%\n",
      "M_pca =  72 , M_lda =  4  --->  Accuracy = 51.92%\n",
      "M_pca =  72 , M_lda =  5  --->  Accuracy = 57.69%\n",
      "M_pca =  72 , M_lda =  6  --->  Accuracy = 64.42%\n",
      "M_pca =  72 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  72 , M_lda =  8  --->  Accuracy = 69.23%\n",
      "M_pca =  72 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  72 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  72 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  72 , M_lda =  12  --->  Accuracy = 79.81%\n",
      "M_pca =  72 , M_lda =  13  --->  Accuracy = 80.77%\n",
      "M_pca =  72 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  72 , M_lda =  15  --->  Accuracy = 80.77%\n",
      "M_pca =  72 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  72 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  72 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  72 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  72 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  72 , M_lda =  21  --->  Accuracy = 82.69%\n",
      "M_pca =  72 , M_lda =  22  --->  Accuracy = 82.69%\n",
      "M_pca =  72 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  72 , M_lda =  24  --->  Accuracy = 84.62%\n",
      "M_pca =  72 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  72 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  72 , M_lda =  27  --->  Accuracy = 83.65%\n",
      "M_pca =  72 , M_lda =  28  --->  Accuracy = 85.58%\n",
      "M_pca =  72 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  72 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  72 , M_lda =  31  --->  Accuracy = 83.65%\n",
      "M_pca =  72 , M_lda =  32  --->  Accuracy = 83.65%\n",
      "M_pca =  72 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  72 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  72 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  72 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  72 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  72 , M_lda =  38  --->  Accuracy = 83.65%\n",
      "M_pca =  72 , M_lda =  39  --->  Accuracy = 82.69%\n",
      "M_pca =  72 , M_lda =  40  --->  Accuracy = 85.58%\n",
      "M_pca =  72 , M_lda =  41  --->  Accuracy = 84.62%\n",
      "M_pca =  72 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  72 , M_lda =  43  --->  Accuracy = 83.65%\n",
      "M_pca =  72 , M_lda =  44  --->  Accuracy = 79.81%\n",
      "M_pca =  72 , M_lda =  45  --->  Accuracy = 79.81%\n",
      "M_pca =  72 , M_lda =  46  --->  Accuracy = 79.81%\n",
      "M_pca =  72 , M_lda =  47  --->  Accuracy = 80.77%\n",
      "M_pca =  72 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  72 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  72 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  72 , M_lda =  51  --->  Accuracy = 80.77%\n",
      "M_pca =  73 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  73 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  73 , M_lda =  3  --->  Accuracy = 37.50%\n",
      "M_pca =  73 , M_lda =  4  --->  Accuracy = 45.19%\n",
      "M_pca =  73 , M_lda =  5  --->  Accuracy = 55.77%\n",
      "M_pca =  73 , M_lda =  6  --->  Accuracy = 62.50%\n",
      "M_pca =  73 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  73 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  73 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  73 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  73 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  73 , M_lda =  12  --->  Accuracy = 79.81%\n",
      "M_pca =  73 , M_lda =  13  --->  Accuracy = 80.77%\n",
      "M_pca =  73 , M_lda =  14  --->  Accuracy = 79.81%\n",
      "M_pca =  73 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  73 , M_lda =  16  --->  Accuracy = 83.65%\n",
      "M_pca =  73 , M_lda =  17  --->  Accuracy = 84.62%\n",
      "M_pca =  73 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  73 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  73 , M_lda =  20  --->  Accuracy = 81.73%\n",
      "M_pca =  73 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  73 , M_lda =  22  --->  Accuracy = 82.69%\n",
      "M_pca =  73 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  73 , M_lda =  24  --->  Accuracy = 83.65%\n",
      "M_pca =  73 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  73 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  73 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  73 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  73 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  73 , M_lda =  30  --->  Accuracy = 84.62%\n",
      "M_pca =  73 , M_lda =  31  --->  Accuracy = 81.73%\n",
      "M_pca =  73 , M_lda =  32  --->  Accuracy = 81.73%\n",
      "M_pca =  73 , M_lda =  33  --->  Accuracy = 81.73%\n",
      "M_pca =  73 , M_lda =  34  --->  Accuracy = 82.69%\n",
      "M_pca =  73 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  73 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  73 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  73 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  73 , M_lda =  39  --->  Accuracy = 84.62%\n",
      "M_pca =  73 , M_lda =  40  --->  Accuracy = 83.65%\n",
      "M_pca =  73 , M_lda =  41  --->  Accuracy = 84.62%\n",
      "M_pca =  73 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  73 , M_lda =  43  --->  Accuracy = 83.65%\n",
      "M_pca =  73 , M_lda =  44  --->  Accuracy = 79.81%\n",
      "M_pca =  73 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  73 , M_lda =  46  --->  Accuracy = 80.77%\n",
      "M_pca =  73 , M_lda =  47  --->  Accuracy = 80.77%\n",
      "M_pca =  73 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  73 , M_lda =  49  --->  Accuracy = 79.81%\n",
      "M_pca =  73 , M_lda =  50  --->  Accuracy = 80.77%\n",
      "M_pca =  73 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  74 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  74 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  74 , M_lda =  3  --->  Accuracy = 36.54%\n",
      "M_pca =  74 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  74 , M_lda =  5  --->  Accuracy = 55.77%\n",
      "M_pca =  74 , M_lda =  6  --->  Accuracy = 64.42%\n",
      "M_pca =  74 , M_lda =  7  --->  Accuracy = 71.15%\n",
      "M_pca =  74 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  74 , M_lda =  9  --->  Accuracy = 76.92%\n",
      "M_pca =  74 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  74 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  74 , M_lda =  12  --->  Accuracy = 79.81%\n",
      "M_pca =  74 , M_lda =  13  --->  Accuracy = 81.73%\n",
      "M_pca =  74 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  74 , M_lda =  15  --->  Accuracy = 83.65%\n",
      "M_pca =  74 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  74 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  74 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  74 , M_lda =  19  --->  Accuracy = 82.69%\n",
      "M_pca =  74 , M_lda =  20  --->  Accuracy = 79.81%\n",
      "M_pca =  74 , M_lda =  21  --->  Accuracy = 82.69%\n",
      "M_pca =  74 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  74 , M_lda =  23  --->  Accuracy = 82.69%\n",
      "M_pca =  74 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  74 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  74 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  74 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  74 , M_lda =  28  --->  Accuracy = 85.58%\n",
      "M_pca =  74 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  74 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  74 , M_lda =  31  --->  Accuracy = 83.65%\n",
      "M_pca =  74 , M_lda =  32  --->  Accuracy = 81.73%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  74 , M_lda =  33  --->  Accuracy = 82.69%\n",
      "M_pca =  74 , M_lda =  34  --->  Accuracy = 82.69%\n",
      "M_pca =  74 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  74 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  74 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  74 , M_lda =  38  --->  Accuracy = 82.69%\n",
      "M_pca =  74 , M_lda =  39  --->  Accuracy = 83.65%\n",
      "M_pca =  74 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  74 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  74 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  74 , M_lda =  43  --->  Accuracy = 82.69%\n",
      "M_pca =  74 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  74 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  74 , M_lda =  46  --->  Accuracy = 80.77%\n",
      "M_pca =  74 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  74 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  74 , M_lda =  49  --->  Accuracy = 79.81%\n",
      "M_pca =  74 , M_lda =  50  --->  Accuracy = 79.81%\n",
      "M_pca =  74 , M_lda =  51  --->  Accuracy = 76.92%\n",
      "M_pca =  75 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  75 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  75 , M_lda =  3  --->  Accuracy = 35.58%\n",
      "M_pca =  75 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  75 , M_lda =  5  --->  Accuracy = 54.81%\n",
      "M_pca =  75 , M_lda =  6  --->  Accuracy = 63.46%\n",
      "M_pca =  75 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  75 , M_lda =  8  --->  Accuracy = 69.23%\n",
      "M_pca =  75 , M_lda =  9  --->  Accuracy = 76.92%\n",
      "M_pca =  75 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  75 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  75 , M_lda =  12  --->  Accuracy = 82.69%\n",
      "M_pca =  75 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  75 , M_lda =  14  --->  Accuracy = 83.65%\n",
      "M_pca =  75 , M_lda =  15  --->  Accuracy = 85.58%\n",
      "M_pca =  75 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  75 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  75 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  75 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  75 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  75 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  75 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  75 , M_lda =  23  --->  Accuracy = 82.69%\n",
      "M_pca =  75 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  75 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  75 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  75 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  75 , M_lda =  28  --->  Accuracy = 85.58%\n",
      "M_pca =  75 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  75 , M_lda =  30  --->  Accuracy = 84.62%\n",
      "M_pca =  75 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  75 , M_lda =  32  --->  Accuracy = 81.73%\n",
      "M_pca =  75 , M_lda =  33  --->  Accuracy = 81.73%\n",
      "M_pca =  75 , M_lda =  34  --->  Accuracy = 83.65%\n",
      "M_pca =  75 , M_lda =  35  --->  Accuracy = 83.65%\n",
      "M_pca =  75 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  75 , M_lda =  37  --->  Accuracy = 84.62%\n",
      "M_pca =  75 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  75 , M_lda =  39  --->  Accuracy = 82.69%\n",
      "M_pca =  75 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  75 , M_lda =  41  --->  Accuracy = 79.81%\n",
      "M_pca =  75 , M_lda =  42  --->  Accuracy = 80.77%\n",
      "M_pca =  75 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  75 , M_lda =  44  --->  Accuracy = 79.81%\n",
      "M_pca =  75 , M_lda =  45  --->  Accuracy = 81.73%\n",
      "M_pca =  75 , M_lda =  46  --->  Accuracy = 81.73%\n",
      "M_pca =  75 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  75 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  75 , M_lda =  49  --->  Accuracy = 79.81%\n",
      "M_pca =  75 , M_lda =  50  --->  Accuracy = 78.85%\n",
      "M_pca =  75 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  76 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  76 , M_lda =  2  --->  Accuracy = 24.04%\n",
      "M_pca =  76 , M_lda =  3  --->  Accuracy = 35.58%\n",
      "M_pca =  76 , M_lda =  4  --->  Accuracy = 50.00%\n",
      "M_pca =  76 , M_lda =  5  --->  Accuracy = 56.73%\n",
      "M_pca =  76 , M_lda =  6  --->  Accuracy = 60.58%\n",
      "M_pca =  76 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  76 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  76 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  76 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  76 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  76 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  76 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  76 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  76 , M_lda =  15  --->  Accuracy = 83.65%\n",
      "M_pca =  76 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  76 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  76 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  76 , M_lda =  19  --->  Accuracy = 82.69%\n",
      "M_pca =  76 , M_lda =  20  --->  Accuracy = 80.77%\n",
      "M_pca =  76 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  76 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  76 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  76 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  76 , M_lda =  25  --->  Accuracy = 83.65%\n",
      "M_pca =  76 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  76 , M_lda =  27  --->  Accuracy = 84.62%\n",
      "M_pca =  76 , M_lda =  28  --->  Accuracy = 84.62%\n",
      "M_pca =  76 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  76 , M_lda =  30  --->  Accuracy = 80.77%\n",
      "M_pca =  76 , M_lda =  31  --->  Accuracy = 80.77%\n",
      "M_pca =  76 , M_lda =  32  --->  Accuracy = 81.73%\n",
      "M_pca =  76 , M_lda =  33  --->  Accuracy = 83.65%\n",
      "M_pca =  76 , M_lda =  34  --->  Accuracy = 82.69%\n",
      "M_pca =  76 , M_lda =  35  --->  Accuracy = 82.69%\n",
      "M_pca =  76 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  76 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  76 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  76 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  76 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  76 , M_lda =  41  --->  Accuracy = 78.85%\n",
      "M_pca =  76 , M_lda =  42  --->  Accuracy = 80.77%\n",
      "M_pca =  76 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  76 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  76 , M_lda =  45  --->  Accuracy = 78.85%\n",
      "M_pca =  76 , M_lda =  46  --->  Accuracy = 78.85%\n",
      "M_pca =  76 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  76 , M_lda =  48  --->  Accuracy = 78.85%\n",
      "M_pca =  76 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  76 , M_lda =  50  --->  Accuracy = 80.77%\n",
      "M_pca =  76 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  77 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  77 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  77 , M_lda =  3  --->  Accuracy = 37.50%\n",
      "M_pca =  77 , M_lda =  4  --->  Accuracy = 48.08%\n",
      "M_pca =  77 , M_lda =  5  --->  Accuracy = 58.65%\n",
      "M_pca =  77 , M_lda =  6  --->  Accuracy = 64.42%\n",
      "M_pca =  77 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  77 , M_lda =  8  --->  Accuracy = 69.23%\n",
      "M_pca =  77 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  77 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  77 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  77 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  77 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  77 , M_lda =  14  --->  Accuracy = 82.69%\n",
      "M_pca =  77 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  77 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  77 , M_lda =  17  --->  Accuracy = 80.77%\n",
      "M_pca =  77 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  77 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  77 , M_lda =  20  --->  Accuracy = 79.81%\n",
      "M_pca =  77 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  77 , M_lda =  22  --->  Accuracy = 81.73%\n",
      "M_pca =  77 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  77 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  77 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  77 , M_lda =  26  --->  Accuracy = 84.62%\n",
      "M_pca =  77 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  77 , M_lda =  28  --->  Accuracy = 83.65%\n",
      "M_pca =  77 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  77 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  77 , M_lda =  31  --->  Accuracy = 81.73%\n",
      "M_pca =  77 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  77 , M_lda =  33  --->  Accuracy = 81.73%\n",
      "M_pca =  77 , M_lda =  34  --->  Accuracy = 81.73%\n",
      "M_pca =  77 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  77 , M_lda =  36  --->  Accuracy = 82.69%\n",
      "M_pca =  77 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  77 , M_lda =  38  --->  Accuracy = 82.69%\n",
      "M_pca =  77 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  77 , M_lda =  40  --->  Accuracy = 79.81%\n",
      "M_pca =  77 , M_lda =  41  --->  Accuracy = 79.81%\n",
      "M_pca =  77 , M_lda =  42  --->  Accuracy = 82.69%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  77 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  77 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  77 , M_lda =  45  --->  Accuracy = 77.88%\n",
      "M_pca =  77 , M_lda =  46  --->  Accuracy = 77.88%\n",
      "M_pca =  77 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  77 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  77 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  77 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  77 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  78 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  78 , M_lda =  2  --->  Accuracy = 22.12%\n",
      "M_pca =  78 , M_lda =  3  --->  Accuracy = 34.62%\n",
      "M_pca =  78 , M_lda =  4  --->  Accuracy = 45.19%\n",
      "M_pca =  78 , M_lda =  5  --->  Accuracy = 57.69%\n",
      "M_pca =  78 , M_lda =  6  --->  Accuracy = 61.54%\n",
      "M_pca =  78 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  78 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  78 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  78 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  78 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  78 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  78 , M_lda =  13  --->  Accuracy = 81.73%\n",
      "M_pca =  78 , M_lda =  14  --->  Accuracy = 80.77%\n",
      "M_pca =  78 , M_lda =  15  --->  Accuracy = 80.77%\n",
      "M_pca =  78 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  78 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  78 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  78 , M_lda =  19  --->  Accuracy = 82.69%\n",
      "M_pca =  78 , M_lda =  20  --->  Accuracy = 80.77%\n",
      "M_pca =  78 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  78 , M_lda =  22  --->  Accuracy = 82.69%\n",
      "M_pca =  78 , M_lda =  23  --->  Accuracy = 83.65%\n",
      "M_pca =  78 , M_lda =  24  --->  Accuracy = 84.62%\n",
      "M_pca =  78 , M_lda =  25  --->  Accuracy = 83.65%\n",
      "M_pca =  78 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  78 , M_lda =  27  --->  Accuracy = 84.62%\n",
      "M_pca =  78 , M_lda =  28  --->  Accuracy = 83.65%\n",
      "M_pca =  78 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  78 , M_lda =  30  --->  Accuracy = 84.62%\n",
      "M_pca =  78 , M_lda =  31  --->  Accuracy = 81.73%\n",
      "M_pca =  78 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  78 , M_lda =  33  --->  Accuracy = 81.73%\n",
      "M_pca =  78 , M_lda =  34  --->  Accuracy = 81.73%\n",
      "M_pca =  78 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  78 , M_lda =  36  --->  Accuracy = 81.73%\n",
      "M_pca =  78 , M_lda =  37  --->  Accuracy = 81.73%\n",
      "M_pca =  78 , M_lda =  38  --->  Accuracy = 82.69%\n",
      "M_pca =  78 , M_lda =  39  --->  Accuracy = 82.69%\n",
      "M_pca =  78 , M_lda =  40  --->  Accuracy = 82.69%\n",
      "M_pca =  78 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  78 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  78 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  78 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  78 , M_lda =  45  --->  Accuracy = 77.88%\n",
      "M_pca =  78 , M_lda =  46  --->  Accuracy = 77.88%\n",
      "M_pca =  78 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  78 , M_lda =  48  --->  Accuracy = 77.88%\n",
      "M_pca =  78 , M_lda =  49  --->  Accuracy = 79.81%\n",
      "M_pca =  78 , M_lda =  50  --->  Accuracy = 79.81%\n",
      "M_pca =  78 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  79 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  79 , M_lda =  2  --->  Accuracy = 23.08%\n",
      "M_pca =  79 , M_lda =  3  --->  Accuracy = 35.58%\n",
      "M_pca =  79 , M_lda =  4  --->  Accuracy = 50.00%\n",
      "M_pca =  79 , M_lda =  5  --->  Accuracy = 55.77%\n",
      "M_pca =  79 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  79 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  79 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  79 , M_lda =  9  --->  Accuracy = 76.92%\n",
      "M_pca =  79 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  79 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  79 , M_lda =  12  --->  Accuracy = 79.81%\n",
      "M_pca =  79 , M_lda =  13  --->  Accuracy = 79.81%\n",
      "M_pca =  79 , M_lda =  14  --->  Accuracy = 79.81%\n",
      "M_pca =  79 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  79 , M_lda =  16  --->  Accuracy = 79.81%\n",
      "M_pca =  79 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  79 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  79 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  79 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  79 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  79 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  79 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  79 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  79 , M_lda =  25  --->  Accuracy = 83.65%\n",
      "M_pca =  79 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  79 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  79 , M_lda =  28  --->  Accuracy = 84.62%\n",
      "M_pca =  79 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  79 , M_lda =  30  --->  Accuracy = 80.77%\n",
      "M_pca =  79 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  79 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  79 , M_lda =  33  --->  Accuracy = 81.73%\n",
      "M_pca =  79 , M_lda =  34  --->  Accuracy = 81.73%\n",
      "M_pca =  79 , M_lda =  35  --->  Accuracy = 82.69%\n",
      "M_pca =  79 , M_lda =  36  --->  Accuracy = 79.81%\n",
      "M_pca =  79 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  79 , M_lda =  38  --->  Accuracy = 80.77%\n",
      "M_pca =  79 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  79 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  79 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  79 , M_lda =  42  --->  Accuracy = 78.85%\n",
      "M_pca =  79 , M_lda =  43  --->  Accuracy = 79.81%\n",
      "M_pca =  79 , M_lda =  44  --->  Accuracy = 79.81%\n",
      "M_pca =  79 , M_lda =  45  --->  Accuracy = 78.85%\n",
      "M_pca =  79 , M_lda =  46  --->  Accuracy = 76.92%\n",
      "M_pca =  79 , M_lda =  47  --->  Accuracy = 77.88%\n",
      "M_pca =  79 , M_lda =  48  --->  Accuracy = 76.92%\n",
      "M_pca =  79 , M_lda =  49  --->  Accuracy = 77.88%\n",
      "M_pca =  79 , M_lda =  50  --->  Accuracy = 79.81%\n",
      "M_pca =  79 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  80 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  80 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  80 , M_lda =  3  --->  Accuracy = 37.50%\n",
      "M_pca =  80 , M_lda =  4  --->  Accuracy = 48.08%\n",
      "M_pca =  80 , M_lda =  5  --->  Accuracy = 57.69%\n",
      "M_pca =  80 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  80 , M_lda =  7  --->  Accuracy = 60.58%\n",
      "M_pca =  80 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  80 , M_lda =  9  --->  Accuracy = 76.92%\n",
      "M_pca =  80 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  80 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  80 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  80 , M_lda =  13  --->  Accuracy = 80.77%\n",
      "M_pca =  80 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  80 , M_lda =  15  --->  Accuracy = 79.81%\n",
      "M_pca =  80 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  80 , M_lda =  17  --->  Accuracy = 81.73%\n",
      "M_pca =  80 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  80 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  80 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  80 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  80 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  80 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  80 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  80 , M_lda =  25  --->  Accuracy = 83.65%\n",
      "M_pca =  80 , M_lda =  26  --->  Accuracy = 84.62%\n",
      "M_pca =  80 , M_lda =  27  --->  Accuracy = 83.65%\n",
      "M_pca =  80 , M_lda =  28  --->  Accuracy = 84.62%\n",
      "M_pca =  80 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  80 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  80 , M_lda =  31  --->  Accuracy = 81.73%\n",
      "M_pca =  80 , M_lda =  32  --->  Accuracy = 81.73%\n",
      "M_pca =  80 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  80 , M_lda =  34  --->  Accuracy = 82.69%\n",
      "M_pca =  80 , M_lda =  35  --->  Accuracy = 82.69%\n",
      "M_pca =  80 , M_lda =  36  --->  Accuracy = 82.69%\n",
      "M_pca =  80 , M_lda =  37  --->  Accuracy = 81.73%\n",
      "M_pca =  80 , M_lda =  38  --->  Accuracy = 82.69%\n",
      "M_pca =  80 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  80 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  80 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  80 , M_lda =  42  --->  Accuracy = 80.77%\n",
      "M_pca =  80 , M_lda =  43  --->  Accuracy = 79.81%\n",
      "M_pca =  80 , M_lda =  44  --->  Accuracy = 79.81%\n",
      "M_pca =  80 , M_lda =  45  --->  Accuracy = 78.85%\n",
      "M_pca =  80 , M_lda =  46  --->  Accuracy = 79.81%\n",
      "M_pca =  80 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  80 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  80 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  80 , M_lda =  50  --->  Accuracy = 80.77%\n",
      "M_pca =  80 , M_lda =  51  --->  Accuracy = 77.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  81 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  81 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  81 , M_lda =  3  --->  Accuracy = 37.50%\n",
      "M_pca =  81 , M_lda =  4  --->  Accuracy = 49.04%\n",
      "M_pca =  81 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  81 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  81 , M_lda =  7  --->  Accuracy = 58.65%\n",
      "M_pca =  81 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  81 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  81 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  81 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  81 , M_lda =  12  --->  Accuracy = 79.81%\n",
      "M_pca =  81 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  81 , M_lda =  14  --->  Accuracy = 82.69%\n",
      "M_pca =  81 , M_lda =  15  --->  Accuracy = 80.77%\n",
      "M_pca =  81 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  81 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  81 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  81 , M_lda =  19  --->  Accuracy = 82.69%\n",
      "M_pca =  81 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  81 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  81 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  81 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  81 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  81 , M_lda =  25  --->  Accuracy = 82.69%\n",
      "M_pca =  81 , M_lda =  26  --->  Accuracy = 83.65%\n",
      "M_pca =  81 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  81 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  81 , M_lda =  29  --->  Accuracy = 84.62%\n",
      "M_pca =  81 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  81 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  81 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  81 , M_lda =  33  --->  Accuracy = 81.73%\n",
      "M_pca =  81 , M_lda =  34  --->  Accuracy = 81.73%\n",
      "M_pca =  81 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  81 , M_lda =  36  --->  Accuracy = 82.69%\n",
      "M_pca =  81 , M_lda =  37  --->  Accuracy = 81.73%\n",
      "M_pca =  81 , M_lda =  38  --->  Accuracy = 82.69%\n",
      "M_pca =  81 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  81 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  81 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  81 , M_lda =  42  --->  Accuracy = 79.81%\n",
      "M_pca =  81 , M_lda =  43  --->  Accuracy = 80.77%\n",
      "M_pca =  81 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  81 , M_lda =  45  --->  Accuracy = 77.88%\n",
      "M_pca =  81 , M_lda =  46  --->  Accuracy = 78.85%\n",
      "M_pca =  81 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  81 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  81 , M_lda =  49  --->  Accuracy = 79.81%\n",
      "M_pca =  81 , M_lda =  50  --->  Accuracy = 79.81%\n",
      "M_pca =  81 , M_lda =  51  --->  Accuracy = 79.81%\n",
      "M_pca =  82 , M_lda =  1  --->  Accuracy = 2.88%\n",
      "M_pca =  82 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  82 , M_lda =  3  --->  Accuracy = 36.54%\n",
      "M_pca =  82 , M_lda =  4  --->  Accuracy = 50.96%\n",
      "M_pca =  82 , M_lda =  5  --->  Accuracy = 50.96%\n",
      "M_pca =  82 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  82 , M_lda =  7  --->  Accuracy = 59.62%\n",
      "M_pca =  82 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  82 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  82 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  82 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  82 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  82 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  82 , M_lda =  14  --->  Accuracy = 83.65%\n",
      "M_pca =  82 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  82 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  82 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  82 , M_lda =  18  --->  Accuracy = 83.65%\n",
      "M_pca =  82 , M_lda =  19  --->  Accuracy = 85.58%\n",
      "M_pca =  82 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  82 , M_lda =  21  --->  Accuracy = 87.50%\n",
      "M_pca =  82 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  82 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  82 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  82 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  82 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  82 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  82 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  82 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  82 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  82 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  82 , M_lda =  32  --->  Accuracy = 85.58%\n",
      "M_pca =  82 , M_lda =  33  --->  Accuracy = 82.69%\n",
      "M_pca =  82 , M_lda =  34  --->  Accuracy = 83.65%\n",
      "M_pca =  82 , M_lda =  35  --->  Accuracy = 83.65%\n",
      "M_pca =  82 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  82 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  82 , M_lda =  38  --->  Accuracy = 83.65%\n",
      "M_pca =  82 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  82 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  82 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  82 , M_lda =  42  --->  Accuracy = 80.77%\n",
      "M_pca =  82 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  82 , M_lda =  44  --->  Accuracy = 79.81%\n",
      "M_pca =  82 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  82 , M_lda =  46  --->  Accuracy = 80.77%\n",
      "M_pca =  82 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  82 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  82 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  82 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  82 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  83 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  83 , M_lda =  2  --->  Accuracy = 24.04%\n",
      "M_pca =  83 , M_lda =  3  --->  Accuracy = 33.65%\n",
      "M_pca =  83 , M_lda =  4  --->  Accuracy = 42.31%\n",
      "M_pca =  83 , M_lda =  5  --->  Accuracy = 53.85%\n",
      "M_pca =  83 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  83 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  83 , M_lda =  8  --->  Accuracy = 63.46%\n",
      "M_pca =  83 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  83 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  83 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  83 , M_lda =  12  --->  Accuracy = 77.88%\n",
      "M_pca =  83 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  83 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  83 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  83 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  83 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  83 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  83 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  83 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  83 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  83 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  83 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  83 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  83 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  83 , M_lda =  26  --->  Accuracy = 84.62%\n",
      "M_pca =  83 , M_lda =  27  --->  Accuracy = 83.65%\n",
      "M_pca =  83 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  83 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  83 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  83 , M_lda =  31  --->  Accuracy = 83.65%\n",
      "M_pca =  83 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  83 , M_lda =  33  --->  Accuracy = 82.69%\n",
      "M_pca =  83 , M_lda =  34  --->  Accuracy = 81.73%\n",
      "M_pca =  83 , M_lda =  35  --->  Accuracy = 83.65%\n",
      "M_pca =  83 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  83 , M_lda =  37  --->  Accuracy = 81.73%\n",
      "M_pca =  83 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  83 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  83 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  83 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  83 , M_lda =  42  --->  Accuracy = 80.77%\n",
      "M_pca =  83 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  83 , M_lda =  44  --->  Accuracy = 83.65%\n",
      "M_pca =  83 , M_lda =  45  --->  Accuracy = 83.65%\n",
      "M_pca =  83 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  83 , M_lda =  47  --->  Accuracy = 80.77%\n",
      "M_pca =  83 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  83 , M_lda =  49  --->  Accuracy = 81.73%\n",
      "M_pca =  83 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  83 , M_lda =  51  --->  Accuracy = 80.77%\n",
      "M_pca =  84 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  84 , M_lda =  2  --->  Accuracy = 23.08%\n",
      "M_pca =  84 , M_lda =  3  --->  Accuracy = 34.62%\n",
      "M_pca =  84 , M_lda =  4  --->  Accuracy = 47.12%\n",
      "M_pca =  84 , M_lda =  5  --->  Accuracy = 51.92%\n",
      "M_pca =  84 , M_lda =  6  --->  Accuracy = 61.54%\n",
      "M_pca =  84 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  84 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  84 , M_lda =  9  --->  Accuracy = 75.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  84 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  84 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  84 , M_lda =  12  --->  Accuracy = 82.69%\n",
      "M_pca =  84 , M_lda =  13  --->  Accuracy = 84.62%\n",
      "M_pca =  84 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  84 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  84 , M_lda =  16  --->  Accuracy = 83.65%\n",
      "M_pca =  84 , M_lda =  17  --->  Accuracy = 84.62%\n",
      "M_pca =  84 , M_lda =  18  --->  Accuracy = 86.54%\n",
      "M_pca =  84 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  84 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  84 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  84 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  84 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  84 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  84 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  84 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  84 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  84 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  84 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  84 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  84 , M_lda =  31  --->  Accuracy = 84.62%\n",
      "M_pca =  84 , M_lda =  32  --->  Accuracy = 83.65%\n",
      "M_pca =  84 , M_lda =  33  --->  Accuracy = 82.69%\n",
      "M_pca =  84 , M_lda =  34  --->  Accuracy = 82.69%\n",
      "M_pca =  84 , M_lda =  35  --->  Accuracy = 83.65%\n",
      "M_pca =  84 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  84 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  84 , M_lda =  38  --->  Accuracy = 83.65%\n",
      "M_pca =  84 , M_lda =  39  --->  Accuracy = 82.69%\n",
      "M_pca =  84 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  84 , M_lda =  41  --->  Accuracy = 79.81%\n",
      "M_pca =  84 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  84 , M_lda =  43  --->  Accuracy = 80.77%\n",
      "M_pca =  84 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  84 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  84 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  84 , M_lda =  47  --->  Accuracy = 81.73%\n",
      "M_pca =  84 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  84 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  84 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  84 , M_lda =  51  --->  Accuracy = 81.73%\n",
      "M_pca =  85 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  85 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  85 , M_lda =  3  --->  Accuracy = 33.65%\n",
      "M_pca =  85 , M_lda =  4  --->  Accuracy = 46.15%\n",
      "M_pca =  85 , M_lda =  5  --->  Accuracy = 50.96%\n",
      "M_pca =  85 , M_lda =  6  --->  Accuracy = 61.54%\n",
      "M_pca =  85 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  85 , M_lda =  8  --->  Accuracy = 71.15%\n",
      "M_pca =  85 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  85 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  85 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  85 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  85 , M_lda =  13  --->  Accuracy = 84.62%\n",
      "M_pca =  85 , M_lda =  14  --->  Accuracy = 83.65%\n",
      "M_pca =  85 , M_lda =  15  --->  Accuracy = 83.65%\n",
      "M_pca =  85 , M_lda =  16  --->  Accuracy = 83.65%\n",
      "M_pca =  85 , M_lda =  17  --->  Accuracy = 84.62%\n",
      "M_pca =  85 , M_lda =  18  --->  Accuracy = 86.54%\n",
      "M_pca =  85 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  85 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  85 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  85 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  85 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  85 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  85 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  85 , M_lda =  26  --->  Accuracy = 83.65%\n",
      "M_pca =  85 , M_lda =  27  --->  Accuracy = 84.62%\n",
      "M_pca =  85 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  85 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  85 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  85 , M_lda =  31  --->  Accuracy = 84.62%\n",
      "M_pca =  85 , M_lda =  32  --->  Accuracy = 84.62%\n",
      "M_pca =  85 , M_lda =  33  --->  Accuracy = 82.69%\n",
      "M_pca =  85 , M_lda =  34  --->  Accuracy = 82.69%\n",
      "M_pca =  85 , M_lda =  35  --->  Accuracy = 82.69%\n",
      "M_pca =  85 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  85 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  85 , M_lda =  38  --->  Accuracy = 83.65%\n",
      "M_pca =  85 , M_lda =  39  --->  Accuracy = 82.69%\n",
      "M_pca =  85 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  85 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  85 , M_lda =  42  --->  Accuracy = 80.77%\n",
      "M_pca =  85 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  85 , M_lda =  44  --->  Accuracy = 80.77%\n",
      "M_pca =  85 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  85 , M_lda =  46  --->  Accuracy = 80.77%\n",
      "M_pca =  85 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  85 , M_lda =  48  --->  Accuracy = 78.85%\n",
      "M_pca =  85 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  85 , M_lda =  50  --->  Accuracy = 80.77%\n",
      "M_pca =  85 , M_lda =  51  --->  Accuracy = 80.77%\n",
      "M_pca =  86 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  86 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  86 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  86 , M_lda =  4  --->  Accuracy = 47.12%\n",
      "M_pca =  86 , M_lda =  5  --->  Accuracy = 52.88%\n",
      "M_pca =  86 , M_lda =  6  --->  Accuracy = 64.42%\n",
      "M_pca =  86 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  86 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  86 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  86 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  86 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  86 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  86 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  86 , M_lda =  14  --->  Accuracy = 82.69%\n",
      "M_pca =  86 , M_lda =  15  --->  Accuracy = 84.62%\n",
      "M_pca =  86 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  86 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  86 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  86 , M_lda =  19  --->  Accuracy = 87.50%\n",
      "M_pca =  86 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  86 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  86 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  86 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  86 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  86 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  86 , M_lda =  26  --->  Accuracy = 84.62%\n",
      "M_pca =  86 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  86 , M_lda =  28  --->  Accuracy = 85.58%\n",
      "M_pca =  86 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  86 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  86 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  86 , M_lda =  32  --->  Accuracy = 85.58%\n",
      "M_pca =  86 , M_lda =  33  --->  Accuracy = 83.65%\n",
      "M_pca =  86 , M_lda =  34  --->  Accuracy = 83.65%\n",
      "M_pca =  86 , M_lda =  35  --->  Accuracy = 82.69%\n",
      "M_pca =  86 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  86 , M_lda =  37  --->  Accuracy = 81.73%\n",
      "M_pca =  86 , M_lda =  38  --->  Accuracy = 83.65%\n",
      "M_pca =  86 , M_lda =  39  --->  Accuracy = 82.69%\n",
      "M_pca =  86 , M_lda =  40  --->  Accuracy = 82.69%\n",
      "M_pca =  86 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  86 , M_lda =  42  --->  Accuracy = 78.85%\n",
      "M_pca =  86 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  86 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  86 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  86 , M_lda =  46  --->  Accuracy = 79.81%\n",
      "M_pca =  86 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  86 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  86 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  86 , M_lda =  50  --->  Accuracy = 80.77%\n",
      "M_pca =  86 , M_lda =  51  --->  Accuracy = 80.77%\n",
      "M_pca =  87 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  87 , M_lda =  2  --->  Accuracy = 22.12%\n",
      "M_pca =  87 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  87 , M_lda =  4  --->  Accuracy = 49.04%\n",
      "M_pca =  87 , M_lda =  5  --->  Accuracy = 52.88%\n",
      "M_pca =  87 , M_lda =  6  --->  Accuracy = 63.46%\n",
      "M_pca =  87 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  87 , M_lda =  8  --->  Accuracy = 69.23%\n",
      "M_pca =  87 , M_lda =  9  --->  Accuracy = 73.08%\n",
      "M_pca =  87 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  87 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  87 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  87 , M_lda =  13  --->  Accuracy = 84.62%\n",
      "M_pca =  87 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  87 , M_lda =  15  --->  Accuracy = 85.58%\n",
      "M_pca =  87 , M_lda =  16  --->  Accuracy = 83.65%\n",
      "M_pca =  87 , M_lda =  17  --->  Accuracy = 84.62%\n",
      "M_pca =  87 , M_lda =  18  --->  Accuracy = 85.58%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  87 , M_lda =  19  --->  Accuracy = 87.50%\n",
      "M_pca =  87 , M_lda =  20  --->  Accuracy = 87.50%\n",
      "M_pca =  87 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  87 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  87 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  87 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  87 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  87 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  87 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  87 , M_lda =  28  --->  Accuracy = 85.58%\n",
      "M_pca =  87 , M_lda =  29  --->  Accuracy = 84.62%\n",
      "M_pca =  87 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  87 , M_lda =  31  --->  Accuracy = 84.62%\n",
      "M_pca =  87 , M_lda =  32  --->  Accuracy = 85.58%\n",
      "M_pca =  87 , M_lda =  33  --->  Accuracy = 83.65%\n",
      "M_pca =  87 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  87 , M_lda =  35  --->  Accuracy = 83.65%\n",
      "M_pca =  87 , M_lda =  36  --->  Accuracy = 82.69%\n",
      "M_pca =  87 , M_lda =  37  --->  Accuracy = 81.73%\n",
      "M_pca =  87 , M_lda =  38  --->  Accuracy = 83.65%\n",
      "M_pca =  87 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  87 , M_lda =  40  --->  Accuracy = 82.69%\n",
      "M_pca =  87 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  87 , M_lda =  42  --->  Accuracy = 78.85%\n",
      "M_pca =  87 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  87 , M_lda =  44  --->  Accuracy = 79.81%\n",
      "M_pca =  87 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  87 , M_lda =  46  --->  Accuracy = 79.81%\n",
      "M_pca =  87 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  87 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  87 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  87 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  87 , M_lda =  51  --->  Accuracy = 81.73%\n",
      "M_pca =  88 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  88 , M_lda =  2  --->  Accuracy = 23.08%\n",
      "M_pca =  88 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  88 , M_lda =  4  --->  Accuracy = 46.15%\n",
      "M_pca =  88 , M_lda =  5  --->  Accuracy = 50.96%\n",
      "M_pca =  88 , M_lda =  6  --->  Accuracy = 62.50%\n",
      "M_pca =  88 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  88 , M_lda =  8  --->  Accuracy = 69.23%\n",
      "M_pca =  88 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  88 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  88 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  88 , M_lda =  12  --->  Accuracy = 82.69%\n",
      "M_pca =  88 , M_lda =  13  --->  Accuracy = 84.62%\n",
      "M_pca =  88 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  88 , M_lda =  15  --->  Accuracy = 85.58%\n",
      "M_pca =  88 , M_lda =  16  --->  Accuracy = 86.54%\n",
      "M_pca =  88 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  88 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  88 , M_lda =  19  --->  Accuracy = 87.50%\n",
      "M_pca =  88 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  88 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  88 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  88 , M_lda =  23  --->  Accuracy = 83.65%\n",
      "M_pca =  88 , M_lda =  24  --->  Accuracy = 84.62%\n",
      "M_pca =  88 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  88 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  88 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  88 , M_lda =  28  --->  Accuracy = 85.58%\n",
      "M_pca =  88 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  88 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  88 , M_lda =  31  --->  Accuracy = 84.62%\n",
      "M_pca =  88 , M_lda =  32  --->  Accuracy = 84.62%\n",
      "M_pca =  88 , M_lda =  33  --->  Accuracy = 81.73%\n",
      "M_pca =  88 , M_lda =  34  --->  Accuracy = 82.69%\n",
      "M_pca =  88 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  88 , M_lda =  36  --->  Accuracy = 81.73%\n",
      "M_pca =  88 , M_lda =  37  --->  Accuracy = 81.73%\n",
      "M_pca =  88 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  88 , M_lda =  39  --->  Accuracy = 82.69%\n",
      "M_pca =  88 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  88 , M_lda =  41  --->  Accuracy = 79.81%\n",
      "M_pca =  88 , M_lda =  42  --->  Accuracy = 78.85%\n",
      "M_pca =  88 , M_lda =  43  --->  Accuracy = 77.88%\n",
      "M_pca =  88 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  88 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  88 , M_lda =  46  --->  Accuracy = 80.77%\n",
      "M_pca =  88 , M_lda =  47  --->  Accuracy = 80.77%\n",
      "M_pca =  88 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  88 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  88 , M_lda =  50  --->  Accuracy = 80.77%\n",
      "M_pca =  88 , M_lda =  51  --->  Accuracy = 80.77%\n",
      "M_pca =  89 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  89 , M_lda =  2  --->  Accuracy = 23.08%\n",
      "M_pca =  89 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  89 , M_lda =  4  --->  Accuracy = 45.19%\n",
      "M_pca =  89 , M_lda =  5  --->  Accuracy = 52.88%\n",
      "M_pca =  89 , M_lda =  6  --->  Accuracy = 62.50%\n",
      "M_pca =  89 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  89 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  89 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  89 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  89 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  89 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  89 , M_lda =  13  --->  Accuracy = 84.62%\n",
      "M_pca =  89 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  89 , M_lda =  15  --->  Accuracy = 84.62%\n",
      "M_pca =  89 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  89 , M_lda =  17  --->  Accuracy = 87.50%\n",
      "M_pca =  89 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  89 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  89 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  89 , M_lda =  21  --->  Accuracy = 88.46%\n",
      "M_pca =  89 , M_lda =  22  --->  Accuracy = 89.42%\n",
      "M_pca =  89 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  89 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  89 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  89 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  89 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  89 , M_lda =  28  --->  Accuracy = 85.58%\n",
      "M_pca =  89 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  89 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  89 , M_lda =  31  --->  Accuracy = 85.58%\n",
      "M_pca =  89 , M_lda =  32  --->  Accuracy = 84.62%\n",
      "M_pca =  89 , M_lda =  33  --->  Accuracy = 82.69%\n",
      "M_pca =  89 , M_lda =  34  --->  Accuracy = 81.73%\n",
      "M_pca =  89 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  89 , M_lda =  36  --->  Accuracy = 81.73%\n",
      "M_pca =  89 , M_lda =  37  --->  Accuracy = 82.69%\n",
      "M_pca =  89 , M_lda =  38  --->  Accuracy = 82.69%\n",
      "M_pca =  89 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  89 , M_lda =  40  --->  Accuracy = 82.69%\n",
      "M_pca =  89 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  89 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  89 , M_lda =  43  --->  Accuracy = 80.77%\n",
      "M_pca =  89 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  89 , M_lda =  45  --->  Accuracy = 79.81%\n",
      "M_pca =  89 , M_lda =  46  --->  Accuracy = 80.77%\n",
      "M_pca =  89 , M_lda =  47  --->  Accuracy = 81.73%\n",
      "M_pca =  89 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  89 , M_lda =  49  --->  Accuracy = 81.73%\n",
      "M_pca =  89 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  89 , M_lda =  51  --->  Accuracy = 81.73%\n",
      "M_pca =  90 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  90 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  90 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  90 , M_lda =  4  --->  Accuracy = 42.31%\n",
      "M_pca =  90 , M_lda =  5  --->  Accuracy = 52.88%\n",
      "M_pca =  90 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  90 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  90 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  90 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  90 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  90 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  90 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  90 , M_lda =  13  --->  Accuracy = 84.62%\n",
      "M_pca =  90 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  90 , M_lda =  15  --->  Accuracy = 84.62%\n",
      "M_pca =  90 , M_lda =  16  --->  Accuracy = 86.54%\n",
      "M_pca =  90 , M_lda =  17  --->  Accuracy = 85.58%\n",
      "M_pca =  90 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  90 , M_lda =  19  --->  Accuracy = 85.58%\n",
      "M_pca =  90 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  90 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  90 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  90 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  90 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  90 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  90 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  90 , M_lda =  27  --->  Accuracy = 88.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  90 , M_lda =  28  --->  Accuracy = 84.62%\n",
      "M_pca =  90 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  90 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  90 , M_lda =  31  --->  Accuracy = 85.58%\n",
      "M_pca =  90 , M_lda =  32  --->  Accuracy = 84.62%\n",
      "M_pca =  90 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  90 , M_lda =  34  --->  Accuracy = 83.65%\n",
      "M_pca =  90 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  90 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  90 , M_lda =  37  --->  Accuracy = 82.69%\n",
      "M_pca =  90 , M_lda =  38  --->  Accuracy = 82.69%\n",
      "M_pca =  90 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  90 , M_lda =  40  --->  Accuracy = 83.65%\n",
      "M_pca =  90 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  90 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  90 , M_lda =  43  --->  Accuracy = 82.69%\n",
      "M_pca =  90 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  90 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  90 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  90 , M_lda =  47  --->  Accuracy = 81.73%\n",
      "M_pca =  90 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  90 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  90 , M_lda =  50  --->  Accuracy = 80.77%\n",
      "M_pca =  90 , M_lda =  51  --->  Accuracy = 81.73%\n",
      "M_pca =  91 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  91 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  91 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  91 , M_lda =  4  --->  Accuracy = 41.35%\n",
      "M_pca =  91 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  91 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  91 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  91 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  91 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  91 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  91 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  91 , M_lda =  12  --->  Accuracy = 82.69%\n",
      "M_pca =  91 , M_lda =  13  --->  Accuracy = 84.62%\n",
      "M_pca =  91 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  91 , M_lda =  15  --->  Accuracy = 85.58%\n",
      "M_pca =  91 , M_lda =  16  --->  Accuracy = 86.54%\n",
      "M_pca =  91 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  91 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  91 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  91 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  91 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  91 , M_lda =  22  --->  Accuracy = 83.65%\n",
      "M_pca =  91 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  91 , M_lda =  24  --->  Accuracy = 83.65%\n",
      "M_pca =  91 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  91 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  91 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  91 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  91 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  91 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  91 , M_lda =  31  --->  Accuracy = 85.58%\n",
      "M_pca =  91 , M_lda =  32  --->  Accuracy = 84.62%\n",
      "M_pca =  91 , M_lda =  33  --->  Accuracy = 82.69%\n",
      "M_pca =  91 , M_lda =  34  --->  Accuracy = 81.73%\n",
      "M_pca =  91 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  91 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  91 , M_lda =  37  --->  Accuracy = 82.69%\n",
      "M_pca =  91 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  91 , M_lda =  39  --->  Accuracy = 82.69%\n",
      "M_pca =  91 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  91 , M_lda =  41  --->  Accuracy = 82.69%\n",
      "M_pca =  91 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  91 , M_lda =  43  --->  Accuracy = 82.69%\n",
      "M_pca =  91 , M_lda =  44  --->  Accuracy = 82.69%\n",
      "M_pca =  91 , M_lda =  45  --->  Accuracy = 81.73%\n",
      "M_pca =  91 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  91 , M_lda =  47  --->  Accuracy = 82.69%\n",
      "M_pca =  91 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  91 , M_lda =  49  --->  Accuracy = 81.73%\n",
      "M_pca =  91 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  91 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  92 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  92 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  92 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  92 , M_lda =  4  --->  Accuracy = 39.42%\n",
      "M_pca =  92 , M_lda =  5  --->  Accuracy = 47.12%\n",
      "M_pca =  92 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  92 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  92 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  92 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  92 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  92 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  92 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  92 , M_lda =  13  --->  Accuracy = 84.62%\n",
      "M_pca =  92 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  92 , M_lda =  15  --->  Accuracy = 86.54%\n",
      "M_pca =  92 , M_lda =  16  --->  Accuracy = 87.50%\n",
      "M_pca =  92 , M_lda =  17  --->  Accuracy = 88.46%\n",
      "M_pca =  92 , M_lda =  18  --->  Accuracy = 87.50%\n",
      "M_pca =  92 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  92 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  92 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  92 , M_lda =  22  --->  Accuracy = 83.65%\n",
      "M_pca =  92 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  92 , M_lda =  24  --->  Accuracy = 84.62%\n",
      "M_pca =  92 , M_lda =  25  --->  Accuracy = 83.65%\n",
      "M_pca =  92 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  92 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  92 , M_lda =  28  --->  Accuracy = 84.62%\n",
      "M_pca =  92 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  92 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  92 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  92 , M_lda =  32  --->  Accuracy = 85.58%\n",
      "M_pca =  92 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  92 , M_lda =  34  --->  Accuracy = 83.65%\n",
      "M_pca =  92 , M_lda =  35  --->  Accuracy = 82.69%\n",
      "M_pca =  92 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  92 , M_lda =  37  --->  Accuracy = 82.69%\n",
      "M_pca =  92 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  92 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  92 , M_lda =  40  --->  Accuracy = 82.69%\n",
      "M_pca =  92 , M_lda =  41  --->  Accuracy = 82.69%\n",
      "M_pca =  92 , M_lda =  42  --->  Accuracy = 83.65%\n",
      "M_pca =  92 , M_lda =  43  --->  Accuracy = 82.69%\n",
      "M_pca =  92 , M_lda =  44  --->  Accuracy = 82.69%\n",
      "M_pca =  92 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  92 , M_lda =  46  --->  Accuracy = 78.85%\n",
      "M_pca =  92 , M_lda =  47  --->  Accuracy = 80.77%\n",
      "M_pca =  92 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  92 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  92 , M_lda =  50  --->  Accuracy = 79.81%\n",
      "M_pca =  92 , M_lda =  51  --->  Accuracy = 79.81%\n",
      "M_pca =  93 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  93 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  93 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  93 , M_lda =  4  --->  Accuracy = 40.38%\n",
      "M_pca =  93 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  93 , M_lda =  6  --->  Accuracy = 64.42%\n",
      "M_pca =  93 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  93 , M_lda =  8  --->  Accuracy = 71.15%\n",
      "M_pca =  93 , M_lda =  9  --->  Accuracy = 73.08%\n",
      "M_pca =  93 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  93 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  93 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  93 , M_lda =  13  --->  Accuracy = 85.58%\n",
      "M_pca =  93 , M_lda =  14  --->  Accuracy = 85.58%\n",
      "M_pca =  93 , M_lda =  15  --->  Accuracy = 83.65%\n",
      "M_pca =  93 , M_lda =  16  --->  Accuracy = 87.50%\n",
      "M_pca =  93 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  93 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  93 , M_lda =  19  --->  Accuracy = 85.58%\n",
      "M_pca =  93 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  93 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  93 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  93 , M_lda =  23  --->  Accuracy = 82.69%\n",
      "M_pca =  93 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  93 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  93 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  93 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  93 , M_lda =  28  --->  Accuracy = 85.58%\n",
      "M_pca =  93 , M_lda =  29  --->  Accuracy = 84.62%\n",
      "M_pca =  93 , M_lda =  30  --->  Accuracy = 84.62%\n",
      "M_pca =  93 , M_lda =  31  --->  Accuracy = 85.58%\n",
      "M_pca =  93 , M_lda =  32  --->  Accuracy = 85.58%\n",
      "M_pca =  93 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  93 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  93 , M_lda =  35  --->  Accuracy = 83.65%\n",
      "M_pca =  93 , M_lda =  36  --->  Accuracy = 83.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  93 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  93 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  93 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  93 , M_lda =  40  --->  Accuracy = 84.62%\n",
      "M_pca =  93 , M_lda =  41  --->  Accuracy = 84.62%\n",
      "M_pca =  93 , M_lda =  42  --->  Accuracy = 83.65%\n",
      "M_pca =  93 , M_lda =  43  --->  Accuracy = 84.62%\n",
      "M_pca =  93 , M_lda =  44  --->  Accuracy = 84.62%\n",
      "M_pca =  93 , M_lda =  45  --->  Accuracy = 84.62%\n",
      "M_pca =  93 , M_lda =  46  --->  Accuracy = 81.73%\n",
      "M_pca =  93 , M_lda =  47  --->  Accuracy = 81.73%\n",
      "M_pca =  93 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  93 , M_lda =  49  --->  Accuracy = 81.73%\n",
      "M_pca =  93 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  93 , M_lda =  51  --->  Accuracy = 81.73%\n",
      "M_pca =  94 , M_lda =  1  --->  Accuracy = 10.58%\n",
      "M_pca =  94 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  94 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  94 , M_lda =  4  --->  Accuracy = 47.12%\n",
      "M_pca =  94 , M_lda =  5  --->  Accuracy = 51.92%\n",
      "M_pca =  94 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  94 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  94 , M_lda =  8  --->  Accuracy = 71.15%\n",
      "M_pca =  94 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  94 , M_lda =  10  --->  Accuracy = 73.08%\n",
      "M_pca =  94 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  94 , M_lda =  12  --->  Accuracy = 77.88%\n",
      "M_pca =  94 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  94 , M_lda =  14  --->  Accuracy = 85.58%\n",
      "M_pca =  94 , M_lda =  15  --->  Accuracy = 87.50%\n",
      "M_pca =  94 , M_lda =  16  --->  Accuracy = 88.46%\n",
      "M_pca =  94 , M_lda =  17  --->  Accuracy = 85.58%\n",
      "M_pca =  94 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  94 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  94 , M_lda =  20  --->  Accuracy = 87.50%\n",
      "M_pca =  94 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  94 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  94 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  94 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  94 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  94 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  94 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  94 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  94 , M_lda =  29  --->  Accuracy = 84.62%\n",
      "M_pca =  94 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  94 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  94 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  94 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  94 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  94 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  94 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  94 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  94 , M_lda =  38  --->  Accuracy = 85.58%\n",
      "M_pca =  94 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  94 , M_lda =  40  --->  Accuracy = 84.62%\n",
      "M_pca =  94 , M_lda =  41  --->  Accuracy = 84.62%\n",
      "M_pca =  94 , M_lda =  42  --->  Accuracy = 84.62%\n",
      "M_pca =  94 , M_lda =  43  --->  Accuracy = 84.62%\n",
      "M_pca =  94 , M_lda =  44  --->  Accuracy = 83.65%\n",
      "M_pca =  94 , M_lda =  45  --->  Accuracy = 84.62%\n",
      "M_pca =  94 , M_lda =  46  --->  Accuracy = 83.65%\n",
      "M_pca =  94 , M_lda =  47  --->  Accuracy = 82.69%\n",
      "M_pca =  94 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  94 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  94 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  94 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  95 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  95 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  95 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  95 , M_lda =  4  --->  Accuracy = 46.15%\n",
      "M_pca =  95 , M_lda =  5  --->  Accuracy = 53.85%\n",
      "M_pca =  95 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  95 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  95 , M_lda =  8  --->  Accuracy = 71.15%\n",
      "M_pca =  95 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  95 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  95 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  95 , M_lda =  12  --->  Accuracy = 79.81%\n",
      "M_pca =  95 , M_lda =  13  --->  Accuracy = 85.58%\n",
      "M_pca =  95 , M_lda =  14  --->  Accuracy = 86.54%\n",
      "M_pca =  95 , M_lda =  15  --->  Accuracy = 86.54%\n",
      "M_pca =  95 , M_lda =  16  --->  Accuracy = 88.46%\n",
      "M_pca =  95 , M_lda =  17  --->  Accuracy = 84.62%\n",
      "M_pca =  95 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  95 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  95 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  95 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  95 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  95 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  95 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  95 , M_lda =  25  --->  Accuracy = 89.42%\n",
      "M_pca =  95 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  95 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  95 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  95 , M_lda =  29  --->  Accuracy = 84.62%\n",
      "M_pca =  95 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  95 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  95 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  95 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  95 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  95 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  95 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  95 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  95 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  95 , M_lda =  39  --->  Accuracy = 84.62%\n",
      "M_pca =  95 , M_lda =  40  --->  Accuracy = 83.65%\n",
      "M_pca =  95 , M_lda =  41  --->  Accuracy = 85.58%\n",
      "M_pca =  95 , M_lda =  42  --->  Accuracy = 84.62%\n",
      "M_pca =  95 , M_lda =  43  --->  Accuracy = 83.65%\n",
      "M_pca =  95 , M_lda =  44  --->  Accuracy = 84.62%\n",
      "M_pca =  95 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  95 , M_lda =  46  --->  Accuracy = 81.73%\n",
      "M_pca =  95 , M_lda =  47  --->  Accuracy = 81.73%\n",
      "M_pca =  95 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  95 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  95 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  95 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  96 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  96 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  96 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  96 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  96 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  96 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  96 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  96 , M_lda =  8  --->  Accuracy = 72.12%\n",
      "M_pca =  96 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  96 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  96 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  96 , M_lda =  12  --->  Accuracy = 79.81%\n",
      "M_pca =  96 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  96 , M_lda =  14  --->  Accuracy = 86.54%\n",
      "M_pca =  96 , M_lda =  15  --->  Accuracy = 88.46%\n",
      "M_pca =  96 , M_lda =  16  --->  Accuracy = 87.50%\n",
      "M_pca =  96 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  96 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  96 , M_lda =  19  --->  Accuracy = 85.58%\n",
      "M_pca =  96 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  96 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  96 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  96 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  96 , M_lda =  24  --->  Accuracy = 84.62%\n",
      "M_pca =  96 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  96 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  96 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  96 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  96 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  96 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  96 , M_lda =  31  --->  Accuracy = 85.58%\n",
      "M_pca =  96 , M_lda =  32  --->  Accuracy = 85.58%\n",
      "M_pca =  96 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  96 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  96 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  96 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  96 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  96 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  96 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  96 , M_lda =  40  --->  Accuracy = 85.58%\n",
      "M_pca =  96 , M_lda =  41  --->  Accuracy = 85.58%\n",
      "M_pca =  96 , M_lda =  42  --->  Accuracy = 84.62%\n",
      "M_pca =  96 , M_lda =  43  --->  Accuracy = 82.69%\n",
      "M_pca =  96 , M_lda =  44  --->  Accuracy = 84.62%\n",
      "M_pca =  96 , M_lda =  45  --->  Accuracy = 85.58%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  96 , M_lda =  46  --->  Accuracy = 85.58%\n",
      "M_pca =  96 , M_lda =  47  --->  Accuracy = 82.69%\n",
      "M_pca =  96 , M_lda =  48  --->  Accuracy = 82.69%\n",
      "M_pca =  96 , M_lda =  49  --->  Accuracy = 83.65%\n",
      "M_pca =  96 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  96 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  97 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  97 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  97 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  97 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  97 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  97 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  97 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  97 , M_lda =  8  --->  Accuracy = 75.96%\n",
      "M_pca =  97 , M_lda =  9  --->  Accuracy = 76.92%\n",
      "M_pca =  97 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  97 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  97 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  97 , M_lda =  13  --->  Accuracy = 86.54%\n",
      "M_pca =  97 , M_lda =  14  --->  Accuracy = 86.54%\n",
      "M_pca =  97 , M_lda =  15  --->  Accuracy = 88.46%\n",
      "M_pca =  97 , M_lda =  16  --->  Accuracy = 86.54%\n",
      "M_pca =  97 , M_lda =  17  --->  Accuracy = 85.58%\n",
      "M_pca =  97 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  97 , M_lda =  19  --->  Accuracy = 85.58%\n",
      "M_pca =  97 , M_lda =  20  --->  Accuracy = 87.50%\n",
      "M_pca =  97 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  97 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  97 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  97 , M_lda =  24  --->  Accuracy = 84.62%\n",
      "M_pca =  97 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  97 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  97 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  97 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  97 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  97 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  97 , M_lda =  31  --->  Accuracy = 83.65%\n",
      "M_pca =  97 , M_lda =  32  --->  Accuracy = 84.62%\n",
      "M_pca =  97 , M_lda =  33  --->  Accuracy = 82.69%\n",
      "M_pca =  97 , M_lda =  34  --->  Accuracy = 83.65%\n",
      "M_pca =  97 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  97 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  97 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  97 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  97 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  97 , M_lda =  40  --->  Accuracy = 85.58%\n",
      "M_pca =  97 , M_lda =  41  --->  Accuracy = 83.65%\n",
      "M_pca =  97 , M_lda =  42  --->  Accuracy = 83.65%\n",
      "M_pca =  97 , M_lda =  43  --->  Accuracy = 86.54%\n",
      "M_pca =  97 , M_lda =  44  --->  Accuracy = 84.62%\n",
      "M_pca =  97 , M_lda =  45  --->  Accuracy = 84.62%\n",
      "M_pca =  97 , M_lda =  46  --->  Accuracy = 85.58%\n",
      "M_pca =  97 , M_lda =  47  --->  Accuracy = 84.62%\n",
      "M_pca =  97 , M_lda =  48  --->  Accuracy = 85.58%\n",
      "M_pca =  97 , M_lda =  49  --->  Accuracy = 85.58%\n",
      "M_pca =  97 , M_lda =  50  --->  Accuracy = 83.65%\n",
      "M_pca =  97 , M_lda =  51  --->  Accuracy = 85.58%\n",
      "M_pca =  98 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  98 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  98 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  98 , M_lda =  4  --->  Accuracy = 46.15%\n",
      "M_pca =  98 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  98 , M_lda =  6  --->  Accuracy = 60.58%\n",
      "M_pca =  98 , M_lda =  7  --->  Accuracy = 68.27%\n",
      "M_pca =  98 , M_lda =  8  --->  Accuracy = 73.08%\n",
      "M_pca =  98 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  98 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  98 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  98 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  98 , M_lda =  13  --->  Accuracy = 85.58%\n",
      "M_pca =  98 , M_lda =  14  --->  Accuracy = 85.58%\n",
      "M_pca =  98 , M_lda =  15  --->  Accuracy = 84.62%\n",
      "M_pca =  98 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  98 , M_lda =  17  --->  Accuracy = 84.62%\n",
      "M_pca =  98 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  98 , M_lda =  19  --->  Accuracy = 85.58%\n",
      "M_pca =  98 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  98 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  98 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  98 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  98 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  98 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  98 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  98 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  98 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  98 , M_lda =  29  --->  Accuracy = 84.62%\n",
      "M_pca =  98 , M_lda =  30  --->  Accuracy = 84.62%\n",
      "M_pca =  98 , M_lda =  31  --->  Accuracy = 84.62%\n",
      "M_pca =  98 , M_lda =  32  --->  Accuracy = 83.65%\n",
      "M_pca =  98 , M_lda =  33  --->  Accuracy = 82.69%\n",
      "M_pca =  98 , M_lda =  34  --->  Accuracy = 82.69%\n",
      "M_pca =  98 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  98 , M_lda =  36  --->  Accuracy = 82.69%\n",
      "M_pca =  98 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  98 , M_lda =  38  --->  Accuracy = 85.58%\n",
      "M_pca =  98 , M_lda =  39  --->  Accuracy = 83.65%\n",
      "M_pca =  98 , M_lda =  40  --->  Accuracy = 83.65%\n",
      "M_pca =  98 , M_lda =  41  --->  Accuracy = 82.69%\n",
      "M_pca =  98 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  98 , M_lda =  43  --->  Accuracy = 82.69%\n",
      "M_pca =  98 , M_lda =  44  --->  Accuracy = 82.69%\n",
      "M_pca =  98 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  98 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  98 , M_lda =  47  --->  Accuracy = 83.65%\n",
      "M_pca =  98 , M_lda =  48  --->  Accuracy = 84.62%\n",
      "M_pca =  98 , M_lda =  49  --->  Accuracy = 84.62%\n",
      "M_pca =  98 , M_lda =  50  --->  Accuracy = 83.65%\n",
      "M_pca =  98 , M_lda =  51  --->  Accuracy = 84.62%\n",
      "M_pca =  99 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  99 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  99 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  99 , M_lda =  4  --->  Accuracy = 45.19%\n",
      "M_pca =  99 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  99 , M_lda =  6  --->  Accuracy = 60.58%\n",
      "M_pca =  99 , M_lda =  7  --->  Accuracy = 69.23%\n",
      "M_pca =  99 , M_lda =  8  --->  Accuracy = 73.08%\n",
      "M_pca =  99 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  99 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  99 , M_lda =  11  --->  Accuracy = 81.73%\n",
      "M_pca =  99 , M_lda =  12  --->  Accuracy = 82.69%\n",
      "M_pca =  99 , M_lda =  13  --->  Accuracy = 85.58%\n",
      "M_pca =  99 , M_lda =  14  --->  Accuracy = 86.54%\n",
      "M_pca =  99 , M_lda =  15  --->  Accuracy = 85.58%\n",
      "M_pca =  99 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  99 , M_lda =  17  --->  Accuracy = 85.58%\n",
      "M_pca =  99 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  99 , M_lda =  19  --->  Accuracy = 85.58%\n",
      "M_pca =  99 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  99 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  99 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  99 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  99 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  99 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  99 , M_lda =  26  --->  Accuracy = 88.46%\n",
      "M_pca =  99 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  99 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  99 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  99 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  99 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  99 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  99 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  99 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  99 , M_lda =  35  --->  Accuracy = 83.65%\n",
      "M_pca =  99 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  99 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  99 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  99 , M_lda =  39  --->  Accuracy = 84.62%\n",
      "M_pca =  99 , M_lda =  40  --->  Accuracy = 84.62%\n",
      "M_pca =  99 , M_lda =  41  --->  Accuracy = 84.62%\n",
      "M_pca =  99 , M_lda =  42  --->  Accuracy = 83.65%\n",
      "M_pca =  99 , M_lda =  43  --->  Accuracy = 83.65%\n",
      "M_pca =  99 , M_lda =  44  --->  Accuracy = 83.65%\n",
      "M_pca =  99 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  99 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  99 , M_lda =  47  --->  Accuracy = 83.65%\n",
      "M_pca =  99 , M_lda =  48  --->  Accuracy = 83.65%\n",
      "M_pca =  99 , M_lda =  49  --->  Accuracy = 83.65%\n",
      "M_pca =  99 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  99 , M_lda =  51  --->  Accuracy = 83.65%\n",
      "M_pca =  100 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  100 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  100 , M_lda =  3  --->  Accuracy = 28.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  100 , M_lda =  4  --->  Accuracy = 45.19%\n",
      "M_pca =  100 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  100 , M_lda =  6  --->  Accuracy = 60.58%\n",
      "M_pca =  100 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  100 , M_lda =  8  --->  Accuracy = 73.08%\n",
      "M_pca =  100 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  100 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  100 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  100 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  100 , M_lda =  13  --->  Accuracy = 85.58%\n",
      "M_pca =  100 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  100 , M_lda =  15  --->  Accuracy = 84.62%\n",
      "M_pca =  100 , M_lda =  16  --->  Accuracy = 86.54%\n",
      "M_pca =  100 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  100 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  100 , M_lda =  19  --->  Accuracy = 85.58%\n",
      "M_pca =  100 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  100 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  100 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  100 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  100 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  100 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  100 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  100 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  100 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  100 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  100 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  100 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  100 , M_lda =  32  --->  Accuracy = 85.58%\n",
      "M_pca =  100 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  100 , M_lda =  34  --->  Accuracy = 83.65%\n",
      "M_pca =  100 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  100 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  100 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  100 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  100 , M_lda =  39  --->  Accuracy = 85.58%\n",
      "M_pca =  100 , M_lda =  40  --->  Accuracy = 84.62%\n",
      "M_pca =  100 , M_lda =  41  --->  Accuracy = 84.62%\n",
      "M_pca =  100 , M_lda =  42  --->  Accuracy = 83.65%\n",
      "M_pca =  100 , M_lda =  43  --->  Accuracy = 83.65%\n",
      "M_pca =  100 , M_lda =  44  --->  Accuracy = 84.62%\n",
      "M_pca =  100 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  100 , M_lda =  46  --->  Accuracy = 83.65%\n",
      "M_pca =  100 , M_lda =  47  --->  Accuracy = 84.62%\n",
      "M_pca =  100 , M_lda =  48  --->  Accuracy = 83.65%\n",
      "M_pca =  100 , M_lda =  49  --->  Accuracy = 83.65%\n",
      "M_pca =  100 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  100 , M_lda =  51  --->  Accuracy = 84.62%\n",
      "M_pca =  101 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  101 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  101 , M_lda =  3  --->  Accuracy = 33.65%\n",
      "M_pca =  101 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  101 , M_lda =  5  --->  Accuracy = 52.88%\n",
      "M_pca =  101 , M_lda =  6  --->  Accuracy = 64.42%\n",
      "M_pca =  101 , M_lda =  7  --->  Accuracy = 69.23%\n",
      "M_pca =  101 , M_lda =  8  --->  Accuracy = 73.08%\n",
      "M_pca =  101 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  101 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  101 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  101 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  101 , M_lda =  13  --->  Accuracy = 86.54%\n",
      "M_pca =  101 , M_lda =  14  --->  Accuracy = 85.58%\n",
      "M_pca =  101 , M_lda =  15  --->  Accuracy = 86.54%\n",
      "M_pca =  101 , M_lda =  16  --->  Accuracy = 85.58%\n",
      "M_pca =  101 , M_lda =  17  --->  Accuracy = 84.62%\n",
      "M_pca =  101 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  101 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  101 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  101 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  101 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  101 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  101 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  101 , M_lda =  25  --->  Accuracy = 88.46%\n",
      "M_pca =  101 , M_lda =  26  --->  Accuracy = 88.46%\n",
      "M_pca =  101 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  101 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  101 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  101 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  101 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  101 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  101 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  101 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  101 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  101 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  101 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  101 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  101 , M_lda =  39  --->  Accuracy = 85.58%\n",
      "M_pca =  101 , M_lda =  40  --->  Accuracy = 85.58%\n",
      "M_pca =  101 , M_lda =  41  --->  Accuracy = 85.58%\n",
      "M_pca =  101 , M_lda =  42  --->  Accuracy = 84.62%\n",
      "M_pca =  101 , M_lda =  43  --->  Accuracy = 85.58%\n",
      "M_pca =  101 , M_lda =  44  --->  Accuracy = 85.58%\n",
      "M_pca =  101 , M_lda =  45  --->  Accuracy = 84.62%\n",
      "M_pca =  101 , M_lda =  46  --->  Accuracy = 84.62%\n",
      "M_pca =  101 , M_lda =  47  --->  Accuracy = 84.62%\n",
      "M_pca =  101 , M_lda =  48  --->  Accuracy = 84.62%\n",
      "M_pca =  101 , M_lda =  49  --->  Accuracy = 84.62%\n",
      "M_pca =  101 , M_lda =  50  --->  Accuracy = 83.65%\n",
      "M_pca =  101 , M_lda =  51  --->  Accuracy = 84.62%\n",
      "M_pca =  102 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  102 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  102 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  102 , M_lda =  4  --->  Accuracy = 45.19%\n",
      "M_pca =  102 , M_lda =  5  --->  Accuracy = 55.77%\n",
      "M_pca =  102 , M_lda =  6  --->  Accuracy = 67.31%\n",
      "M_pca =  102 , M_lda =  7  --->  Accuracy = 71.15%\n",
      "M_pca =  102 , M_lda =  8  --->  Accuracy = 75.00%\n",
      "M_pca =  102 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  102 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  102 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  102 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  102 , M_lda =  13  --->  Accuracy = 86.54%\n",
      "M_pca =  102 , M_lda =  14  --->  Accuracy = 87.50%\n",
      "M_pca =  102 , M_lda =  15  --->  Accuracy = 86.54%\n",
      "M_pca =  102 , M_lda =  16  --->  Accuracy = 87.50%\n",
      "M_pca =  102 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  102 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  102 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  102 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  102 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  102 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  102 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  102 , M_lda =  24  --->  Accuracy = 89.42%\n",
      "M_pca =  102 , M_lda =  25  --->  Accuracy = 88.46%\n",
      "M_pca =  102 , M_lda =  26  --->  Accuracy = 88.46%\n",
      "M_pca =  102 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  102 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  102 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  102 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  102 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  102 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  102 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  102 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  102 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  102 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  102 , M_lda =  37  --->  Accuracy = 84.62%\n",
      "M_pca =  102 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  102 , M_lda =  39  --->  Accuracy = 85.58%\n",
      "M_pca =  102 , M_lda =  40  --->  Accuracy = 85.58%\n",
      "M_pca =  102 , M_lda =  41  --->  Accuracy = 86.54%\n",
      "M_pca =  102 , M_lda =  42  --->  Accuracy = 85.58%\n",
      "M_pca =  102 , M_lda =  43  --->  Accuracy = 86.54%\n",
      "M_pca =  102 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  102 , M_lda =  45  --->  Accuracy = 85.58%\n",
      "M_pca =  102 , M_lda =  46  --->  Accuracy = 85.58%\n",
      "M_pca =  102 , M_lda =  47  --->  Accuracy = 85.58%\n",
      "M_pca =  102 , M_lda =  48  --->  Accuracy = 84.62%\n",
      "M_pca =  102 , M_lda =  49  --->  Accuracy = 86.54%\n",
      "M_pca =  102 , M_lda =  50  --->  Accuracy = 83.65%\n",
      "M_pca =  102 , M_lda =  51  --->  Accuracy = 84.62%\n",
      "M_pca =  103 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  103 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  103 , M_lda =  3  --->  Accuracy = 35.58%\n",
      "M_pca =  103 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  103 , M_lda =  5  --->  Accuracy = 55.77%\n",
      "M_pca =  103 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  103 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  103 , M_lda =  8  --->  Accuracy = 74.04%\n",
      "M_pca =  103 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  103 , M_lda =  10  --->  Accuracy = 76.92%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  103 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  103 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  103 , M_lda =  13  --->  Accuracy = 85.58%\n",
      "M_pca =  103 , M_lda =  14  --->  Accuracy = 85.58%\n",
      "M_pca =  103 , M_lda =  15  --->  Accuracy = 86.54%\n",
      "M_pca =  103 , M_lda =  16  --->  Accuracy = 89.42%\n",
      "M_pca =  103 , M_lda =  17  --->  Accuracy = 85.58%\n",
      "M_pca =  103 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  103 , M_lda =  19  --->  Accuracy = 88.46%\n",
      "M_pca =  103 , M_lda =  20  --->  Accuracy = 89.42%\n",
      "M_pca =  103 , M_lda =  21  --->  Accuracy = 88.46%\n",
      "M_pca =  103 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  103 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  103 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  103 , M_lda =  25  --->  Accuracy = 89.42%\n",
      "M_pca =  103 , M_lda =  26  --->  Accuracy = 89.42%\n",
      "M_pca =  103 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  103 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  103 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  103 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  103 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  103 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  103 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  103 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  103 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  103 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  103 , M_lda =  37  --->  Accuracy = 84.62%\n",
      "M_pca =  103 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  103 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  103 , M_lda =  40  --->  Accuracy = 86.54%\n",
      "M_pca =  103 , M_lda =  41  --->  Accuracy = 85.58%\n",
      "M_pca =  103 , M_lda =  42  --->  Accuracy = 85.58%\n",
      "M_pca =  103 , M_lda =  43  --->  Accuracy = 86.54%\n",
      "M_pca =  103 , M_lda =  44  --->  Accuracy = 85.58%\n",
      "M_pca =  103 , M_lda =  45  --->  Accuracy = 85.58%\n",
      "M_pca =  103 , M_lda =  46  --->  Accuracy = 86.54%\n",
      "M_pca =  103 , M_lda =  47  --->  Accuracy = 86.54%\n",
      "M_pca =  103 , M_lda =  48  --->  Accuracy = 86.54%\n",
      "M_pca =  103 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  103 , M_lda =  50  --->  Accuracy = 85.58%\n",
      "M_pca =  103 , M_lda =  51  --->  Accuracy = 85.58%\n",
      "M_pca =  104 , M_lda =  1  --->  Accuracy = 1.92%\n",
      "M_pca =  104 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  104 , M_lda =  3  --->  Accuracy = 35.58%\n",
      "M_pca =  104 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  104 , M_lda =  5  --->  Accuracy = 54.81%\n",
      "M_pca =  104 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  104 , M_lda =  7  --->  Accuracy = 67.31%\n",
      "M_pca =  104 , M_lda =  8  --->  Accuracy = 75.00%\n",
      "M_pca =  104 , M_lda =  9  --->  Accuracy = 77.88%\n",
      "M_pca =  104 , M_lda =  10  --->  Accuracy = 80.77%\n",
      "M_pca =  104 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  104 , M_lda =  12  --->  Accuracy = 82.69%\n",
      "M_pca =  104 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  104 , M_lda =  14  --->  Accuracy = 86.54%\n",
      "M_pca =  104 , M_lda =  15  --->  Accuracy = 85.58%\n",
      "M_pca =  104 , M_lda =  16  --->  Accuracy = 88.46%\n",
      "M_pca =  104 , M_lda =  17  --->  Accuracy = 84.62%\n",
      "M_pca =  104 , M_lda =  18  --->  Accuracy = 83.65%\n",
      "M_pca =  104 , M_lda =  19  --->  Accuracy = 87.50%\n",
      "M_pca =  104 , M_lda =  20  --->  Accuracy = 88.46%\n",
      "M_pca =  104 , M_lda =  21  --->  Accuracy = 88.46%\n",
      "M_pca =  104 , M_lda =  22  --->  Accuracy = 88.46%\n",
      "M_pca =  104 , M_lda =  23  --->  Accuracy = 89.42%\n",
      "M_pca =  104 , M_lda =  24  --->  Accuracy = 90.38%\n",
      "M_pca =  104 , M_lda =  25  --->  Accuracy = 89.42%\n",
      "M_pca =  104 , M_lda =  26  --->  Accuracy = 89.42%\n",
      "M_pca =  104 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  104 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  104 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  104 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  104 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  104 , M_lda =  32  --->  Accuracy = 85.58%\n",
      "M_pca =  104 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  104 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  104 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  104 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  104 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  104 , M_lda =  38  --->  Accuracy = 83.65%\n",
      "M_pca =  104 , M_lda =  39  --->  Accuracy = 83.65%\n",
      "M_pca =  104 , M_lda =  40  --->  Accuracy = 83.65%\n",
      "M_pca =  104 , M_lda =  41  --->  Accuracy = 84.62%\n",
      "M_pca =  104 , M_lda =  42  --->  Accuracy = 84.62%\n",
      "M_pca =  104 , M_lda =  43  --->  Accuracy = 84.62%\n",
      "M_pca =  104 , M_lda =  44  --->  Accuracy = 83.65%\n",
      "M_pca =  104 , M_lda =  45  --->  Accuracy = 85.58%\n",
      "M_pca =  104 , M_lda =  46  --->  Accuracy = 85.58%\n",
      "M_pca =  104 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  104 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  104 , M_lda =  49  --->  Accuracy = 84.62%\n",
      "M_pca =  104 , M_lda =  50  --->  Accuracy = 83.65%\n",
      "M_pca =  104 , M_lda =  51  --->  Accuracy = 83.65%\n",
      "M_pca =  105 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  105 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  105 , M_lda =  3  --->  Accuracy = 33.65%\n",
      "M_pca =  105 , M_lda =  4  --->  Accuracy = 46.15%\n",
      "M_pca =  105 , M_lda =  5  --->  Accuracy = 54.81%\n",
      "M_pca =  105 , M_lda =  6  --->  Accuracy = 60.58%\n",
      "M_pca =  105 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  105 , M_lda =  8  --->  Accuracy = 75.96%\n",
      "M_pca =  105 , M_lda =  9  --->  Accuracy = 76.92%\n",
      "M_pca =  105 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  105 , M_lda =  11  --->  Accuracy = 81.73%\n",
      "M_pca =  105 , M_lda =  12  --->  Accuracy = 82.69%\n",
      "M_pca =  105 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  105 , M_lda =  14  --->  Accuracy = 86.54%\n",
      "M_pca =  105 , M_lda =  15  --->  Accuracy = 86.54%\n",
      "M_pca =  105 , M_lda =  16  --->  Accuracy = 89.42%\n",
      "M_pca =  105 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  105 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  105 , M_lda =  19  --->  Accuracy = 88.46%\n",
      "M_pca =  105 , M_lda =  20  --->  Accuracy = 89.42%\n",
      "M_pca =  105 , M_lda =  21  --->  Accuracy = 88.46%\n",
      "M_pca =  105 , M_lda =  22  --->  Accuracy = 88.46%\n",
      "M_pca =  105 , M_lda =  23  --->  Accuracy = 89.42%\n",
      "M_pca =  105 , M_lda =  24  --->  Accuracy = 90.38%\n",
      "M_pca =  105 , M_lda =  25  --->  Accuracy = 90.38%\n",
      "M_pca =  105 , M_lda =  26  --->  Accuracy = 89.42%\n",
      "M_pca =  105 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  105 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  105 , M_lda =  29  --->  Accuracy = 89.42%\n",
      "M_pca =  105 , M_lda =  30  --->  Accuracy = 89.42%\n",
      "M_pca =  105 , M_lda =  31  --->  Accuracy = 89.42%\n",
      "M_pca =  105 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  105 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  105 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  105 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  105 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  105 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  105 , M_lda =  38  --->  Accuracy = 85.58%\n",
      "M_pca =  105 , M_lda =  39  --->  Accuracy = 84.62%\n",
      "M_pca =  105 , M_lda =  40  --->  Accuracy = 85.58%\n",
      "M_pca =  105 , M_lda =  41  --->  Accuracy = 84.62%\n",
      "M_pca =  105 , M_lda =  42  --->  Accuracy = 85.58%\n",
      "M_pca =  105 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  105 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  105 , M_lda =  45  --->  Accuracy = 86.54%\n",
      "M_pca =  105 , M_lda =  46  --->  Accuracy = 86.54%\n",
      "M_pca =  105 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  105 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  105 , M_lda =  49  --->  Accuracy = 85.58%\n",
      "M_pca =  105 , M_lda =  50  --->  Accuracy = 85.58%\n",
      "M_pca =  105 , M_lda =  51  --->  Accuracy = 85.58%\n",
      "M_pca =  106 , M_lda =  1  --->  Accuracy = 11.54%\n",
      "M_pca =  106 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  106 , M_lda =  3  --->  Accuracy = 36.54%\n",
      "M_pca =  106 , M_lda =  4  --->  Accuracy = 50.00%\n",
      "M_pca =  106 , M_lda =  5  --->  Accuracy = 53.85%\n",
      "M_pca =  106 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  106 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  106 , M_lda =  8  --->  Accuracy = 74.04%\n",
      "M_pca =  106 , M_lda =  9  --->  Accuracy = 77.88%\n",
      "M_pca =  106 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  106 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  106 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  106 , M_lda =  13  --->  Accuracy = 84.62%\n",
      "M_pca =  106 , M_lda =  14  --->  Accuracy = 87.50%\n",
      "M_pca =  106 , M_lda =  15  --->  Accuracy = 87.50%\n",
      "M_pca =  106 , M_lda =  16  --->  Accuracy = 89.42%\n",
      "M_pca =  106 , M_lda =  17  --->  Accuracy = 88.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  106 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  106 , M_lda =  19  --->  Accuracy = 90.38%\n",
      "M_pca =  106 , M_lda =  20  --->  Accuracy = 90.38%\n",
      "M_pca =  106 , M_lda =  21  --->  Accuracy = 89.42%\n",
      "M_pca =  106 , M_lda =  22  --->  Accuracy = 89.42%\n",
      "M_pca =  106 , M_lda =  23  --->  Accuracy = 89.42%\n",
      "M_pca =  106 , M_lda =  24  --->  Accuracy = 89.42%\n",
      "M_pca =  106 , M_lda =  25  --->  Accuracy = 90.38%\n",
      "M_pca =  106 , M_lda =  26  --->  Accuracy = 89.42%\n",
      "M_pca =  106 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  106 , M_lda =  28  --->  Accuracy = 90.38%\n",
      "M_pca =  106 , M_lda =  29  --->  Accuracy = 89.42%\n",
      "M_pca =  106 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  106 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  106 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  106 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  106 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  106 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  106 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  106 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  106 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  106 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  106 , M_lda =  40  --->  Accuracy = 86.54%\n",
      "M_pca =  106 , M_lda =  41  --->  Accuracy = 86.54%\n",
      "M_pca =  106 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  106 , M_lda =  43  --->  Accuracy = 86.54%\n",
      "M_pca =  106 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  106 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  106 , M_lda =  46  --->  Accuracy = 86.54%\n",
      "M_pca =  106 , M_lda =  47  --->  Accuracy = 86.54%\n",
      "M_pca =  106 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  106 , M_lda =  49  --->  Accuracy = 85.58%\n",
      "M_pca =  106 , M_lda =  50  --->  Accuracy = 85.58%\n",
      "M_pca =  106 , M_lda =  51  --->  Accuracy = 85.58%\n",
      "M_pca =  107 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  107 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  107 , M_lda =  3  --->  Accuracy = 35.58%\n",
      "M_pca =  107 , M_lda =  4  --->  Accuracy = 48.08%\n",
      "M_pca =  107 , M_lda =  5  --->  Accuracy = 56.73%\n",
      "M_pca =  107 , M_lda =  6  --->  Accuracy = 63.46%\n",
      "M_pca =  107 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  107 , M_lda =  8  --->  Accuracy = 73.08%\n",
      "M_pca =  107 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  107 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  107 , M_lda =  11  --->  Accuracy = 81.73%\n",
      "M_pca =  107 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  107 , M_lda =  13  --->  Accuracy = 85.58%\n",
      "M_pca =  107 , M_lda =  14  --->  Accuracy = 86.54%\n",
      "M_pca =  107 , M_lda =  15  --->  Accuracy = 89.42%\n",
      "M_pca =  107 , M_lda =  16  --->  Accuracy = 88.46%\n",
      "M_pca =  107 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  107 , M_lda =  18  --->  Accuracy = 87.50%\n",
      "M_pca =  107 , M_lda =  19  --->  Accuracy = 89.42%\n",
      "M_pca =  107 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  107 , M_lda =  21  --->  Accuracy = 87.50%\n",
      "M_pca =  107 , M_lda =  22  --->  Accuracy = 88.46%\n",
      "M_pca =  107 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  107 , M_lda =  24  --->  Accuracy = 89.42%\n",
      "M_pca =  107 , M_lda =  25  --->  Accuracy = 90.38%\n",
      "M_pca =  107 , M_lda =  26  --->  Accuracy = 89.42%\n",
      "M_pca =  107 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  107 , M_lda =  28  --->  Accuracy = 90.38%\n",
      "M_pca =  107 , M_lda =  29  --->  Accuracy = 89.42%\n",
      "M_pca =  107 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  107 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  107 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  107 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  107 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  107 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  107 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  107 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  107 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  107 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  107 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  107 , M_lda =  41  --->  Accuracy = 86.54%\n",
      "M_pca =  107 , M_lda =  42  --->  Accuracy = 86.54%\n",
      "M_pca =  107 , M_lda =  43  --->  Accuracy = 84.62%\n",
      "M_pca =  107 , M_lda =  44  --->  Accuracy = 85.58%\n",
      "M_pca =  107 , M_lda =  45  --->  Accuracy = 85.58%\n",
      "M_pca =  107 , M_lda =  46  --->  Accuracy = 85.58%\n",
      "M_pca =  107 , M_lda =  47  --->  Accuracy = 86.54%\n",
      "M_pca =  107 , M_lda =  48  --->  Accuracy = 85.58%\n",
      "M_pca =  107 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  107 , M_lda =  50  --->  Accuracy = 84.62%\n",
      "M_pca =  107 , M_lda =  51  --->  Accuracy = 85.58%\n",
      "M_pca =  108 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  108 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  108 , M_lda =  3  --->  Accuracy = 36.54%\n",
      "M_pca =  108 , M_lda =  4  --->  Accuracy = 50.00%\n",
      "M_pca =  108 , M_lda =  5  --->  Accuracy = 55.77%\n",
      "M_pca =  108 , M_lda =  6  --->  Accuracy = 61.54%\n",
      "M_pca =  108 , M_lda =  7  --->  Accuracy = 68.27%\n",
      "M_pca =  108 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  108 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  108 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  108 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  108 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  108 , M_lda =  13  --->  Accuracy = 85.58%\n",
      "M_pca =  108 , M_lda =  14  --->  Accuracy = 87.50%\n",
      "M_pca =  108 , M_lda =  15  --->  Accuracy = 86.54%\n",
      "M_pca =  108 , M_lda =  16  --->  Accuracy = 86.54%\n",
      "M_pca =  108 , M_lda =  17  --->  Accuracy = 87.50%\n",
      "M_pca =  108 , M_lda =  18  --->  Accuracy = 86.54%\n",
      "M_pca =  108 , M_lda =  19  --->  Accuracy = 89.42%\n",
      "M_pca =  108 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  108 , M_lda =  21  --->  Accuracy = 87.50%\n",
      "M_pca =  108 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  108 , M_lda =  23  --->  Accuracy = 89.42%\n",
      "M_pca =  108 , M_lda =  24  --->  Accuracy = 90.38%\n",
      "M_pca =  108 , M_lda =  25  --->  Accuracy = 88.46%\n",
      "M_pca =  108 , M_lda =  26  --->  Accuracy = 89.42%\n",
      "M_pca =  108 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  108 , M_lda =  28  --->  Accuracy = 89.42%\n",
      "M_pca =  108 , M_lda =  29  --->  Accuracy = 90.38%\n",
      "M_pca =  108 , M_lda =  30  --->  Accuracy = 90.38%\n",
      "M_pca =  108 , M_lda =  31  --->  Accuracy = 90.38%\n",
      "M_pca =  108 , M_lda =  32  --->  Accuracy = 89.42%\n",
      "M_pca =  108 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  108 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  108 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  108 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  108 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  108 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  108 , M_lda =  39  --->  Accuracy = 85.58%\n",
      "M_pca =  108 , M_lda =  40  --->  Accuracy = 84.62%\n",
      "M_pca =  108 , M_lda =  41  --->  Accuracy = 85.58%\n",
      "M_pca =  108 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  108 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  108 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  108 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  108 , M_lda =  46  --->  Accuracy = 86.54%\n",
      "M_pca =  108 , M_lda =  47  --->  Accuracy = 86.54%\n",
      "M_pca =  108 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  108 , M_lda =  49  --->  Accuracy = 85.58%\n",
      "M_pca =  108 , M_lda =  50  --->  Accuracy = 84.62%\n",
      "M_pca =  108 , M_lda =  51  --->  Accuracy = 85.58%\n",
      "M_pca =  109 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  109 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  109 , M_lda =  3  --->  Accuracy = 35.58%\n",
      "M_pca =  109 , M_lda =  4  --->  Accuracy = 50.96%\n",
      "M_pca =  109 , M_lda =  5  --->  Accuracy = 52.88%\n",
      "M_pca =  109 , M_lda =  6  --->  Accuracy = 61.54%\n",
      "M_pca =  109 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  109 , M_lda =  8  --->  Accuracy = 69.23%\n",
      "M_pca =  109 , M_lda =  9  --->  Accuracy = 77.88%\n",
      "M_pca =  109 , M_lda =  10  --->  Accuracy = 80.77%\n",
      "M_pca =  109 , M_lda =  11  --->  Accuracy = 81.73%\n",
      "M_pca =  109 , M_lda =  12  --->  Accuracy = 83.65%\n",
      "M_pca =  109 , M_lda =  13  --->  Accuracy = 86.54%\n",
      "M_pca =  109 , M_lda =  14  --->  Accuracy = 88.46%\n",
      "M_pca =  109 , M_lda =  15  --->  Accuracy = 90.38%\n",
      "M_pca =  109 , M_lda =  16  --->  Accuracy = 87.50%\n",
      "M_pca =  109 , M_lda =  17  --->  Accuracy = 87.50%\n",
      "M_pca =  109 , M_lda =  18  --->  Accuracy = 87.50%\n",
      "M_pca =  109 , M_lda =  19  --->  Accuracy = 91.35%\n",
      "M_pca =  109 , M_lda =  20  --->  Accuracy = 88.46%\n",
      "M_pca =  109 , M_lda =  21  --->  Accuracy = 88.46%\n",
      "M_pca =  109 , M_lda =  22  --->  Accuracy = 89.42%\n",
      "M_pca =  109 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  109 , M_lda =  24  --->  Accuracy = 89.42%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  109 , M_lda =  25  --->  Accuracy = 88.46%\n",
      "M_pca =  109 , M_lda =  26  --->  Accuracy = 89.42%\n",
      "M_pca =  109 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  109 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  109 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  109 , M_lda =  30  --->  Accuracy = 89.42%\n",
      "M_pca =  109 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  109 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  109 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  109 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  109 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  109 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  109 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  109 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  109 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  109 , M_lda =  40  --->  Accuracy = 85.58%\n",
      "M_pca =  109 , M_lda =  41  --->  Accuracy = 84.62%\n",
      "M_pca =  109 , M_lda =  42  --->  Accuracy = 86.54%\n",
      "M_pca =  109 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  109 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  109 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  109 , M_lda =  46  --->  Accuracy = 86.54%\n",
      "M_pca =  109 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  109 , M_lda =  48  --->  Accuracy = 86.54%\n",
      "M_pca =  109 , M_lda =  49  --->  Accuracy = 85.58%\n",
      "M_pca =  109 , M_lda =  50  --->  Accuracy = 84.62%\n",
      "M_pca =  109 , M_lda =  51  --->  Accuracy = 85.58%\n",
      "M_pca =  110 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  110 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  110 , M_lda =  3  --->  Accuracy = 39.42%\n",
      "M_pca =  110 , M_lda =  4  --->  Accuracy = 49.04%\n",
      "M_pca =  110 , M_lda =  5  --->  Accuracy = 54.81%\n",
      "M_pca =  110 , M_lda =  6  --->  Accuracy = 60.58%\n",
      "M_pca =  110 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  110 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  110 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  110 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  110 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  110 , M_lda =  12  --->  Accuracy = 82.69%\n",
      "M_pca =  110 , M_lda =  13  --->  Accuracy = 86.54%\n",
      "M_pca =  110 , M_lda =  14  --->  Accuracy = 89.42%\n",
      "M_pca =  110 , M_lda =  15  --->  Accuracy = 92.31%\n",
      "M_pca =  110 , M_lda =  16  --->  Accuracy = 89.42%\n",
      "M_pca =  110 , M_lda =  17  --->  Accuracy = 89.42%\n",
      "M_pca =  110 , M_lda =  18  --->  Accuracy = 88.46%\n",
      "M_pca =  110 , M_lda =  19  --->  Accuracy = 90.38%\n",
      "M_pca =  110 , M_lda =  20  --->  Accuracy = 87.50%\n",
      "M_pca =  110 , M_lda =  21  --->  Accuracy = 89.42%\n",
      "M_pca =  110 , M_lda =  22  --->  Accuracy = 89.42%\n",
      "M_pca =  110 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  110 , M_lda =  24  --->  Accuracy = 89.42%\n",
      "M_pca =  110 , M_lda =  25  --->  Accuracy = 90.38%\n",
      "M_pca =  110 , M_lda =  26  --->  Accuracy = 90.38%\n",
      "M_pca =  110 , M_lda =  27  --->  Accuracy = 89.42%\n",
      "M_pca =  110 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  110 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  110 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  110 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  110 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  110 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  110 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  110 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  110 , M_lda =  36  --->  Accuracy = 89.42%\n",
      "M_pca =  110 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  110 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  110 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  110 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  110 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  110 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  110 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  110 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  110 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  110 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  110 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  110 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  110 , M_lda =  49  --->  Accuracy = 86.54%\n",
      "M_pca =  110 , M_lda =  50  --->  Accuracy = 85.58%\n",
      "M_pca =  110 , M_lda =  51  --->  Accuracy = 85.58%\n",
      "M_pca =  111 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  111 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  111 , M_lda =  3  --->  Accuracy = 39.42%\n",
      "M_pca =  111 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  111 , M_lda =  5  --->  Accuracy = 52.88%\n",
      "M_pca =  111 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  111 , M_lda =  7  --->  Accuracy = 60.58%\n",
      "M_pca =  111 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  111 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  111 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  111 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  111 , M_lda =  12  --->  Accuracy = 85.58%\n",
      "M_pca =  111 , M_lda =  13  --->  Accuracy = 86.54%\n",
      "M_pca =  111 , M_lda =  14  --->  Accuracy = 88.46%\n",
      "M_pca =  111 , M_lda =  15  --->  Accuracy = 91.35%\n",
      "M_pca =  111 , M_lda =  16  --->  Accuracy = 89.42%\n",
      "M_pca =  111 , M_lda =  17  --->  Accuracy = 87.50%\n",
      "M_pca =  111 , M_lda =  18  --->  Accuracy = 87.50%\n",
      "M_pca =  111 , M_lda =  19  --->  Accuracy = 89.42%\n",
      "M_pca =  111 , M_lda =  20  --->  Accuracy = 87.50%\n",
      "M_pca =  111 , M_lda =  21  --->  Accuracy = 89.42%\n",
      "M_pca =  111 , M_lda =  22  --->  Accuracy = 89.42%\n",
      "M_pca =  111 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  111 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  111 , M_lda =  25  --->  Accuracy = 88.46%\n",
      "M_pca =  111 , M_lda =  26  --->  Accuracy = 88.46%\n",
      "M_pca =  111 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  111 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  111 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  111 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  111 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  111 , M_lda =  32  --->  Accuracy = 89.42%\n",
      "M_pca =  111 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  111 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  111 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  111 , M_lda =  36  --->  Accuracy = 89.42%\n",
      "M_pca =  111 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  111 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  111 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  111 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  111 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  111 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  111 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  111 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  111 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  111 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  111 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  111 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  111 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  111 , M_lda =  50  --->  Accuracy = 86.54%\n",
      "M_pca =  111 , M_lda =  51  --->  Accuracy = 86.54%\n",
      "M_pca =  112 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  112 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  112 , M_lda =  3  --->  Accuracy = 42.31%\n",
      "M_pca =  112 , M_lda =  4  --->  Accuracy = 45.19%\n",
      "M_pca =  112 , M_lda =  5  --->  Accuracy = 50.96%\n",
      "M_pca =  112 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  112 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  112 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  112 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  112 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  112 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  112 , M_lda =  12  --->  Accuracy = 82.69%\n",
      "M_pca =  112 , M_lda =  13  --->  Accuracy = 86.54%\n",
      "M_pca =  112 , M_lda =  14  --->  Accuracy = 88.46%\n",
      "M_pca =  112 , M_lda =  15  --->  Accuracy = 87.50%\n",
      "M_pca =  112 , M_lda =  16  --->  Accuracy = 89.42%\n",
      "M_pca =  112 , M_lda =  17  --->  Accuracy = 89.42%\n",
      "M_pca =  112 , M_lda =  18  --->  Accuracy = 90.38%\n",
      "M_pca =  112 , M_lda =  19  --->  Accuracy = 90.38%\n",
      "M_pca =  112 , M_lda =  20  --->  Accuracy = 88.46%\n",
      "M_pca =  112 , M_lda =  21  --->  Accuracy = 89.42%\n",
      "M_pca =  112 , M_lda =  22  --->  Accuracy = 89.42%\n",
      "M_pca =  112 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  112 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  112 , M_lda =  25  --->  Accuracy = 89.42%\n",
      "M_pca =  112 , M_lda =  26  --->  Accuracy = 88.46%\n",
      "M_pca =  112 , M_lda =  27  --->  Accuracy = 89.42%\n",
      "M_pca =  112 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  112 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  112 , M_lda =  30  --->  Accuracy = 90.38%\n",
      "M_pca =  112 , M_lda =  31  --->  Accuracy = 90.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  112 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  112 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  112 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  112 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  112 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  112 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  112 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  112 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  112 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  112 , M_lda =  41  --->  Accuracy = 86.54%\n",
      "M_pca =  112 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  112 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  112 , M_lda =  44  --->  Accuracy = 86.54%\n",
      "M_pca =  112 , M_lda =  45  --->  Accuracy = 86.54%\n",
      "M_pca =  112 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  112 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  112 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  112 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  112 , M_lda =  50  --->  Accuracy = 86.54%\n",
      "M_pca =  112 , M_lda =  51  --->  Accuracy = 86.54%\n",
      "M_pca =  113 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  113 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  113 , M_lda =  3  --->  Accuracy = 42.31%\n",
      "M_pca =  113 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  113 , M_lda =  5  --->  Accuracy = 54.81%\n",
      "M_pca =  113 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  113 , M_lda =  7  --->  Accuracy = 61.54%\n",
      "M_pca =  113 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  113 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  113 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  113 , M_lda =  11  --->  Accuracy = 82.69%\n",
      "M_pca =  113 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  113 , M_lda =  13  --->  Accuracy = 84.62%\n",
      "M_pca =  113 , M_lda =  14  --->  Accuracy = 87.50%\n",
      "M_pca =  113 , M_lda =  15  --->  Accuracy = 86.54%\n",
      "M_pca =  113 , M_lda =  16  --->  Accuracy = 87.50%\n",
      "M_pca =  113 , M_lda =  17  --->  Accuracy = 88.46%\n",
      "M_pca =  113 , M_lda =  18  --->  Accuracy = 87.50%\n",
      "M_pca =  113 , M_lda =  19  --->  Accuracy = 87.50%\n",
      "M_pca =  113 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  113 , M_lda =  21  --->  Accuracy = 87.50%\n",
      "M_pca =  113 , M_lda =  22  --->  Accuracy = 88.46%\n",
      "M_pca =  113 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  113 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  113 , M_lda =  25  --->  Accuracy = 90.38%\n",
      "M_pca =  113 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  113 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  113 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  113 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  113 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  113 , M_lda =  31  --->  Accuracy = 90.38%\n",
      "M_pca =  113 , M_lda =  32  --->  Accuracy = 89.42%\n",
      "M_pca =  113 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  113 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  113 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  113 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  113 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  113 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  113 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  113 , M_lda =  40  --->  Accuracy = 86.54%\n",
      "M_pca =  113 , M_lda =  41  --->  Accuracy = 86.54%\n",
      "M_pca =  113 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  113 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  113 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  113 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  113 , M_lda =  46  --->  Accuracy = 87.50%\n",
      "M_pca =  113 , M_lda =  47  --->  Accuracy = 86.54%\n",
      "M_pca =  113 , M_lda =  48  --->  Accuracy = 86.54%\n",
      "M_pca =  113 , M_lda =  49  --->  Accuracy = 84.62%\n",
      "M_pca =  113 , M_lda =  50  --->  Accuracy = 85.58%\n",
      "M_pca =  113 , M_lda =  51  --->  Accuracy = 85.58%\n",
      "M_pca =  114 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  114 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  114 , M_lda =  3  --->  Accuracy = 40.38%\n",
      "M_pca =  114 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  114 , M_lda =  5  --->  Accuracy = 51.92%\n",
      "M_pca =  114 , M_lda =  6  --->  Accuracy = 52.88%\n",
      "M_pca =  114 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  114 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  114 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  114 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  114 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  114 , M_lda =  12  --->  Accuracy = 84.62%\n",
      "M_pca =  114 , M_lda =  13  --->  Accuracy = 84.62%\n",
      "M_pca =  114 , M_lda =  14  --->  Accuracy = 88.46%\n",
      "M_pca =  114 , M_lda =  15  --->  Accuracy = 86.54%\n",
      "M_pca =  114 , M_lda =  16  --->  Accuracy = 85.58%\n",
      "M_pca =  114 , M_lda =  17  --->  Accuracy = 87.50%\n",
      "M_pca =  114 , M_lda =  18  --->  Accuracy = 87.50%\n",
      "M_pca =  114 , M_lda =  19  --->  Accuracy = 89.42%\n",
      "M_pca =  114 , M_lda =  20  --->  Accuracy = 87.50%\n",
      "M_pca =  114 , M_lda =  21  --->  Accuracy = 87.50%\n",
      "M_pca =  114 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  114 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  114 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  114 , M_lda =  25  --->  Accuracy = 89.42%\n",
      "M_pca =  114 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  114 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  114 , M_lda =  28  --->  Accuracy = 89.42%\n",
      "M_pca =  114 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  114 , M_lda =  30  --->  Accuracy = 89.42%\n",
      "M_pca =  114 , M_lda =  31  --->  Accuracy = 90.38%\n",
      "M_pca =  114 , M_lda =  32  --->  Accuracy = 89.42%\n",
      "M_pca =  114 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  114 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  114 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  114 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  114 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  114 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  114 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  114 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  114 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  114 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  114 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  114 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  114 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  114 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  114 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  114 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  114 , M_lda =  49  --->  Accuracy = 86.54%\n",
      "M_pca =  114 , M_lda =  50  --->  Accuracy = 86.54%\n",
      "M_pca =  114 , M_lda =  51  --->  Accuracy = 85.58%\n",
      "M_pca =  115 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  115 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  115 , M_lda =  3  --->  Accuracy = 34.62%\n",
      "M_pca =  115 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  115 , M_lda =  5  --->  Accuracy = 50.96%\n",
      "M_pca =  115 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  115 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  115 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  115 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  115 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  115 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  115 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  115 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  115 , M_lda =  14  --->  Accuracy = 87.50%\n",
      "M_pca =  115 , M_lda =  15  --->  Accuracy = 85.58%\n",
      "M_pca =  115 , M_lda =  16  --->  Accuracy = 85.58%\n",
      "M_pca =  115 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  115 , M_lda =  18  --->  Accuracy = 87.50%\n",
      "M_pca =  115 , M_lda =  19  --->  Accuracy = 87.50%\n",
      "M_pca =  115 , M_lda =  20  --->  Accuracy = 87.50%\n",
      "M_pca =  115 , M_lda =  21  --->  Accuracy = 88.46%\n",
      "M_pca =  115 , M_lda =  22  --->  Accuracy = 88.46%\n",
      "M_pca =  115 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  115 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  115 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  115 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  115 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  115 , M_lda =  28  --->  Accuracy = 89.42%\n",
      "M_pca =  115 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  115 , M_lda =  30  --->  Accuracy = 89.42%\n",
      "M_pca =  115 , M_lda =  31  --->  Accuracy = 91.35%\n",
      "M_pca =  115 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  115 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  115 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  115 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  115 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  115 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  115 , M_lda =  38  --->  Accuracy = 86.54%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  115 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  115 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  115 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  115 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  115 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  115 , M_lda =  44  --->  Accuracy = 86.54%\n",
      "M_pca =  115 , M_lda =  45  --->  Accuracy = 85.58%\n",
      "M_pca =  115 , M_lda =  46  --->  Accuracy = 87.50%\n",
      "M_pca =  115 , M_lda =  47  --->  Accuracy = 86.54%\n",
      "M_pca =  115 , M_lda =  48  --->  Accuracy = 85.58%\n",
      "M_pca =  115 , M_lda =  49  --->  Accuracy = 85.58%\n",
      "M_pca =  115 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  115 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  116 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  116 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  116 , M_lda =  3  --->  Accuracy = 35.58%\n",
      "M_pca =  116 , M_lda =  4  --->  Accuracy = 47.12%\n",
      "M_pca =  116 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  116 , M_lda =  6  --->  Accuracy = 54.81%\n",
      "M_pca =  116 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  116 , M_lda =  8  --->  Accuracy = 64.42%\n",
      "M_pca =  116 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  116 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  116 , M_lda =  11  --->  Accuracy = 75.96%\n",
      "M_pca =  116 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  116 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  116 , M_lda =  14  --->  Accuracy = 87.50%\n",
      "M_pca =  116 , M_lda =  15  --->  Accuracy = 84.62%\n",
      "M_pca =  116 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  116 , M_lda =  17  --->  Accuracy = 87.50%\n",
      "M_pca =  116 , M_lda =  18  --->  Accuracy = 86.54%\n",
      "M_pca =  116 , M_lda =  19  --->  Accuracy = 89.42%\n",
      "M_pca =  116 , M_lda =  20  --->  Accuracy = 88.46%\n",
      "M_pca =  116 , M_lda =  21  --->  Accuracy = 89.42%\n",
      "M_pca =  116 , M_lda =  22  --->  Accuracy = 89.42%\n",
      "M_pca =  116 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  116 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  116 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  116 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  116 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  116 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  116 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  116 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  116 , M_lda =  31  --->  Accuracy = 89.42%\n",
      "M_pca =  116 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  116 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  116 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  116 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  116 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  116 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  116 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  116 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  116 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  116 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  116 , M_lda =  42  --->  Accuracy = 86.54%\n",
      "M_pca =  116 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  116 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  116 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  116 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  116 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  116 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  116 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  116 , M_lda =  50  --->  Accuracy = 85.58%\n",
      "M_pca =  116 , M_lda =  51  --->  Accuracy = 84.62%\n",
      "M_pca =  117 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  117 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  117 , M_lda =  3  --->  Accuracy = 35.58%\n",
      "M_pca =  117 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  117 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  117 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  117 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  117 , M_lda =  8  --->  Accuracy = 64.42%\n",
      "M_pca =  117 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  117 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  117 , M_lda =  11  --->  Accuracy = 75.96%\n",
      "M_pca =  117 , M_lda =  12  --->  Accuracy = 77.88%\n",
      "M_pca =  117 , M_lda =  13  --->  Accuracy = 81.73%\n",
      "M_pca =  117 , M_lda =  14  --->  Accuracy = 86.54%\n",
      "M_pca =  117 , M_lda =  15  --->  Accuracy = 83.65%\n",
      "M_pca =  117 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  117 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  117 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  117 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  117 , M_lda =  20  --->  Accuracy = 88.46%\n",
      "M_pca =  117 , M_lda =  21  --->  Accuracy = 89.42%\n",
      "M_pca =  117 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  117 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  117 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  117 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  117 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  117 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  117 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  117 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  117 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  117 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  117 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  117 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  117 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  117 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  117 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  117 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  117 , M_lda =  38  --->  Accuracy = 85.58%\n",
      "M_pca =  117 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  117 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  117 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  117 , M_lda =  42  --->  Accuracy = 86.54%\n",
      "M_pca =  117 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  117 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  117 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  117 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  117 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  117 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  117 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  117 , M_lda =  50  --->  Accuracy = 85.58%\n",
      "M_pca =  117 , M_lda =  51  --->  Accuracy = 85.58%\n",
      "M_pca =  118 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  118 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  118 , M_lda =  3  --->  Accuracy = 36.54%\n",
      "M_pca =  118 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  118 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  118 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  118 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  118 , M_lda =  8  --->  Accuracy = 63.46%\n",
      "M_pca =  118 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  118 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  118 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  118 , M_lda =  12  --->  Accuracy = 82.69%\n",
      "M_pca =  118 , M_lda =  13  --->  Accuracy = 81.73%\n",
      "M_pca =  118 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  118 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  118 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  118 , M_lda =  17  --->  Accuracy = 85.58%\n",
      "M_pca =  118 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  118 , M_lda =  19  --->  Accuracy = 85.58%\n",
      "M_pca =  118 , M_lda =  20  --->  Accuracy = 87.50%\n",
      "M_pca =  118 , M_lda =  21  --->  Accuracy = 90.38%\n",
      "M_pca =  118 , M_lda =  22  --->  Accuracy = 89.42%\n",
      "M_pca =  118 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  118 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  118 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  118 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  118 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  118 , M_lda =  28  --->  Accuracy = 89.42%\n",
      "M_pca =  118 , M_lda =  29  --->  Accuracy = 89.42%\n",
      "M_pca =  118 , M_lda =  30  --->  Accuracy = 89.42%\n",
      "M_pca =  118 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  118 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  118 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  118 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  118 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  118 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  118 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  118 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  118 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  118 , M_lda =  40  --->  Accuracy = 86.54%\n",
      "M_pca =  118 , M_lda =  41  --->  Accuracy = 85.58%\n",
      "M_pca =  118 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  118 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  118 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  118 , M_lda =  45  --->  Accuracy = 87.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  118 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  118 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  118 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  118 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  118 , M_lda =  50  --->  Accuracy = 86.54%\n",
      "M_pca =  118 , M_lda =  51  --->  Accuracy = 86.54%\n",
      "M_pca =  119 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  119 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  119 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  119 , M_lda =  4  --->  Accuracy = 42.31%\n",
      "M_pca =  119 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  119 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  119 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  119 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  119 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  119 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  119 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  119 , M_lda =  12  --->  Accuracy = 82.69%\n",
      "M_pca =  119 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  119 , M_lda =  14  --->  Accuracy = 83.65%\n",
      "M_pca =  119 , M_lda =  15  --->  Accuracy = 79.81%\n",
      "M_pca =  119 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  119 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  119 , M_lda =  18  --->  Accuracy = 86.54%\n",
      "M_pca =  119 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  119 , M_lda =  20  --->  Accuracy = 87.50%\n",
      "M_pca =  119 , M_lda =  21  --->  Accuracy = 89.42%\n",
      "M_pca =  119 , M_lda =  22  --->  Accuracy = 88.46%\n",
      "M_pca =  119 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  119 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  119 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  119 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  119 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  119 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  119 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  119 , M_lda =  30  --->  Accuracy = 89.42%\n",
      "M_pca =  119 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  119 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  119 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  119 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  119 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  119 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  119 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  119 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  119 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  119 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  119 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  119 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  119 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  119 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  119 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  119 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  119 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  119 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  119 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  119 , M_lda =  50  --->  Accuracy = 87.50%\n",
      "M_pca =  119 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  120 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  120 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  120 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  120 , M_lda =  4  --->  Accuracy = 41.35%\n",
      "M_pca =  120 , M_lda =  5  --->  Accuracy = 44.23%\n",
      "M_pca =  120 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  120 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  120 , M_lda =  8  --->  Accuracy = 64.42%\n",
      "M_pca =  120 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  120 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  120 , M_lda =  11  --->  Accuracy = 75.96%\n",
      "M_pca =  120 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  120 , M_lda =  13  --->  Accuracy = 84.62%\n",
      "M_pca =  120 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  120 , M_lda =  15  --->  Accuracy = 80.77%\n",
      "M_pca =  120 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  120 , M_lda =  17  --->  Accuracy = 84.62%\n",
      "M_pca =  120 , M_lda =  18  --->  Accuracy = 86.54%\n",
      "M_pca =  120 , M_lda =  19  --->  Accuracy = 87.50%\n",
      "M_pca =  120 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  120 , M_lda =  21  --->  Accuracy = 89.42%\n",
      "M_pca =  120 , M_lda =  22  --->  Accuracy = 88.46%\n",
      "M_pca =  120 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  120 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  120 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  120 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  120 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  120 , M_lda =  28  --->  Accuracy = 89.42%\n",
      "M_pca =  120 , M_lda =  29  --->  Accuracy = 89.42%\n",
      "M_pca =  120 , M_lda =  30  --->  Accuracy = 89.42%\n",
      "M_pca =  120 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  120 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  120 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  120 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  120 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  120 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  120 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  120 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  120 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  120 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  120 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  120 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  120 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  120 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  120 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  120 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  120 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  120 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  120 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  120 , M_lda =  50  --->  Accuracy = 86.54%\n",
      "M_pca =  120 , M_lda =  51  --->  Accuracy = 86.54%\n",
      "M_pca =  121 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  121 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  121 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  121 , M_lda =  4  --->  Accuracy = 40.38%\n",
      "M_pca =  121 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  121 , M_lda =  6  --->  Accuracy = 50.96%\n",
      "M_pca =  121 , M_lda =  7  --->  Accuracy = 58.65%\n",
      "M_pca =  121 , M_lda =  8  --->  Accuracy = 64.42%\n",
      "M_pca =  121 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  121 , M_lda =  10  --->  Accuracy = 72.12%\n",
      "M_pca =  121 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  121 , M_lda =  12  --->  Accuracy = 84.62%\n",
      "M_pca =  121 , M_lda =  13  --->  Accuracy = 84.62%\n",
      "M_pca =  121 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  121 , M_lda =  15  --->  Accuracy = 83.65%\n",
      "M_pca =  121 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  121 , M_lda =  17  --->  Accuracy = 85.58%\n",
      "M_pca =  121 , M_lda =  18  --->  Accuracy = 87.50%\n",
      "M_pca =  121 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  121 , M_lda =  20  --->  Accuracy = 89.42%\n",
      "M_pca =  121 , M_lda =  21  --->  Accuracy = 90.38%\n",
      "M_pca =  121 , M_lda =  22  --->  Accuracy = 89.42%\n",
      "M_pca =  121 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  121 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  121 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  121 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  121 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  121 , M_lda =  28  --->  Accuracy = 89.42%\n",
      "M_pca =  121 , M_lda =  29  --->  Accuracy = 90.38%\n",
      "M_pca =  121 , M_lda =  30  --->  Accuracy = 90.38%\n",
      "M_pca =  121 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  121 , M_lda =  32  --->  Accuracy = 89.42%\n",
      "M_pca =  121 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  121 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  121 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  121 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  121 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  121 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  121 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  121 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  121 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  121 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  121 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  121 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  121 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  121 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  121 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  121 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  121 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  121 , M_lda =  50  --->  Accuracy = 87.50%\n",
      "M_pca =  121 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  122 , M_lda =  1  --->  Accuracy = 7.69%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  122 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  122 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  122 , M_lda =  4  --->  Accuracy = 40.38%\n",
      "M_pca =  122 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  122 , M_lda =  6  --->  Accuracy = 54.81%\n",
      "M_pca =  122 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  122 , M_lda =  8  --->  Accuracy = 64.42%\n",
      "M_pca =  122 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  122 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  122 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  122 , M_lda =  12  --->  Accuracy = 83.65%\n",
      "M_pca =  122 , M_lda =  13  --->  Accuracy = 84.62%\n",
      "M_pca =  122 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  122 , M_lda =  15  --->  Accuracy = 86.54%\n",
      "M_pca =  122 , M_lda =  16  --->  Accuracy = 87.50%\n",
      "M_pca =  122 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  122 , M_lda =  18  --->  Accuracy = 86.54%\n",
      "M_pca =  122 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  122 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  122 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  122 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  122 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  122 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  122 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  122 , M_lda =  26  --->  Accuracy = 88.46%\n",
      "M_pca =  122 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  122 , M_lda =  28  --->  Accuracy = 89.42%\n",
      "M_pca =  122 , M_lda =  29  --->  Accuracy = 89.42%\n",
      "M_pca =  122 , M_lda =  30  --->  Accuracy = 91.35%\n",
      "M_pca =  122 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  122 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  122 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  122 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  122 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  122 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  122 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  122 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  122 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  122 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  122 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  122 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  122 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  122 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  122 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  122 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  122 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  122 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  122 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  122 , M_lda =  50  --->  Accuracy = 88.46%\n",
      "M_pca =  122 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  123 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  123 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  123 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  123 , M_lda =  4  --->  Accuracy = 39.42%\n",
      "M_pca =  123 , M_lda =  5  --->  Accuracy = 43.27%\n",
      "M_pca =  123 , M_lda =  6  --->  Accuracy = 49.04%\n",
      "M_pca =  123 , M_lda =  7  --->  Accuracy = 59.62%\n",
      "M_pca =  123 , M_lda =  8  --->  Accuracy = 62.50%\n",
      "M_pca =  123 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  123 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  123 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  123 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  123 , M_lda =  13  --->  Accuracy = 81.73%\n",
      "M_pca =  123 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  123 , M_lda =  15  --->  Accuracy = 85.58%\n",
      "M_pca =  123 , M_lda =  16  --->  Accuracy = 86.54%\n",
      "M_pca =  123 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  123 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  123 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  123 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  123 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  123 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  123 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  123 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  123 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  123 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  123 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  123 , M_lda =  28  --->  Accuracy = 89.42%\n",
      "M_pca =  123 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  123 , M_lda =  30  --->  Accuracy = 90.38%\n",
      "M_pca =  123 , M_lda =  31  --->  Accuracy = 89.42%\n",
      "M_pca =  123 , M_lda =  32  --->  Accuracy = 90.38%\n",
      "M_pca =  123 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  123 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  123 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  123 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  123 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  123 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  123 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  123 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  123 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  123 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  123 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  123 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  123 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  123 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  123 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  123 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  123 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  123 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  123 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  124 , M_lda =  1  --->  Accuracy = 11.54%\n",
      "M_pca =  124 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  124 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  124 , M_lda =  4  --->  Accuracy = 33.65%\n",
      "M_pca =  124 , M_lda =  5  --->  Accuracy = 40.38%\n",
      "M_pca =  124 , M_lda =  6  --->  Accuracy = 52.88%\n",
      "M_pca =  124 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  124 , M_lda =  8  --->  Accuracy = 65.38%\n",
      "M_pca =  124 , M_lda =  9  --->  Accuracy = 73.08%\n",
      "M_pca =  124 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  124 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  124 , M_lda =  12  --->  Accuracy = 82.69%\n",
      "M_pca =  124 , M_lda =  13  --->  Accuracy = 85.58%\n",
      "M_pca =  124 , M_lda =  14  --->  Accuracy = 87.50%\n",
      "M_pca =  124 , M_lda =  15  --->  Accuracy = 88.46%\n",
      "M_pca =  124 , M_lda =  16  --->  Accuracy = 87.50%\n",
      "M_pca =  124 , M_lda =  17  --->  Accuracy = 88.46%\n",
      "M_pca =  124 , M_lda =  18  --->  Accuracy = 86.54%\n",
      "M_pca =  124 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  124 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  124 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  124 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  124 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  124 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  124 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  124 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  124 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  124 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  124 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  124 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  124 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  124 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  124 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  124 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  124 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  124 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  124 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  124 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  124 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  124 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  124 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  124 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  124 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  124 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  124 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  124 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  124 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  124 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  124 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  124 , M_lda =  50  --->  Accuracy = 88.46%\n",
      "M_pca =  124 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  125 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  125 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  125 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  125 , M_lda =  4  --->  Accuracy = 37.50%\n",
      "M_pca =  125 , M_lda =  5  --->  Accuracy = 42.31%\n",
      "M_pca =  125 , M_lda =  6  --->  Accuracy = 52.88%\n",
      "M_pca =  125 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  125 , M_lda =  8  --->  Accuracy = 67.31%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  125 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  125 , M_lda =  10  --->  Accuracy = 80.77%\n",
      "M_pca =  125 , M_lda =  11  --->  Accuracy = 81.73%\n",
      "M_pca =  125 , M_lda =  12  --->  Accuracy = 82.69%\n",
      "M_pca =  125 , M_lda =  13  --->  Accuracy = 86.54%\n",
      "M_pca =  125 , M_lda =  14  --->  Accuracy = 86.54%\n",
      "M_pca =  125 , M_lda =  15  --->  Accuracy = 87.50%\n",
      "M_pca =  125 , M_lda =  16  --->  Accuracy = 87.50%\n",
      "M_pca =  125 , M_lda =  17  --->  Accuracy = 88.46%\n",
      "M_pca =  125 , M_lda =  18  --->  Accuracy = 86.54%\n",
      "M_pca =  125 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  125 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  125 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  125 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  125 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  125 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  125 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  125 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  125 , M_lda =  27  --->  Accuracy = 89.42%\n",
      "M_pca =  125 , M_lda =  28  --->  Accuracy = 90.38%\n",
      "M_pca =  125 , M_lda =  29  --->  Accuracy = 89.42%\n",
      "M_pca =  125 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  125 , M_lda =  31  --->  Accuracy = 89.42%\n",
      "M_pca =  125 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  125 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  125 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  125 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  125 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  125 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  125 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  125 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  125 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  125 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  125 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  125 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  125 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  125 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  125 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  125 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  125 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  125 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  125 , M_lda =  50  --->  Accuracy = 88.46%\n",
      "M_pca =  125 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  126 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  126 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  126 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  126 , M_lda =  4  --->  Accuracy = 39.42%\n",
      "M_pca =  126 , M_lda =  5  --->  Accuracy = 42.31%\n",
      "M_pca =  126 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  126 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  126 , M_lda =  8  --->  Accuracy = 64.42%\n",
      "M_pca =  126 , M_lda =  9  --->  Accuracy = 73.08%\n",
      "M_pca =  126 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  126 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  126 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  126 , M_lda =  13  --->  Accuracy = 86.54%\n",
      "M_pca =  126 , M_lda =  14  --->  Accuracy = 86.54%\n",
      "M_pca =  126 , M_lda =  15  --->  Accuracy = 86.54%\n",
      "M_pca =  126 , M_lda =  16  --->  Accuracy = 87.50%\n",
      "M_pca =  126 , M_lda =  17  --->  Accuracy = 88.46%\n",
      "M_pca =  126 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  126 , M_lda =  19  --->  Accuracy = 85.58%\n",
      "M_pca =  126 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  126 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  126 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  126 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  126 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  126 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  126 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  126 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  126 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  126 , M_lda =  29  --->  Accuracy = 89.42%\n",
      "M_pca =  126 , M_lda =  30  --->  Accuracy = 89.42%\n",
      "M_pca =  126 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  126 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  126 , M_lda =  33  --->  Accuracy = 89.42%\n",
      "M_pca =  126 , M_lda =  34  --->  Accuracy = 89.42%\n",
      "M_pca =  126 , M_lda =  35  --->  Accuracy = 89.42%\n",
      "M_pca =  126 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  126 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  126 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  126 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  126 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  126 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  126 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  126 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  126 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  126 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  126 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  126 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  126 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  126 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  126 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  126 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  127 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  127 , M_lda =  2  --->  Accuracy = 22.12%\n",
      "M_pca =  127 , M_lda =  3  --->  Accuracy = 25.96%\n",
      "M_pca =  127 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  127 , M_lda =  5  --->  Accuracy = 44.23%\n",
      "M_pca =  127 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  127 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  127 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  127 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  127 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  127 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  127 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  127 , M_lda =  13  --->  Accuracy = 86.54%\n",
      "M_pca =  127 , M_lda =  14  --->  Accuracy = 86.54%\n",
      "M_pca =  127 , M_lda =  15  --->  Accuracy = 87.50%\n",
      "M_pca =  127 , M_lda =  16  --->  Accuracy = 87.50%\n",
      "M_pca =  127 , M_lda =  17  --->  Accuracy = 88.46%\n",
      "M_pca =  127 , M_lda =  18  --->  Accuracy = 87.50%\n",
      "M_pca =  127 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  127 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  127 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  127 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  127 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  127 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  127 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  127 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  127 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  127 , M_lda =  28  --->  Accuracy = 89.42%\n",
      "M_pca =  127 , M_lda =  29  --->  Accuracy = 90.38%\n",
      "M_pca =  127 , M_lda =  30  --->  Accuracy = 90.38%\n",
      "M_pca =  127 , M_lda =  31  --->  Accuracy = 89.42%\n",
      "M_pca =  127 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  127 , M_lda =  33  --->  Accuracy = 89.42%\n",
      "M_pca =  127 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  127 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  127 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  127 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  127 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  127 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  127 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  127 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  127 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  127 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  127 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  127 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  127 , M_lda =  46  --->  Accuracy = 87.50%\n",
      "M_pca =  127 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  127 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  127 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  127 , M_lda =  50  --->  Accuracy = 88.46%\n",
      "M_pca =  127 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  128 , M_lda =  1  --->  Accuracy = 10.58%\n",
      "M_pca =  128 , M_lda =  2  --->  Accuracy = 23.08%\n",
      "M_pca =  128 , M_lda =  3  --->  Accuracy = 27.88%\n",
      "M_pca =  128 , M_lda =  4  --->  Accuracy = 40.38%\n",
      "M_pca =  128 , M_lda =  5  --->  Accuracy = 44.23%\n",
      "M_pca =  128 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  128 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  128 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  128 , M_lda =  9  --->  Accuracy = 73.08%\n",
      "M_pca =  128 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  128 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  128 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  128 , M_lda =  13  --->  Accuracy = 84.62%\n",
      "M_pca =  128 , M_lda =  14  --->  Accuracy = 89.42%\n",
      "M_pca =  128 , M_lda =  15  --->  Accuracy = 87.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  128 , M_lda =  16  --->  Accuracy = 87.50%\n",
      "M_pca =  128 , M_lda =  17  --->  Accuracy = 87.50%\n",
      "M_pca =  128 , M_lda =  18  --->  Accuracy = 87.50%\n",
      "M_pca =  128 , M_lda =  19  --->  Accuracy = 87.50%\n",
      "M_pca =  128 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  128 , M_lda =  21  --->  Accuracy = 87.50%\n",
      "M_pca =  128 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  128 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  128 , M_lda =  24  --->  Accuracy = 89.42%\n",
      "M_pca =  128 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  128 , M_lda =  26  --->  Accuracy = 88.46%\n",
      "M_pca =  128 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  128 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  128 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  128 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  128 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  128 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  128 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  128 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  128 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  128 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  128 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  128 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  128 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  128 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  128 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  128 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  128 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  128 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  128 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  128 , M_lda =  46  --->  Accuracy = 87.50%\n",
      "M_pca =  128 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  128 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  128 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  128 , M_lda =  50  --->  Accuracy = 87.50%\n",
      "M_pca =  128 , M_lda =  51  --->  Accuracy = 87.50%\n",
      "M_pca =  129 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  129 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  129 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  129 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  129 , M_lda =  5  --->  Accuracy = 45.19%\n",
      "M_pca =  129 , M_lda =  6  --->  Accuracy = 48.08%\n",
      "M_pca =  129 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  129 , M_lda =  8  --->  Accuracy = 65.38%\n",
      "M_pca =  129 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  129 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  129 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  129 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  129 , M_lda =  13  --->  Accuracy = 84.62%\n",
      "M_pca =  129 , M_lda =  14  --->  Accuracy = 83.65%\n",
      "M_pca =  129 , M_lda =  15  --->  Accuracy = 87.50%\n",
      "M_pca =  129 , M_lda =  16  --->  Accuracy = 86.54%\n",
      "M_pca =  129 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  129 , M_lda =  18  --->  Accuracy = 86.54%\n",
      "M_pca =  129 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  129 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  129 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  129 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  129 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  129 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  129 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  129 , M_lda =  26  --->  Accuracy = 88.46%\n",
      "M_pca =  129 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  129 , M_lda =  28  --->  Accuracy = 89.42%\n",
      "M_pca =  129 , M_lda =  29  --->  Accuracy = 90.38%\n",
      "M_pca =  129 , M_lda =  30  --->  Accuracy = 89.42%\n",
      "M_pca =  129 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  129 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  129 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  129 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  129 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  129 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  129 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  129 , M_lda =  38  --->  Accuracy = 90.38%\n",
      "M_pca =  129 , M_lda =  39  --->  Accuracy = 90.38%\n",
      "M_pca =  129 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  129 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  129 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  129 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  129 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  129 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  129 , M_lda =  46  --->  Accuracy = 87.50%\n",
      "M_pca =  129 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  129 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  129 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  129 , M_lda =  50  --->  Accuracy = 87.50%\n",
      "M_pca =  129 , M_lda =  51  --->  Accuracy = 87.50%\n",
      "M_pca =  130 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  130 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  130 , M_lda =  3  --->  Accuracy = 27.88%\n",
      "M_pca =  130 , M_lda =  4  --->  Accuracy = 39.42%\n",
      "M_pca =  130 , M_lda =  5  --->  Accuracy = 46.15%\n",
      "M_pca =  130 , M_lda =  6  --->  Accuracy = 54.81%\n",
      "M_pca =  130 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  130 , M_lda =  8  --->  Accuracy = 71.15%\n",
      "M_pca =  130 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  130 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  130 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  130 , M_lda =  12  --->  Accuracy = 82.69%\n",
      "M_pca =  130 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  130 , M_lda =  14  --->  Accuracy = 86.54%\n",
      "M_pca =  130 , M_lda =  15  --->  Accuracy = 87.50%\n",
      "M_pca =  130 , M_lda =  16  --->  Accuracy = 87.50%\n",
      "M_pca =  130 , M_lda =  17  --->  Accuracy = 87.50%\n",
      "M_pca =  130 , M_lda =  18  --->  Accuracy = 86.54%\n",
      "M_pca =  130 , M_lda =  19  --->  Accuracy = 88.46%\n",
      "M_pca =  130 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  130 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  130 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  130 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  130 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  130 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  130 , M_lda =  26  --->  Accuracy = 88.46%\n",
      "M_pca =  130 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  130 , M_lda =  28  --->  Accuracy = 90.38%\n",
      "M_pca =  130 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  130 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  130 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  130 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  130 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  130 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  130 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  130 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  130 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  130 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  130 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  130 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  130 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  130 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  130 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  130 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  130 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  130 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  130 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  130 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  130 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  130 , M_lda =  50  --->  Accuracy = 87.50%\n",
      "M_pca =  130 , M_lda =  51  --->  Accuracy = 86.54%\n",
      "M_pca =  131 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  131 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  131 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  131 , M_lda =  4  --->  Accuracy = 40.38%\n",
      "M_pca =  131 , M_lda =  5  --->  Accuracy = 45.19%\n",
      "M_pca =  131 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  131 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  131 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  131 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  131 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  131 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  131 , M_lda =  12  --->  Accuracy = 84.62%\n",
      "M_pca =  131 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  131 , M_lda =  14  --->  Accuracy = 83.65%\n",
      "M_pca =  131 , M_lda =  15  --->  Accuracy = 85.58%\n",
      "M_pca =  131 , M_lda =  16  --->  Accuracy = 87.50%\n",
      "M_pca =  131 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  131 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  131 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  131 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  131 , M_lda =  21  --->  Accuracy = 87.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  131 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  131 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  131 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  131 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  131 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  131 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  131 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  131 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  131 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  131 , M_lda =  31  --->  Accuracy = 90.38%\n",
      "M_pca =  131 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  131 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  131 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  131 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  131 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  131 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  131 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  131 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  131 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  131 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  131 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  131 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  131 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  131 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  131 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  131 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  131 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  131 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  131 , M_lda =  50  --->  Accuracy = 87.50%\n",
      "M_pca =  131 , M_lda =  51  --->  Accuracy = 87.50%\n",
      "M_pca =  132 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  132 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  132 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  132 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  132 , M_lda =  5  --->  Accuracy = 44.23%\n",
      "M_pca =  132 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  132 , M_lda =  7  --->  Accuracy = 67.31%\n",
      "M_pca =  132 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  132 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  132 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  132 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  132 , M_lda =  12  --->  Accuracy = 84.62%\n",
      "M_pca =  132 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  132 , M_lda =  14  --->  Accuracy = 83.65%\n",
      "M_pca =  132 , M_lda =  15  --->  Accuracy = 87.50%\n",
      "M_pca =  132 , M_lda =  16  --->  Accuracy = 87.50%\n",
      "M_pca =  132 , M_lda =  17  --->  Accuracy = 87.50%\n",
      "M_pca =  132 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  132 , M_lda =  19  --->  Accuracy = 87.50%\n",
      "M_pca =  132 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  132 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  132 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  132 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  132 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  132 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  132 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  132 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  132 , M_lda =  28  --->  Accuracy = 85.58%\n",
      "M_pca =  132 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  132 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  132 , M_lda =  31  --->  Accuracy = 89.42%\n",
      "M_pca =  132 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  132 , M_lda =  33  --->  Accuracy = 89.42%\n",
      "M_pca =  132 , M_lda =  34  --->  Accuracy = 89.42%\n",
      "M_pca =  132 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  132 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  132 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  132 , M_lda =  38  --->  Accuracy = 90.38%\n",
      "M_pca =  132 , M_lda =  39  --->  Accuracy = 90.38%\n",
      "M_pca =  132 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  132 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  132 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  132 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  132 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  132 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  132 , M_lda =  46  --->  Accuracy = 87.50%\n",
      "M_pca =  132 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  132 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  132 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  132 , M_lda =  50  --->  Accuracy = 88.46%\n",
      "M_pca =  132 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  133 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  133 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  133 , M_lda =  3  --->  Accuracy = 24.04%\n",
      "M_pca =  133 , M_lda =  4  --->  Accuracy = 37.50%\n",
      "M_pca =  133 , M_lda =  5  --->  Accuracy = 47.12%\n",
      "M_pca =  133 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  133 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  133 , M_lda =  8  --->  Accuracy = 75.96%\n",
      "M_pca =  133 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  133 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  133 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  133 , M_lda =  12  --->  Accuracy = 86.54%\n",
      "M_pca =  133 , M_lda =  13  --->  Accuracy = 84.62%\n",
      "M_pca =  133 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  133 , M_lda =  15  --->  Accuracy = 85.58%\n",
      "M_pca =  133 , M_lda =  16  --->  Accuracy = 88.46%\n",
      "M_pca =  133 , M_lda =  17  --->  Accuracy = 85.58%\n",
      "M_pca =  133 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  133 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  133 , M_lda =  20  --->  Accuracy = 87.50%\n",
      "M_pca =  133 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  133 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  133 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  133 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  133 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  133 , M_lda =  26  --->  Accuracy = 84.62%\n",
      "M_pca =  133 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  133 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  133 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  133 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  133 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  133 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  133 , M_lda =  33  --->  Accuracy = 90.38%\n",
      "M_pca =  133 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  133 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  133 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  133 , M_lda =  37  --->  Accuracy = 89.42%\n",
      "M_pca =  133 , M_lda =  38  --->  Accuracy = 90.38%\n",
      "M_pca =  133 , M_lda =  39  --->  Accuracy = 90.38%\n",
      "M_pca =  133 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  133 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  133 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  133 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  133 , M_lda =  44  --->  Accuracy = 86.54%\n",
      "M_pca =  133 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  133 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  133 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  133 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  133 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  133 , M_lda =  50  --->  Accuracy = 87.50%\n",
      "M_pca =  133 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  134 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  134 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  134 , M_lda =  3  --->  Accuracy = 22.12%\n",
      "M_pca =  134 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  134 , M_lda =  5  --->  Accuracy = 46.15%\n",
      "M_pca =  134 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  134 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  134 , M_lda =  8  --->  Accuracy = 74.04%\n",
      "M_pca =  134 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  134 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  134 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  134 , M_lda =  12  --->  Accuracy = 83.65%\n",
      "M_pca =  134 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  134 , M_lda =  14  --->  Accuracy = 86.54%\n",
      "M_pca =  134 , M_lda =  15  --->  Accuracy = 86.54%\n",
      "M_pca =  134 , M_lda =  16  --->  Accuracy = 87.50%\n",
      "M_pca =  134 , M_lda =  17  --->  Accuracy = 85.58%\n",
      "M_pca =  134 , M_lda =  18  --->  Accuracy = 87.50%\n",
      "M_pca =  134 , M_lda =  19  --->  Accuracy = 87.50%\n",
      "M_pca =  134 , M_lda =  20  --->  Accuracy = 88.46%\n",
      "M_pca =  134 , M_lda =  21  --->  Accuracy = 87.50%\n",
      "M_pca =  134 , M_lda =  22  --->  Accuracy = 83.65%\n",
      "M_pca =  134 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  134 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  134 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  134 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  134 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  134 , M_lda =  28  --->  Accuracy = 88.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  134 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  134 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  134 , M_lda =  31  --->  Accuracy = 89.42%\n",
      "M_pca =  134 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  134 , M_lda =  33  --->  Accuracy = 90.38%\n",
      "M_pca =  134 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  134 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  134 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  134 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  134 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  134 , M_lda =  39  --->  Accuracy = 90.38%\n",
      "M_pca =  134 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  134 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  134 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  134 , M_lda =  43  --->  Accuracy = 86.54%\n",
      "M_pca =  134 , M_lda =  44  --->  Accuracy = 86.54%\n",
      "M_pca =  134 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  134 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  134 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  134 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  134 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  134 , M_lda =  50  --->  Accuracy = 88.46%\n",
      "M_pca =  134 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  135 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  135 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  135 , M_lda =  3  --->  Accuracy = 24.04%\n",
      "M_pca =  135 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  135 , M_lda =  5  --->  Accuracy = 47.12%\n",
      "M_pca =  135 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  135 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  135 , M_lda =  8  --->  Accuracy = 72.12%\n",
      "M_pca =  135 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  135 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  135 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  135 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  135 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  135 , M_lda =  14  --->  Accuracy = 87.50%\n",
      "M_pca =  135 , M_lda =  15  --->  Accuracy = 87.50%\n",
      "M_pca =  135 , M_lda =  16  --->  Accuracy = 88.46%\n",
      "M_pca =  135 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  135 , M_lda =  18  --->  Accuracy = 87.50%\n",
      "M_pca =  135 , M_lda =  19  --->  Accuracy = 88.46%\n",
      "M_pca =  135 , M_lda =  20  --->  Accuracy = 88.46%\n",
      "M_pca =  135 , M_lda =  21  --->  Accuracy = 88.46%\n",
      "M_pca =  135 , M_lda =  22  --->  Accuracy = 89.42%\n",
      "M_pca =  135 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  135 , M_lda =  24  --->  Accuracy = 89.42%\n",
      "M_pca =  135 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  135 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  135 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  135 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  135 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  135 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  135 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  135 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  135 , M_lda =  33  --->  Accuracy = 89.42%\n",
      "M_pca =  135 , M_lda =  34  --->  Accuracy = 89.42%\n",
      "M_pca =  135 , M_lda =  35  --->  Accuracy = 89.42%\n",
      "M_pca =  135 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  135 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  135 , M_lda =  38  --->  Accuracy = 90.38%\n",
      "M_pca =  135 , M_lda =  39  --->  Accuracy = 90.38%\n",
      "M_pca =  135 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  135 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  135 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  135 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  135 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  135 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  135 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  135 , M_lda =  47  --->  Accuracy = 91.35%\n",
      "M_pca =  135 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  135 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  135 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  135 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  136 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  136 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  136 , M_lda =  3  --->  Accuracy = 22.12%\n",
      "M_pca =  136 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  136 , M_lda =  5  --->  Accuracy = 45.19%\n",
      "M_pca =  136 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  136 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  136 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  136 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  136 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  136 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  136 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  136 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  136 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  136 , M_lda =  15  --->  Accuracy = 84.62%\n",
      "M_pca =  136 , M_lda =  16  --->  Accuracy = 85.58%\n",
      "M_pca =  136 , M_lda =  17  --->  Accuracy = 87.50%\n",
      "M_pca =  136 , M_lda =  18  --->  Accuracy = 86.54%\n",
      "M_pca =  136 , M_lda =  19  --->  Accuracy = 85.58%\n",
      "M_pca =  136 , M_lda =  20  --->  Accuracy = 87.50%\n",
      "M_pca =  136 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  136 , M_lda =  22  --->  Accuracy = 88.46%\n",
      "M_pca =  136 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  136 , M_lda =  24  --->  Accuracy = 89.42%\n",
      "M_pca =  136 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  136 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  136 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  136 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  136 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  136 , M_lda =  30  --->  Accuracy = 89.42%\n",
      "M_pca =  136 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  136 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  136 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  136 , M_lda =  34  --->  Accuracy = 90.38%\n",
      "M_pca =  136 , M_lda =  35  --->  Accuracy = 90.38%\n",
      "M_pca =  136 , M_lda =  36  --->  Accuracy = 89.42%\n",
      "M_pca =  136 , M_lda =  37  --->  Accuracy = 89.42%\n",
      "M_pca =  136 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  136 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  136 , M_lda =  40  --->  Accuracy = 90.38%\n",
      "M_pca =  136 , M_lda =  41  --->  Accuracy = 90.38%\n",
      "M_pca =  136 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  136 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  136 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  136 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  136 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  136 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  136 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  136 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  136 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  136 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  137 , M_lda =  1  --->  Accuracy = 11.54%\n",
      "M_pca =  137 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  137 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  137 , M_lda =  4  --->  Accuracy = 40.38%\n",
      "M_pca =  137 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  137 , M_lda =  6  --->  Accuracy = 61.54%\n",
      "M_pca =  137 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  137 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  137 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  137 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  137 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  137 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  137 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  137 , M_lda =  14  --->  Accuracy = 83.65%\n",
      "M_pca =  137 , M_lda =  15  --->  Accuracy = 84.62%\n",
      "M_pca =  137 , M_lda =  16  --->  Accuracy = 86.54%\n",
      "M_pca =  137 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  137 , M_lda =  18  --->  Accuracy = 86.54%\n",
      "M_pca =  137 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  137 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  137 , M_lda =  21  --->  Accuracy = 87.50%\n",
      "M_pca =  137 , M_lda =  22  --->  Accuracy = 88.46%\n",
      "M_pca =  137 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  137 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  137 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  137 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  137 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  137 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  137 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  137 , M_lda =  30  --->  Accuracy = 84.62%\n",
      "M_pca =  137 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  137 , M_lda =  32  --->  Accuracy = 85.58%\n",
      "M_pca =  137 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  137 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  137 , M_lda =  35  --->  Accuracy = 87.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  137 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  137 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  137 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  137 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  137 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  137 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  137 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  137 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  137 , M_lda =  44  --->  Accuracy = 85.58%\n",
      "M_pca =  137 , M_lda =  45  --->  Accuracy = 85.58%\n",
      "M_pca =  137 , M_lda =  46  --->  Accuracy = 86.54%\n",
      "M_pca =  137 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  137 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  137 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  137 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  137 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  138 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  138 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  138 , M_lda =  3  --->  Accuracy = 25.00%\n",
      "M_pca =  138 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  138 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  138 , M_lda =  6  --->  Accuracy = 54.81%\n",
      "M_pca =  138 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  138 , M_lda =  8  --->  Accuracy = 64.42%\n",
      "M_pca =  138 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  138 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  138 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  138 , M_lda =  12  --->  Accuracy = 82.69%\n",
      "M_pca =  138 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  138 , M_lda =  14  --->  Accuracy = 82.69%\n",
      "M_pca =  138 , M_lda =  15  --->  Accuracy = 84.62%\n",
      "M_pca =  138 , M_lda =  16  --->  Accuracy = 88.46%\n",
      "M_pca =  138 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  138 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  138 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  138 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  138 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  138 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  138 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  138 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  138 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  138 , M_lda =  26  --->  Accuracy = 84.62%\n",
      "M_pca =  138 , M_lda =  27  --->  Accuracy = 84.62%\n",
      "M_pca =  138 , M_lda =  28  --->  Accuracy = 85.58%\n",
      "M_pca =  138 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  138 , M_lda =  30  --->  Accuracy = 84.62%\n",
      "M_pca =  138 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  138 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  138 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  138 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  138 , M_lda =  35  --->  Accuracy = 89.42%\n",
      "M_pca =  138 , M_lda =  36  --->  Accuracy = 89.42%\n",
      "M_pca =  138 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  138 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  138 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  138 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  138 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  138 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  138 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  138 , M_lda =  44  --->  Accuracy = 86.54%\n",
      "M_pca =  138 , M_lda =  45  --->  Accuracy = 86.54%\n",
      "M_pca =  138 , M_lda =  46  --->  Accuracy = 87.50%\n",
      "M_pca =  138 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  138 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  138 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  138 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  138 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  139 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  139 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  139 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  139 , M_lda =  4  --->  Accuracy = 38.46%\n",
      "M_pca =  139 , M_lda =  5  --->  Accuracy = 47.12%\n",
      "M_pca =  139 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  139 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  139 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  139 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  139 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  139 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  139 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  139 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  139 , M_lda =  14  --->  Accuracy = 82.69%\n",
      "M_pca =  139 , M_lda =  15  --->  Accuracy = 83.65%\n",
      "M_pca =  139 , M_lda =  16  --->  Accuracy = 86.54%\n",
      "M_pca =  139 , M_lda =  17  --->  Accuracy = 87.50%\n",
      "M_pca =  139 , M_lda =  18  --->  Accuracy = 87.50%\n",
      "M_pca =  139 , M_lda =  19  --->  Accuracy = 87.50%\n",
      "M_pca =  139 , M_lda =  20  --->  Accuracy = 88.46%\n",
      "M_pca =  139 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  139 , M_lda =  22  --->  Accuracy = 89.42%\n",
      "M_pca =  139 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  139 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  139 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  139 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  139 , M_lda =  27  --->  Accuracy = 84.62%\n",
      "M_pca =  139 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  139 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  139 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  139 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  139 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  139 , M_lda =  33  --->  Accuracy = 89.42%\n",
      "M_pca =  139 , M_lda =  34  --->  Accuracy = 89.42%\n",
      "M_pca =  139 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  139 , M_lda =  36  --->  Accuracy = 89.42%\n",
      "M_pca =  139 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  139 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  139 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  139 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  139 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  139 , M_lda =  42  --->  Accuracy = 91.35%\n",
      "M_pca =  139 , M_lda =  43  --->  Accuracy = 92.31%\n",
      "M_pca =  139 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  139 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  139 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  139 , M_lda =  47  --->  Accuracy = 91.35%\n",
      "M_pca =  139 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  139 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  139 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  139 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  140 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  140 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  140 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  140 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  140 , M_lda =  5  --->  Accuracy = 52.88%\n",
      "M_pca =  140 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  140 , M_lda =  7  --->  Accuracy = 60.58%\n",
      "M_pca =  140 , M_lda =  8  --->  Accuracy = 65.38%\n",
      "M_pca =  140 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  140 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  140 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  140 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  140 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  140 , M_lda =  14  --->  Accuracy = 86.54%\n",
      "M_pca =  140 , M_lda =  15  --->  Accuracy = 85.58%\n",
      "M_pca =  140 , M_lda =  16  --->  Accuracy = 86.54%\n",
      "M_pca =  140 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  140 , M_lda =  18  --->  Accuracy = 87.50%\n",
      "M_pca =  140 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  140 , M_lda =  20  --->  Accuracy = 88.46%\n",
      "M_pca =  140 , M_lda =  21  --->  Accuracy = 87.50%\n",
      "M_pca =  140 , M_lda =  22  --->  Accuracy = 89.42%\n",
      "M_pca =  140 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  140 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  140 , M_lda =  25  --->  Accuracy = 88.46%\n",
      "M_pca =  140 , M_lda =  26  --->  Accuracy = 88.46%\n",
      "M_pca =  140 , M_lda =  27  --->  Accuracy = 84.62%\n",
      "M_pca =  140 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  140 , M_lda =  29  --->  Accuracy = 89.42%\n",
      "M_pca =  140 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  140 , M_lda =  31  --->  Accuracy = 89.42%\n",
      "M_pca =  140 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  140 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  140 , M_lda =  34  --->  Accuracy = 89.42%\n",
      "M_pca =  140 , M_lda =  35  --->  Accuracy = 89.42%\n",
      "M_pca =  140 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  140 , M_lda =  37  --->  Accuracy = 89.42%\n",
      "M_pca =  140 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  140 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  140 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  140 , M_lda =  41  --->  Accuracy = 89.42%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  140 , M_lda =  42  --->  Accuracy = 91.35%\n",
      "M_pca =  140 , M_lda =  43  --->  Accuracy = 91.35%\n",
      "M_pca =  140 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  140 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  140 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  140 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  140 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  140 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  140 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  140 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  141 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  141 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  141 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  141 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  141 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  141 , M_lda =  6  --->  Accuracy = 52.88%\n",
      "M_pca =  141 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  141 , M_lda =  8  --->  Accuracy = 65.38%\n",
      "M_pca =  141 , M_lda =  9  --->  Accuracy = 68.27%\n",
      "M_pca =  141 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  141 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  141 , M_lda =  12  --->  Accuracy = 83.65%\n",
      "M_pca =  141 , M_lda =  13  --->  Accuracy = 81.73%\n",
      "M_pca =  141 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  141 , M_lda =  15  --->  Accuracy = 84.62%\n",
      "M_pca =  141 , M_lda =  16  --->  Accuracy = 85.58%\n",
      "M_pca =  141 , M_lda =  17  --->  Accuracy = 87.50%\n",
      "M_pca =  141 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  141 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  141 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  141 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  141 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  141 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  141 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  141 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  141 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  141 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  141 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  141 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  141 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  141 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  141 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  141 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  141 , M_lda =  34  --->  Accuracy = 89.42%\n",
      "M_pca =  141 , M_lda =  35  --->  Accuracy = 89.42%\n",
      "M_pca =  141 , M_lda =  36  --->  Accuracy = 89.42%\n",
      "M_pca =  141 , M_lda =  37  --->  Accuracy = 89.42%\n",
      "M_pca =  141 , M_lda =  38  --->  Accuracy = 90.38%\n",
      "M_pca =  141 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  141 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  141 , M_lda =  41  --->  Accuracy = 90.38%\n",
      "M_pca =  141 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  141 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  141 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  141 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  141 , M_lda =  46  --->  Accuracy = 91.35%\n",
      "M_pca =  141 , M_lda =  47  --->  Accuracy = 91.35%\n",
      "M_pca =  141 , M_lda =  48  --->  Accuracy = 91.35%\n",
      "M_pca =  141 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  141 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  141 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  142 , M_lda =  1  --->  Accuracy = 1.92%\n",
      "M_pca =  142 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  142 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  142 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  142 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  142 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  142 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  142 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  142 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  142 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  142 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  142 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  142 , M_lda =  13  --->  Accuracy = 81.73%\n",
      "M_pca =  142 , M_lda =  14  --->  Accuracy = 85.58%\n",
      "M_pca =  142 , M_lda =  15  --->  Accuracy = 85.58%\n",
      "M_pca =  142 , M_lda =  16  --->  Accuracy = 85.58%\n",
      "M_pca =  142 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  142 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  142 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  142 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  142 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  142 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  142 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  142 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  142 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  142 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  142 , M_lda =  27  --->  Accuracy = 84.62%\n",
      "M_pca =  142 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  142 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  142 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  142 , M_lda =  31  --->  Accuracy = 89.42%\n",
      "M_pca =  142 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  142 , M_lda =  33  --->  Accuracy = 89.42%\n",
      "M_pca =  142 , M_lda =  34  --->  Accuracy = 89.42%\n",
      "M_pca =  142 , M_lda =  35  --->  Accuracy = 89.42%\n",
      "M_pca =  142 , M_lda =  36  --->  Accuracy = 90.38%\n",
      "M_pca =  142 , M_lda =  37  --->  Accuracy = 91.35%\n",
      "M_pca =  142 , M_lda =  38  --->  Accuracy = 91.35%\n",
      "M_pca =  142 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  142 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  142 , M_lda =  41  --->  Accuracy = 90.38%\n",
      "M_pca =  142 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  142 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  142 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  142 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  142 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  142 , M_lda =  47  --->  Accuracy = 91.35%\n",
      "M_pca =  142 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  142 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  142 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  142 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  143 , M_lda =  1  --->  Accuracy = 11.54%\n",
      "M_pca =  143 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  143 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  143 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  143 , M_lda =  5  --->  Accuracy = 47.12%\n",
      "M_pca =  143 , M_lda =  6  --->  Accuracy = 51.92%\n",
      "M_pca =  143 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  143 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  143 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  143 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  143 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  143 , M_lda =  12  --->  Accuracy = 83.65%\n",
      "M_pca =  143 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  143 , M_lda =  14  --->  Accuracy = 85.58%\n",
      "M_pca =  143 , M_lda =  15  --->  Accuracy = 85.58%\n",
      "M_pca =  143 , M_lda =  16  --->  Accuracy = 86.54%\n",
      "M_pca =  143 , M_lda =  17  --->  Accuracy = 85.58%\n",
      "M_pca =  143 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  143 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  143 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  143 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  143 , M_lda =  22  --->  Accuracy = 83.65%\n",
      "M_pca =  143 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  143 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  143 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  143 , M_lda =  26  --->  Accuracy = 89.42%\n",
      "M_pca =  143 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  143 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  143 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  143 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  143 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  143 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  143 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  143 , M_lda =  34  --->  Accuracy = 89.42%\n",
      "M_pca =  143 , M_lda =  35  --->  Accuracy = 89.42%\n",
      "M_pca =  143 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  143 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  143 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  143 , M_lda =  39  --->  Accuracy = 90.38%\n",
      "M_pca =  143 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  143 , M_lda =  41  --->  Accuracy = 90.38%\n",
      "M_pca =  143 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  143 , M_lda =  43  --->  Accuracy = 92.31%\n",
      "M_pca =  143 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  143 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  143 , M_lda =  46  --->  Accuracy = 91.35%\n",
      "M_pca =  143 , M_lda =  47  --->  Accuracy = 92.31%\n",
      "M_pca =  143 , M_lda =  48  --->  Accuracy = 91.35%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  143 , M_lda =  49  --->  Accuracy = 91.35%\n",
      "M_pca =  143 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  143 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  144 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  144 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  144 , M_lda =  3  --->  Accuracy = 33.65%\n",
      "M_pca =  144 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  144 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  144 , M_lda =  6  --->  Accuracy = 50.96%\n",
      "M_pca =  144 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  144 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  144 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  144 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  144 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  144 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  144 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  144 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  144 , M_lda =  15  --->  Accuracy = 85.58%\n",
      "M_pca =  144 , M_lda =  16  --->  Accuracy = 86.54%\n",
      "M_pca =  144 , M_lda =  17  --->  Accuracy = 87.50%\n",
      "M_pca =  144 , M_lda =  18  --->  Accuracy = 83.65%\n",
      "M_pca =  144 , M_lda =  19  --->  Accuracy = 85.58%\n",
      "M_pca =  144 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  144 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  144 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  144 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  144 , M_lda =  24  --->  Accuracy = 89.42%\n",
      "M_pca =  144 , M_lda =  25  --->  Accuracy = 89.42%\n",
      "M_pca =  144 , M_lda =  26  --->  Accuracy = 90.38%\n",
      "M_pca =  144 , M_lda =  27  --->  Accuracy = 89.42%\n",
      "M_pca =  144 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  144 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  144 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  144 , M_lda =  31  --->  Accuracy = 90.38%\n",
      "M_pca =  144 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  144 , M_lda =  33  --->  Accuracy = 90.38%\n",
      "M_pca =  144 , M_lda =  34  --->  Accuracy = 90.38%\n",
      "M_pca =  144 , M_lda =  35  --->  Accuracy = 91.35%\n",
      "M_pca =  144 , M_lda =  36  --->  Accuracy = 90.38%\n",
      "M_pca =  144 , M_lda =  37  --->  Accuracy = 91.35%\n",
      "M_pca =  144 , M_lda =  38  --->  Accuracy = 93.27%\n",
      "M_pca =  144 , M_lda =  39  --->  Accuracy = 90.38%\n",
      "M_pca =  144 , M_lda =  40  --->  Accuracy = 90.38%\n",
      "M_pca =  144 , M_lda =  41  --->  Accuracy = 91.35%\n",
      "M_pca =  144 , M_lda =  42  --->  Accuracy = 92.31%\n",
      "M_pca =  144 , M_lda =  43  --->  Accuracy = 92.31%\n",
      "M_pca =  144 , M_lda =  44  --->  Accuracy = 91.35%\n",
      "M_pca =  144 , M_lda =  45  --->  Accuracy = 92.31%\n",
      "M_pca =  144 , M_lda =  46  --->  Accuracy = 93.27%\n",
      "M_pca =  144 , M_lda =  47  --->  Accuracy = 93.27%\n",
      "M_pca =  144 , M_lda =  48  --->  Accuracy = 91.35%\n",
      "M_pca =  144 , M_lda =  49  --->  Accuracy = 91.35%\n",
      "M_pca =  144 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  144 , M_lda =  51  --->  Accuracy = 93.27%\n",
      "M_pca =  145 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  145 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  145 , M_lda =  3  --->  Accuracy = 25.96%\n",
      "M_pca =  145 , M_lda =  4  --->  Accuracy = 41.35%\n",
      "M_pca =  145 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  145 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  145 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  145 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  145 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  145 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  145 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  145 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  145 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  145 , M_lda =  14  --->  Accuracy = 86.54%\n",
      "M_pca =  145 , M_lda =  15  --->  Accuracy = 86.54%\n",
      "M_pca =  145 , M_lda =  16  --->  Accuracy = 87.50%\n",
      "M_pca =  145 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  145 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  145 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  145 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  145 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  145 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  145 , M_lda =  23  --->  Accuracy = 90.38%\n",
      "M_pca =  145 , M_lda =  24  --->  Accuracy = 91.35%\n",
      "M_pca =  145 , M_lda =  25  --->  Accuracy = 90.38%\n",
      "M_pca =  145 , M_lda =  26  --->  Accuracy = 91.35%\n",
      "M_pca =  145 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  145 , M_lda =  28  --->  Accuracy = 91.35%\n",
      "M_pca =  145 , M_lda =  29  --->  Accuracy = 91.35%\n",
      "M_pca =  145 , M_lda =  30  --->  Accuracy = 90.38%\n",
      "M_pca =  145 , M_lda =  31  --->  Accuracy = 92.31%\n",
      "M_pca =  145 , M_lda =  32  --->  Accuracy = 90.38%\n",
      "M_pca =  145 , M_lda =  33  --->  Accuracy = 90.38%\n",
      "M_pca =  145 , M_lda =  34  --->  Accuracy = 91.35%\n",
      "M_pca =  145 , M_lda =  35  --->  Accuracy = 91.35%\n",
      "M_pca =  145 , M_lda =  36  --->  Accuracy = 90.38%\n",
      "M_pca =  145 , M_lda =  37  --->  Accuracy = 89.42%\n",
      "M_pca =  145 , M_lda =  38  --->  Accuracy = 91.35%\n",
      "M_pca =  145 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  145 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  145 , M_lda =  41  --->  Accuracy = 90.38%\n",
      "M_pca =  145 , M_lda =  42  --->  Accuracy = 92.31%\n",
      "M_pca =  145 , M_lda =  43  --->  Accuracy = 92.31%\n",
      "M_pca =  145 , M_lda =  44  --->  Accuracy = 92.31%\n",
      "M_pca =  145 , M_lda =  45  --->  Accuracy = 91.35%\n",
      "M_pca =  145 , M_lda =  46  --->  Accuracy = 93.27%\n",
      "M_pca =  145 , M_lda =  47  --->  Accuracy = 92.31%\n",
      "M_pca =  145 , M_lda =  48  --->  Accuracy = 92.31%\n",
      "M_pca =  145 , M_lda =  49  --->  Accuracy = 92.31%\n",
      "M_pca =  145 , M_lda =  50  --->  Accuracy = 92.31%\n",
      "M_pca =  145 , M_lda =  51  --->  Accuracy = 92.31%\n",
      "M_pca =  146 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  146 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  146 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  146 , M_lda =  4  --->  Accuracy = 42.31%\n",
      "M_pca =  146 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  146 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  146 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  146 , M_lda =  8  --->  Accuracy = 69.23%\n",
      "M_pca =  146 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  146 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  146 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  146 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  146 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  146 , M_lda =  14  --->  Accuracy = 86.54%\n",
      "M_pca =  146 , M_lda =  15  --->  Accuracy = 85.58%\n",
      "M_pca =  146 , M_lda =  16  --->  Accuracy = 86.54%\n",
      "M_pca =  146 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  146 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  146 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  146 , M_lda =  20  --->  Accuracy = 87.50%\n",
      "M_pca =  146 , M_lda =  21  --->  Accuracy = 87.50%\n",
      "M_pca =  146 , M_lda =  22  --->  Accuracy = 88.46%\n",
      "M_pca =  146 , M_lda =  23  --->  Accuracy = 90.38%\n",
      "M_pca =  146 , M_lda =  24  --->  Accuracy = 93.27%\n",
      "M_pca =  146 , M_lda =  25  --->  Accuracy = 90.38%\n",
      "M_pca =  146 , M_lda =  26  --->  Accuracy = 89.42%\n",
      "M_pca =  146 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  146 , M_lda =  28  --->  Accuracy = 89.42%\n",
      "M_pca =  146 , M_lda =  29  --->  Accuracy = 89.42%\n",
      "M_pca =  146 , M_lda =  30  --->  Accuracy = 89.42%\n",
      "M_pca =  146 , M_lda =  31  --->  Accuracy = 90.38%\n",
      "M_pca =  146 , M_lda =  32  --->  Accuracy = 89.42%\n",
      "M_pca =  146 , M_lda =  33  --->  Accuracy = 89.42%\n",
      "M_pca =  146 , M_lda =  34  --->  Accuracy = 90.38%\n",
      "M_pca =  146 , M_lda =  35  --->  Accuracy = 90.38%\n",
      "M_pca =  146 , M_lda =  36  --->  Accuracy = 90.38%\n",
      "M_pca =  146 , M_lda =  37  --->  Accuracy = 89.42%\n",
      "M_pca =  146 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  146 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  146 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  146 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  146 , M_lda =  42  --->  Accuracy = 91.35%\n",
      "M_pca =  146 , M_lda =  43  --->  Accuracy = 93.27%\n",
      "M_pca =  146 , M_lda =  44  --->  Accuracy = 92.31%\n",
      "M_pca =  146 , M_lda =  45  --->  Accuracy = 91.35%\n",
      "M_pca =  146 , M_lda =  46  --->  Accuracy = 93.27%\n",
      "M_pca =  146 , M_lda =  47  --->  Accuracy = 92.31%\n",
      "M_pca =  146 , M_lda =  48  --->  Accuracy = 92.31%\n",
      "M_pca =  146 , M_lda =  49  --->  Accuracy = 91.35%\n",
      "M_pca =  146 , M_lda =  50  --->  Accuracy = 92.31%\n",
      "M_pca =  146 , M_lda =  51  --->  Accuracy = 92.31%\n",
      "M_pca =  147 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  147 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  147 , M_lda =  3  --->  Accuracy = 28.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  147 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  147 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  147 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  147 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  147 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  147 , M_lda =  9  --->  Accuracy = 73.08%\n",
      "M_pca =  147 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  147 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  147 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  147 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  147 , M_lda =  14  --->  Accuracy = 85.58%\n",
      "M_pca =  147 , M_lda =  15  --->  Accuracy = 85.58%\n",
      "M_pca =  147 , M_lda =  16  --->  Accuracy = 85.58%\n",
      "M_pca =  147 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  147 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  147 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  147 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  147 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  147 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  147 , M_lda =  23  --->  Accuracy = 90.38%\n",
      "M_pca =  147 , M_lda =  24  --->  Accuracy = 91.35%\n",
      "M_pca =  147 , M_lda =  25  --->  Accuracy = 89.42%\n",
      "M_pca =  147 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  147 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  147 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  147 , M_lda =  29  --->  Accuracy = 89.42%\n",
      "M_pca =  147 , M_lda =  30  --->  Accuracy = 91.35%\n",
      "M_pca =  147 , M_lda =  31  --->  Accuracy = 91.35%\n",
      "M_pca =  147 , M_lda =  32  --->  Accuracy = 89.42%\n",
      "M_pca =  147 , M_lda =  33  --->  Accuracy = 90.38%\n",
      "M_pca =  147 , M_lda =  34  --->  Accuracy = 89.42%\n",
      "M_pca =  147 , M_lda =  35  --->  Accuracy = 90.38%\n",
      "M_pca =  147 , M_lda =  36  --->  Accuracy = 90.38%\n",
      "M_pca =  147 , M_lda =  37  --->  Accuracy = 90.38%\n",
      "M_pca =  147 , M_lda =  38  --->  Accuracy = 90.38%\n",
      "M_pca =  147 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  147 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  147 , M_lda =  41  --->  Accuracy = 90.38%\n",
      "M_pca =  147 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  147 , M_lda =  43  --->  Accuracy = 92.31%\n",
      "M_pca =  147 , M_lda =  44  --->  Accuracy = 92.31%\n",
      "M_pca =  147 , M_lda =  45  --->  Accuracy = 91.35%\n",
      "M_pca =  147 , M_lda =  46  --->  Accuracy = 94.23%\n",
      "M_pca =  147 , M_lda =  47  --->  Accuracy = 93.27%\n",
      "M_pca =  147 , M_lda =  48  --->  Accuracy = 93.27%\n",
      "M_pca =  147 , M_lda =  49  --->  Accuracy = 92.31%\n",
      "M_pca =  147 , M_lda =  50  --->  Accuracy = 92.31%\n",
      "M_pca =  147 , M_lda =  51  --->  Accuracy = 92.31%\n",
      "M_pca =  148 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  148 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  148 , M_lda =  3  --->  Accuracy = 27.88%\n",
      "M_pca =  148 , M_lda =  4  --->  Accuracy = 47.12%\n",
      "M_pca =  148 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  148 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  148 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  148 , M_lda =  8  --->  Accuracy = 69.23%\n",
      "M_pca =  148 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  148 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  148 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  148 , M_lda =  12  --->  Accuracy = 79.81%\n",
      "M_pca =  148 , M_lda =  13  --->  Accuracy = 80.77%\n",
      "M_pca =  148 , M_lda =  14  --->  Accuracy = 85.58%\n",
      "M_pca =  148 , M_lda =  15  --->  Accuracy = 84.62%\n",
      "M_pca =  148 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  148 , M_lda =  17  --->  Accuracy = 84.62%\n",
      "M_pca =  148 , M_lda =  18  --->  Accuracy = 86.54%\n",
      "M_pca =  148 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  148 , M_lda =  20  --->  Accuracy = 87.50%\n",
      "M_pca =  148 , M_lda =  21  --->  Accuracy = 87.50%\n",
      "M_pca =  148 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  148 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  148 , M_lda =  24  --->  Accuracy = 89.42%\n",
      "M_pca =  148 , M_lda =  25  --->  Accuracy = 89.42%\n",
      "M_pca =  148 , M_lda =  26  --->  Accuracy = 89.42%\n",
      "M_pca =  148 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  148 , M_lda =  28  --->  Accuracy = 89.42%\n",
      "M_pca =  148 , M_lda =  29  --->  Accuracy = 90.38%\n",
      "M_pca =  148 , M_lda =  30  --->  Accuracy = 89.42%\n",
      "M_pca =  148 , M_lda =  31  --->  Accuracy = 90.38%\n",
      "M_pca =  148 , M_lda =  32  --->  Accuracy = 91.35%\n",
      "M_pca =  148 , M_lda =  33  --->  Accuracy = 91.35%\n",
      "M_pca =  148 , M_lda =  34  --->  Accuracy = 90.38%\n",
      "M_pca =  148 , M_lda =  35  --->  Accuracy = 91.35%\n",
      "M_pca =  148 , M_lda =  36  --->  Accuracy = 90.38%\n",
      "M_pca =  148 , M_lda =  37  --->  Accuracy = 91.35%\n",
      "M_pca =  148 , M_lda =  38  --->  Accuracy = 91.35%\n",
      "M_pca =  148 , M_lda =  39  --->  Accuracy = 90.38%\n",
      "M_pca =  148 , M_lda =  40  --->  Accuracy = 90.38%\n",
      "M_pca =  148 , M_lda =  41  --->  Accuracy = 90.38%\n",
      "M_pca =  148 , M_lda =  42  --->  Accuracy = 91.35%\n",
      "M_pca =  148 , M_lda =  43  --->  Accuracy = 93.27%\n",
      "M_pca =  148 , M_lda =  44  --->  Accuracy = 93.27%\n",
      "M_pca =  148 , M_lda =  45  --->  Accuracy = 92.31%\n",
      "M_pca =  148 , M_lda =  46  --->  Accuracy = 92.31%\n",
      "M_pca =  148 , M_lda =  47  --->  Accuracy = 92.31%\n",
      "M_pca =  148 , M_lda =  48  --->  Accuracy = 91.35%\n",
      "M_pca =  148 , M_lda =  49  --->  Accuracy = 92.31%\n",
      "M_pca =  148 , M_lda =  50  --->  Accuracy = 92.31%\n",
      "M_pca =  148 , M_lda =  51  --->  Accuracy = 92.31%\n",
      "M_pca =  149 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  149 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  149 , M_lda =  3  --->  Accuracy = 25.00%\n",
      "M_pca =  149 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  149 , M_lda =  5  --->  Accuracy = 51.92%\n",
      "M_pca =  149 , M_lda =  6  --->  Accuracy = 62.50%\n",
      "M_pca =  149 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  149 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  149 , M_lda =  9  --->  Accuracy = 73.08%\n",
      "M_pca =  149 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  149 , M_lda =  11  --->  Accuracy = 81.73%\n",
      "M_pca =  149 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  149 , M_lda =  13  --->  Accuracy = 81.73%\n",
      "M_pca =  149 , M_lda =  14  --->  Accuracy = 83.65%\n",
      "M_pca =  149 , M_lda =  15  --->  Accuracy = 85.58%\n",
      "M_pca =  149 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  149 , M_lda =  17  --->  Accuracy = 87.50%\n",
      "M_pca =  149 , M_lda =  18  --->  Accuracy = 88.46%\n",
      "M_pca =  149 , M_lda =  19  --->  Accuracy = 88.46%\n",
      "M_pca =  149 , M_lda =  20  --->  Accuracy = 87.50%\n",
      "M_pca =  149 , M_lda =  21  --->  Accuracy = 88.46%\n",
      "M_pca =  149 , M_lda =  22  --->  Accuracy = 89.42%\n",
      "M_pca =  149 , M_lda =  23  --->  Accuracy = 89.42%\n",
      "M_pca =  149 , M_lda =  24  --->  Accuracy = 90.38%\n",
      "M_pca =  149 , M_lda =  25  --->  Accuracy = 89.42%\n",
      "M_pca =  149 , M_lda =  26  --->  Accuracy = 89.42%\n",
      "M_pca =  149 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  149 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  149 , M_lda =  29  --->  Accuracy = 89.42%\n",
      "M_pca =  149 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  149 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  149 , M_lda =  32  --->  Accuracy = 89.42%\n",
      "M_pca =  149 , M_lda =  33  --->  Accuracy = 89.42%\n",
      "M_pca =  149 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  149 , M_lda =  35  --->  Accuracy = 90.38%\n",
      "M_pca =  149 , M_lda =  36  --->  Accuracy = 89.42%\n",
      "M_pca =  149 , M_lda =  37  --->  Accuracy = 90.38%\n",
      "M_pca =  149 , M_lda =  38  --->  Accuracy = 90.38%\n",
      "M_pca =  149 , M_lda =  39  --->  Accuracy = 90.38%\n",
      "M_pca =  149 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  149 , M_lda =  41  --->  Accuracy = 90.38%\n",
      "M_pca =  149 , M_lda =  42  --->  Accuracy = 91.35%\n",
      "M_pca =  149 , M_lda =  43  --->  Accuracy = 92.31%\n",
      "M_pca =  149 , M_lda =  44  --->  Accuracy = 92.31%\n",
      "M_pca =  149 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  149 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  149 , M_lda =  47  --->  Accuracy = 91.35%\n",
      "M_pca =  149 , M_lda =  48  --->  Accuracy = 91.35%\n",
      "M_pca =  149 , M_lda =  49  --->  Accuracy = 91.35%\n",
      "M_pca =  149 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  149 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  150 , M_lda =  1  --->  Accuracy = 11.54%\n",
      "M_pca =  150 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  150 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  150 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  150 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  150 , M_lda =  6  --->  Accuracy = 61.54%\n",
      "M_pca =  150 , M_lda =  7  --->  Accuracy = 60.58%\n",
      "M_pca =  150 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  150 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  150 , M_lda =  10  --->  Accuracy = 77.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  150 , M_lda =  11  --->  Accuracy = 81.73%\n",
      "M_pca =  150 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  150 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  150 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  150 , M_lda =  15  --->  Accuracy = 87.50%\n",
      "M_pca =  150 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  150 , M_lda =  17  --->  Accuracy = 84.62%\n",
      "M_pca =  150 , M_lda =  18  --->  Accuracy = 86.54%\n",
      "M_pca =  150 , M_lda =  19  --->  Accuracy = 88.46%\n",
      "M_pca =  150 , M_lda =  20  --->  Accuracy = 88.46%\n",
      "M_pca =  150 , M_lda =  21  --->  Accuracy = 89.42%\n",
      "M_pca =  150 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  150 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  150 , M_lda =  24  --->  Accuracy = 89.42%\n",
      "M_pca =  150 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  150 , M_lda =  26  --->  Accuracy = 88.46%\n",
      "M_pca =  150 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  150 , M_lda =  28  --->  Accuracy = 89.42%\n",
      "M_pca =  150 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  150 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  150 , M_lda =  31  --->  Accuracy = 89.42%\n",
      "M_pca =  150 , M_lda =  32  --->  Accuracy = 89.42%\n",
      "M_pca =  150 , M_lda =  33  --->  Accuracy = 89.42%\n",
      "M_pca =  150 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  150 , M_lda =  35  --->  Accuracy = 90.38%\n",
      "M_pca =  150 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  150 , M_lda =  37  --->  Accuracy = 91.35%\n",
      "M_pca =  150 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  150 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  150 , M_lda =  40  --->  Accuracy = 90.38%\n",
      "M_pca =  150 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  150 , M_lda =  42  --->  Accuracy = 91.35%\n",
      "M_pca =  150 , M_lda =  43  --->  Accuracy = 91.35%\n",
      "M_pca =  150 , M_lda =  44  --->  Accuracy = 91.35%\n",
      "M_pca =  150 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  150 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  150 , M_lda =  47  --->  Accuracy = 91.35%\n",
      "M_pca =  150 , M_lda =  48  --->  Accuracy = 91.35%\n",
      "M_pca =  150 , M_lda =  49  --->  Accuracy = 91.35%\n",
      "M_pca =  150 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  150 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  151 , M_lda =  1  --->  Accuracy = 12.50%\n",
      "M_pca =  151 , M_lda =  2  --->  Accuracy = 22.12%\n",
      "M_pca =  151 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  151 , M_lda =  4  --->  Accuracy = 39.42%\n",
      "M_pca =  151 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  151 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  151 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  151 , M_lda =  8  --->  Accuracy = 65.38%\n",
      "M_pca =  151 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  151 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  151 , M_lda =  11  --->  Accuracy = 80.77%\n",
      "M_pca =  151 , M_lda =  12  --->  Accuracy = 79.81%\n",
      "M_pca =  151 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  151 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  151 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  151 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  151 , M_lda =  17  --->  Accuracy = 85.58%\n",
      "M_pca =  151 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  151 , M_lda =  19  --->  Accuracy = 87.50%\n",
      "M_pca =  151 , M_lda =  20  --->  Accuracy = 88.46%\n",
      "M_pca =  151 , M_lda =  21  --->  Accuracy = 89.42%\n",
      "M_pca =  151 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  151 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  151 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  151 , M_lda =  25  --->  Accuracy = 88.46%\n",
      "M_pca =  151 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  151 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  151 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  151 , M_lda =  29  --->  Accuracy = 89.42%\n",
      "M_pca =  151 , M_lda =  30  --->  Accuracy = 90.38%\n",
      "M_pca =  151 , M_lda =  31  --->  Accuracy = 91.35%\n",
      "M_pca =  151 , M_lda =  32  --->  Accuracy = 90.38%\n",
      "M_pca =  151 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  151 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  151 , M_lda =  35  --->  Accuracy = 89.42%\n",
      "M_pca =  151 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  151 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  151 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  151 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  151 , M_lda =  40  --->  Accuracy = 90.38%\n",
      "M_pca =  151 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  151 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  151 , M_lda =  43  --->  Accuracy = 91.35%\n",
      "M_pca =  151 , M_lda =  44  --->  Accuracy = 91.35%\n",
      "M_pca =  151 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  151 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  151 , M_lda =  47  --->  Accuracy = 91.35%\n",
      "M_pca =  151 , M_lda =  48  --->  Accuracy = 91.35%\n",
      "M_pca =  151 , M_lda =  49  --->  Accuracy = 92.31%\n",
      "M_pca =  151 , M_lda =  50  --->  Accuracy = 92.31%\n",
      "M_pca =  151 , M_lda =  51  --->  Accuracy = 92.31%\n",
      "M_pca =  152 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  152 , M_lda =  2  --->  Accuracy = 22.12%\n",
      "M_pca =  152 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  152 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  152 , M_lda =  5  --->  Accuracy = 46.15%\n",
      "M_pca =  152 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  152 , M_lda =  7  --->  Accuracy = 61.54%\n",
      "M_pca =  152 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  152 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  152 , M_lda =  10  --->  Accuracy = 79.81%\n",
      "M_pca =  152 , M_lda =  11  --->  Accuracy = 83.65%\n",
      "M_pca =  152 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  152 , M_lda =  13  --->  Accuracy = 81.73%\n",
      "M_pca =  152 , M_lda =  14  --->  Accuracy = 79.81%\n",
      "M_pca =  152 , M_lda =  15  --->  Accuracy = 83.65%\n",
      "M_pca =  152 , M_lda =  16  --->  Accuracy = 85.58%\n",
      "M_pca =  152 , M_lda =  17  --->  Accuracy = 86.54%\n",
      "M_pca =  152 , M_lda =  18  --->  Accuracy = 86.54%\n",
      "M_pca =  152 , M_lda =  19  --->  Accuracy = 88.46%\n",
      "M_pca =  152 , M_lda =  20  --->  Accuracy = 88.46%\n",
      "M_pca =  152 , M_lda =  21  --->  Accuracy = 87.50%\n",
      "M_pca =  152 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  152 , M_lda =  23  --->  Accuracy = 89.42%\n",
      "M_pca =  152 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  152 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  152 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  152 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  152 , M_lda =  28  --->  Accuracy = 89.42%\n",
      "M_pca =  152 , M_lda =  29  --->  Accuracy = 90.38%\n",
      "M_pca =  152 , M_lda =  30  --->  Accuracy = 90.38%\n",
      "M_pca =  152 , M_lda =  31  --->  Accuracy = 90.38%\n",
      "M_pca =  152 , M_lda =  32  --->  Accuracy = 89.42%\n",
      "M_pca =  152 , M_lda =  33  --->  Accuracy = 89.42%\n",
      "M_pca =  152 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  152 , M_lda =  35  --->  Accuracy = 89.42%\n",
      "M_pca =  152 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  152 , M_lda =  37  --->  Accuracy = 90.38%\n",
      "M_pca =  152 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  152 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  152 , M_lda =  40  --->  Accuracy = 91.35%\n",
      "M_pca =  152 , M_lda =  41  --->  Accuracy = 91.35%\n",
      "M_pca =  152 , M_lda =  42  --->  Accuracy = 92.31%\n",
      "M_pca =  152 , M_lda =  43  --->  Accuracy = 92.31%\n",
      "M_pca =  152 , M_lda =  44  --->  Accuracy = 91.35%\n",
      "M_pca =  152 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  152 , M_lda =  46  --->  Accuracy = 91.35%\n",
      "M_pca =  152 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  152 , M_lda =  48  --->  Accuracy = 91.35%\n",
      "M_pca =  152 , M_lda =  49  --->  Accuracy = 92.31%\n",
      "M_pca =  152 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  152 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  153 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  153 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  153 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  153 , M_lda =  4  --->  Accuracy = 41.35%\n",
      "M_pca =  153 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  153 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  153 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  153 , M_lda =  8  --->  Accuracy = 69.23%\n",
      "M_pca =  153 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  153 , M_lda =  10  --->  Accuracy = 79.81%\n",
      "M_pca =  153 , M_lda =  11  --->  Accuracy = 82.69%\n",
      "M_pca =  153 , M_lda =  12  --->  Accuracy = 79.81%\n",
      "M_pca =  153 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  153 , M_lda =  14  --->  Accuracy = 85.58%\n",
      "M_pca =  153 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  153 , M_lda =  16  --->  Accuracy = 85.58%\n",
      "M_pca =  153 , M_lda =  17  --->  Accuracy = 84.62%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  153 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  153 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  153 , M_lda =  20  --->  Accuracy = 88.46%\n",
      "M_pca =  153 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  153 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  153 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  153 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  153 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  153 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  153 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  153 , M_lda =  28  --->  Accuracy = 90.38%\n",
      "M_pca =  153 , M_lda =  29  --->  Accuracy = 91.35%\n",
      "M_pca =  153 , M_lda =  30  --->  Accuracy = 90.38%\n",
      "M_pca =  153 , M_lda =  31  --->  Accuracy = 90.38%\n",
      "M_pca =  153 , M_lda =  32  --->  Accuracy = 91.35%\n",
      "M_pca =  153 , M_lda =  33  --->  Accuracy = 90.38%\n",
      "M_pca =  153 , M_lda =  34  --->  Accuracy = 89.42%\n",
      "M_pca =  153 , M_lda =  35  --->  Accuracy = 90.38%\n",
      "M_pca =  153 , M_lda =  36  --->  Accuracy = 90.38%\n",
      "M_pca =  153 , M_lda =  37  --->  Accuracy = 91.35%\n",
      "M_pca =  153 , M_lda =  38  --->  Accuracy = 91.35%\n",
      "M_pca =  153 , M_lda =  39  --->  Accuracy = 90.38%\n",
      "M_pca =  153 , M_lda =  40  --->  Accuracy = 91.35%\n",
      "M_pca =  153 , M_lda =  41  --->  Accuracy = 92.31%\n",
      "M_pca =  153 , M_lda =  42  --->  Accuracy = 92.31%\n",
      "M_pca =  153 , M_lda =  43  --->  Accuracy = 92.31%\n",
      "M_pca =  153 , M_lda =  44  --->  Accuracy = 91.35%\n",
      "M_pca =  153 , M_lda =  45  --->  Accuracy = 91.35%\n",
      "M_pca =  153 , M_lda =  46  --->  Accuracy = 91.35%\n",
      "M_pca =  153 , M_lda =  47  --->  Accuracy = 91.35%\n",
      "M_pca =  153 , M_lda =  48  --->  Accuracy = 91.35%\n",
      "M_pca =  153 , M_lda =  49  --->  Accuracy = 92.31%\n",
      "M_pca =  153 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  153 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  154 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  154 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  154 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  154 , M_lda =  4  --->  Accuracy = 41.35%\n",
      "M_pca =  154 , M_lda =  5  --->  Accuracy = 51.92%\n",
      "M_pca =  154 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  154 , M_lda =  7  --->  Accuracy = 61.54%\n",
      "M_pca =  154 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  154 , M_lda =  9  --->  Accuracy = 73.08%\n",
      "M_pca =  154 , M_lda =  10  --->  Accuracy = 79.81%\n",
      "M_pca =  154 , M_lda =  11  --->  Accuracy = 81.73%\n",
      "M_pca =  154 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  154 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  154 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  154 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  154 , M_lda =  16  --->  Accuracy = 85.58%\n",
      "M_pca =  154 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  154 , M_lda =  18  --->  Accuracy = 83.65%\n",
      "M_pca =  154 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  154 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  154 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  154 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  154 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  154 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  154 , M_lda =  25  --->  Accuracy = 88.46%\n",
      "M_pca =  154 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  154 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  154 , M_lda =  28  --->  Accuracy = 90.38%\n",
      "M_pca =  154 , M_lda =  29  --->  Accuracy = 91.35%\n",
      "M_pca =  154 , M_lda =  30  --->  Accuracy = 90.38%\n",
      "M_pca =  154 , M_lda =  31  --->  Accuracy = 91.35%\n",
      "M_pca =  154 , M_lda =  32  --->  Accuracy = 91.35%\n",
      "M_pca =  154 , M_lda =  33  --->  Accuracy = 91.35%\n",
      "M_pca =  154 , M_lda =  34  --->  Accuracy = 91.35%\n",
      "M_pca =  154 , M_lda =  35  --->  Accuracy = 90.38%\n",
      "M_pca =  154 , M_lda =  36  --->  Accuracy = 89.42%\n",
      "M_pca =  154 , M_lda =  37  --->  Accuracy = 90.38%\n",
      "M_pca =  154 , M_lda =  38  --->  Accuracy = 91.35%\n",
      "M_pca =  154 , M_lda =  39  --->  Accuracy = 91.35%\n",
      "M_pca =  154 , M_lda =  40  --->  Accuracy = 91.35%\n",
      "M_pca =  154 , M_lda =  41  --->  Accuracy = 92.31%\n",
      "M_pca =  154 , M_lda =  42  --->  Accuracy = 92.31%\n",
      "M_pca =  154 , M_lda =  43  --->  Accuracy = 91.35%\n",
      "M_pca =  154 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  154 , M_lda =  45  --->  Accuracy = 91.35%\n",
      "M_pca =  154 , M_lda =  46  --->  Accuracy = 91.35%\n",
      "M_pca =  154 , M_lda =  47  --->  Accuracy = 92.31%\n",
      "M_pca =  154 , M_lda =  48  --->  Accuracy = 91.35%\n",
      "M_pca =  154 , M_lda =  49  --->  Accuracy = 91.35%\n",
      "M_pca =  154 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  154 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  155 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  155 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  155 , M_lda =  3  --->  Accuracy = 34.62%\n",
      "M_pca =  155 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  155 , M_lda =  5  --->  Accuracy = 50.96%\n",
      "M_pca =  155 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  155 , M_lda =  7  --->  Accuracy = 61.54%\n",
      "M_pca =  155 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  155 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  155 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  155 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  155 , M_lda =  12  --->  Accuracy = 78.85%\n",
      "M_pca =  155 , M_lda =  13  --->  Accuracy = 80.77%\n",
      "M_pca =  155 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  155 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  155 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  155 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  155 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  155 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  155 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  155 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  155 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  155 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  155 , M_lda =  24  --->  Accuracy = 90.38%\n",
      "M_pca =  155 , M_lda =  25  --->  Accuracy = 89.42%\n",
      "M_pca =  155 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  155 , M_lda =  27  --->  Accuracy = 89.42%\n",
      "M_pca =  155 , M_lda =  28  --->  Accuracy = 91.35%\n",
      "M_pca =  155 , M_lda =  29  --->  Accuracy = 91.35%\n",
      "M_pca =  155 , M_lda =  30  --->  Accuracy = 90.38%\n",
      "M_pca =  155 , M_lda =  31  --->  Accuracy = 92.31%\n",
      "M_pca =  155 , M_lda =  32  --->  Accuracy = 92.31%\n",
      "M_pca =  155 , M_lda =  33  --->  Accuracy = 92.31%\n",
      "M_pca =  155 , M_lda =  34  --->  Accuracy = 92.31%\n",
      "M_pca =  155 , M_lda =  35  --->  Accuracy = 93.27%\n",
      "M_pca =  155 , M_lda =  36  --->  Accuracy = 91.35%\n",
      "M_pca =  155 , M_lda =  37  --->  Accuracy = 91.35%\n",
      "M_pca =  155 , M_lda =  38  --->  Accuracy = 92.31%\n",
      "M_pca =  155 , M_lda =  39  --->  Accuracy = 92.31%\n",
      "M_pca =  155 , M_lda =  40  --->  Accuracy = 92.31%\n",
      "M_pca =  155 , M_lda =  41  --->  Accuracy = 91.35%\n",
      "M_pca =  155 , M_lda =  42  --->  Accuracy = 92.31%\n",
      "M_pca =  155 , M_lda =  43  --->  Accuracy = 91.35%\n",
      "M_pca =  155 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  155 , M_lda =  45  --->  Accuracy = 92.31%\n",
      "M_pca =  155 , M_lda =  46  --->  Accuracy = 92.31%\n",
      "M_pca =  155 , M_lda =  47  --->  Accuracy = 92.31%\n",
      "M_pca =  155 , M_lda =  48  --->  Accuracy = 91.35%\n",
      "M_pca =  155 , M_lda =  49  --->  Accuracy = 92.31%\n",
      "M_pca =  155 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  155 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  156 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  156 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  156 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  156 , M_lda =  4  --->  Accuracy = 46.15%\n",
      "M_pca =  156 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  156 , M_lda =  6  --->  Accuracy = 60.58%\n",
      "M_pca =  156 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  156 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  156 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  156 , M_lda =  10  --->  Accuracy = 80.77%\n",
      "M_pca =  156 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  156 , M_lda =  12  --->  Accuracy = 78.85%\n",
      "M_pca =  156 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  156 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  156 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  156 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  156 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  156 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  156 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  156 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  156 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  156 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  156 , M_lda =  23  --->  Accuracy = 86.54%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  156 , M_lda =  24  --->  Accuracy = 91.35%\n",
      "M_pca =  156 , M_lda =  25  --->  Accuracy = 89.42%\n",
      "M_pca =  156 , M_lda =  26  --->  Accuracy = 90.38%\n",
      "M_pca =  156 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  156 , M_lda =  28  --->  Accuracy = 91.35%\n",
      "M_pca =  156 , M_lda =  29  --->  Accuracy = 90.38%\n",
      "M_pca =  156 , M_lda =  30  --->  Accuracy = 93.27%\n",
      "M_pca =  156 , M_lda =  31  --->  Accuracy = 92.31%\n",
      "M_pca =  156 , M_lda =  32  --->  Accuracy = 92.31%\n",
      "M_pca =  156 , M_lda =  33  --->  Accuracy = 91.35%\n",
      "M_pca =  156 , M_lda =  34  --->  Accuracy = 92.31%\n",
      "M_pca =  156 , M_lda =  35  --->  Accuracy = 92.31%\n",
      "M_pca =  156 , M_lda =  36  --->  Accuracy = 90.38%\n",
      "M_pca =  156 , M_lda =  37  --->  Accuracy = 91.35%\n",
      "M_pca =  156 , M_lda =  38  --->  Accuracy = 91.35%\n",
      "M_pca =  156 , M_lda =  39  --->  Accuracy = 91.35%\n",
      "M_pca =  156 , M_lda =  40  --->  Accuracy = 91.35%\n",
      "M_pca =  156 , M_lda =  41  --->  Accuracy = 91.35%\n",
      "M_pca =  156 , M_lda =  42  --->  Accuracy = 91.35%\n",
      "M_pca =  156 , M_lda =  43  --->  Accuracy = 91.35%\n",
      "M_pca =  156 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  156 , M_lda =  45  --->  Accuracy = 92.31%\n",
      "M_pca =  156 , M_lda =  46  --->  Accuracy = 93.27%\n",
      "M_pca =  156 , M_lda =  47  --->  Accuracy = 93.27%\n",
      "M_pca =  156 , M_lda =  48  --->  Accuracy = 92.31%\n",
      "M_pca =  156 , M_lda =  49  --->  Accuracy = 92.31%\n",
      "M_pca =  156 , M_lda =  50  --->  Accuracy = 92.31%\n",
      "M_pca =  156 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  157 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  157 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  157 , M_lda =  3  --->  Accuracy = 34.62%\n",
      "M_pca =  157 , M_lda =  4  --->  Accuracy = 50.96%\n",
      "M_pca =  157 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  157 , M_lda =  6  --->  Accuracy = 61.54%\n",
      "M_pca =  157 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  157 , M_lda =  8  --->  Accuracy = 69.23%\n",
      "M_pca =  157 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  157 , M_lda =  10  --->  Accuracy = 79.81%\n",
      "M_pca =  157 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  157 , M_lda =  12  --->  Accuracy = 79.81%\n",
      "M_pca =  157 , M_lda =  13  --->  Accuracy = 80.77%\n",
      "M_pca =  157 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  157 , M_lda =  15  --->  Accuracy = 80.77%\n",
      "M_pca =  157 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  157 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  157 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  157 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  157 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  157 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  157 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  157 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  157 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  157 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  157 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  157 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  157 , M_lda =  28  --->  Accuracy = 90.38%\n",
      "M_pca =  157 , M_lda =  29  --->  Accuracy = 90.38%\n",
      "M_pca =  157 , M_lda =  30  --->  Accuracy = 92.31%\n",
      "M_pca =  157 , M_lda =  31  --->  Accuracy = 92.31%\n",
      "M_pca =  157 , M_lda =  32  --->  Accuracy = 91.35%\n",
      "M_pca =  157 , M_lda =  33  --->  Accuracy = 91.35%\n",
      "M_pca =  157 , M_lda =  34  --->  Accuracy = 91.35%\n",
      "M_pca =  157 , M_lda =  35  --->  Accuracy = 91.35%\n",
      "M_pca =  157 , M_lda =  36  --->  Accuracy = 91.35%\n",
      "M_pca =  157 , M_lda =  37  --->  Accuracy = 91.35%\n",
      "M_pca =  157 , M_lda =  38  --->  Accuracy = 91.35%\n",
      "M_pca =  157 , M_lda =  39  --->  Accuracy = 91.35%\n",
      "M_pca =  157 , M_lda =  40  --->  Accuracy = 92.31%\n",
      "M_pca =  157 , M_lda =  41  --->  Accuracy = 92.31%\n",
      "M_pca =  157 , M_lda =  42  --->  Accuracy = 92.31%\n",
      "M_pca =  157 , M_lda =  43  --->  Accuracy = 91.35%\n",
      "M_pca =  157 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  157 , M_lda =  45  --->  Accuracy = 92.31%\n",
      "M_pca =  157 , M_lda =  46  --->  Accuracy = 91.35%\n",
      "M_pca =  157 , M_lda =  47  --->  Accuracy = 92.31%\n",
      "M_pca =  157 , M_lda =  48  --->  Accuracy = 92.31%\n",
      "M_pca =  157 , M_lda =  49  --->  Accuracy = 92.31%\n",
      "M_pca =  157 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  157 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  158 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  158 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  158 , M_lda =  3  --->  Accuracy = 36.54%\n",
      "M_pca =  158 , M_lda =  4  --->  Accuracy = 50.00%\n",
      "M_pca =  158 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  158 , M_lda =  6  --->  Accuracy = 61.54%\n",
      "M_pca =  158 , M_lda =  7  --->  Accuracy = 68.27%\n",
      "M_pca =  158 , M_lda =  8  --->  Accuracy = 72.12%\n",
      "M_pca =  158 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  158 , M_lda =  10  --->  Accuracy = 82.69%\n",
      "M_pca =  158 , M_lda =  11  --->  Accuracy = 82.69%\n",
      "M_pca =  158 , M_lda =  12  --->  Accuracy = 84.62%\n",
      "M_pca =  158 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  158 , M_lda =  14  --->  Accuracy = 85.58%\n",
      "M_pca =  158 , M_lda =  15  --->  Accuracy = 80.77%\n",
      "M_pca =  158 , M_lda =  16  --->  Accuracy = 83.65%\n",
      "M_pca =  158 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  158 , M_lda =  18  --->  Accuracy = 83.65%\n",
      "M_pca =  158 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  158 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  158 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  158 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  158 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  158 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  158 , M_lda =  25  --->  Accuracy = 88.46%\n",
      "M_pca =  158 , M_lda =  26  --->  Accuracy = 89.42%\n",
      "M_pca =  158 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  158 , M_lda =  28  --->  Accuracy = 91.35%\n",
      "M_pca =  158 , M_lda =  29  --->  Accuracy = 90.38%\n",
      "M_pca =  158 , M_lda =  30  --->  Accuracy = 91.35%\n",
      "M_pca =  158 , M_lda =  31  --->  Accuracy = 91.35%\n",
      "M_pca =  158 , M_lda =  32  --->  Accuracy = 91.35%\n",
      "M_pca =  158 , M_lda =  33  --->  Accuracy = 91.35%\n",
      "M_pca =  158 , M_lda =  34  --->  Accuracy = 90.38%\n",
      "M_pca =  158 , M_lda =  35  --->  Accuracy = 89.42%\n",
      "M_pca =  158 , M_lda =  36  --->  Accuracy = 91.35%\n",
      "M_pca =  158 , M_lda =  37  --->  Accuracy = 91.35%\n",
      "M_pca =  158 , M_lda =  38  --->  Accuracy = 90.38%\n",
      "M_pca =  158 , M_lda =  39  --->  Accuracy = 90.38%\n",
      "M_pca =  158 , M_lda =  40  --->  Accuracy = 91.35%\n",
      "M_pca =  158 , M_lda =  41  --->  Accuracy = 91.35%\n",
      "M_pca =  158 , M_lda =  42  --->  Accuracy = 91.35%\n",
      "M_pca =  158 , M_lda =  43  --->  Accuracy = 92.31%\n",
      "M_pca =  158 , M_lda =  44  --->  Accuracy = 92.31%\n",
      "M_pca =  158 , M_lda =  45  --->  Accuracy = 92.31%\n",
      "M_pca =  158 , M_lda =  46  --->  Accuracy = 91.35%\n",
      "M_pca =  158 , M_lda =  47  --->  Accuracy = 93.27%\n",
      "M_pca =  158 , M_lda =  48  --->  Accuracy = 93.27%\n",
      "M_pca =  158 , M_lda =  49  --->  Accuracy = 93.27%\n",
      "M_pca =  158 , M_lda =  50  --->  Accuracy = 93.27%\n",
      "M_pca =  158 , M_lda =  51  --->  Accuracy = 93.27%\n",
      "M_pca =  159 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  159 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  159 , M_lda =  3  --->  Accuracy = 33.65%\n",
      "M_pca =  159 , M_lda =  4  --->  Accuracy = 50.96%\n",
      "M_pca =  159 , M_lda =  5  --->  Accuracy = 47.12%\n",
      "M_pca =  159 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  159 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  159 , M_lda =  8  --->  Accuracy = 72.12%\n",
      "M_pca =  159 , M_lda =  9  --->  Accuracy = 76.92%\n",
      "M_pca =  159 , M_lda =  10  --->  Accuracy = 85.58%\n",
      "M_pca =  159 , M_lda =  11  --->  Accuracy = 88.46%\n",
      "M_pca =  159 , M_lda =  12  --->  Accuracy = 84.62%\n",
      "M_pca =  159 , M_lda =  13  --->  Accuracy = 85.58%\n",
      "M_pca =  159 , M_lda =  14  --->  Accuracy = 83.65%\n",
      "M_pca =  159 , M_lda =  15  --->  Accuracy = 80.77%\n",
      "M_pca =  159 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  159 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  159 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  159 , M_lda =  19  --->  Accuracy = 85.58%\n",
      "M_pca =  159 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  159 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  159 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  159 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  159 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  159 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  159 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  159 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  159 , M_lda =  28  --->  Accuracy = 90.38%\n",
      "M_pca =  159 , M_lda =  29  --->  Accuracy = 90.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  159 , M_lda =  30  --->  Accuracy = 91.35%\n",
      "M_pca =  159 , M_lda =  31  --->  Accuracy = 91.35%\n",
      "M_pca =  159 , M_lda =  32  --->  Accuracy = 91.35%\n",
      "M_pca =  159 , M_lda =  33  --->  Accuracy = 90.38%\n",
      "M_pca =  159 , M_lda =  34  --->  Accuracy = 90.38%\n",
      "M_pca =  159 , M_lda =  35  --->  Accuracy = 90.38%\n",
      "M_pca =  159 , M_lda =  36  --->  Accuracy = 90.38%\n",
      "M_pca =  159 , M_lda =  37  --->  Accuracy = 90.38%\n",
      "M_pca =  159 , M_lda =  38  --->  Accuracy = 90.38%\n",
      "M_pca =  159 , M_lda =  39  --->  Accuracy = 90.38%\n",
      "M_pca =  159 , M_lda =  40  --->  Accuracy = 91.35%\n",
      "M_pca =  159 , M_lda =  41  --->  Accuracy = 91.35%\n",
      "M_pca =  159 , M_lda =  42  --->  Accuracy = 91.35%\n",
      "M_pca =  159 , M_lda =  43  --->  Accuracy = 92.31%\n",
      "M_pca =  159 , M_lda =  44  --->  Accuracy = 92.31%\n",
      "M_pca =  159 , M_lda =  45  --->  Accuracy = 93.27%\n",
      "M_pca =  159 , M_lda =  46  --->  Accuracy = 93.27%\n",
      "M_pca =  159 , M_lda =  47  --->  Accuracy = 92.31%\n",
      "M_pca =  159 , M_lda =  48  --->  Accuracy = 93.27%\n",
      "M_pca =  159 , M_lda =  49  --->  Accuracy = 92.31%\n",
      "M_pca =  159 , M_lda =  50  --->  Accuracy = 92.31%\n",
      "M_pca =  159 , M_lda =  51  --->  Accuracy = 92.31%\n",
      "M_pca =  160 , M_lda =  1  --->  Accuracy = 10.58%\n",
      "M_pca =  160 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  160 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  160 , M_lda =  4  --->  Accuracy = 50.00%\n",
      "M_pca =  160 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  160 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  160 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  160 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  160 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  160 , M_lda =  10  --->  Accuracy = 81.73%\n",
      "M_pca =  160 , M_lda =  11  --->  Accuracy = 83.65%\n",
      "M_pca =  160 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  160 , M_lda =  13  --->  Accuracy = 84.62%\n",
      "M_pca =  160 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  160 , M_lda =  15  --->  Accuracy = 83.65%\n",
      "M_pca =  160 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  160 , M_lda =  17  --->  Accuracy = 85.58%\n",
      "M_pca =  160 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  160 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  160 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  160 , M_lda =  21  --->  Accuracy = 82.69%\n",
      "M_pca =  160 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  160 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  160 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  160 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  160 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  160 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  160 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  160 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  160 , M_lda =  30  --->  Accuracy = 89.42%\n",
      "M_pca =  160 , M_lda =  31  --->  Accuracy = 89.42%\n",
      "M_pca =  160 , M_lda =  32  --->  Accuracy = 90.38%\n",
      "M_pca =  160 , M_lda =  33  --->  Accuracy = 90.38%\n",
      "M_pca =  160 , M_lda =  34  --->  Accuracy = 90.38%\n",
      "M_pca =  160 , M_lda =  35  --->  Accuracy = 90.38%\n",
      "M_pca =  160 , M_lda =  36  --->  Accuracy = 89.42%\n",
      "M_pca =  160 , M_lda =  37  --->  Accuracy = 89.42%\n",
      "M_pca =  160 , M_lda =  38  --->  Accuracy = 90.38%\n",
      "M_pca =  160 , M_lda =  39  --->  Accuracy = 90.38%\n",
      "M_pca =  160 , M_lda =  40  --->  Accuracy = 91.35%\n",
      "M_pca =  160 , M_lda =  41  --->  Accuracy = 91.35%\n",
      "M_pca =  160 , M_lda =  42  --->  Accuracy = 91.35%\n",
      "M_pca =  160 , M_lda =  43  --->  Accuracy = 91.35%\n",
      "M_pca =  160 , M_lda =  44  --->  Accuracy = 92.31%\n",
      "M_pca =  160 , M_lda =  45  --->  Accuracy = 92.31%\n",
      "M_pca =  160 , M_lda =  46  --->  Accuracy = 92.31%\n",
      "M_pca =  160 , M_lda =  47  --->  Accuracy = 92.31%\n",
      "M_pca =  160 , M_lda =  48  --->  Accuracy = 93.27%\n",
      "M_pca =  160 , M_lda =  49  --->  Accuracy = 93.27%\n",
      "M_pca =  160 , M_lda =  50  --->  Accuracy = 93.27%\n",
      "M_pca =  160 , M_lda =  51  --->  Accuracy = 93.27%\n",
      "M_pca =  161 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  161 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  161 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  161 , M_lda =  4  --->  Accuracy = 47.12%\n",
      "M_pca =  161 , M_lda =  5  --->  Accuracy = 50.96%\n",
      "M_pca =  161 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  161 , M_lda =  7  --->  Accuracy = 68.27%\n",
      "M_pca =  161 , M_lda =  8  --->  Accuracy = 72.12%\n",
      "M_pca =  161 , M_lda =  9  --->  Accuracy = 80.77%\n",
      "M_pca =  161 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  161 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  161 , M_lda =  12  --->  Accuracy = 82.69%\n",
      "M_pca =  161 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  161 , M_lda =  14  --->  Accuracy = 82.69%\n",
      "M_pca =  161 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  161 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  161 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  161 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  161 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  161 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  161 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  161 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  161 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  161 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  161 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  161 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  161 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  161 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  161 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  161 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  161 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  161 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  161 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  161 , M_lda =  34  --->  Accuracy = 89.42%\n",
      "M_pca =  161 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  161 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  161 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  161 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  161 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  161 , M_lda =  40  --->  Accuracy = 90.38%\n",
      "M_pca =  161 , M_lda =  41  --->  Accuracy = 90.38%\n",
      "M_pca =  161 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  161 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  161 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  161 , M_lda =  45  --->  Accuracy = 91.35%\n",
      "M_pca =  161 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  161 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  161 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  161 , M_lda =  49  --->  Accuracy = 91.35%\n",
      "M_pca =  161 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  161 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  162 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  162 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  162 , M_lda =  3  --->  Accuracy = 34.62%\n",
      "M_pca =  162 , M_lda =  4  --->  Accuracy = 48.08%\n",
      "M_pca =  162 , M_lda =  5  --->  Accuracy = 53.85%\n",
      "M_pca =  162 , M_lda =  6  --->  Accuracy = 62.50%\n",
      "M_pca =  162 , M_lda =  7  --->  Accuracy = 70.19%\n",
      "M_pca =  162 , M_lda =  8  --->  Accuracy = 74.04%\n",
      "M_pca =  162 , M_lda =  9  --->  Accuracy = 76.92%\n",
      "M_pca =  162 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  162 , M_lda =  11  --->  Accuracy = 82.69%\n",
      "M_pca =  162 , M_lda =  12  --->  Accuracy = 83.65%\n",
      "M_pca =  162 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  162 , M_lda =  14  --->  Accuracy = 83.65%\n",
      "M_pca =  162 , M_lda =  15  --->  Accuracy = 83.65%\n",
      "M_pca =  162 , M_lda =  16  --->  Accuracy = 83.65%\n",
      "M_pca =  162 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  162 , M_lda =  18  --->  Accuracy = 83.65%\n",
      "M_pca =  162 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  162 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  162 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  162 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  162 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  162 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  162 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  162 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  162 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  162 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  162 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  162 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  162 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  162 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  162 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  162 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  162 , M_lda =  35  --->  Accuracy = 88.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  162 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  162 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  162 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  162 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  162 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  162 , M_lda =  41  --->  Accuracy = 90.38%\n",
      "M_pca =  162 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  162 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  162 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  162 , M_lda =  45  --->  Accuracy = 91.35%\n",
      "M_pca =  162 , M_lda =  46  --->  Accuracy = 91.35%\n",
      "M_pca =  162 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  162 , M_lda =  48  --->  Accuracy = 91.35%\n",
      "M_pca =  162 , M_lda =  49  --->  Accuracy = 91.35%\n",
      "M_pca =  162 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  162 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  163 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  163 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  163 , M_lda =  3  --->  Accuracy = 33.65%\n",
      "M_pca =  163 , M_lda =  4  --->  Accuracy = 45.19%\n",
      "M_pca =  163 , M_lda =  5  --->  Accuracy = 52.88%\n",
      "M_pca =  163 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  163 , M_lda =  7  --->  Accuracy = 68.27%\n",
      "M_pca =  163 , M_lda =  8  --->  Accuracy = 75.00%\n",
      "M_pca =  163 , M_lda =  9  --->  Accuracy = 77.88%\n",
      "M_pca =  163 , M_lda =  10  --->  Accuracy = 79.81%\n",
      "M_pca =  163 , M_lda =  11  --->  Accuracy = 82.69%\n",
      "M_pca =  163 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  163 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  163 , M_lda =  14  --->  Accuracy = 82.69%\n",
      "M_pca =  163 , M_lda =  15  --->  Accuracy = 83.65%\n",
      "M_pca =  163 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  163 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  163 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  163 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  163 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  163 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  163 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  163 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  163 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  163 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  163 , M_lda =  26  --->  Accuracy = 88.46%\n",
      "M_pca =  163 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  163 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  163 , M_lda =  29  --->  Accuracy = 90.38%\n",
      "M_pca =  163 , M_lda =  30  --->  Accuracy = 89.42%\n",
      "M_pca =  163 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  163 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  163 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  163 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  163 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  163 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  163 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  163 , M_lda =  38  --->  Accuracy = 85.58%\n",
      "M_pca =  163 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  163 , M_lda =  40  --->  Accuracy = 86.54%\n",
      "M_pca =  163 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  163 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  163 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  163 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  163 , M_lda =  45  --->  Accuracy = 91.35%\n",
      "M_pca =  163 , M_lda =  46  --->  Accuracy = 92.31%\n",
      "M_pca =  163 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  163 , M_lda =  48  --->  Accuracy = 91.35%\n",
      "M_pca =  163 , M_lda =  49  --->  Accuracy = 91.35%\n",
      "M_pca =  163 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  163 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  164 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  164 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  164 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  164 , M_lda =  4  --->  Accuracy = 45.19%\n",
      "M_pca =  164 , M_lda =  5  --->  Accuracy = 55.77%\n",
      "M_pca =  164 , M_lda =  6  --->  Accuracy = 60.58%\n",
      "M_pca =  164 , M_lda =  7  --->  Accuracy = 70.19%\n",
      "M_pca =  164 , M_lda =  8  --->  Accuracy = 74.04%\n",
      "M_pca =  164 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  164 , M_lda =  10  --->  Accuracy = 80.77%\n",
      "M_pca =  164 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  164 , M_lda =  12  --->  Accuracy = 77.88%\n",
      "M_pca =  164 , M_lda =  13  --->  Accuracy = 80.77%\n",
      "M_pca =  164 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  164 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  164 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  164 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  164 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  164 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  164 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  164 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  164 , M_lda =  22  --->  Accuracy = 83.65%\n",
      "M_pca =  164 , M_lda =  23  --->  Accuracy = 89.42%\n",
      "M_pca =  164 , M_lda =  24  --->  Accuracy = 89.42%\n",
      "M_pca =  164 , M_lda =  25  --->  Accuracy = 88.46%\n",
      "M_pca =  164 , M_lda =  26  --->  Accuracy = 88.46%\n",
      "M_pca =  164 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  164 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  164 , M_lda =  29  --->  Accuracy = 89.42%\n",
      "M_pca =  164 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  164 , M_lda =  31  --->  Accuracy = 89.42%\n",
      "M_pca =  164 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  164 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  164 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  164 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  164 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  164 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  164 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  164 , M_lda =  39  --->  Accuracy = 85.58%\n",
      "M_pca =  164 , M_lda =  40  --->  Accuracy = 86.54%\n",
      "M_pca =  164 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  164 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  164 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  164 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  164 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  164 , M_lda =  46  --->  Accuracy = 91.35%\n",
      "M_pca =  164 , M_lda =  47  --->  Accuracy = 91.35%\n",
      "M_pca =  164 , M_lda =  48  --->  Accuracy = 92.31%\n",
      "M_pca =  164 , M_lda =  49  --->  Accuracy = 92.31%\n",
      "M_pca =  164 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  164 , M_lda =  51  --->  Accuracy = 92.31%\n",
      "M_pca =  165 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  165 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  165 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  165 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  165 , M_lda =  5  --->  Accuracy = 56.73%\n",
      "M_pca =  165 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  165 , M_lda =  7  --->  Accuracy = 72.12%\n",
      "M_pca =  165 , M_lda =  8  --->  Accuracy = 71.15%\n",
      "M_pca =  165 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  165 , M_lda =  10  --->  Accuracy = 79.81%\n",
      "M_pca =  165 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  165 , M_lda =  12  --->  Accuracy = 81.73%\n",
      "M_pca =  165 , M_lda =  13  --->  Accuracy = 80.77%\n",
      "M_pca =  165 , M_lda =  14  --->  Accuracy = 85.58%\n",
      "M_pca =  165 , M_lda =  15  --->  Accuracy = 84.62%\n",
      "M_pca =  165 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  165 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  165 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  165 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  165 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  165 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  165 , M_lda =  22  --->  Accuracy = 82.69%\n",
      "M_pca =  165 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  165 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  165 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  165 , M_lda =  26  --->  Accuracy = 88.46%\n",
      "M_pca =  165 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  165 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  165 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  165 , M_lda =  30  --->  Accuracy = 90.38%\n",
      "M_pca =  165 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  165 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  165 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  165 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  165 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  165 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  165 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  165 , M_lda =  38  --->  Accuracy = 85.58%\n",
      "M_pca =  165 , M_lda =  39  --->  Accuracy = 85.58%\n",
      "M_pca =  165 , M_lda =  40  --->  Accuracy = 86.54%\n",
      "M_pca =  165 , M_lda =  41  --->  Accuracy = 87.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  165 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  165 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  165 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  165 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  165 , M_lda =  46  --->  Accuracy = 91.35%\n",
      "M_pca =  165 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  165 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  165 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  165 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  165 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  166 , M_lda =  1  --->  Accuracy = 10.58%\n",
      "M_pca =  166 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  166 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  166 , M_lda =  4  --->  Accuracy = 45.19%\n",
      "M_pca =  166 , M_lda =  5  --->  Accuracy = 56.73%\n",
      "M_pca =  166 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  166 , M_lda =  7  --->  Accuracy = 67.31%\n",
      "M_pca =  166 , M_lda =  8  --->  Accuracy = 72.12%\n",
      "M_pca =  166 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  166 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  166 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  166 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  166 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  166 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  166 , M_lda =  15  --->  Accuracy = 84.62%\n",
      "M_pca =  166 , M_lda =  16  --->  Accuracy = 83.65%\n",
      "M_pca =  166 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  166 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  166 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  166 , M_lda =  20  --->  Accuracy = 80.77%\n",
      "M_pca =  166 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  166 , M_lda =  22  --->  Accuracy = 81.73%\n",
      "M_pca =  166 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  166 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  166 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  166 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  166 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  166 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  166 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  166 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  166 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  166 , M_lda =  32  --->  Accuracy = 89.42%\n",
      "M_pca =  166 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  166 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  166 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  166 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  166 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  166 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  166 , M_lda =  39  --->  Accuracy = 85.58%\n",
      "M_pca =  166 , M_lda =  40  --->  Accuracy = 86.54%\n",
      "M_pca =  166 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  166 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  166 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  166 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  166 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  166 , M_lda =  46  --->  Accuracy = 91.35%\n",
      "M_pca =  166 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  166 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  166 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  166 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  166 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  167 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  167 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  167 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  167 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  167 , M_lda =  5  --->  Accuracy = 55.77%\n",
      "M_pca =  167 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  167 , M_lda =  7  --->  Accuracy = 67.31%\n",
      "M_pca =  167 , M_lda =  8  --->  Accuracy = 71.15%\n",
      "M_pca =  167 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  167 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  167 , M_lda =  11  --->  Accuracy = 75.00%\n",
      "M_pca =  167 , M_lda =  12  --->  Accuracy = 79.81%\n",
      "M_pca =  167 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  167 , M_lda =  14  --->  Accuracy = 83.65%\n",
      "M_pca =  167 , M_lda =  15  --->  Accuracy = 85.58%\n",
      "M_pca =  167 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  167 , M_lda =  17  --->  Accuracy = 81.73%\n",
      "M_pca =  167 , M_lda =  18  --->  Accuracy = 79.81%\n",
      "M_pca =  167 , M_lda =  19  --->  Accuracy = 77.88%\n",
      "M_pca =  167 , M_lda =  20  --->  Accuracy = 79.81%\n",
      "M_pca =  167 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  167 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  167 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  167 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  167 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  167 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  167 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  167 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  167 , M_lda =  29  --->  Accuracy = 89.42%\n",
      "M_pca =  167 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  167 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  167 , M_lda =  32  --->  Accuracy = 90.38%\n",
      "M_pca =  167 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  167 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  167 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  167 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  167 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  167 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  167 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  167 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  167 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  167 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  167 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  167 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  167 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  167 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  167 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  167 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  167 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  167 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  167 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  168 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  168 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  168 , M_lda =  3  --->  Accuracy = 27.88%\n",
      "M_pca =  168 , M_lda =  4  --->  Accuracy = 40.38%\n",
      "M_pca =  168 , M_lda =  5  --->  Accuracy = 56.73%\n",
      "M_pca =  168 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  168 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  168 , M_lda =  8  --->  Accuracy = 69.23%\n",
      "M_pca =  168 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  168 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  168 , M_lda =  11  --->  Accuracy = 75.00%\n",
      "M_pca =  168 , M_lda =  12  --->  Accuracy = 82.69%\n",
      "M_pca =  168 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  168 , M_lda =  14  --->  Accuracy = 82.69%\n",
      "M_pca =  168 , M_lda =  15  --->  Accuracy = 84.62%\n",
      "M_pca =  168 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  168 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  168 , M_lda =  18  --->  Accuracy = 79.81%\n",
      "M_pca =  168 , M_lda =  19  --->  Accuracy = 78.85%\n",
      "M_pca =  168 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  168 , M_lda =  21  --->  Accuracy = 82.69%\n",
      "M_pca =  168 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  168 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  168 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  168 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  168 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  168 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  168 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  168 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  168 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  168 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  168 , M_lda =  32  --->  Accuracy = 89.42%\n",
      "M_pca =  168 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  168 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  168 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  168 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  168 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  168 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  168 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  168 , M_lda =  40  --->  Accuracy = 86.54%\n",
      "M_pca =  168 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  168 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  168 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  168 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  168 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  168 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  168 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  168 , M_lda =  48  --->  Accuracy = 89.42%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  168 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  168 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  168 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  169 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  169 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  169 , M_lda =  3  --->  Accuracy = 25.00%\n",
      "M_pca =  169 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  169 , M_lda =  5  --->  Accuracy = 59.62%\n",
      "M_pca =  169 , M_lda =  6  --->  Accuracy = 62.50%\n",
      "M_pca =  169 , M_lda =  7  --->  Accuracy = 72.12%\n",
      "M_pca =  169 , M_lda =  8  --->  Accuracy = 72.12%\n",
      "M_pca =  169 , M_lda =  9  --->  Accuracy = 76.92%\n",
      "M_pca =  169 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  169 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  169 , M_lda =  12  --->  Accuracy = 83.65%\n",
      "M_pca =  169 , M_lda =  13  --->  Accuracy = 83.65%\n",
      "M_pca =  169 , M_lda =  14  --->  Accuracy = 83.65%\n",
      "M_pca =  169 , M_lda =  15  --->  Accuracy = 83.65%\n",
      "M_pca =  169 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  169 , M_lda =  17  --->  Accuracy = 80.77%\n",
      "M_pca =  169 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  169 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  169 , M_lda =  20  --->  Accuracy = 79.81%\n",
      "M_pca =  169 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  169 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  169 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  169 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  169 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  169 , M_lda =  26  --->  Accuracy = 84.62%\n",
      "M_pca =  169 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  169 , M_lda =  28  --->  Accuracy = 84.62%\n",
      "M_pca =  169 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  169 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  169 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  169 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  169 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  169 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  169 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  169 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  169 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  169 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  169 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  169 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  169 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  169 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  169 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  169 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  169 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  169 , M_lda =  46  --->  Accuracy = 87.50%\n",
      "M_pca =  169 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  169 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  169 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  169 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  169 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  170 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  170 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  170 , M_lda =  3  --->  Accuracy = 25.96%\n",
      "M_pca =  170 , M_lda =  4  --->  Accuracy = 45.19%\n",
      "M_pca =  170 , M_lda =  5  --->  Accuracy = 57.69%\n",
      "M_pca =  170 , M_lda =  6  --->  Accuracy = 62.50%\n",
      "M_pca =  170 , M_lda =  7  --->  Accuracy = 69.23%\n",
      "M_pca =  170 , M_lda =  8  --->  Accuracy = 72.12%\n",
      "M_pca =  170 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  170 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  170 , M_lda =  11  --->  Accuracy = 75.96%\n",
      "M_pca =  170 , M_lda =  12  --->  Accuracy = 83.65%\n",
      "M_pca =  170 , M_lda =  13  --->  Accuracy = 81.73%\n",
      "M_pca =  170 , M_lda =  14  --->  Accuracy = 83.65%\n",
      "M_pca =  170 , M_lda =  15  --->  Accuracy = 84.62%\n",
      "M_pca =  170 , M_lda =  16  --->  Accuracy = 79.81%\n",
      "M_pca =  170 , M_lda =  17  --->  Accuracy = 81.73%\n",
      "M_pca =  170 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  170 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  170 , M_lda =  20  --->  Accuracy = 81.73%\n",
      "M_pca =  170 , M_lda =  21  --->  Accuracy = 82.69%\n",
      "M_pca =  170 , M_lda =  22  --->  Accuracy = 83.65%\n",
      "M_pca =  170 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  170 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  170 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  170 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  170 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  170 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  170 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  170 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  170 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  170 , M_lda =  32  --->  Accuracy = 89.42%\n",
      "M_pca =  170 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  170 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  170 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  170 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  170 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  170 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  170 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  170 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  170 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  170 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  170 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  170 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  170 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  170 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  170 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  170 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  170 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  170 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  170 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  171 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  171 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  171 , M_lda =  3  --->  Accuracy = 25.00%\n",
      "M_pca =  171 , M_lda =  4  --->  Accuracy = 47.12%\n",
      "M_pca =  171 , M_lda =  5  --->  Accuracy = 57.69%\n",
      "M_pca =  171 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  171 , M_lda =  7  --->  Accuracy = 68.27%\n",
      "M_pca =  171 , M_lda =  8  --->  Accuracy = 72.12%\n",
      "M_pca =  171 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  171 , M_lda =  10  --->  Accuracy = 79.81%\n",
      "M_pca =  171 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  171 , M_lda =  12  --->  Accuracy = 84.62%\n",
      "M_pca =  171 , M_lda =  13  --->  Accuracy = 81.73%\n",
      "M_pca =  171 , M_lda =  14  --->  Accuracy = 82.69%\n",
      "M_pca =  171 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  171 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  171 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  171 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  171 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  171 , M_lda =  20  --->  Accuracy = 80.77%\n",
      "M_pca =  171 , M_lda =  21  --->  Accuracy = 81.73%\n",
      "M_pca =  171 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  171 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  171 , M_lda =  24  --->  Accuracy = 84.62%\n",
      "M_pca =  171 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  171 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  171 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  171 , M_lda =  28  --->  Accuracy = 89.42%\n",
      "M_pca =  171 , M_lda =  29  --->  Accuracy = 89.42%\n",
      "M_pca =  171 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  171 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  171 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  171 , M_lda =  33  --->  Accuracy = 89.42%\n",
      "M_pca =  171 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  171 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  171 , M_lda =  36  --->  Accuracy = 89.42%\n",
      "M_pca =  171 , M_lda =  37  --->  Accuracy = 90.38%\n",
      "M_pca =  171 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  171 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  171 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  171 , M_lda =  41  --->  Accuracy = 90.38%\n",
      "M_pca =  171 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  171 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  171 , M_lda =  44  --->  Accuracy = 91.35%\n",
      "M_pca =  171 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  171 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  171 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  171 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  171 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  171 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  171 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  172 , M_lda =  1  --->  Accuracy = 2.88%\n",
      "M_pca =  172 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  172 , M_lda =  3  --->  Accuracy = 27.88%\n",
      "M_pca =  172 , M_lda =  4  --->  Accuracy = 44.23%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  172 , M_lda =  5  --->  Accuracy = 56.73%\n",
      "M_pca =  172 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  172 , M_lda =  7  --->  Accuracy = 69.23%\n",
      "M_pca =  172 , M_lda =  8  --->  Accuracy = 72.12%\n",
      "M_pca =  172 , M_lda =  9  --->  Accuracy = 77.88%\n",
      "M_pca =  172 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  172 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  172 , M_lda =  12  --->  Accuracy = 82.69%\n",
      "M_pca =  172 , M_lda =  13  --->  Accuracy = 79.81%\n",
      "M_pca =  172 , M_lda =  14  --->  Accuracy = 82.69%\n",
      "M_pca =  172 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  172 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  172 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  172 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  172 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  172 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  172 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  172 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  172 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  172 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  172 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  172 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  172 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  172 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  172 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  172 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  172 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  172 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  172 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  172 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  172 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  172 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  172 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  172 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  172 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  172 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  172 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  172 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  172 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  172 , M_lda =  44  --->  Accuracy = 91.35%\n",
      "M_pca =  172 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  172 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  172 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  172 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  172 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  172 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  172 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  173 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  173 , M_lda =  2  --->  Accuracy = 11.54%\n",
      "M_pca =  173 , M_lda =  3  --->  Accuracy = 21.15%\n",
      "M_pca =  173 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  173 , M_lda =  5  --->  Accuracy = 57.69%\n",
      "M_pca =  173 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  173 , M_lda =  7  --->  Accuracy = 70.19%\n",
      "M_pca =  173 , M_lda =  8  --->  Accuracy = 72.12%\n",
      "M_pca =  173 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  173 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  173 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  173 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  173 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  173 , M_lda =  14  --->  Accuracy = 80.77%\n",
      "M_pca =  173 , M_lda =  15  --->  Accuracy = 80.77%\n",
      "M_pca =  173 , M_lda =  16  --->  Accuracy = 79.81%\n",
      "M_pca =  173 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  173 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  173 , M_lda =  19  --->  Accuracy = 82.69%\n",
      "M_pca =  173 , M_lda =  20  --->  Accuracy = 80.77%\n",
      "M_pca =  173 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  173 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  173 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  173 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  173 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  173 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  173 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  173 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  173 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  173 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  173 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  173 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  173 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  173 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  173 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  173 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  173 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  173 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  173 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  173 , M_lda =  40  --->  Accuracy = 86.54%\n",
      "M_pca =  173 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  173 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  173 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  173 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  173 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  173 , M_lda =  46  --->  Accuracy = 87.50%\n",
      "M_pca =  173 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  173 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  173 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  173 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  173 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  174 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  174 , M_lda =  2  --->  Accuracy = 10.58%\n",
      "M_pca =  174 , M_lda =  3  --->  Accuracy = 23.08%\n",
      "M_pca =  174 , M_lda =  4  --->  Accuracy = 42.31%\n",
      "M_pca =  174 , M_lda =  5  --->  Accuracy = 52.88%\n",
      "M_pca =  174 , M_lda =  6  --->  Accuracy = 51.92%\n",
      "M_pca =  174 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  174 , M_lda =  8  --->  Accuracy = 71.15%\n",
      "M_pca =  174 , M_lda =  9  --->  Accuracy = 76.92%\n",
      "M_pca =  174 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  174 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  174 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  174 , M_lda =  13  --->  Accuracy = 79.81%\n",
      "M_pca =  174 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  174 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  174 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  174 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  174 , M_lda =  18  --->  Accuracy = 83.65%\n",
      "M_pca =  174 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  174 , M_lda =  20  --->  Accuracy = 81.73%\n",
      "M_pca =  174 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  174 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  174 , M_lda =  23  --->  Accuracy = 83.65%\n",
      "M_pca =  174 , M_lda =  24  --->  Accuracy = 84.62%\n",
      "M_pca =  174 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  174 , M_lda =  26  --->  Accuracy = 84.62%\n",
      "M_pca =  174 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  174 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  174 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  174 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  174 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  174 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  174 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  174 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  174 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  174 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  174 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  174 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  174 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  174 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  174 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  174 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  174 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  174 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  174 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  174 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  174 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  174 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  174 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  174 , M_lda =  50  --->  Accuracy = 88.46%\n",
      "M_pca =  174 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  175 , M_lda =  1  --->  Accuracy = 2.88%\n",
      "M_pca =  175 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  175 , M_lda =  3  --->  Accuracy = 27.88%\n",
      "M_pca =  175 , M_lda =  4  --->  Accuracy = 42.31%\n",
      "M_pca =  175 , M_lda =  5  --->  Accuracy = 50.96%\n",
      "M_pca =  175 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  175 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  175 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  175 , M_lda =  9  --->  Accuracy = 76.92%\n",
      "M_pca =  175 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  175 , M_lda =  11  --->  Accuracy = 78.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  175 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  175 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  175 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  175 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  175 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  175 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  175 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  175 , M_lda =  19  --->  Accuracy = 85.58%\n",
      "M_pca =  175 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  175 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  175 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  175 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  175 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  175 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  175 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  175 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  175 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  175 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  175 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  175 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  175 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  175 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  175 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  175 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  175 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  175 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  175 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  175 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  175 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  175 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  175 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  175 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  175 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  175 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  175 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  175 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  175 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  175 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  175 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  175 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  176 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  176 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  176 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  176 , M_lda =  4  --->  Accuracy = 39.42%\n",
      "M_pca =  176 , M_lda =  5  --->  Accuracy = 50.96%\n",
      "M_pca =  176 , M_lda =  6  --->  Accuracy = 54.81%\n",
      "M_pca =  176 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  176 , M_lda =  8  --->  Accuracy = 69.23%\n",
      "M_pca =  176 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  176 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  176 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  176 , M_lda =  12  --->  Accuracy = 79.81%\n",
      "M_pca =  176 , M_lda =  13  --->  Accuracy = 79.81%\n",
      "M_pca =  176 , M_lda =  14  --->  Accuracy = 82.69%\n",
      "M_pca =  176 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  176 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  176 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  176 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  176 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  176 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  176 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  176 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  176 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  176 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  176 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  176 , M_lda =  26  --->  Accuracy = 88.46%\n",
      "M_pca =  176 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  176 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  176 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  176 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  176 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  176 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  176 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  176 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  176 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  176 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  176 , M_lda =  37  --->  Accuracy = 90.38%\n",
      "M_pca =  176 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  176 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  176 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  176 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  176 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  176 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  176 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  176 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  176 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  176 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  176 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  176 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  176 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  176 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  177 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  177 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  177 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  177 , M_lda =  4  --->  Accuracy = 38.46%\n",
      "M_pca =  177 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  177 , M_lda =  6  --->  Accuracy = 60.58%\n",
      "M_pca =  177 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  177 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  177 , M_lda =  9  --->  Accuracy = 77.88%\n",
      "M_pca =  177 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  177 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  177 , M_lda =  12  --->  Accuracy = 78.85%\n",
      "M_pca =  177 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  177 , M_lda =  14  --->  Accuracy = 84.62%\n",
      "M_pca =  177 , M_lda =  15  --->  Accuracy = 84.62%\n",
      "M_pca =  177 , M_lda =  16  --->  Accuracy = 83.65%\n",
      "M_pca =  177 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  177 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  177 , M_lda =  19  --->  Accuracy = 85.58%\n",
      "M_pca =  177 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  177 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  177 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  177 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  177 , M_lda =  24  --->  Accuracy = 84.62%\n",
      "M_pca =  177 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  177 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  177 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  177 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  177 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  177 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  177 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  177 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  177 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  177 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  177 , M_lda =  35  --->  Accuracy = 89.42%\n",
      "M_pca =  177 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  177 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  177 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  177 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  177 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  177 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  177 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  177 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  177 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  177 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  177 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  177 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  177 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  177 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  177 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  177 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  178 , M_lda =  1  --->  Accuracy = 2.88%\n",
      "M_pca =  178 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  178 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  178 , M_lda =  4  --->  Accuracy = 39.42%\n",
      "M_pca =  178 , M_lda =  5  --->  Accuracy = 47.12%\n",
      "M_pca =  178 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  178 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  178 , M_lda =  8  --->  Accuracy = 71.15%\n",
      "M_pca =  178 , M_lda =  9  --->  Accuracy = 76.92%\n",
      "M_pca =  178 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  178 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  178 , M_lda =  12  --->  Accuracy = 78.85%\n",
      "M_pca =  178 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  178 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  178 , M_lda =  15  --->  Accuracy = 83.65%\n",
      "M_pca =  178 , M_lda =  16  --->  Accuracy = 83.65%\n",
      "M_pca =  178 , M_lda =  17  --->  Accuracy = 83.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  178 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  178 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  178 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  178 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  178 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  178 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  178 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  178 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  178 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  178 , M_lda =  27  --->  Accuracy = 89.42%\n",
      "M_pca =  178 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  178 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  178 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  178 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  178 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  178 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  178 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  178 , M_lda =  35  --->  Accuracy = 89.42%\n",
      "M_pca =  178 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  178 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  178 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  178 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  178 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  178 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  178 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  178 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  178 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  178 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  178 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  178 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  178 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  178 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  178 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  178 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  179 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  179 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  179 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  179 , M_lda =  4  --->  Accuracy = 37.50%\n",
      "M_pca =  179 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  179 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  179 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  179 , M_lda =  8  --->  Accuracy = 69.23%\n",
      "M_pca =  179 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  179 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  179 , M_lda =  11  --->  Accuracy = 75.96%\n",
      "M_pca =  179 , M_lda =  12  --->  Accuracy = 80.77%\n",
      "M_pca =  179 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  179 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  179 , M_lda =  15  --->  Accuracy = 83.65%\n",
      "M_pca =  179 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  179 , M_lda =  17  --->  Accuracy = 81.73%\n",
      "M_pca =  179 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  179 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  179 , M_lda =  20  --->  Accuracy = 81.73%\n",
      "M_pca =  179 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  179 , M_lda =  22  --->  Accuracy = 83.65%\n",
      "M_pca =  179 , M_lda =  23  --->  Accuracy = 83.65%\n",
      "M_pca =  179 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  179 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  179 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  179 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  179 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  179 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  179 , M_lda =  30  --->  Accuracy = 84.62%\n",
      "M_pca =  179 , M_lda =  31  --->  Accuracy = 85.58%\n",
      "M_pca =  179 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  179 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  179 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  179 , M_lda =  35  --->  Accuracy = 89.42%\n",
      "M_pca =  179 , M_lda =  36  --->  Accuracy = 89.42%\n",
      "M_pca =  179 , M_lda =  37  --->  Accuracy = 89.42%\n",
      "M_pca =  179 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  179 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  179 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  179 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  179 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  179 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  179 , M_lda =  44  --->  Accuracy = 91.35%\n",
      "M_pca =  179 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  179 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  179 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  179 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  179 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  179 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  179 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  180 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  180 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  180 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  180 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  180 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  180 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  180 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  180 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  180 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  180 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  180 , M_lda =  11  --->  Accuracy = 75.96%\n",
      "M_pca =  180 , M_lda =  12  --->  Accuracy = 79.81%\n",
      "M_pca =  180 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  180 , M_lda =  14  --->  Accuracy = 80.77%\n",
      "M_pca =  180 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  180 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  180 , M_lda =  17  --->  Accuracy = 81.73%\n",
      "M_pca =  180 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  180 , M_lda =  19  --->  Accuracy = 82.69%\n",
      "M_pca =  180 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  180 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  180 , M_lda =  22  --->  Accuracy = 82.69%\n",
      "M_pca =  180 , M_lda =  23  --->  Accuracy = 83.65%\n",
      "M_pca =  180 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  180 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  180 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  180 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  180 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  180 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  180 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  180 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  180 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  180 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  180 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  180 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  180 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  180 , M_lda =  37  --->  Accuracy = 89.42%\n",
      "M_pca =  180 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  180 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  180 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  180 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  180 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  180 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  180 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  180 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  180 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  180 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  180 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  180 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  180 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  180 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  181 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  181 , M_lda =  2  --->  Accuracy = 22.12%\n",
      "M_pca =  181 , M_lda =  3  --->  Accuracy = 34.62%\n",
      "M_pca =  181 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  181 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  181 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  181 , M_lda =  7  --->  Accuracy = 67.31%\n",
      "M_pca =  181 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  181 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  181 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  181 , M_lda =  11  --->  Accuracy = 75.00%\n",
      "M_pca =  181 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  181 , M_lda =  13  --->  Accuracy = 81.73%\n",
      "M_pca =  181 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  181 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  181 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  181 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  181 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  181 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  181 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  181 , M_lda =  21  --->  Accuracy = 88.46%\n",
      "M_pca =  181 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  181 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  181 , M_lda =  24  --->  Accuracy = 86.54%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  181 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  181 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  181 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  181 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  181 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  181 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  181 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  181 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  181 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  181 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  181 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  181 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  181 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  181 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  181 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  181 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  181 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  181 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  181 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  181 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  181 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  181 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  181 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  181 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  181 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  181 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  181 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  182 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  182 , M_lda =  2  --->  Accuracy = 22.12%\n",
      "M_pca =  182 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  182 , M_lda =  4  --->  Accuracy = 37.50%\n",
      "M_pca =  182 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  182 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  182 , M_lda =  7  --->  Accuracy = 68.27%\n",
      "M_pca =  182 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  182 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  182 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  182 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  182 , M_lda =  12  --->  Accuracy = 77.88%\n",
      "M_pca =  182 , M_lda =  13  --->  Accuracy = 79.81%\n",
      "M_pca =  182 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  182 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  182 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  182 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  182 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  182 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  182 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  182 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  182 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  182 , M_lda =  23  --->  Accuracy = 83.65%\n",
      "M_pca =  182 , M_lda =  24  --->  Accuracy = 83.65%\n",
      "M_pca =  182 , M_lda =  25  --->  Accuracy = 83.65%\n",
      "M_pca =  182 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  182 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  182 , M_lda =  28  --->  Accuracy = 85.58%\n",
      "M_pca =  182 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  182 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  182 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  182 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  182 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  182 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  182 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  182 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  182 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  182 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  182 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  182 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  182 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  182 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  182 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  182 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  182 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  182 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  182 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  182 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  182 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  182 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  182 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  183 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  183 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  183 , M_lda =  3  --->  Accuracy = 33.65%\n",
      "M_pca =  183 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  183 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  183 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  183 , M_lda =  7  --->  Accuracy = 67.31%\n",
      "M_pca =  183 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  183 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  183 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  183 , M_lda =  11  --->  Accuracy = 75.96%\n",
      "M_pca =  183 , M_lda =  12  --->  Accuracy = 78.85%\n",
      "M_pca =  183 , M_lda =  13  --->  Accuracy = 79.81%\n",
      "M_pca =  183 , M_lda =  14  --->  Accuracy = 82.69%\n",
      "M_pca =  183 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  183 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  183 , M_lda =  17  --->  Accuracy = 84.62%\n",
      "M_pca =  183 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  183 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  183 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  183 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  183 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  183 , M_lda =  23  --->  Accuracy = 83.65%\n",
      "M_pca =  183 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  183 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  183 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  183 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  183 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  183 , M_lda =  29  --->  Accuracy = 84.62%\n",
      "M_pca =  183 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  183 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  183 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  183 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  183 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  183 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  183 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  183 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  183 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  183 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  183 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  183 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  183 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  183 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  183 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  183 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  183 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  183 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  183 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  183 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  183 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  183 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  184 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  184 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  184 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  184 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  184 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  184 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  184 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  184 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  184 , M_lda =  9  --->  Accuracy = 73.08%\n",
      "M_pca =  184 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  184 , M_lda =  11  --->  Accuracy = 75.00%\n",
      "M_pca =  184 , M_lda =  12  --->  Accuracy = 78.85%\n",
      "M_pca =  184 , M_lda =  13  --->  Accuracy = 79.81%\n",
      "M_pca =  184 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  184 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  184 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  184 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  184 , M_lda =  18  --->  Accuracy = 83.65%\n",
      "M_pca =  184 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  184 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  184 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  184 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  184 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  184 , M_lda =  24  --->  Accuracy = 84.62%\n",
      "M_pca =  184 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  184 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  184 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  184 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  184 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  184 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  184 , M_lda =  31  --->  Accuracy = 86.54%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  184 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  184 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  184 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  184 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  184 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  184 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  184 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  184 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  184 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  184 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  184 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  184 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  184 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  184 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  184 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  184 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  184 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  184 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  184 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  184 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  185 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  185 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  185 , M_lda =  3  --->  Accuracy = 33.65%\n",
      "M_pca =  185 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  185 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  185 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  185 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  185 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  185 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  185 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  185 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  185 , M_lda =  12  --->  Accuracy = 78.85%\n",
      "M_pca =  185 , M_lda =  13  --->  Accuracy = 79.81%\n",
      "M_pca =  185 , M_lda =  14  --->  Accuracy = 81.73%\n",
      "M_pca =  185 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  185 , M_lda =  16  --->  Accuracy = 83.65%\n",
      "M_pca =  185 , M_lda =  17  --->  Accuracy = 84.62%\n",
      "M_pca =  185 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  185 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  185 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  185 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  185 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  185 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  185 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  185 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  185 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  185 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  185 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  185 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  185 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  185 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  185 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  185 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  185 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  185 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  185 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  185 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  185 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  185 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  185 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  185 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  185 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  185 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  185 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  185 , M_lda =  45  --->  Accuracy = 91.35%\n",
      "M_pca =  185 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  185 , M_lda =  47  --->  Accuracy = 91.35%\n",
      "M_pca =  185 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  185 , M_lda =  49  --->  Accuracy = 91.35%\n",
      "M_pca =  185 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  185 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  186 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  186 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  186 , M_lda =  3  --->  Accuracy = 34.62%\n",
      "M_pca =  186 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  186 , M_lda =  5  --->  Accuracy = 50.96%\n",
      "M_pca =  186 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  186 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  186 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  186 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  186 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  186 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  186 , M_lda =  12  --->  Accuracy = 79.81%\n",
      "M_pca =  186 , M_lda =  13  --->  Accuracy = 79.81%\n",
      "M_pca =  186 , M_lda =  14  --->  Accuracy = 80.77%\n",
      "M_pca =  186 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  186 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  186 , M_lda =  17  --->  Accuracy = 84.62%\n",
      "M_pca =  186 , M_lda =  18  --->  Accuracy = 87.50%\n",
      "M_pca =  186 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  186 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  186 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  186 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  186 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  186 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  186 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  186 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  186 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  186 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  186 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  186 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  186 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  186 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  186 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  186 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  186 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  186 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  186 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  186 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  186 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  186 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  186 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  186 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  186 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  186 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  186 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  186 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  186 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  186 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  186 , M_lda =  49  --->  Accuracy = 91.35%\n",
      "M_pca =  186 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  186 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  187 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  187 , M_lda =  2  --->  Accuracy = 12.50%\n",
      "M_pca =  187 , M_lda =  3  --->  Accuracy = 35.58%\n",
      "M_pca =  187 , M_lda =  4  --->  Accuracy = 34.62%\n",
      "M_pca =  187 , M_lda =  5  --->  Accuracy = 46.15%\n",
      "M_pca =  187 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  187 , M_lda =  7  --->  Accuracy = 67.31%\n",
      "M_pca =  187 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  187 , M_lda =  9  --->  Accuracy = 73.08%\n",
      "M_pca =  187 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  187 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  187 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  187 , M_lda =  13  --->  Accuracy = 79.81%\n",
      "M_pca =  187 , M_lda =  14  --->  Accuracy = 79.81%\n",
      "M_pca =  187 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  187 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  187 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  187 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  187 , M_lda =  19  --->  Accuracy = 85.58%\n",
      "M_pca =  187 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  187 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  187 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  187 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  187 , M_lda =  24  --->  Accuracy = 84.62%\n",
      "M_pca =  187 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  187 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  187 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  187 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  187 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  187 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  187 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  187 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  187 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  187 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  187 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  187 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  187 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  187 , M_lda =  38  --->  Accuracy = 88.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  187 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  187 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  187 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  187 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  187 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  187 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  187 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  187 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  187 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  187 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  187 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  187 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  187 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  188 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  188 , M_lda =  2  --->  Accuracy = 12.50%\n",
      "M_pca =  188 , M_lda =  3  --->  Accuracy = 36.54%\n",
      "M_pca =  188 , M_lda =  4  --->  Accuracy = 34.62%\n",
      "M_pca =  188 , M_lda =  5  --->  Accuracy = 46.15%\n",
      "M_pca =  188 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  188 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  188 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  188 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  188 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  188 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  188 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  188 , M_lda =  13  --->  Accuracy = 76.92%\n",
      "M_pca =  188 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  188 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  188 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  188 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  188 , M_lda =  18  --->  Accuracy = 85.58%\n",
      "M_pca =  188 , M_lda =  19  --->  Accuracy = 85.58%\n",
      "M_pca =  188 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  188 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  188 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  188 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  188 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  188 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  188 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  188 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  188 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  188 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  188 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  188 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  188 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  188 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  188 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  188 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  188 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  188 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  188 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  188 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  188 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  188 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  188 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  188 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  188 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  188 , M_lda =  45  --->  Accuracy = 91.35%\n",
      "M_pca =  188 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  188 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  188 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  188 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  188 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  188 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  189 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  189 , M_lda =  2  --->  Accuracy = 11.54%\n",
      "M_pca =  189 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  189 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  189 , M_lda =  5  --->  Accuracy = 45.19%\n",
      "M_pca =  189 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  189 , M_lda =  7  --->  Accuracy = 61.54%\n",
      "M_pca =  189 , M_lda =  8  --->  Accuracy = 69.23%\n",
      "M_pca =  189 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  189 , M_lda =  10  --->  Accuracy = 78.85%\n",
      "M_pca =  189 , M_lda =  11  --->  Accuracy = 81.73%\n",
      "M_pca =  189 , M_lda =  12  --->  Accuracy = 78.85%\n",
      "M_pca =  189 , M_lda =  13  --->  Accuracy = 80.77%\n",
      "M_pca =  189 , M_lda =  14  --->  Accuracy = 80.77%\n",
      "M_pca =  189 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  189 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  189 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  189 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  189 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  189 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  189 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  189 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  189 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  189 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  189 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  189 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  189 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  189 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  189 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  189 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  189 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  189 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  189 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  189 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  189 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  189 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  189 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  189 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  189 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  189 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  189 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  189 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  189 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  189 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  189 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  189 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  189 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  189 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  189 , M_lda =  49  --->  Accuracy = 91.35%\n",
      "M_pca =  189 , M_lda =  50  --->  Accuracy = 92.31%\n",
      "M_pca =  189 , M_lda =  51  --->  Accuracy = 92.31%\n",
      "M_pca =  190 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  190 , M_lda =  2  --->  Accuracy = 12.50%\n",
      "M_pca =  190 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  190 , M_lda =  4  --->  Accuracy = 45.19%\n",
      "M_pca =  190 , M_lda =  5  --->  Accuracy = 46.15%\n",
      "M_pca =  190 , M_lda =  6  --->  Accuracy = 52.88%\n",
      "M_pca =  190 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  190 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  190 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  190 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  190 , M_lda =  11  --->  Accuracy = 79.81%\n",
      "M_pca =  190 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  190 , M_lda =  13  --->  Accuracy = 82.69%\n",
      "M_pca =  190 , M_lda =  14  --->  Accuracy = 79.81%\n",
      "M_pca =  190 , M_lda =  15  --->  Accuracy = 82.69%\n",
      "M_pca =  190 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  190 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  190 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  190 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  190 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  190 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  190 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  190 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  190 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  190 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  190 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  190 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  190 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  190 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  190 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  190 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  190 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  190 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  190 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  190 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  190 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  190 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  190 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  190 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  190 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  190 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  190 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  190 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  190 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  190 , M_lda =  45  --->  Accuracy = 90.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  190 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  190 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  190 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  190 , M_lda =  49  --->  Accuracy = 91.35%\n",
      "M_pca =  190 , M_lda =  50  --->  Accuracy = 92.31%\n",
      "M_pca =  190 , M_lda =  51  --->  Accuracy = 92.31%\n",
      "M_pca =  191 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  191 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  191 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  191 , M_lda =  4  --->  Accuracy = 47.12%\n",
      "M_pca =  191 , M_lda =  5  --->  Accuracy = 47.12%\n",
      "M_pca =  191 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  191 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  191 , M_lda =  8  --->  Accuracy = 71.15%\n",
      "M_pca =  191 , M_lda =  9  --->  Accuracy = 75.96%\n",
      "M_pca =  191 , M_lda =  10  --->  Accuracy = 77.88%\n",
      "M_pca =  191 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  191 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  191 , M_lda =  13  --->  Accuracy = 79.81%\n",
      "M_pca =  191 , M_lda =  14  --->  Accuracy = 80.77%\n",
      "M_pca =  191 , M_lda =  15  --->  Accuracy = 83.65%\n",
      "M_pca =  191 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  191 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  191 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  191 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  191 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  191 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  191 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  191 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  191 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  191 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  191 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  191 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  191 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  191 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  191 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  191 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  191 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  191 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  191 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  191 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  191 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  191 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  191 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  191 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  191 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  191 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  191 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  191 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  191 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  191 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  191 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  191 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  191 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  191 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  191 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  191 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  192 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  192 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  192 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  192 , M_lda =  4  --->  Accuracy = 45.19%\n",
      "M_pca =  192 , M_lda =  5  --->  Accuracy = 46.15%\n",
      "M_pca =  192 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  192 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  192 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  192 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  192 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  192 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  192 , M_lda =  12  --->  Accuracy = 75.00%\n",
      "M_pca =  192 , M_lda =  13  --->  Accuracy = 79.81%\n",
      "M_pca =  192 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  192 , M_lda =  15  --->  Accuracy = 79.81%\n",
      "M_pca =  192 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  192 , M_lda =  17  --->  Accuracy = 81.73%\n",
      "M_pca =  192 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  192 , M_lda =  19  --->  Accuracy = 85.58%\n",
      "M_pca =  192 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  192 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  192 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  192 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  192 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  192 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  192 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  192 , M_lda =  27  --->  Accuracy = 89.42%\n",
      "M_pca =  192 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  192 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  192 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  192 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  192 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  192 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  192 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  192 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  192 , M_lda =  36  --->  Accuracy = 89.42%\n",
      "M_pca =  192 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  192 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  192 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  192 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  192 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  192 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  192 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  192 , M_lda =  44  --->  Accuracy = 91.35%\n",
      "M_pca =  192 , M_lda =  45  --->  Accuracy = 93.27%\n",
      "M_pca =  192 , M_lda =  46  --->  Accuracy = 91.35%\n",
      "M_pca =  192 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  192 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  192 , M_lda =  49  --->  Accuracy = 91.35%\n",
      "M_pca =  192 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  192 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  193 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  193 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  193 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  193 , M_lda =  4  --->  Accuracy = 48.08%\n",
      "M_pca =  193 , M_lda =  5  --->  Accuracy = 46.15%\n",
      "M_pca =  193 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  193 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  193 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  193 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  193 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  193 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  193 , M_lda =  12  --->  Accuracy = 75.00%\n",
      "M_pca =  193 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  193 , M_lda =  14  --->  Accuracy = 79.81%\n",
      "M_pca =  193 , M_lda =  15  --->  Accuracy = 79.81%\n",
      "M_pca =  193 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  193 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  193 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  193 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  193 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  193 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  193 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  193 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  193 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  193 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  193 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  193 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  193 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  193 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  193 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  193 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  193 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  193 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  193 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  193 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  193 , M_lda =  36  --->  Accuracy = 90.38%\n",
      "M_pca =  193 , M_lda =  37  --->  Accuracy = 90.38%\n",
      "M_pca =  193 , M_lda =  38  --->  Accuracy = 90.38%\n",
      "M_pca =  193 , M_lda =  39  --->  Accuracy = 90.38%\n",
      "M_pca =  193 , M_lda =  40  --->  Accuracy = 91.35%\n",
      "M_pca =  193 , M_lda =  41  --->  Accuracy = 92.31%\n",
      "M_pca =  193 , M_lda =  42  --->  Accuracy = 91.35%\n",
      "M_pca =  193 , M_lda =  43  --->  Accuracy = 91.35%\n",
      "M_pca =  193 , M_lda =  44  --->  Accuracy = 92.31%\n",
      "M_pca =  193 , M_lda =  45  --->  Accuracy = 92.31%\n",
      "M_pca =  193 , M_lda =  46  --->  Accuracy = 91.35%\n",
      "M_pca =  193 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  193 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  193 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  193 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  193 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  194 , M_lda =  1  --->  Accuracy = 8.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  194 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  194 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  194 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  194 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  194 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  194 , M_lda =  7  --->  Accuracy = 67.31%\n",
      "M_pca =  194 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  194 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  194 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  194 , M_lda =  11  --->  Accuracy = 75.96%\n",
      "M_pca =  194 , M_lda =  12  --->  Accuracy = 75.00%\n",
      "M_pca =  194 , M_lda =  13  --->  Accuracy = 75.96%\n",
      "M_pca =  194 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  194 , M_lda =  15  --->  Accuracy = 78.85%\n",
      "M_pca =  194 , M_lda =  16  --->  Accuracy = 83.65%\n",
      "M_pca =  194 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  194 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  194 , M_lda =  19  --->  Accuracy = 87.50%\n",
      "M_pca =  194 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  194 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  194 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  194 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  194 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  194 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  194 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  194 , M_lda =  27  --->  Accuracy = 89.42%\n",
      "M_pca =  194 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  194 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  194 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  194 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  194 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  194 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  194 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  194 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  194 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  194 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  194 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  194 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  194 , M_lda =  40  --->  Accuracy = 90.38%\n",
      "M_pca =  194 , M_lda =  41  --->  Accuracy = 91.35%\n",
      "M_pca =  194 , M_lda =  42  --->  Accuracy = 91.35%\n",
      "M_pca =  194 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  194 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  194 , M_lda =  45  --->  Accuracy = 92.31%\n",
      "M_pca =  194 , M_lda =  46  --->  Accuracy = 91.35%\n",
      "M_pca =  194 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  194 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  194 , M_lda =  49  --->  Accuracy = 91.35%\n",
      "M_pca =  194 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  194 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  195 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  195 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  195 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  195 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  195 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  195 , M_lda =  6  --->  Accuracy = 52.88%\n",
      "M_pca =  195 , M_lda =  7  --->  Accuracy = 68.27%\n",
      "M_pca =  195 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  195 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  195 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  195 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  195 , M_lda =  12  --->  Accuracy = 75.00%\n",
      "M_pca =  195 , M_lda =  13  --->  Accuracy = 76.92%\n",
      "M_pca =  195 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  195 , M_lda =  15  --->  Accuracy = 80.77%\n",
      "M_pca =  195 , M_lda =  16  --->  Accuracy = 83.65%\n",
      "M_pca =  195 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  195 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  195 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  195 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  195 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  195 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  195 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  195 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  195 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  195 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  195 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  195 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  195 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  195 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  195 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  195 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  195 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  195 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  195 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  195 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  195 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  195 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  195 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  195 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  195 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  195 , M_lda =  42  --->  Accuracy = 91.35%\n",
      "M_pca =  195 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  195 , M_lda =  44  --->  Accuracy = 92.31%\n",
      "M_pca =  195 , M_lda =  45  --->  Accuracy = 91.35%\n",
      "M_pca =  195 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  195 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  195 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  195 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  195 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  195 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  196 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  196 , M_lda =  2  --->  Accuracy = 12.50%\n",
      "M_pca =  196 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  196 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  196 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  196 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  196 , M_lda =  7  --->  Accuracy = 68.27%\n",
      "M_pca =  196 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  196 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  196 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  196 , M_lda =  11  --->  Accuracy = 75.96%\n",
      "M_pca =  196 , M_lda =  12  --->  Accuracy = 75.00%\n",
      "M_pca =  196 , M_lda =  13  --->  Accuracy = 73.08%\n",
      "M_pca =  196 , M_lda =  14  --->  Accuracy = 75.96%\n",
      "M_pca =  196 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  196 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  196 , M_lda =  17  --->  Accuracy = 81.73%\n",
      "M_pca =  196 , M_lda =  18  --->  Accuracy = 83.65%\n",
      "M_pca =  196 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  196 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  196 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  196 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  196 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  196 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  196 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  196 , M_lda =  26  --->  Accuracy = 84.62%\n",
      "M_pca =  196 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  196 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  196 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  196 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  196 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  196 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  196 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  196 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  196 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  196 , M_lda =  36  --->  Accuracy = 89.42%\n",
      "M_pca =  196 , M_lda =  37  --->  Accuracy = 89.42%\n",
      "M_pca =  196 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  196 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  196 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  196 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  196 , M_lda =  42  --->  Accuracy = 91.35%\n",
      "M_pca =  196 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  196 , M_lda =  44  --->  Accuracy = 91.35%\n",
      "M_pca =  196 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  196 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  196 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  196 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  196 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  196 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  196 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  197 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  197 , M_lda =  2  --->  Accuracy = 11.54%\n",
      "M_pca =  197 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  197 , M_lda =  4  --->  Accuracy = 42.31%\n",
      "M_pca =  197 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  197 , M_lda =  6  --->  Accuracy = 51.92%\n",
      "M_pca =  197 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  197 , M_lda =  8  --->  Accuracy = 72.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  197 , M_lda =  9  --->  Accuracy = 75.00%\n",
      "M_pca =  197 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  197 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  197 , M_lda =  12  --->  Accuracy = 75.00%\n",
      "M_pca =  197 , M_lda =  13  --->  Accuracy = 75.96%\n",
      "M_pca =  197 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  197 , M_lda =  15  --->  Accuracy = 80.77%\n",
      "M_pca =  197 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  197 , M_lda =  17  --->  Accuracy = 84.62%\n",
      "M_pca =  197 , M_lda =  18  --->  Accuracy = 83.65%\n",
      "M_pca =  197 , M_lda =  19  --->  Accuracy = 86.54%\n",
      "M_pca =  197 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  197 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  197 , M_lda =  22  --->  Accuracy = 83.65%\n",
      "M_pca =  197 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  197 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  197 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  197 , M_lda =  26  --->  Accuracy = 84.62%\n",
      "M_pca =  197 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  197 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  197 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  197 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  197 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  197 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  197 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  197 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  197 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  197 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  197 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  197 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  197 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  197 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  197 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  197 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  197 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  197 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  197 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  197 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  197 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  197 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  197 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  197 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  197 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  198 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  198 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  198 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  198 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  198 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  198 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  198 , M_lda =  7  --->  Accuracy = 61.54%\n",
      "M_pca =  198 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  198 , M_lda =  9  --->  Accuracy = 69.23%\n",
      "M_pca =  198 , M_lda =  10  --->  Accuracy = 72.12%\n",
      "M_pca =  198 , M_lda =  11  --->  Accuracy = 75.96%\n",
      "M_pca =  198 , M_lda =  12  --->  Accuracy = 75.96%\n",
      "M_pca =  198 , M_lda =  13  --->  Accuracy = 75.96%\n",
      "M_pca =  198 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  198 , M_lda =  15  --->  Accuracy = 80.77%\n",
      "M_pca =  198 , M_lda =  16  --->  Accuracy = 83.65%\n",
      "M_pca =  198 , M_lda =  17  --->  Accuracy = 81.73%\n",
      "M_pca =  198 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  198 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  198 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  198 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  198 , M_lda =  22  --->  Accuracy = 83.65%\n",
      "M_pca =  198 , M_lda =  23  --->  Accuracy = 83.65%\n",
      "M_pca =  198 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  198 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  198 , M_lda =  26  --->  Accuracy = 84.62%\n",
      "M_pca =  198 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  198 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  198 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  198 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  198 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  198 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  198 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  198 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  198 , M_lda =  35  --->  Accuracy = 89.42%\n",
      "M_pca =  198 , M_lda =  36  --->  Accuracy = 89.42%\n",
      "M_pca =  198 , M_lda =  37  --->  Accuracy = 89.42%\n",
      "M_pca =  198 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  198 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  198 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  198 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  198 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  198 , M_lda =  43  --->  Accuracy = 91.35%\n",
      "M_pca =  198 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  198 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  198 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  198 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  198 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  198 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  198 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  198 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  199 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  199 , M_lda =  2  --->  Accuracy = 28.85%\n",
      "M_pca =  199 , M_lda =  3  --->  Accuracy = 35.58%\n",
      "M_pca =  199 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  199 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  199 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  199 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  199 , M_lda =  8  --->  Accuracy = 71.15%\n",
      "M_pca =  199 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  199 , M_lda =  10  --->  Accuracy = 72.12%\n",
      "M_pca =  199 , M_lda =  11  --->  Accuracy = 75.96%\n",
      "M_pca =  199 , M_lda =  12  --->  Accuracy = 77.88%\n",
      "M_pca =  199 , M_lda =  13  --->  Accuracy = 76.92%\n",
      "M_pca =  199 , M_lda =  14  --->  Accuracy = 79.81%\n",
      "M_pca =  199 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  199 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  199 , M_lda =  17  --->  Accuracy = 80.77%\n",
      "M_pca =  199 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  199 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  199 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  199 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  199 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  199 , M_lda =  23  --->  Accuracy = 83.65%\n",
      "M_pca =  199 , M_lda =  24  --->  Accuracy = 82.69%\n",
      "M_pca =  199 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  199 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  199 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  199 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  199 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  199 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  199 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  199 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  199 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  199 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  199 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  199 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  199 , M_lda =  37  --->  Accuracy = 89.42%\n",
      "M_pca =  199 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  199 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  199 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  199 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  199 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  199 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  199 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  199 , M_lda =  45  --->  Accuracy = 91.35%\n",
      "M_pca =  199 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  199 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  199 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  199 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  199 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  199 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  200 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  200 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  200 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  200 , M_lda =  4  --->  Accuracy = 41.35%\n",
      "M_pca =  200 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  200 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  200 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  200 , M_lda =  8  --->  Accuracy = 69.23%\n",
      "M_pca =  200 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  200 , M_lda =  10  --->  Accuracy = 72.12%\n",
      "M_pca =  200 , M_lda =  11  --->  Accuracy = 75.00%\n",
      "M_pca =  200 , M_lda =  12  --->  Accuracy = 77.88%\n",
      "M_pca =  200 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  200 , M_lda =  14  --->  Accuracy = 80.77%\n",
      "M_pca =  200 , M_lda =  15  --->  Accuracy = 82.69%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  200 , M_lda =  16  --->  Accuracy = 83.65%\n",
      "M_pca =  200 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  200 , M_lda =  18  --->  Accuracy = 83.65%\n",
      "M_pca =  200 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  200 , M_lda =  20  --->  Accuracy = 86.54%\n",
      "M_pca =  200 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  200 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  200 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  200 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  200 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  200 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  200 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  200 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  200 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  200 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  200 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  200 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  200 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  200 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  200 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  200 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  200 , M_lda =  37  --->  Accuracy = 89.42%\n",
      "M_pca =  200 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  200 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  200 , M_lda =  40  --->  Accuracy = 90.38%\n",
      "M_pca =  200 , M_lda =  41  --->  Accuracy = 90.38%\n",
      "M_pca =  200 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  200 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  200 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  200 , M_lda =  45  --->  Accuracy = 91.35%\n",
      "M_pca =  200 , M_lda =  46  --->  Accuracy = 92.31%\n",
      "M_pca =  200 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  200 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  200 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  200 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  200 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  201 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  201 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  201 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  201 , M_lda =  4  --->  Accuracy = 41.35%\n",
      "M_pca =  201 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  201 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  201 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  201 , M_lda =  8  --->  Accuracy = 72.12%\n",
      "M_pca =  201 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  201 , M_lda =  10  --->  Accuracy = 72.12%\n",
      "M_pca =  201 , M_lda =  11  --->  Accuracy = 75.96%\n",
      "M_pca =  201 , M_lda =  12  --->  Accuracy = 75.96%\n",
      "M_pca =  201 , M_lda =  13  --->  Accuracy = 77.88%\n",
      "M_pca =  201 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  201 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  201 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  201 , M_lda =  17  --->  Accuracy = 83.65%\n",
      "M_pca =  201 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  201 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  201 , M_lda =  20  --->  Accuracy = 85.58%\n",
      "M_pca =  201 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  201 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  201 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  201 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  201 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  201 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  201 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  201 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  201 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  201 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  201 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  201 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  201 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  201 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  201 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  201 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  201 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  201 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  201 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  201 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  201 , M_lda =  41  --->  Accuracy = 90.38%\n",
      "M_pca =  201 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  201 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  201 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  201 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  201 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  201 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  201 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  201 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  201 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  201 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  202 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  202 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  202 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  202 , M_lda =  4  --->  Accuracy = 42.31%\n",
      "M_pca =  202 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  202 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  202 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  202 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  202 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  202 , M_lda =  10  --->  Accuracy = 73.08%\n",
      "M_pca =  202 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  202 , M_lda =  12  --->  Accuracy = 75.96%\n",
      "M_pca =  202 , M_lda =  13  --->  Accuracy = 77.88%\n",
      "M_pca =  202 , M_lda =  14  --->  Accuracy = 79.81%\n",
      "M_pca =  202 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  202 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  202 , M_lda =  17  --->  Accuracy = 81.73%\n",
      "M_pca =  202 , M_lda =  18  --->  Accuracy = 84.62%\n",
      "M_pca =  202 , M_lda =  19  --->  Accuracy = 85.58%\n",
      "M_pca =  202 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  202 , M_lda =  21  --->  Accuracy = 88.46%\n",
      "M_pca =  202 , M_lda =  22  --->  Accuracy = 89.42%\n",
      "M_pca =  202 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  202 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  202 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  202 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  202 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  202 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  202 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  202 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  202 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  202 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  202 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  202 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  202 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  202 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  202 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  202 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  202 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  202 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  202 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  202 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  202 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  202 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  202 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  202 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  202 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  202 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  202 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  202 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  202 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  203 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  203 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  203 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  203 , M_lda =  4  --->  Accuracy = 39.42%\n",
      "M_pca =  203 , M_lda =  5  --->  Accuracy = 50.96%\n",
      "M_pca =  203 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  203 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  203 , M_lda =  8  --->  Accuracy = 69.23%\n",
      "M_pca =  203 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  203 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  203 , M_lda =  11  --->  Accuracy = 78.85%\n",
      "M_pca =  203 , M_lda =  12  --->  Accuracy = 78.85%\n",
      "M_pca =  203 , M_lda =  13  --->  Accuracy = 77.88%\n",
      "M_pca =  203 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  203 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  203 , M_lda =  16  --->  Accuracy = 84.62%\n",
      "M_pca =  203 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  203 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  203 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  203 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  203 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  203 , M_lda =  22  --->  Accuracy = 88.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  203 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  203 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  203 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  203 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  203 , M_lda =  27  --->  Accuracy = 84.62%\n",
      "M_pca =  203 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  203 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  203 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  203 , M_lda =  31  --->  Accuracy = 85.58%\n",
      "M_pca =  203 , M_lda =  32  --->  Accuracy = 84.62%\n",
      "M_pca =  203 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  203 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  203 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  203 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  203 , M_lda =  37  --->  Accuracy = 84.62%\n",
      "M_pca =  203 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  203 , M_lda =  39  --->  Accuracy = 85.58%\n",
      "M_pca =  203 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  203 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  203 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  203 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  203 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  203 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  203 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  203 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  203 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  203 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  203 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  203 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  204 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  204 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  204 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  204 , M_lda =  4  --->  Accuracy = 40.38%\n",
      "M_pca =  204 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  204 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  204 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  204 , M_lda =  8  --->  Accuracy = 71.15%\n",
      "M_pca =  204 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  204 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  204 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  204 , M_lda =  12  --->  Accuracy = 75.96%\n",
      "M_pca =  204 , M_lda =  13  --->  Accuracy = 77.88%\n",
      "M_pca =  204 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  204 , M_lda =  15  --->  Accuracy = 79.81%\n",
      "M_pca =  204 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  204 , M_lda =  17  --->  Accuracy = 81.73%\n",
      "M_pca =  204 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  204 , M_lda =  19  --->  Accuracy = 82.69%\n",
      "M_pca =  204 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  204 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  204 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  204 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  204 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  204 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  204 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  204 , M_lda =  27  --->  Accuracy = 84.62%\n",
      "M_pca =  204 , M_lda =  28  --->  Accuracy = 85.58%\n",
      "M_pca =  204 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  204 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  204 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  204 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  204 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  204 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  204 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  204 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  204 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  204 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  204 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  204 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  204 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  204 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  204 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  204 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  204 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  204 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  204 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  204 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  204 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  204 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  204 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  205 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  205 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  205 , M_lda =  3  --->  Accuracy = 34.62%\n",
      "M_pca =  205 , M_lda =  4  --->  Accuracy = 40.38%\n",
      "M_pca =  205 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  205 , M_lda =  6  --->  Accuracy = 61.54%\n",
      "M_pca =  205 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  205 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  205 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  205 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  205 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  205 , M_lda =  12  --->  Accuracy = 77.88%\n",
      "M_pca =  205 , M_lda =  13  --->  Accuracy = 77.88%\n",
      "M_pca =  205 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  205 , M_lda =  15  --->  Accuracy = 79.81%\n",
      "M_pca =  205 , M_lda =  16  --->  Accuracy = 82.69%\n",
      "M_pca =  205 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  205 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  205 , M_lda =  19  --->  Accuracy = 84.62%\n",
      "M_pca =  205 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  205 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  205 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  205 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  205 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  205 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  205 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  205 , M_lda =  27  --->  Accuracy = 84.62%\n",
      "M_pca =  205 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  205 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  205 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  205 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  205 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  205 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  205 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  205 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  205 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  205 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  205 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  205 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  205 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  205 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  205 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  205 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  205 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  205 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  205 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  205 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  205 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  205 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  205 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  205 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  206 , M_lda =  1  --->  Accuracy = 10.58%\n",
      "M_pca =  206 , M_lda =  2  --->  Accuracy = 23.08%\n",
      "M_pca =  206 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  206 , M_lda =  4  --->  Accuracy = 37.50%\n",
      "M_pca =  206 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  206 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  206 , M_lda =  7  --->  Accuracy = 59.62%\n",
      "M_pca =  206 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  206 , M_lda =  9  --->  Accuracy = 74.04%\n",
      "M_pca =  206 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  206 , M_lda =  11  --->  Accuracy = 77.88%\n",
      "M_pca =  206 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  206 , M_lda =  13  --->  Accuracy = 76.92%\n",
      "M_pca =  206 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  206 , M_lda =  15  --->  Accuracy = 78.85%\n",
      "M_pca =  206 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  206 , M_lda =  17  --->  Accuracy = 82.69%\n",
      "M_pca =  206 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  206 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  206 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  206 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  206 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  206 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  206 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  206 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  206 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  206 , M_lda =  27  --->  Accuracy = 84.62%\n",
      "M_pca =  206 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  206 , M_lda =  29  --->  Accuracy = 85.58%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  206 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  206 , M_lda =  31  --->  Accuracy = 85.58%\n",
      "M_pca =  206 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  206 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  206 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  206 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  206 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  206 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  206 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  206 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  206 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  206 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  206 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  206 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  206 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  206 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  206 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  206 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  206 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  206 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  206 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  206 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  207 , M_lda =  1  --->  Accuracy = 13.46%\n",
      "M_pca =  207 , M_lda =  2  --->  Accuracy = 23.08%\n",
      "M_pca =  207 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  207 , M_lda =  4  --->  Accuracy = 40.38%\n",
      "M_pca =  207 , M_lda =  5  --->  Accuracy = 47.12%\n",
      "M_pca =  207 , M_lda =  6  --->  Accuracy = 52.88%\n",
      "M_pca =  207 , M_lda =  7  --->  Accuracy = 58.65%\n",
      "M_pca =  207 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  207 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  207 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  207 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  207 , M_lda =  12  --->  Accuracy = 78.85%\n",
      "M_pca =  207 , M_lda =  13  --->  Accuracy = 77.88%\n",
      "M_pca =  207 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  207 , M_lda =  15  --->  Accuracy = 78.85%\n",
      "M_pca =  207 , M_lda =  16  --->  Accuracy = 83.65%\n",
      "M_pca =  207 , M_lda =  17  --->  Accuracy = 81.73%\n",
      "M_pca =  207 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  207 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  207 , M_lda =  20  --->  Accuracy = 81.73%\n",
      "M_pca =  207 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  207 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  207 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  207 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  207 , M_lda =  25  --->  Accuracy = 88.46%\n",
      "M_pca =  207 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  207 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  207 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  207 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  207 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  207 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  207 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  207 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  207 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  207 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  207 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  207 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  207 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  207 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  207 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  207 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  207 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  207 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  207 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  207 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  207 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  207 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  207 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  207 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  207 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  207 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  208 , M_lda =  1  --->  Accuracy = 13.46%\n",
      "M_pca =  208 , M_lda =  2  --->  Accuracy = 24.04%\n",
      "M_pca =  208 , M_lda =  3  --->  Accuracy = 27.88%\n",
      "M_pca =  208 , M_lda =  4  --->  Accuracy = 47.12%\n",
      "M_pca =  208 , M_lda =  5  --->  Accuracy = 50.96%\n",
      "M_pca =  208 , M_lda =  6  --->  Accuracy = 54.81%\n",
      "M_pca =  208 , M_lda =  7  --->  Accuracy = 59.62%\n",
      "M_pca =  208 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  208 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  208 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  208 , M_lda =  11  --->  Accuracy = 75.96%\n",
      "M_pca =  208 , M_lda =  12  --->  Accuracy = 74.04%\n",
      "M_pca =  208 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  208 , M_lda =  14  --->  Accuracy = 76.92%\n",
      "M_pca =  208 , M_lda =  15  --->  Accuracy = 78.85%\n",
      "M_pca =  208 , M_lda =  16  --->  Accuracy = 79.81%\n",
      "M_pca =  208 , M_lda =  17  --->  Accuracy = 80.77%\n",
      "M_pca =  208 , M_lda =  18  --->  Accuracy = 79.81%\n",
      "M_pca =  208 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  208 , M_lda =  20  --->  Accuracy = 81.73%\n",
      "M_pca =  208 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  208 , M_lda =  22  --->  Accuracy = 88.46%\n",
      "M_pca =  208 , M_lda =  23  --->  Accuracy = 89.42%\n",
      "M_pca =  208 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  208 , M_lda =  25  --->  Accuracy = 88.46%\n",
      "M_pca =  208 , M_lda =  26  --->  Accuracy = 88.46%\n",
      "M_pca =  208 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  208 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  208 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  208 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  208 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  208 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  208 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  208 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  208 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  208 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  208 , M_lda =  37  --->  Accuracy = 84.62%\n",
      "M_pca =  208 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  208 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  208 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  208 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  208 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  208 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  208 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  208 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  208 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  208 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  208 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  208 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  208 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  208 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  209 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  209 , M_lda =  2  --->  Accuracy = 22.12%\n",
      "M_pca =  209 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  209 , M_lda =  4  --->  Accuracy = 46.15%\n",
      "M_pca =  209 , M_lda =  5  --->  Accuracy = 52.88%\n",
      "M_pca =  209 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  209 , M_lda =  7  --->  Accuracy = 59.62%\n",
      "M_pca =  209 , M_lda =  8  --->  Accuracy = 69.23%\n",
      "M_pca =  209 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  209 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  209 , M_lda =  11  --->  Accuracy = 75.00%\n",
      "M_pca =  209 , M_lda =  12  --->  Accuracy = 75.00%\n",
      "M_pca =  209 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  209 , M_lda =  14  --->  Accuracy = 76.92%\n",
      "M_pca =  209 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  209 , M_lda =  16  --->  Accuracy = 79.81%\n",
      "M_pca =  209 , M_lda =  17  --->  Accuracy = 80.77%\n",
      "M_pca =  209 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  209 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  209 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  209 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  209 , M_lda =  22  --->  Accuracy = 88.46%\n",
      "M_pca =  209 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  209 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  209 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  209 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  209 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  209 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  209 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  209 , M_lda =  30  --->  Accuracy = 84.62%\n",
      "M_pca =  209 , M_lda =  31  --->  Accuracy = 85.58%\n",
      "M_pca =  209 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  209 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  209 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  209 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  209 , M_lda =  36  --->  Accuracy = 86.54%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  209 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  209 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  209 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  209 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  209 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  209 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  209 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  209 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  209 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  209 , M_lda =  46  --->  Accuracy = 87.50%\n",
      "M_pca =  209 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  209 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  209 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  209 , M_lda =  50  --->  Accuracy = 88.46%\n",
      "M_pca =  209 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  210 , M_lda =  1  --->  Accuracy = 12.50%\n",
      "M_pca =  210 , M_lda =  2  --->  Accuracy = 25.00%\n",
      "M_pca =  210 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  210 , M_lda =  4  --->  Accuracy = 48.08%\n",
      "M_pca =  210 , M_lda =  5  --->  Accuracy = 53.85%\n",
      "M_pca =  210 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  210 , M_lda =  7  --->  Accuracy = 58.65%\n",
      "M_pca =  210 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  210 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  210 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  210 , M_lda =  11  --->  Accuracy = 75.96%\n",
      "M_pca =  210 , M_lda =  12  --->  Accuracy = 78.85%\n",
      "M_pca =  210 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  210 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  210 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  210 , M_lda =  16  --->  Accuracy = 79.81%\n",
      "M_pca =  210 , M_lda =  17  --->  Accuracy = 78.85%\n",
      "M_pca =  210 , M_lda =  18  --->  Accuracy = 78.85%\n",
      "M_pca =  210 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  210 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  210 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  210 , M_lda =  22  --->  Accuracy = 89.42%\n",
      "M_pca =  210 , M_lda =  23  --->  Accuracy = 89.42%\n",
      "M_pca =  210 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  210 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  210 , M_lda =  26  --->  Accuracy = 89.42%\n",
      "M_pca =  210 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  210 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  210 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  210 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  210 , M_lda =  31  --->  Accuracy = 85.58%\n",
      "M_pca =  210 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  210 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  210 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  210 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  210 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  210 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  210 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  210 , M_lda =  39  --->  Accuracy = 85.58%\n",
      "M_pca =  210 , M_lda =  40  --->  Accuracy = 86.54%\n",
      "M_pca =  210 , M_lda =  41  --->  Accuracy = 86.54%\n",
      "M_pca =  210 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  210 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  210 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  210 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  210 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  210 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  210 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  210 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  210 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  210 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  211 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  211 , M_lda =  2  --->  Accuracy = 24.04%\n",
      "M_pca =  211 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  211 , M_lda =  4  --->  Accuracy = 42.31%\n",
      "M_pca =  211 , M_lda =  5  --->  Accuracy = 51.92%\n",
      "M_pca =  211 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  211 , M_lda =  7  --->  Accuracy = 60.58%\n",
      "M_pca =  211 , M_lda =  8  --->  Accuracy = 65.38%\n",
      "M_pca =  211 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  211 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  211 , M_lda =  11  --->  Accuracy = 76.92%\n",
      "M_pca =  211 , M_lda =  12  --->  Accuracy = 77.88%\n",
      "M_pca =  211 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  211 , M_lda =  14  --->  Accuracy = 79.81%\n",
      "M_pca =  211 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  211 , M_lda =  16  --->  Accuracy = 75.96%\n",
      "M_pca =  211 , M_lda =  17  --->  Accuracy = 77.88%\n",
      "M_pca =  211 , M_lda =  18  --->  Accuracy = 78.85%\n",
      "M_pca =  211 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  211 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  211 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  211 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  211 , M_lda =  23  --->  Accuracy = 89.42%\n",
      "M_pca =  211 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  211 , M_lda =  25  --->  Accuracy = 88.46%\n",
      "M_pca =  211 , M_lda =  26  --->  Accuracy = 89.42%\n",
      "M_pca =  211 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  211 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  211 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  211 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  211 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  211 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  211 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  211 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  211 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  211 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  211 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  211 , M_lda =  38  --->  Accuracy = 85.58%\n",
      "M_pca =  211 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  211 , M_lda =  40  --->  Accuracy = 86.54%\n",
      "M_pca =  211 , M_lda =  41  --->  Accuracy = 86.54%\n",
      "M_pca =  211 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  211 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  211 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  211 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  211 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  211 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  211 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  211 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  211 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  211 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  212 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  212 , M_lda =  2  --->  Accuracy = 25.96%\n",
      "M_pca =  212 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  212 , M_lda =  4  --->  Accuracy = 48.08%\n",
      "M_pca =  212 , M_lda =  5  --->  Accuracy = 52.88%\n",
      "M_pca =  212 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  212 , M_lda =  7  --->  Accuracy = 59.62%\n",
      "M_pca =  212 , M_lda =  8  --->  Accuracy = 64.42%\n",
      "M_pca =  212 , M_lda =  9  --->  Accuracy = 68.27%\n",
      "M_pca =  212 , M_lda =  10  --->  Accuracy = 73.08%\n",
      "M_pca =  212 , M_lda =  11  --->  Accuracy = 74.04%\n",
      "M_pca =  212 , M_lda =  12  --->  Accuracy = 77.88%\n",
      "M_pca =  212 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  212 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  212 , M_lda =  15  --->  Accuracy = 76.92%\n",
      "M_pca =  212 , M_lda =  16  --->  Accuracy = 76.92%\n",
      "M_pca =  212 , M_lda =  17  --->  Accuracy = 78.85%\n",
      "M_pca =  212 , M_lda =  18  --->  Accuracy = 79.81%\n",
      "M_pca =  212 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  212 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  212 , M_lda =  21  --->  Accuracy = 87.50%\n",
      "M_pca =  212 , M_lda =  22  --->  Accuracy = 89.42%\n",
      "M_pca =  212 , M_lda =  23  --->  Accuracy = 90.38%\n",
      "M_pca =  212 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  212 , M_lda =  25  --->  Accuracy = 88.46%\n",
      "M_pca =  212 , M_lda =  26  --->  Accuracy = 88.46%\n",
      "M_pca =  212 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  212 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  212 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  212 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  212 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  212 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  212 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  212 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  212 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  212 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  212 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  212 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  212 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  212 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  212 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  212 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  212 , M_lda =  43  --->  Accuracy = 89.42%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  212 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  212 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  212 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  212 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  212 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  212 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  212 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  212 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  213 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  213 , M_lda =  2  --->  Accuracy = 24.04%\n",
      "M_pca =  213 , M_lda =  3  --->  Accuracy = 33.65%\n",
      "M_pca =  213 , M_lda =  4  --->  Accuracy = 49.04%\n",
      "M_pca =  213 , M_lda =  5  --->  Accuracy = 51.92%\n",
      "M_pca =  213 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  213 , M_lda =  7  --->  Accuracy = 59.62%\n",
      "M_pca =  213 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  213 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  213 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  213 , M_lda =  11  --->  Accuracy = 75.00%\n",
      "M_pca =  213 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  213 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  213 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  213 , M_lda =  15  --->  Accuracy = 76.92%\n",
      "M_pca =  213 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  213 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  213 , M_lda =  18  --->  Accuracy = 79.81%\n",
      "M_pca =  213 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  213 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  213 , M_lda =  21  --->  Accuracy = 87.50%\n",
      "M_pca =  213 , M_lda =  22  --->  Accuracy = 88.46%\n",
      "M_pca =  213 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  213 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  213 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  213 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  213 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  213 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  213 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  213 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  213 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  213 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  213 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  213 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  213 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  213 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  213 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  213 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  213 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  213 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  213 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  213 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  213 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  213 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  213 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  213 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  213 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  213 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  213 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  213 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  213 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  214 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  214 , M_lda =  2  --->  Accuracy = 24.04%\n",
      "M_pca =  214 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  214 , M_lda =  4  --->  Accuracy = 47.12%\n",
      "M_pca =  214 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  214 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  214 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  214 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  214 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  214 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  214 , M_lda =  11  --->  Accuracy = 74.04%\n",
      "M_pca =  214 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  214 , M_lda =  13  --->  Accuracy = 77.88%\n",
      "M_pca =  214 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  214 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  214 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  214 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  214 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  214 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  214 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  214 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  214 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  214 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  214 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  214 , M_lda =  25  --->  Accuracy = 89.42%\n",
      "M_pca =  214 , M_lda =  26  --->  Accuracy = 88.46%\n",
      "M_pca =  214 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  214 , M_lda =  28  --->  Accuracy = 89.42%\n",
      "M_pca =  214 , M_lda =  29  --->  Accuracy = 89.42%\n",
      "M_pca =  214 , M_lda =  30  --->  Accuracy = 89.42%\n",
      "M_pca =  214 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  214 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  214 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  214 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  214 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  214 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  214 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  214 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  214 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  214 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  214 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  214 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  214 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  214 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  214 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  214 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  214 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  214 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  214 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  214 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  214 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  215 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  215 , M_lda =  2  --->  Accuracy = 25.96%\n",
      "M_pca =  215 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  215 , M_lda =  4  --->  Accuracy = 47.12%\n",
      "M_pca =  215 , M_lda =  5  --->  Accuracy = 45.19%\n",
      "M_pca =  215 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  215 , M_lda =  7  --->  Accuracy = 58.65%\n",
      "M_pca =  215 , M_lda =  8  --->  Accuracy = 65.38%\n",
      "M_pca =  215 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  215 , M_lda =  10  --->  Accuracy = 76.92%\n",
      "M_pca =  215 , M_lda =  11  --->  Accuracy = 75.00%\n",
      "M_pca =  215 , M_lda =  12  --->  Accuracy = 77.88%\n",
      "M_pca =  215 , M_lda =  13  --->  Accuracy = 77.88%\n",
      "M_pca =  215 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  215 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  215 , M_lda =  16  --->  Accuracy = 79.81%\n",
      "M_pca =  215 , M_lda =  17  --->  Accuracy = 80.77%\n",
      "M_pca =  215 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  215 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  215 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  215 , M_lda =  21  --->  Accuracy = 87.50%\n",
      "M_pca =  215 , M_lda =  22  --->  Accuracy = 88.46%\n",
      "M_pca =  215 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  215 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  215 , M_lda =  25  --->  Accuracy = 88.46%\n",
      "M_pca =  215 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  215 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  215 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  215 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  215 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  215 , M_lda =  31  --->  Accuracy = 85.58%\n",
      "M_pca =  215 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  215 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  215 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  215 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  215 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  215 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  215 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  215 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  215 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  215 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  215 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  215 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  215 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  215 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  215 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  215 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  215 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  215 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  215 , M_lda =  50  --->  Accuracy = 89.42%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  215 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  216 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  216 , M_lda =  2  --->  Accuracy = 26.92%\n",
      "M_pca =  216 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  216 , M_lda =  4  --->  Accuracy = 46.15%\n",
      "M_pca =  216 , M_lda =  5  --->  Accuracy = 46.15%\n",
      "M_pca =  216 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  216 , M_lda =  7  --->  Accuracy = 60.58%\n",
      "M_pca =  216 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  216 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  216 , M_lda =  10  --->  Accuracy = 75.96%\n",
      "M_pca =  216 , M_lda =  11  --->  Accuracy = 75.00%\n",
      "M_pca =  216 , M_lda =  12  --->  Accuracy = 75.00%\n",
      "M_pca =  216 , M_lda =  13  --->  Accuracy = 77.88%\n",
      "M_pca =  216 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  216 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  216 , M_lda =  16  --->  Accuracy = 77.88%\n",
      "M_pca =  216 , M_lda =  17  --->  Accuracy = 81.73%\n",
      "M_pca =  216 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  216 , M_lda =  19  --->  Accuracy = 82.69%\n",
      "M_pca =  216 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  216 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  216 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  216 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  216 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  216 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  216 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  216 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  216 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  216 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  216 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  216 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  216 , M_lda =  32  --->  Accuracy = 85.58%\n",
      "M_pca =  216 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  216 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  216 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  216 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  216 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  216 , M_lda =  38  --->  Accuracy = 85.58%\n",
      "M_pca =  216 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  216 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  216 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  216 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  216 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  216 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  216 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  216 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  216 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  216 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  216 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  216 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  216 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  217 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  217 , M_lda =  2  --->  Accuracy = 26.92%\n",
      "M_pca =  217 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  217 , M_lda =  4  --->  Accuracy = 41.35%\n",
      "M_pca =  217 , M_lda =  5  --->  Accuracy = 44.23%\n",
      "M_pca =  217 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  217 , M_lda =  7  --->  Accuracy = 59.62%\n",
      "M_pca =  217 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  217 , M_lda =  9  --->  Accuracy = 69.23%\n",
      "M_pca =  217 , M_lda =  10  --->  Accuracy = 73.08%\n",
      "M_pca =  217 , M_lda =  11  --->  Accuracy = 75.96%\n",
      "M_pca =  217 , M_lda =  12  --->  Accuracy = 76.92%\n",
      "M_pca =  217 , M_lda =  13  --->  Accuracy = 77.88%\n",
      "M_pca =  217 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  217 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  217 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  217 , M_lda =  17  --->  Accuracy = 80.77%\n",
      "M_pca =  217 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  217 , M_lda =  19  --->  Accuracy = 82.69%\n",
      "M_pca =  217 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  217 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  217 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  217 , M_lda =  23  --->  Accuracy = 87.50%\n",
      "M_pca =  217 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  217 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  217 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  217 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  217 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  217 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  217 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  217 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  217 , M_lda =  32  --->  Accuracy = 85.58%\n",
      "M_pca =  217 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  217 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  217 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  217 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  217 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  217 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  217 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  217 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  217 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  217 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  217 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  217 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  217 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  217 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  217 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  217 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  217 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  217 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  217 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  218 , M_lda =  1  --->  Accuracy = 10.58%\n",
      "M_pca =  218 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  218 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  218 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  218 , M_lda =  5  --->  Accuracy = 42.31%\n",
      "M_pca =  218 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  218 , M_lda =  7  --->  Accuracy = 56.73%\n",
      "M_pca =  218 , M_lda =  8  --->  Accuracy = 64.42%\n",
      "M_pca =  218 , M_lda =  9  --->  Accuracy = 66.35%\n",
      "M_pca =  218 , M_lda =  10  --->  Accuracy = 75.00%\n",
      "M_pca =  218 , M_lda =  11  --->  Accuracy = 75.00%\n",
      "M_pca =  218 , M_lda =  12  --->  Accuracy = 73.08%\n",
      "M_pca =  218 , M_lda =  13  --->  Accuracy = 75.96%\n",
      "M_pca =  218 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  218 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  218 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  218 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  218 , M_lda =  18  --->  Accuracy = 83.65%\n",
      "M_pca =  218 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  218 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  218 , M_lda =  21  --->  Accuracy = 87.50%\n",
      "M_pca =  218 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  218 , M_lda =  23  --->  Accuracy = 88.46%\n",
      "M_pca =  218 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  218 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  218 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  218 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  218 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  218 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  218 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  218 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  218 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  218 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  218 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  218 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  218 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  218 , M_lda =  37  --->  Accuracy = 84.62%\n",
      "M_pca =  218 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  218 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  218 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  218 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  218 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  218 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  218 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  218 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  218 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  218 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  218 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  218 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  218 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  218 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  219 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  219 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  219 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  219 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  219 , M_lda =  5  --->  Accuracy = 42.31%\n",
      "M_pca =  219 , M_lda =  6  --->  Accuracy = 56.73%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  219 , M_lda =  7  --->  Accuracy = 59.62%\n",
      "M_pca =  219 , M_lda =  8  --->  Accuracy = 65.38%\n",
      "M_pca =  219 , M_lda =  9  --->  Accuracy = 65.38%\n",
      "M_pca =  219 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  219 , M_lda =  11  --->  Accuracy = 74.04%\n",
      "M_pca =  219 , M_lda =  12  --->  Accuracy = 73.08%\n",
      "M_pca =  219 , M_lda =  13  --->  Accuracy = 75.96%\n",
      "M_pca =  219 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  219 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  219 , M_lda =  16  --->  Accuracy = 79.81%\n",
      "M_pca =  219 , M_lda =  17  --->  Accuracy = 80.77%\n",
      "M_pca =  219 , M_lda =  18  --->  Accuracy = 83.65%\n",
      "M_pca =  219 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  219 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  219 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  219 , M_lda =  22  --->  Accuracy = 87.50%\n",
      "M_pca =  219 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  219 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  219 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  219 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  219 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  219 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  219 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  219 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  219 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  219 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  219 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  219 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  219 , M_lda =  35  --->  Accuracy = 83.65%\n",
      "M_pca =  219 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  219 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  219 , M_lda =  38  --->  Accuracy = 85.58%\n",
      "M_pca =  219 , M_lda =  39  --->  Accuracy = 84.62%\n",
      "M_pca =  219 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  219 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  219 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  219 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  219 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  219 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  219 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  219 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  219 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  219 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  219 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  219 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  220 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  220 , M_lda =  2  --->  Accuracy = 22.12%\n",
      "M_pca =  220 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  220 , M_lda =  4  --->  Accuracy = 33.65%\n",
      "M_pca =  220 , M_lda =  5  --->  Accuracy = 38.46%\n",
      "M_pca =  220 , M_lda =  6  --->  Accuracy = 52.88%\n",
      "M_pca =  220 , M_lda =  7  --->  Accuracy = 59.62%\n",
      "M_pca =  220 , M_lda =  8  --->  Accuracy = 63.46%\n",
      "M_pca =  220 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  220 , M_lda =  10  --->  Accuracy = 73.08%\n",
      "M_pca =  220 , M_lda =  11  --->  Accuracy = 73.08%\n",
      "M_pca =  220 , M_lda =  12  --->  Accuracy = 74.04%\n",
      "M_pca =  220 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  220 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  220 , M_lda =  15  --->  Accuracy = 78.85%\n",
      "M_pca =  220 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  220 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  220 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  220 , M_lda =  19  --->  Accuracy = 82.69%\n",
      "M_pca =  220 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  220 , M_lda =  21  --->  Accuracy = 86.54%\n",
      "M_pca =  220 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  220 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  220 , M_lda =  24  --->  Accuracy = 85.58%\n",
      "M_pca =  220 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  220 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  220 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  220 , M_lda =  28  --->  Accuracy = 85.58%\n",
      "M_pca =  220 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  220 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  220 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  220 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  220 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  220 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  220 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  220 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  220 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  220 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  220 , M_lda =  39  --->  Accuracy = 85.58%\n",
      "M_pca =  220 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  220 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  220 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  220 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  220 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  220 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  220 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  220 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  220 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  220 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  220 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  220 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  221 , M_lda =  1  --->  Accuracy = 10.58%\n",
      "M_pca =  221 , M_lda =  2  --->  Accuracy = 25.96%\n",
      "M_pca =  221 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  221 , M_lda =  4  --->  Accuracy = 45.19%\n",
      "M_pca =  221 , M_lda =  5  --->  Accuracy = 42.31%\n",
      "M_pca =  221 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  221 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  221 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  221 , M_lda =  9  --->  Accuracy = 73.08%\n",
      "M_pca =  221 , M_lda =  10  --->  Accuracy = 72.12%\n",
      "M_pca =  221 , M_lda =  11  --->  Accuracy = 74.04%\n",
      "M_pca =  221 , M_lda =  12  --->  Accuracy = 73.08%\n",
      "M_pca =  221 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  221 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  221 , M_lda =  15  --->  Accuracy = 80.77%\n",
      "M_pca =  221 , M_lda =  16  --->  Accuracy = 79.81%\n",
      "M_pca =  221 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  221 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  221 , M_lda =  19  --->  Accuracy = 82.69%\n",
      "M_pca =  221 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  221 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  221 , M_lda =  22  --->  Accuracy = 86.54%\n",
      "M_pca =  221 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  221 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  221 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  221 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  221 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  221 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  221 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  221 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  221 , M_lda =  31  --->  Accuracy = 85.58%\n",
      "M_pca =  221 , M_lda =  32  --->  Accuracy = 85.58%\n",
      "M_pca =  221 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  221 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  221 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  221 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  221 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  221 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  221 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  221 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  221 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  221 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  221 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  221 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  221 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  221 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  221 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  221 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  221 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  221 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  221 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  222 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  222 , M_lda =  2  --->  Accuracy = 23.08%\n",
      "M_pca =  222 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  222 , M_lda =  4  --->  Accuracy = 39.42%\n",
      "M_pca =  222 , M_lda =  5  --->  Accuracy = 46.15%\n",
      "M_pca =  222 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  222 , M_lda =  7  --->  Accuracy = 59.62%\n",
      "M_pca =  222 , M_lda =  8  --->  Accuracy = 65.38%\n",
      "M_pca =  222 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  222 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  222 , M_lda =  11  --->  Accuracy = 74.04%\n",
      "M_pca =  222 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  222 , M_lda =  13  --->  Accuracy = 75.96%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  222 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  222 , M_lda =  15  --->  Accuracy = 78.85%\n",
      "M_pca =  222 , M_lda =  16  --->  Accuracy = 79.81%\n",
      "M_pca =  222 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  222 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  222 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  222 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  222 , M_lda =  21  --->  Accuracy = 85.58%\n",
      "M_pca =  222 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  222 , M_lda =  23  --->  Accuracy = 85.58%\n",
      "M_pca =  222 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  222 , M_lda =  25  --->  Accuracy = 88.46%\n",
      "M_pca =  222 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  222 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  222 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  222 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  222 , M_lda =  30  --->  Accuracy = 86.54%\n",
      "M_pca =  222 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  222 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  222 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  222 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  222 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  222 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  222 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  222 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  222 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  222 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  222 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  222 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  222 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  222 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  222 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  222 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  222 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  222 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  222 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  222 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  222 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  223 , M_lda =  1  --->  Accuracy = 10.58%\n",
      "M_pca =  223 , M_lda =  2  --->  Accuracy = 23.08%\n",
      "M_pca =  223 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  223 , M_lda =  4  --->  Accuracy = 41.35%\n",
      "M_pca =  223 , M_lda =  5  --->  Accuracy = 44.23%\n",
      "M_pca =  223 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  223 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  223 , M_lda =  8  --->  Accuracy = 65.38%\n",
      "M_pca =  223 , M_lda =  9  --->  Accuracy = 68.27%\n",
      "M_pca =  223 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  223 , M_lda =  11  --->  Accuracy = 71.15%\n",
      "M_pca =  223 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  223 , M_lda =  13  --->  Accuracy = 75.96%\n",
      "M_pca =  223 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  223 , M_lda =  15  --->  Accuracy = 81.73%\n",
      "M_pca =  223 , M_lda =  16  --->  Accuracy = 81.73%\n",
      "M_pca =  223 , M_lda =  17  --->  Accuracy = 80.77%\n",
      "M_pca =  223 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  223 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  223 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  223 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  223 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  223 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  223 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  223 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  223 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  223 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  223 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  223 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  223 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  223 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  223 , M_lda =  32  --->  Accuracy = 85.58%\n",
      "M_pca =  223 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  223 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  223 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  223 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  223 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  223 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  223 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  223 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  223 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  223 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  223 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  223 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  223 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  223 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  223 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  223 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  223 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  223 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  223 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  224 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  224 , M_lda =  2  --->  Accuracy = 22.12%\n",
      "M_pca =  224 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  224 , M_lda =  4  --->  Accuracy = 41.35%\n",
      "M_pca =  224 , M_lda =  5  --->  Accuracy = 46.15%\n",
      "M_pca =  224 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  224 , M_lda =  7  --->  Accuracy = 60.58%\n",
      "M_pca =  224 , M_lda =  8  --->  Accuracy = 64.42%\n",
      "M_pca =  224 , M_lda =  9  --->  Accuracy = 67.31%\n",
      "M_pca =  224 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  224 , M_lda =  11  --->  Accuracy = 73.08%\n",
      "M_pca =  224 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  224 , M_lda =  13  --->  Accuracy = 75.96%\n",
      "M_pca =  224 , M_lda =  14  --->  Accuracy = 75.96%\n",
      "M_pca =  224 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  224 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  224 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  224 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  224 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  224 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  224 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  224 , M_lda =  22  --->  Accuracy = 83.65%\n",
      "M_pca =  224 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  224 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  224 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  224 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  224 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  224 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  224 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  224 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  224 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  224 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  224 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  224 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  224 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  224 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  224 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  224 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  224 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  224 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  224 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  224 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  224 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  224 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  224 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  224 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  224 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  224 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  224 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  224 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  224 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  225 , M_lda =  1  --->  Accuracy = 10.58%\n",
      "M_pca =  225 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  225 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  225 , M_lda =  4  --->  Accuracy = 39.42%\n",
      "M_pca =  225 , M_lda =  5  --->  Accuracy = 47.12%\n",
      "M_pca =  225 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  225 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  225 , M_lda =  8  --->  Accuracy = 65.38%\n",
      "M_pca =  225 , M_lda =  9  --->  Accuracy = 69.23%\n",
      "M_pca =  225 , M_lda =  10  --->  Accuracy = 74.04%\n",
      "M_pca =  225 , M_lda =  11  --->  Accuracy = 73.08%\n",
      "M_pca =  225 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  225 , M_lda =  13  --->  Accuracy = 75.00%\n",
      "M_pca =  225 , M_lda =  14  --->  Accuracy = 75.96%\n",
      "M_pca =  225 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  225 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  225 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  225 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  225 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  225 , M_lda =  20  --->  Accuracy = 82.69%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  225 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  225 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  225 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  225 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  225 , M_lda =  25  --->  Accuracy = 87.50%\n",
      "M_pca =  225 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  225 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  225 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  225 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  225 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  225 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  225 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  225 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  225 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  225 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  225 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  225 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  225 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  225 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  225 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  225 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  225 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  225 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  225 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  225 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  225 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  225 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  225 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  225 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  225 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  225 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  226 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  226 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  226 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  226 , M_lda =  4  --->  Accuracy = 34.62%\n",
      "M_pca =  226 , M_lda =  5  --->  Accuracy = 43.27%\n",
      "M_pca =  226 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  226 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  226 , M_lda =  8  --->  Accuracy = 65.38%\n",
      "M_pca =  226 , M_lda =  9  --->  Accuracy = 66.35%\n",
      "M_pca =  226 , M_lda =  10  --->  Accuracy = 72.12%\n",
      "M_pca =  226 , M_lda =  11  --->  Accuracy = 71.15%\n",
      "M_pca =  226 , M_lda =  12  --->  Accuracy = 75.00%\n",
      "M_pca =  226 , M_lda =  13  --->  Accuracy = 75.96%\n",
      "M_pca =  226 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  226 , M_lda =  15  --->  Accuracy = 78.85%\n",
      "M_pca =  226 , M_lda =  16  --->  Accuracy = 77.88%\n",
      "M_pca =  226 , M_lda =  17  --->  Accuracy = 80.77%\n",
      "M_pca =  226 , M_lda =  18  --->  Accuracy = 83.65%\n",
      "M_pca =  226 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  226 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  226 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  226 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  226 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  226 , M_lda =  24  --->  Accuracy = 88.46%\n",
      "M_pca =  226 , M_lda =  25  --->  Accuracy = 88.46%\n",
      "M_pca =  226 , M_lda =  26  --->  Accuracy = 87.50%\n",
      "M_pca =  226 , M_lda =  27  --->  Accuracy = 87.50%\n",
      "M_pca =  226 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  226 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  226 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  226 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  226 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  226 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  226 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  226 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  226 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  226 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  226 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  226 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  226 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  226 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  226 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  226 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  226 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  226 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  226 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  226 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  226 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  226 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  226 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  226 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  227 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  227 , M_lda =  2  --->  Accuracy = 24.04%\n",
      "M_pca =  227 , M_lda =  3  --->  Accuracy = 22.12%\n",
      "M_pca =  227 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  227 , M_lda =  5  --->  Accuracy = 41.35%\n",
      "M_pca =  227 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  227 , M_lda =  7  --->  Accuracy = 61.54%\n",
      "M_pca =  227 , M_lda =  8  --->  Accuracy = 65.38%\n",
      "M_pca =  227 , M_lda =  9  --->  Accuracy = 67.31%\n",
      "M_pca =  227 , M_lda =  10  --->  Accuracy = 68.27%\n",
      "M_pca =  227 , M_lda =  11  --->  Accuracy = 71.15%\n",
      "M_pca =  227 , M_lda =  12  --->  Accuracy = 74.04%\n",
      "M_pca =  227 , M_lda =  13  --->  Accuracy = 74.04%\n",
      "M_pca =  227 , M_lda =  14  --->  Accuracy = 76.92%\n",
      "M_pca =  227 , M_lda =  15  --->  Accuracy = 79.81%\n",
      "M_pca =  227 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  227 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  227 , M_lda =  18  --->  Accuracy = 83.65%\n",
      "M_pca =  227 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  227 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  227 , M_lda =  21  --->  Accuracy = 83.65%\n",
      "M_pca =  227 , M_lda =  22  --->  Accuracy = 83.65%\n",
      "M_pca =  227 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  227 , M_lda =  24  --->  Accuracy = 87.50%\n",
      "M_pca =  227 , M_lda =  25  --->  Accuracy = 88.46%\n",
      "M_pca =  227 , M_lda =  26  --->  Accuracy = 86.54%\n",
      "M_pca =  227 , M_lda =  27  --->  Accuracy = 88.46%\n",
      "M_pca =  227 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  227 , M_lda =  29  --->  Accuracy = 88.46%\n",
      "M_pca =  227 , M_lda =  30  --->  Accuracy = 89.42%\n",
      "M_pca =  227 , M_lda =  31  --->  Accuracy = 90.38%\n",
      "M_pca =  227 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  227 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  227 , M_lda =  34  --->  Accuracy = 89.42%\n",
      "M_pca =  227 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  227 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  227 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  227 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  227 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  227 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  227 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  227 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  227 , M_lda =  43  --->  Accuracy = 89.42%\n",
      "M_pca =  227 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  227 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  227 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  227 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  227 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  227 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  227 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  227 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  228 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  228 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  228 , M_lda =  3  --->  Accuracy = 25.96%\n",
      "M_pca =  228 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  228 , M_lda =  5  --->  Accuracy = 45.19%\n",
      "M_pca =  228 , M_lda =  6  --->  Accuracy = 60.58%\n",
      "M_pca =  228 , M_lda =  7  --->  Accuracy = 66.35%\n",
      "M_pca =  228 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  228 , M_lda =  9  --->  Accuracy = 68.27%\n",
      "M_pca =  228 , M_lda =  10  --->  Accuracy = 70.19%\n",
      "M_pca =  228 , M_lda =  11  --->  Accuracy = 73.08%\n",
      "M_pca =  228 , M_lda =  12  --->  Accuracy = 75.96%\n",
      "M_pca =  228 , M_lda =  13  --->  Accuracy = 76.92%\n",
      "M_pca =  228 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  228 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  228 , M_lda =  16  --->  Accuracy = 76.92%\n",
      "M_pca =  228 , M_lda =  17  --->  Accuracy = 81.73%\n",
      "M_pca =  228 , M_lda =  18  --->  Accuracy = 83.65%\n",
      "M_pca =  228 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  228 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  228 , M_lda =  21  --->  Accuracy = 84.62%\n",
      "M_pca =  228 , M_lda =  22  --->  Accuracy = 85.58%\n",
      "M_pca =  228 , M_lda =  23  --->  Accuracy = 86.54%\n",
      "M_pca =  228 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  228 , M_lda =  25  --->  Accuracy = 86.54%\n",
      "M_pca =  228 , M_lda =  26  --->  Accuracy = 88.46%\n",
      "M_pca =  228 , M_lda =  27  --->  Accuracy = 87.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  228 , M_lda =  28  --->  Accuracy = 87.50%\n",
      "M_pca =  228 , M_lda =  29  --->  Accuracy = 89.42%\n",
      "M_pca =  228 , M_lda =  30  --->  Accuracy = 89.42%\n",
      "M_pca =  228 , M_lda =  31  --->  Accuracy = 90.38%\n",
      "M_pca =  228 , M_lda =  32  --->  Accuracy = 90.38%\n",
      "M_pca =  228 , M_lda =  33  --->  Accuracy = 89.42%\n",
      "M_pca =  228 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  228 , M_lda =  35  --->  Accuracy = 89.42%\n",
      "M_pca =  228 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  228 , M_lda =  37  --->  Accuracy = 89.42%\n",
      "M_pca =  228 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  228 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  228 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  228 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  228 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  228 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  228 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  228 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  228 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  228 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  228 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  228 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  228 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  228 , M_lda =  51  --->  Accuracy = 90.38%\n",
      "M_pca =  229 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  229 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  229 , M_lda =  3  --->  Accuracy = 25.96%\n",
      "M_pca =  229 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  229 , M_lda =  5  --->  Accuracy = 43.27%\n",
      "M_pca =  229 , M_lda =  6  --->  Accuracy = 60.58%\n",
      "M_pca =  229 , M_lda =  7  --->  Accuracy = 68.27%\n",
      "M_pca =  229 , M_lda =  8  --->  Accuracy = 64.42%\n",
      "M_pca =  229 , M_lda =  9  --->  Accuracy = 67.31%\n",
      "M_pca =  229 , M_lda =  10  --->  Accuracy = 69.23%\n",
      "M_pca =  229 , M_lda =  11  --->  Accuracy = 71.15%\n",
      "M_pca =  229 , M_lda =  12  --->  Accuracy = 73.08%\n",
      "M_pca =  229 , M_lda =  13  --->  Accuracy = 75.96%\n",
      "M_pca =  229 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  229 , M_lda =  15  --->  Accuracy = 78.85%\n",
      "M_pca =  229 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  229 , M_lda =  17  --->  Accuracy = 81.73%\n",
      "M_pca =  229 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  229 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  229 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  229 , M_lda =  21  --->  Accuracy = 82.69%\n",
      "M_pca =  229 , M_lda =  22  --->  Accuracy = 84.62%\n",
      "M_pca =  229 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  229 , M_lda =  24  --->  Accuracy = 86.54%\n",
      "M_pca =  229 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  229 , M_lda =  26  --->  Accuracy = 85.58%\n",
      "M_pca =  229 , M_lda =  27  --->  Accuracy = 86.54%\n",
      "M_pca =  229 , M_lda =  28  --->  Accuracy = 88.46%\n",
      "M_pca =  229 , M_lda =  29  --->  Accuracy = 89.42%\n",
      "M_pca =  229 , M_lda =  30  --->  Accuracy = 90.38%\n",
      "M_pca =  229 , M_lda =  31  --->  Accuracy = 92.31%\n",
      "M_pca =  229 , M_lda =  32  --->  Accuracy = 91.35%\n",
      "M_pca =  229 , M_lda =  33  --->  Accuracy = 90.38%\n",
      "M_pca =  229 , M_lda =  34  --->  Accuracy = 89.42%\n",
      "M_pca =  229 , M_lda =  35  --->  Accuracy = 89.42%\n",
      "M_pca =  229 , M_lda =  36  --->  Accuracy = 89.42%\n",
      "M_pca =  229 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  229 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  229 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  229 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  229 , M_lda =  41  --->  Accuracy = 90.38%\n",
      "M_pca =  229 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  229 , M_lda =  43  --->  Accuracy = 91.35%\n",
      "M_pca =  229 , M_lda =  44  --->  Accuracy = 91.35%\n",
      "M_pca =  229 , M_lda =  45  --->  Accuracy = 91.35%\n",
      "M_pca =  229 , M_lda =  46  --->  Accuracy = 91.35%\n",
      "M_pca =  229 , M_lda =  47  --->  Accuracy = 91.35%\n",
      "M_pca =  229 , M_lda =  48  --->  Accuracy = 91.35%\n",
      "M_pca =  229 , M_lda =  49  --->  Accuracy = 91.35%\n",
      "M_pca =  229 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  229 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  230 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  230 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  230 , M_lda =  3  --->  Accuracy = 27.88%\n",
      "M_pca =  230 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  230 , M_lda =  5  --->  Accuracy = 46.15%\n",
      "M_pca =  230 , M_lda =  6  --->  Accuracy = 60.58%\n",
      "M_pca =  230 , M_lda =  7  --->  Accuracy = 69.23%\n",
      "M_pca =  230 , M_lda =  8  --->  Accuracy = 62.50%\n",
      "M_pca =  230 , M_lda =  9  --->  Accuracy = 67.31%\n",
      "M_pca =  230 , M_lda =  10  --->  Accuracy = 69.23%\n",
      "M_pca =  230 , M_lda =  11  --->  Accuracy = 70.19%\n",
      "M_pca =  230 , M_lda =  12  --->  Accuracy = 74.04%\n",
      "M_pca =  230 , M_lda =  13  --->  Accuracy = 75.00%\n",
      "M_pca =  230 , M_lda =  14  --->  Accuracy = 79.81%\n",
      "M_pca =  230 , M_lda =  15  --->  Accuracy = 79.81%\n",
      "M_pca =  230 , M_lda =  16  --->  Accuracy = 77.88%\n",
      "M_pca =  230 , M_lda =  17  --->  Accuracy = 81.73%\n",
      "M_pca =  230 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  230 , M_lda =  19  --->  Accuracy = 82.69%\n",
      "M_pca =  230 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  230 , M_lda =  21  --->  Accuracy = 81.73%\n",
      "M_pca =  230 , M_lda =  22  --->  Accuracy = 82.69%\n",
      "M_pca =  230 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  230 , M_lda =  24  --->  Accuracy = 84.62%\n",
      "M_pca =  230 , M_lda =  25  --->  Accuracy = 83.65%\n",
      "M_pca =  230 , M_lda =  26  --->  Accuracy = 83.65%\n",
      "M_pca =  230 , M_lda =  27  --->  Accuracy = 83.65%\n",
      "M_pca =  230 , M_lda =  28  --->  Accuracy = 84.62%\n",
      "M_pca =  230 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  230 , M_lda =  30  --->  Accuracy = 89.42%\n",
      "M_pca =  230 , M_lda =  31  --->  Accuracy = 89.42%\n",
      "M_pca =  230 , M_lda =  32  --->  Accuracy = 88.46%\n",
      "M_pca =  230 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  230 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  230 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  230 , M_lda =  36  --->  Accuracy = 89.42%\n",
      "M_pca =  230 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  230 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  230 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  230 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  230 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  230 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  230 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  230 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  230 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  230 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  230 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  230 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  230 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  230 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  230 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  231 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  231 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  231 , M_lda =  3  --->  Accuracy = 21.15%\n",
      "M_pca =  231 , M_lda =  4  --->  Accuracy = 32.69%\n",
      "M_pca =  231 , M_lda =  5  --->  Accuracy = 46.15%\n",
      "M_pca =  231 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  231 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  231 , M_lda =  8  --->  Accuracy = 60.58%\n",
      "M_pca =  231 , M_lda =  9  --->  Accuracy = 67.31%\n",
      "M_pca =  231 , M_lda =  10  --->  Accuracy = 69.23%\n",
      "M_pca =  231 , M_lda =  11  --->  Accuracy = 72.12%\n",
      "M_pca =  231 , M_lda =  12  --->  Accuracy = 74.04%\n",
      "M_pca =  231 , M_lda =  13  --->  Accuracy = 75.96%\n",
      "M_pca =  231 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  231 , M_lda =  15  --->  Accuracy = 78.85%\n",
      "M_pca =  231 , M_lda =  16  --->  Accuracy = 77.88%\n",
      "M_pca =  231 , M_lda =  17  --->  Accuracy = 81.73%\n",
      "M_pca =  231 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  231 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  231 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  231 , M_lda =  21  --->  Accuracy = 81.73%\n",
      "M_pca =  231 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  231 , M_lda =  23  --->  Accuracy = 82.69%\n",
      "M_pca =  231 , M_lda =  24  --->  Accuracy = 83.65%\n",
      "M_pca =  231 , M_lda =  25  --->  Accuracy = 83.65%\n",
      "M_pca =  231 , M_lda =  26  --->  Accuracy = 83.65%\n",
      "M_pca =  231 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  231 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  231 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  231 , M_lda =  30  --->  Accuracy = 90.38%\n",
      "M_pca =  231 , M_lda =  31  --->  Accuracy = 90.38%\n",
      "M_pca =  231 , M_lda =  32  --->  Accuracy = 90.38%\n",
      "M_pca =  231 , M_lda =  33  --->  Accuracy = 89.42%\n",
      "M_pca =  231 , M_lda =  34  --->  Accuracy = 87.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  231 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  231 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  231 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  231 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  231 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  231 , M_lda =  40  --->  Accuracy = 90.38%\n",
      "M_pca =  231 , M_lda =  41  --->  Accuracy = 90.38%\n",
      "M_pca =  231 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  231 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  231 , M_lda =  44  --->  Accuracy = 89.42%\n",
      "M_pca =  231 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  231 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  231 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  231 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  231 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  231 , M_lda =  50  --->  Accuracy = 91.35%\n",
      "M_pca =  231 , M_lda =  51  --->  Accuracy = 92.31%\n",
      "M_pca =  232 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  232 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  232 , M_lda =  3  --->  Accuracy = 24.04%\n",
      "M_pca =  232 , M_lda =  4  --->  Accuracy = 33.65%\n",
      "M_pca =  232 , M_lda =  5  --->  Accuracy = 46.15%\n",
      "M_pca =  232 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  232 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  232 , M_lda =  8  --->  Accuracy = 63.46%\n",
      "M_pca =  232 , M_lda =  9  --->  Accuracy = 67.31%\n",
      "M_pca =  232 , M_lda =  10  --->  Accuracy = 68.27%\n",
      "M_pca =  232 , M_lda =  11  --->  Accuracy = 70.19%\n",
      "M_pca =  232 , M_lda =  12  --->  Accuracy = 74.04%\n",
      "M_pca =  232 , M_lda =  13  --->  Accuracy = 75.96%\n",
      "M_pca =  232 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  232 , M_lda =  15  --->  Accuracy = 76.92%\n",
      "M_pca =  232 , M_lda =  16  --->  Accuracy = 76.92%\n",
      "M_pca =  232 , M_lda =  17  --->  Accuracy = 78.85%\n",
      "M_pca =  232 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  232 , M_lda =  19  --->  Accuracy = 82.69%\n",
      "M_pca =  232 , M_lda =  20  --->  Accuracy = 83.65%\n",
      "M_pca =  232 , M_lda =  21  --->  Accuracy = 81.73%\n",
      "M_pca =  232 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  232 , M_lda =  23  --->  Accuracy = 82.69%\n",
      "M_pca =  232 , M_lda =  24  --->  Accuracy = 84.62%\n",
      "M_pca =  232 , M_lda =  25  --->  Accuracy = 83.65%\n",
      "M_pca =  232 , M_lda =  26  --->  Accuracy = 83.65%\n",
      "M_pca =  232 , M_lda =  27  --->  Accuracy = 84.62%\n",
      "M_pca =  232 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  232 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  232 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  232 , M_lda =  31  --->  Accuracy = 89.42%\n",
      "M_pca =  232 , M_lda =  32  --->  Accuracy = 89.42%\n",
      "M_pca =  232 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  232 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  232 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  232 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  232 , M_lda =  37  --->  Accuracy = 89.42%\n",
      "M_pca =  232 , M_lda =  38  --->  Accuracy = 90.38%\n",
      "M_pca =  232 , M_lda =  39  --->  Accuracy = 89.42%\n",
      "M_pca =  232 , M_lda =  40  --->  Accuracy = 90.38%\n",
      "M_pca =  232 , M_lda =  41  --->  Accuracy = 90.38%\n",
      "M_pca =  232 , M_lda =  42  --->  Accuracy = 89.42%\n",
      "M_pca =  232 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  232 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  232 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  232 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  232 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  232 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  232 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  232 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  232 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  233 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  233 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  233 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  233 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  233 , M_lda =  5  --->  Accuracy = 47.12%\n",
      "M_pca =  233 , M_lda =  6  --->  Accuracy = 58.65%\n",
      "M_pca =  233 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  233 , M_lda =  8  --->  Accuracy = 62.50%\n",
      "M_pca =  233 , M_lda =  9  --->  Accuracy = 67.31%\n",
      "M_pca =  233 , M_lda =  10  --->  Accuracy = 69.23%\n",
      "M_pca =  233 , M_lda =  11  --->  Accuracy = 71.15%\n",
      "M_pca =  233 , M_lda =  12  --->  Accuracy = 73.08%\n",
      "M_pca =  233 , M_lda =  13  --->  Accuracy = 75.96%\n",
      "M_pca =  233 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  233 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  233 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  233 , M_lda =  17  --->  Accuracy = 78.85%\n",
      "M_pca =  233 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  233 , M_lda =  19  --->  Accuracy = 82.69%\n",
      "M_pca =  233 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  233 , M_lda =  21  --->  Accuracy = 81.73%\n",
      "M_pca =  233 , M_lda =  22  --->  Accuracy = 79.81%\n",
      "M_pca =  233 , M_lda =  23  --->  Accuracy = 82.69%\n",
      "M_pca =  233 , M_lda =  24  --->  Accuracy = 83.65%\n",
      "M_pca =  233 , M_lda =  25  --->  Accuracy = 84.62%\n",
      "M_pca =  233 , M_lda =  26  --->  Accuracy = 84.62%\n",
      "M_pca =  233 , M_lda =  27  --->  Accuracy = 84.62%\n",
      "M_pca =  233 , M_lda =  28  --->  Accuracy = 85.58%\n",
      "M_pca =  233 , M_lda =  29  --->  Accuracy = 86.54%\n",
      "M_pca =  233 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  233 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  233 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  233 , M_lda =  33  --->  Accuracy = 88.46%\n",
      "M_pca =  233 , M_lda =  34  --->  Accuracy = 88.46%\n",
      "M_pca =  233 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  233 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  233 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  233 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  233 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  233 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  233 , M_lda =  41  --->  Accuracy = 89.42%\n",
      "M_pca =  233 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  233 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  233 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  233 , M_lda =  45  --->  Accuracy = 89.42%\n",
      "M_pca =  233 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  233 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  233 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  233 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  233 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  233 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  234 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  234 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  234 , M_lda =  3  --->  Accuracy = 25.96%\n",
      "M_pca =  234 , M_lda =  4  --->  Accuracy = 34.62%\n",
      "M_pca =  234 , M_lda =  5  --->  Accuracy = 46.15%\n",
      "M_pca =  234 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  234 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  234 , M_lda =  8  --->  Accuracy = 62.50%\n",
      "M_pca =  234 , M_lda =  9  --->  Accuracy = 66.35%\n",
      "M_pca =  234 , M_lda =  10  --->  Accuracy = 69.23%\n",
      "M_pca =  234 , M_lda =  11  --->  Accuracy = 71.15%\n",
      "M_pca =  234 , M_lda =  12  --->  Accuracy = 75.96%\n",
      "M_pca =  234 , M_lda =  13  --->  Accuracy = 75.96%\n",
      "M_pca =  234 , M_lda =  14  --->  Accuracy = 76.92%\n",
      "M_pca =  234 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  234 , M_lda =  16  --->  Accuracy = 79.81%\n",
      "M_pca =  234 , M_lda =  17  --->  Accuracy = 77.88%\n",
      "M_pca =  234 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  234 , M_lda =  19  --->  Accuracy = 82.69%\n",
      "M_pca =  234 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  234 , M_lda =  21  --->  Accuracy = 81.73%\n",
      "M_pca =  234 , M_lda =  22  --->  Accuracy = 79.81%\n",
      "M_pca =  234 , M_lda =  23  --->  Accuracy = 83.65%\n",
      "M_pca =  234 , M_lda =  24  --->  Accuracy = 82.69%\n",
      "M_pca =  234 , M_lda =  25  --->  Accuracy = 83.65%\n",
      "M_pca =  234 , M_lda =  26  --->  Accuracy = 83.65%\n",
      "M_pca =  234 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  234 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  234 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  234 , M_lda =  30  --->  Accuracy = 87.50%\n",
      "M_pca =  234 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  234 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  234 , M_lda =  33  --->  Accuracy = 89.42%\n",
      "M_pca =  234 , M_lda =  34  --->  Accuracy = 89.42%\n",
      "M_pca =  234 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  234 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  234 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  234 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  234 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  234 , M_lda =  40  --->  Accuracy = 89.42%\n",
      "M_pca =  234 , M_lda =  41  --->  Accuracy = 90.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  234 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  234 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  234 , M_lda =  44  --->  Accuracy = 91.35%\n",
      "M_pca =  234 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  234 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  234 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  234 , M_lda =  48  --->  Accuracy = 90.38%\n",
      "M_pca =  234 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  234 , M_lda =  50  --->  Accuracy = 92.31%\n",
      "M_pca =  234 , M_lda =  51  --->  Accuracy = 92.31%\n",
      "M_pca =  235 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  235 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  235 , M_lda =  3  --->  Accuracy = 27.88%\n",
      "M_pca =  235 , M_lda =  4  --->  Accuracy = 37.50%\n",
      "M_pca =  235 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  235 , M_lda =  6  --->  Accuracy = 60.58%\n",
      "M_pca =  235 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  235 , M_lda =  8  --->  Accuracy = 64.42%\n",
      "M_pca =  235 , M_lda =  9  --->  Accuracy = 67.31%\n",
      "M_pca =  235 , M_lda =  10  --->  Accuracy = 69.23%\n",
      "M_pca =  235 , M_lda =  11  --->  Accuracy = 71.15%\n",
      "M_pca =  235 , M_lda =  12  --->  Accuracy = 73.08%\n",
      "M_pca =  235 , M_lda =  13  --->  Accuracy = 77.88%\n",
      "M_pca =  235 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  235 , M_lda =  15  --->  Accuracy = 76.92%\n",
      "M_pca =  235 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  235 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  235 , M_lda =  18  --->  Accuracy = 82.69%\n",
      "M_pca =  235 , M_lda =  19  --->  Accuracy = 83.65%\n",
      "M_pca =  235 , M_lda =  20  --->  Accuracy = 84.62%\n",
      "M_pca =  235 , M_lda =  21  --->  Accuracy = 81.73%\n",
      "M_pca =  235 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  235 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  235 , M_lda =  24  --->  Accuracy = 83.65%\n",
      "M_pca =  235 , M_lda =  25  --->  Accuracy = 85.58%\n",
      "M_pca =  235 , M_lda =  26  --->  Accuracy = 83.65%\n",
      "M_pca =  235 , M_lda =  27  --->  Accuracy = 85.58%\n",
      "M_pca =  235 , M_lda =  28  --->  Accuracy = 86.54%\n",
      "M_pca =  235 , M_lda =  29  --->  Accuracy = 87.50%\n",
      "M_pca =  235 , M_lda =  30  --->  Accuracy = 88.46%\n",
      "M_pca =  235 , M_lda =  31  --->  Accuracy = 88.46%\n",
      "M_pca =  235 , M_lda =  32  --->  Accuracy = 89.42%\n",
      "M_pca =  235 , M_lda =  33  --->  Accuracy = 89.42%\n",
      "M_pca =  235 , M_lda =  34  --->  Accuracy = 90.38%\n",
      "M_pca =  235 , M_lda =  35  --->  Accuracy = 88.46%\n",
      "M_pca =  235 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  235 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  235 , M_lda =  38  --->  Accuracy = 90.38%\n",
      "M_pca =  235 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  235 , M_lda =  40  --->  Accuracy = 90.38%\n",
      "M_pca =  235 , M_lda =  41  --->  Accuracy = 90.38%\n",
      "M_pca =  235 , M_lda =  42  --->  Accuracy = 90.38%\n",
      "M_pca =  235 , M_lda =  43  --->  Accuracy = 90.38%\n",
      "M_pca =  235 , M_lda =  44  --->  Accuracy = 90.38%\n",
      "M_pca =  235 , M_lda =  45  --->  Accuracy = 90.38%\n",
      "M_pca =  235 , M_lda =  46  --->  Accuracy = 90.38%\n",
      "M_pca =  235 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  235 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  235 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  235 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  235 , M_lda =  51  --->  Accuracy = 91.35%\n",
      "M_pca =  236 , M_lda =  1  --->  Accuracy = 10.58%\n",
      "M_pca =  236 , M_lda =  2  --->  Accuracy = 23.08%\n",
      "M_pca =  236 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  236 , M_lda =  4  --->  Accuracy = 31.73%\n",
      "M_pca =  236 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  236 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  236 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  236 , M_lda =  8  --->  Accuracy = 64.42%\n",
      "M_pca =  236 , M_lda =  9  --->  Accuracy = 64.42%\n",
      "M_pca =  236 , M_lda =  10  --->  Accuracy = 69.23%\n",
      "M_pca =  236 , M_lda =  11  --->  Accuracy = 71.15%\n",
      "M_pca =  236 , M_lda =  12  --->  Accuracy = 73.08%\n",
      "M_pca =  236 , M_lda =  13  --->  Accuracy = 77.88%\n",
      "M_pca =  236 , M_lda =  14  --->  Accuracy = 79.81%\n",
      "M_pca =  236 , M_lda =  15  --->  Accuracy = 78.85%\n",
      "M_pca =  236 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  236 , M_lda =  17  --->  Accuracy = 80.77%\n",
      "M_pca =  236 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  236 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  236 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  236 , M_lda =  21  --->  Accuracy = 81.73%\n",
      "M_pca =  236 , M_lda =  22  --->  Accuracy = 81.73%\n",
      "M_pca =  236 , M_lda =  23  --->  Accuracy = 83.65%\n",
      "M_pca =  236 , M_lda =  24  --->  Accuracy = 82.69%\n",
      "M_pca =  236 , M_lda =  25  --->  Accuracy = 82.69%\n",
      "M_pca =  236 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  236 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  236 , M_lda =  28  --->  Accuracy = 83.65%\n",
      "M_pca =  236 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  236 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  236 , M_lda =  31  --->  Accuracy = 85.58%\n",
      "M_pca =  236 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  236 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  236 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  236 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  236 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  236 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  236 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  236 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  236 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  236 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  236 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  236 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  236 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  236 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  236 , M_lda =  46  --->  Accuracy = 87.50%\n",
      "M_pca =  236 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  236 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  236 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  236 , M_lda =  50  --->  Accuracy = 88.46%\n",
      "M_pca =  236 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  237 , M_lda =  1  --->  Accuracy = 11.54%\n",
      "M_pca =  237 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  237 , M_lda =  3  --->  Accuracy = 27.88%\n",
      "M_pca =  237 , M_lda =  4  --->  Accuracy = 34.62%\n",
      "M_pca =  237 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  237 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  237 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  237 , M_lda =  8  --->  Accuracy = 62.50%\n",
      "M_pca =  237 , M_lda =  9  --->  Accuracy = 67.31%\n",
      "M_pca =  237 , M_lda =  10  --->  Accuracy = 71.15%\n",
      "M_pca =  237 , M_lda =  11  --->  Accuracy = 70.19%\n",
      "M_pca =  237 , M_lda =  12  --->  Accuracy = 75.00%\n",
      "M_pca =  237 , M_lda =  13  --->  Accuracy = 78.85%\n",
      "M_pca =  237 , M_lda =  14  --->  Accuracy = 79.81%\n",
      "M_pca =  237 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  237 , M_lda =  16  --->  Accuracy = 80.77%\n",
      "M_pca =  237 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  237 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  237 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  237 , M_lda =  20  --->  Accuracy = 80.77%\n",
      "M_pca =  237 , M_lda =  21  --->  Accuracy = 81.73%\n",
      "M_pca =  237 , M_lda =  22  --->  Accuracy = 83.65%\n",
      "M_pca =  237 , M_lda =  23  --->  Accuracy = 82.69%\n",
      "M_pca =  237 , M_lda =  24  --->  Accuracy = 82.69%\n",
      "M_pca =  237 , M_lda =  25  --->  Accuracy = 82.69%\n",
      "M_pca =  237 , M_lda =  26  --->  Accuracy = 83.65%\n",
      "M_pca =  237 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  237 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  237 , M_lda =  29  --->  Accuracy = 84.62%\n",
      "M_pca =  237 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  237 , M_lda =  31  --->  Accuracy = 87.50%\n",
      "M_pca =  237 , M_lda =  32  --->  Accuracy = 87.50%\n",
      "M_pca =  237 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  237 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  237 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  237 , M_lda =  36  --->  Accuracy = 86.54%\n",
      "M_pca =  237 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  237 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  237 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  237 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  237 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  237 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  237 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  237 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  237 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  237 , M_lda =  46  --->  Accuracy = 87.50%\n",
      "M_pca =  237 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  237 , M_lda =  48  --->  Accuracy = 88.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  237 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  237 , M_lda =  50  --->  Accuracy = 88.46%\n",
      "M_pca =  237 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  238 , M_lda =  1  --->  Accuracy = 11.54%\n",
      "M_pca =  238 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  238 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  238 , M_lda =  4  --->  Accuracy = 40.38%\n",
      "M_pca =  238 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  238 , M_lda =  6  --->  Accuracy = 59.62%\n",
      "M_pca =  238 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  238 , M_lda =  8  --->  Accuracy = 65.38%\n",
      "M_pca =  238 , M_lda =  9  --->  Accuracy = 65.38%\n",
      "M_pca =  238 , M_lda =  10  --->  Accuracy = 71.15%\n",
      "M_pca =  238 , M_lda =  11  --->  Accuracy = 69.23%\n",
      "M_pca =  238 , M_lda =  12  --->  Accuracy = 74.04%\n",
      "M_pca =  238 , M_lda =  13  --->  Accuracy = 77.88%\n",
      "M_pca =  238 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  238 , M_lda =  15  --->  Accuracy = 76.92%\n",
      "M_pca =  238 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  238 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  238 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  238 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  238 , M_lda =  20  --->  Accuracy = 79.81%\n",
      "M_pca =  238 , M_lda =  21  --->  Accuracy = 79.81%\n",
      "M_pca =  238 , M_lda =  22  --->  Accuracy = 81.73%\n",
      "M_pca =  238 , M_lda =  23  --->  Accuracy = 82.69%\n",
      "M_pca =  238 , M_lda =  24  --->  Accuracy = 83.65%\n",
      "M_pca =  238 , M_lda =  25  --->  Accuracy = 82.69%\n",
      "M_pca =  238 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  238 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  238 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  238 , M_lda =  29  --->  Accuracy = 84.62%\n",
      "M_pca =  238 , M_lda =  30  --->  Accuracy = 84.62%\n",
      "M_pca =  238 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  238 , M_lda =  32  --->  Accuracy = 83.65%\n",
      "M_pca =  238 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  238 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  238 , M_lda =  35  --->  Accuracy = 86.54%\n",
      "M_pca =  238 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  238 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  238 , M_lda =  38  --->  Accuracy = 87.50%\n",
      "M_pca =  238 , M_lda =  39  --->  Accuracy = 87.50%\n",
      "M_pca =  238 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  238 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  238 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  238 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  238 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  238 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  238 , M_lda =  46  --->  Accuracy = 86.54%\n",
      "M_pca =  238 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  238 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  238 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  238 , M_lda =  50  --->  Accuracy = 88.46%\n",
      "M_pca =  238 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  239 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  239 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  239 , M_lda =  3  --->  Accuracy = 25.00%\n",
      "M_pca =  239 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  239 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  239 , M_lda =  6  --->  Accuracy = 57.69%\n",
      "M_pca =  239 , M_lda =  7  --->  Accuracy = 65.38%\n",
      "M_pca =  239 , M_lda =  8  --->  Accuracy = 65.38%\n",
      "M_pca =  239 , M_lda =  9  --->  Accuracy = 67.31%\n",
      "M_pca =  239 , M_lda =  10  --->  Accuracy = 69.23%\n",
      "M_pca =  239 , M_lda =  11  --->  Accuracy = 69.23%\n",
      "M_pca =  239 , M_lda =  12  --->  Accuracy = 71.15%\n",
      "M_pca =  239 , M_lda =  13  --->  Accuracy = 77.88%\n",
      "M_pca =  239 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  239 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  239 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  239 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  239 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  239 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  239 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  239 , M_lda =  21  --->  Accuracy = 79.81%\n",
      "M_pca =  239 , M_lda =  22  --->  Accuracy = 82.69%\n",
      "M_pca =  239 , M_lda =  23  --->  Accuracy = 82.69%\n",
      "M_pca =  239 , M_lda =  24  --->  Accuracy = 81.73%\n",
      "M_pca =  239 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  239 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  239 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  239 , M_lda =  28  --->  Accuracy = 83.65%\n",
      "M_pca =  239 , M_lda =  29  --->  Accuracy = 85.58%\n",
      "M_pca =  239 , M_lda =  30  --->  Accuracy = 85.58%\n",
      "M_pca =  239 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  239 , M_lda =  32  --->  Accuracy = 86.54%\n",
      "M_pca =  239 , M_lda =  33  --->  Accuracy = 87.50%\n",
      "M_pca =  239 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  239 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  239 , M_lda =  36  --->  Accuracy = 88.46%\n",
      "M_pca =  239 , M_lda =  37  --->  Accuracy = 88.46%\n",
      "M_pca =  239 , M_lda =  38  --->  Accuracy = 88.46%\n",
      "M_pca =  239 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  239 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  239 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  239 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  239 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  239 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  239 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  239 , M_lda =  46  --->  Accuracy = 87.50%\n",
      "M_pca =  239 , M_lda =  47  --->  Accuracy = 90.38%\n",
      "M_pca =  239 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  239 , M_lda =  49  --->  Accuracy = 90.38%\n",
      "M_pca =  239 , M_lda =  50  --->  Accuracy = 90.38%\n",
      "M_pca =  239 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  240 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  240 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  240 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  240 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  240 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  240 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  240 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  240 , M_lda =  8  --->  Accuracy = 65.38%\n",
      "M_pca =  240 , M_lda =  9  --->  Accuracy = 64.42%\n",
      "M_pca =  240 , M_lda =  10  --->  Accuracy = 72.12%\n",
      "M_pca =  240 , M_lda =  11  --->  Accuracy = 68.27%\n",
      "M_pca =  240 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  240 , M_lda =  13  --->  Accuracy = 75.96%\n",
      "M_pca =  240 , M_lda =  14  --->  Accuracy = 75.96%\n",
      "M_pca =  240 , M_lda =  15  --->  Accuracy = 76.92%\n",
      "M_pca =  240 , M_lda =  16  --->  Accuracy = 76.92%\n",
      "M_pca =  240 , M_lda =  17  --->  Accuracy = 76.92%\n",
      "M_pca =  240 , M_lda =  18  --->  Accuracy = 77.88%\n",
      "M_pca =  240 , M_lda =  19  --->  Accuracy = 78.85%\n",
      "M_pca =  240 , M_lda =  20  --->  Accuracy = 77.88%\n",
      "M_pca =  240 , M_lda =  21  --->  Accuracy = 79.81%\n",
      "M_pca =  240 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  240 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  240 , M_lda =  24  --->  Accuracy = 81.73%\n",
      "M_pca =  240 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  240 , M_lda =  26  --->  Accuracy = 81.73%\n",
      "M_pca =  240 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  240 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  240 , M_lda =  29  --->  Accuracy = 84.62%\n",
      "M_pca =  240 , M_lda =  30  --->  Accuracy = 84.62%\n",
      "M_pca =  240 , M_lda =  31  --->  Accuracy = 86.54%\n",
      "M_pca =  240 , M_lda =  32  --->  Accuracy = 84.62%\n",
      "M_pca =  240 , M_lda =  33  --->  Accuracy = 86.54%\n",
      "M_pca =  240 , M_lda =  34  --->  Accuracy = 87.50%\n",
      "M_pca =  240 , M_lda =  35  --->  Accuracy = 87.50%\n",
      "M_pca =  240 , M_lda =  36  --->  Accuracy = 87.50%\n",
      "M_pca =  240 , M_lda =  37  --->  Accuracy = 87.50%\n",
      "M_pca =  240 , M_lda =  38  --->  Accuracy = 89.42%\n",
      "M_pca =  240 , M_lda =  39  --->  Accuracy = 88.46%\n",
      "M_pca =  240 , M_lda =  40  --->  Accuracy = 86.54%\n",
      "M_pca =  240 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  240 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  240 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  240 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  240 , M_lda =  45  --->  Accuracy = 88.46%\n",
      "M_pca =  240 , M_lda =  46  --->  Accuracy = 87.50%\n",
      "M_pca =  240 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  240 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  240 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  240 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  240 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  241 , M_lda =  1  --->  Accuracy = 0.96%\n",
      "M_pca =  241 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  241 , M_lda =  3  --->  Accuracy = 22.12%\n",
      "M_pca =  241 , M_lda =  4  --->  Accuracy = 34.62%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  241 , M_lda =  5  --->  Accuracy = 45.19%\n",
      "M_pca =  241 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  241 , M_lda =  7  --->  Accuracy = 59.62%\n",
      "M_pca =  241 , M_lda =  8  --->  Accuracy = 64.42%\n",
      "M_pca =  241 , M_lda =  9  --->  Accuracy = 66.35%\n",
      "M_pca =  241 , M_lda =  10  --->  Accuracy = 69.23%\n",
      "M_pca =  241 , M_lda =  11  --->  Accuracy = 70.19%\n",
      "M_pca =  241 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  241 , M_lda =  13  --->  Accuracy = 75.00%\n",
      "M_pca =  241 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  241 , M_lda =  15  --->  Accuracy = 76.92%\n",
      "M_pca =  241 , M_lda =  16  --->  Accuracy = 77.88%\n",
      "M_pca =  241 , M_lda =  17  --->  Accuracy = 77.88%\n",
      "M_pca =  241 , M_lda =  18  --->  Accuracy = 77.88%\n",
      "M_pca =  241 , M_lda =  19  --->  Accuracy = 77.88%\n",
      "M_pca =  241 , M_lda =  20  --->  Accuracy = 77.88%\n",
      "M_pca =  241 , M_lda =  21  --->  Accuracy = 77.88%\n",
      "M_pca =  241 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  241 , M_lda =  23  --->  Accuracy = 80.77%\n",
      "M_pca =  241 , M_lda =  24  --->  Accuracy = 81.73%\n",
      "M_pca =  241 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  241 , M_lda =  26  --->  Accuracy = 81.73%\n",
      "M_pca =  241 , M_lda =  27  --->  Accuracy = 83.65%\n",
      "M_pca =  241 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  241 , M_lda =  29  --->  Accuracy = 84.62%\n",
      "M_pca =  241 , M_lda =  30  --->  Accuracy = 84.62%\n",
      "M_pca =  241 , M_lda =  31  --->  Accuracy = 83.65%\n",
      "M_pca =  241 , M_lda =  32  --->  Accuracy = 83.65%\n",
      "M_pca =  241 , M_lda =  33  --->  Accuracy = 83.65%\n",
      "M_pca =  241 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  241 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  241 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  241 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  241 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  241 , M_lda =  39  --->  Accuracy = 85.58%\n",
      "M_pca =  241 , M_lda =  40  --->  Accuracy = 85.58%\n",
      "M_pca =  241 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  241 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  241 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  241 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  241 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  241 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  241 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  241 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  241 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  241 , M_lda =  50  --->  Accuracy = 88.46%\n",
      "M_pca =  241 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  242 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  242 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  242 , M_lda =  3  --->  Accuracy = 25.96%\n",
      "M_pca =  242 , M_lda =  4  --->  Accuracy = 38.46%\n",
      "M_pca =  242 , M_lda =  5  --->  Accuracy = 51.92%\n",
      "M_pca =  242 , M_lda =  6  --->  Accuracy = 54.81%\n",
      "M_pca =  242 , M_lda =  7  --->  Accuracy = 60.58%\n",
      "M_pca =  242 , M_lda =  8  --->  Accuracy = 62.50%\n",
      "M_pca =  242 , M_lda =  9  --->  Accuracy = 65.38%\n",
      "M_pca =  242 , M_lda =  10  --->  Accuracy = 68.27%\n",
      "M_pca =  242 , M_lda =  11  --->  Accuracy = 68.27%\n",
      "M_pca =  242 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  242 , M_lda =  13  --->  Accuracy = 73.08%\n",
      "M_pca =  242 , M_lda =  14  --->  Accuracy = 75.96%\n",
      "M_pca =  242 , M_lda =  15  --->  Accuracy = 75.00%\n",
      "M_pca =  242 , M_lda =  16  --->  Accuracy = 75.96%\n",
      "M_pca =  242 , M_lda =  17  --->  Accuracy = 77.88%\n",
      "M_pca =  242 , M_lda =  18  --->  Accuracy = 77.88%\n",
      "M_pca =  242 , M_lda =  19  --->  Accuracy = 75.00%\n",
      "M_pca =  242 , M_lda =  20  --->  Accuracy = 75.96%\n",
      "M_pca =  242 , M_lda =  21  --->  Accuracy = 77.88%\n",
      "M_pca =  242 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  242 , M_lda =  23  --->  Accuracy = 80.77%\n",
      "M_pca =  242 , M_lda =  24  --->  Accuracy = 81.73%\n",
      "M_pca =  242 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  242 , M_lda =  26  --->  Accuracy = 81.73%\n",
      "M_pca =  242 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  242 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  242 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  242 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  242 , M_lda =  31  --->  Accuracy = 83.65%\n",
      "M_pca =  242 , M_lda =  32  --->  Accuracy = 84.62%\n",
      "M_pca =  242 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  242 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  242 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  242 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  242 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  242 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  242 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  242 , M_lda =  40  --->  Accuracy = 87.50%\n",
      "M_pca =  242 , M_lda =  41  --->  Accuracy = 86.54%\n",
      "M_pca =  242 , M_lda =  42  --->  Accuracy = 86.54%\n",
      "M_pca =  242 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  242 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  242 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  242 , M_lda =  46  --->  Accuracy = 87.50%\n",
      "M_pca =  242 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  242 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  242 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  242 , M_lda =  50  --->  Accuracy = 88.46%\n",
      "M_pca =  242 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  243 , M_lda =  1  --->  Accuracy = 11.54%\n",
      "M_pca =  243 , M_lda =  2  --->  Accuracy = 23.08%\n",
      "M_pca =  243 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  243 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  243 , M_lda =  5  --->  Accuracy = 50.96%\n",
      "M_pca =  243 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  243 , M_lda =  7  --->  Accuracy = 61.54%\n",
      "M_pca =  243 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  243 , M_lda =  9  --->  Accuracy = 67.31%\n",
      "M_pca =  243 , M_lda =  10  --->  Accuracy = 69.23%\n",
      "M_pca =  243 , M_lda =  11  --->  Accuracy = 68.27%\n",
      "M_pca =  243 , M_lda =  12  --->  Accuracy = 74.04%\n",
      "M_pca =  243 , M_lda =  13  --->  Accuracy = 74.04%\n",
      "M_pca =  243 , M_lda =  14  --->  Accuracy = 75.00%\n",
      "M_pca =  243 , M_lda =  15  --->  Accuracy = 76.92%\n",
      "M_pca =  243 , M_lda =  16  --->  Accuracy = 75.96%\n",
      "M_pca =  243 , M_lda =  17  --->  Accuracy = 75.96%\n",
      "M_pca =  243 , M_lda =  18  --->  Accuracy = 77.88%\n",
      "M_pca =  243 , M_lda =  19  --->  Accuracy = 75.96%\n",
      "M_pca =  243 , M_lda =  20  --->  Accuracy = 77.88%\n",
      "M_pca =  243 , M_lda =  21  --->  Accuracy = 79.81%\n",
      "M_pca =  243 , M_lda =  22  --->  Accuracy = 79.81%\n",
      "M_pca =  243 , M_lda =  23  --->  Accuracy = 82.69%\n",
      "M_pca =  243 , M_lda =  24  --->  Accuracy = 82.69%\n",
      "M_pca =  243 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  243 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  243 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  243 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  243 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  243 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  243 , M_lda =  31  --->  Accuracy = 84.62%\n",
      "M_pca =  243 , M_lda =  32  --->  Accuracy = 84.62%\n",
      "M_pca =  243 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  243 , M_lda =  34  --->  Accuracy = 83.65%\n",
      "M_pca =  243 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  243 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  243 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  243 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  243 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  243 , M_lda =  40  --->  Accuracy = 88.46%\n",
      "M_pca =  243 , M_lda =  41  --->  Accuracy = 88.46%\n",
      "M_pca =  243 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  243 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  243 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  243 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  243 , M_lda =  46  --->  Accuracy = 89.42%\n",
      "M_pca =  243 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  243 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  243 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  243 , M_lda =  50  --->  Accuracy = 88.46%\n",
      "M_pca =  243 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  244 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  244 , M_lda =  2  --->  Accuracy = 23.08%\n",
      "M_pca =  244 , M_lda =  3  --->  Accuracy = 24.04%\n",
      "M_pca =  244 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  244 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  244 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  244 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  244 , M_lda =  8  --->  Accuracy = 66.35%\n",
      "M_pca =  244 , M_lda =  9  --->  Accuracy = 66.35%\n",
      "M_pca =  244 , M_lda =  10  --->  Accuracy = 69.23%\n",
      "M_pca =  244 , M_lda =  11  --->  Accuracy = 67.31%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  244 , M_lda =  12  --->  Accuracy = 71.15%\n",
      "M_pca =  244 , M_lda =  13  --->  Accuracy = 73.08%\n",
      "M_pca =  244 , M_lda =  14  --->  Accuracy = 75.00%\n",
      "M_pca =  244 , M_lda =  15  --->  Accuracy = 75.96%\n",
      "M_pca =  244 , M_lda =  16  --->  Accuracy = 75.96%\n",
      "M_pca =  244 , M_lda =  17  --->  Accuracy = 75.96%\n",
      "M_pca =  244 , M_lda =  18  --->  Accuracy = 77.88%\n",
      "M_pca =  244 , M_lda =  19  --->  Accuracy = 76.92%\n",
      "M_pca =  244 , M_lda =  20  --->  Accuracy = 77.88%\n",
      "M_pca =  244 , M_lda =  21  --->  Accuracy = 79.81%\n",
      "M_pca =  244 , M_lda =  22  --->  Accuracy = 81.73%\n",
      "M_pca =  244 , M_lda =  23  --->  Accuracy = 79.81%\n",
      "M_pca =  244 , M_lda =  24  --->  Accuracy = 81.73%\n",
      "M_pca =  244 , M_lda =  25  --->  Accuracy = 80.77%\n",
      "M_pca =  244 , M_lda =  26  --->  Accuracy = 79.81%\n",
      "M_pca =  244 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  244 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  244 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  244 , M_lda =  30  --->  Accuracy = 84.62%\n",
      "M_pca =  244 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  244 , M_lda =  32  --->  Accuracy = 83.65%\n",
      "M_pca =  244 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  244 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  244 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  244 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  244 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  244 , M_lda =  38  --->  Accuracy = 85.58%\n",
      "M_pca =  244 , M_lda =  39  --->  Accuracy = 85.58%\n",
      "M_pca =  244 , M_lda =  40  --->  Accuracy = 86.54%\n",
      "M_pca =  244 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  244 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  244 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  244 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  244 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  244 , M_lda =  46  --->  Accuracy = 87.50%\n",
      "M_pca =  244 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  244 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  244 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  244 , M_lda =  50  --->  Accuracy = 88.46%\n",
      "M_pca =  244 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  245 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  245 , M_lda =  2  --->  Accuracy = 22.12%\n",
      "M_pca =  245 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  245 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  245 , M_lda =  5  --->  Accuracy = 55.77%\n",
      "M_pca =  245 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  245 , M_lda =  7  --->  Accuracy = 64.42%\n",
      "M_pca =  245 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  245 , M_lda =  9  --->  Accuracy = 71.15%\n",
      "M_pca =  245 , M_lda =  10  --->  Accuracy = 72.12%\n",
      "M_pca =  245 , M_lda =  11  --->  Accuracy = 72.12%\n",
      "M_pca =  245 , M_lda =  12  --->  Accuracy = 73.08%\n",
      "M_pca =  245 , M_lda =  13  --->  Accuracy = 76.92%\n",
      "M_pca =  245 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  245 , M_lda =  15  --->  Accuracy = 76.92%\n",
      "M_pca =  245 , M_lda =  16  --->  Accuracy = 77.88%\n",
      "M_pca =  245 , M_lda =  17  --->  Accuracy = 77.88%\n",
      "M_pca =  245 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  245 , M_lda =  19  --->  Accuracy = 76.92%\n",
      "M_pca =  245 , M_lda =  20  --->  Accuracy = 77.88%\n",
      "M_pca =  245 , M_lda =  21  --->  Accuracy = 77.88%\n",
      "M_pca =  245 , M_lda =  22  --->  Accuracy = 81.73%\n",
      "M_pca =  245 , M_lda =  23  --->  Accuracy = 84.62%\n",
      "M_pca =  245 , M_lda =  24  --->  Accuracy = 84.62%\n",
      "M_pca =  245 , M_lda =  25  --->  Accuracy = 82.69%\n",
      "M_pca =  245 , M_lda =  26  --->  Accuracy = 81.73%\n",
      "M_pca =  245 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  245 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  245 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  245 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  245 , M_lda =  31  --->  Accuracy = 83.65%\n",
      "M_pca =  245 , M_lda =  32  --->  Accuracy = 83.65%\n",
      "M_pca =  245 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  245 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  245 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  245 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  245 , M_lda =  37  --->  Accuracy = 84.62%\n",
      "M_pca =  245 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  245 , M_lda =  39  --->  Accuracy = 84.62%\n",
      "M_pca =  245 , M_lda =  40  --->  Accuracy = 86.54%\n",
      "M_pca =  245 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  245 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  245 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  245 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  245 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  245 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  245 , M_lda =  47  --->  Accuracy = 89.42%\n",
      "M_pca =  245 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  245 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  245 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  245 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  246 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  246 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  246 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  246 , M_lda =  4  --->  Accuracy = 44.23%\n",
      "M_pca =  246 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  246 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  246 , M_lda =  7  --->  Accuracy = 63.46%\n",
      "M_pca =  246 , M_lda =  8  --->  Accuracy = 71.15%\n",
      "M_pca =  246 , M_lda =  9  --->  Accuracy = 72.12%\n",
      "M_pca =  246 , M_lda =  10  --->  Accuracy = 73.08%\n",
      "M_pca =  246 , M_lda =  11  --->  Accuracy = 72.12%\n",
      "M_pca =  246 , M_lda =  12  --->  Accuracy = 75.00%\n",
      "M_pca =  246 , M_lda =  13  --->  Accuracy = 75.96%\n",
      "M_pca =  246 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  246 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  246 , M_lda =  16  --->  Accuracy = 76.92%\n",
      "M_pca =  246 , M_lda =  17  --->  Accuracy = 78.85%\n",
      "M_pca =  246 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  246 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  246 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  246 , M_lda =  21  --->  Accuracy = 78.85%\n",
      "M_pca =  246 , M_lda =  22  --->  Accuracy = 81.73%\n",
      "M_pca =  246 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  246 , M_lda =  24  --->  Accuracy = 83.65%\n",
      "M_pca =  246 , M_lda =  25  --->  Accuracy = 82.69%\n",
      "M_pca =  246 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  246 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  246 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  246 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  246 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  246 , M_lda =  31  --->  Accuracy = 83.65%\n",
      "M_pca =  246 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  246 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  246 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  246 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  246 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  246 , M_lda =  37  --->  Accuracy = 84.62%\n",
      "M_pca =  246 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  246 , M_lda =  39  --->  Accuracy = 84.62%\n",
      "M_pca =  246 , M_lda =  40  --->  Accuracy = 86.54%\n",
      "M_pca =  246 , M_lda =  41  --->  Accuracy = 86.54%\n",
      "M_pca =  246 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  246 , M_lda =  43  --->  Accuracy = 86.54%\n",
      "M_pca =  246 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  246 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  246 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  246 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  246 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  246 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  246 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  246 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  247 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  247 , M_lda =  2  --->  Accuracy = 25.00%\n",
      "M_pca =  247 , M_lda =  3  --->  Accuracy = 33.65%\n",
      "M_pca =  247 , M_lda =  4  --->  Accuracy = 43.27%\n",
      "M_pca =  247 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  247 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  247 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  247 , M_lda =  8  --->  Accuracy = 71.15%\n",
      "M_pca =  247 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  247 , M_lda =  10  --->  Accuracy = 72.12%\n",
      "M_pca =  247 , M_lda =  11  --->  Accuracy = 73.08%\n",
      "M_pca =  247 , M_lda =  12  --->  Accuracy = 75.00%\n",
      "M_pca =  247 , M_lda =  13  --->  Accuracy = 75.96%\n",
      "M_pca =  247 , M_lda =  14  --->  Accuracy = 78.85%\n",
      "M_pca =  247 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  247 , M_lda =  16  --->  Accuracy = 77.88%\n",
      "M_pca =  247 , M_lda =  17  --->  Accuracy = 78.85%\n",
      "M_pca =  247 , M_lda =  18  --->  Accuracy = 80.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  247 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  247 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  247 , M_lda =  21  --->  Accuracy = 79.81%\n",
      "M_pca =  247 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  247 , M_lda =  23  --->  Accuracy = 83.65%\n",
      "M_pca =  247 , M_lda =  24  --->  Accuracy = 83.65%\n",
      "M_pca =  247 , M_lda =  25  --->  Accuracy = 82.69%\n",
      "M_pca =  247 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  247 , M_lda =  27  --->  Accuracy = 83.65%\n",
      "M_pca =  247 , M_lda =  28  --->  Accuracy = 84.62%\n",
      "M_pca =  247 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  247 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  247 , M_lda =  31  --->  Accuracy = 83.65%\n",
      "M_pca =  247 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  247 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  247 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  247 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  247 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  247 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  247 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  247 , M_lda =  39  --->  Accuracy = 84.62%\n",
      "M_pca =  247 , M_lda =  40  --->  Accuracy = 84.62%\n",
      "M_pca =  247 , M_lda =  41  --->  Accuracy = 85.58%\n",
      "M_pca =  247 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  247 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  247 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  247 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  247 , M_lda =  46  --->  Accuracy = 88.46%\n",
      "M_pca =  247 , M_lda =  47  --->  Accuracy = 88.46%\n",
      "M_pca =  247 , M_lda =  48  --->  Accuracy = 89.42%\n",
      "M_pca =  247 , M_lda =  49  --->  Accuracy = 89.42%\n",
      "M_pca =  247 , M_lda =  50  --->  Accuracy = 89.42%\n",
      "M_pca =  247 , M_lda =  51  --->  Accuracy = 89.42%\n",
      "M_pca =  248 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  248 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  248 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  248 , M_lda =  4  --->  Accuracy = 37.50%\n",
      "M_pca =  248 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  248 , M_lda =  6  --->  Accuracy = 51.92%\n",
      "M_pca =  248 , M_lda =  7  --->  Accuracy = 61.54%\n",
      "M_pca =  248 , M_lda =  8  --->  Accuracy = 70.19%\n",
      "M_pca =  248 , M_lda =  9  --->  Accuracy = 70.19%\n",
      "M_pca =  248 , M_lda =  10  --->  Accuracy = 72.12%\n",
      "M_pca =  248 , M_lda =  11  --->  Accuracy = 70.19%\n",
      "M_pca =  248 , M_lda =  12  --->  Accuracy = 70.19%\n",
      "M_pca =  248 , M_lda =  13  --->  Accuracy = 75.00%\n",
      "M_pca =  248 , M_lda =  14  --->  Accuracy = 74.04%\n",
      "M_pca =  248 , M_lda =  15  --->  Accuracy = 78.85%\n",
      "M_pca =  248 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  248 , M_lda =  17  --->  Accuracy = 78.85%\n",
      "M_pca =  248 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  248 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  248 , M_lda =  20  --->  Accuracy = 76.92%\n",
      "M_pca =  248 , M_lda =  21  --->  Accuracy = 78.85%\n",
      "M_pca =  248 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  248 , M_lda =  23  --->  Accuracy = 83.65%\n",
      "M_pca =  248 , M_lda =  24  --->  Accuracy = 82.69%\n",
      "M_pca =  248 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  248 , M_lda =  26  --->  Accuracy = 81.73%\n",
      "M_pca =  248 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  248 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  248 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  248 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  248 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  248 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  248 , M_lda =  33  --->  Accuracy = 82.69%\n",
      "M_pca =  248 , M_lda =  34  --->  Accuracy = 82.69%\n",
      "M_pca =  248 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  248 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  248 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  248 , M_lda =  38  --->  Accuracy = 85.58%\n",
      "M_pca =  248 , M_lda =  39  --->  Accuracy = 85.58%\n",
      "M_pca =  248 , M_lda =  40  --->  Accuracy = 85.58%\n",
      "M_pca =  248 , M_lda =  41  --->  Accuracy = 86.54%\n",
      "M_pca =  248 , M_lda =  42  --->  Accuracy = 85.58%\n",
      "M_pca =  248 , M_lda =  43  --->  Accuracy = 85.58%\n",
      "M_pca =  248 , M_lda =  44  --->  Accuracy = 86.54%\n",
      "M_pca =  248 , M_lda =  45  --->  Accuracy = 86.54%\n",
      "M_pca =  248 , M_lda =  46  --->  Accuracy = 87.50%\n",
      "M_pca =  248 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  248 , M_lda =  48  --->  Accuracy = 88.46%\n",
      "M_pca =  248 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  248 , M_lda =  50  --->  Accuracy = 88.46%\n",
      "M_pca =  248 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  249 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  249 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  249 , M_lda =  3  --->  Accuracy = 27.88%\n",
      "M_pca =  249 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  249 , M_lda =  5  --->  Accuracy = 45.19%\n",
      "M_pca =  249 , M_lda =  6  --->  Accuracy = 54.81%\n",
      "M_pca =  249 , M_lda =  7  --->  Accuracy = 59.62%\n",
      "M_pca =  249 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  249 , M_lda =  9  --->  Accuracy = 68.27%\n",
      "M_pca =  249 , M_lda =  10  --->  Accuracy = 68.27%\n",
      "M_pca =  249 , M_lda =  11  --->  Accuracy = 71.15%\n",
      "M_pca =  249 , M_lda =  12  --->  Accuracy = 71.15%\n",
      "M_pca =  249 , M_lda =  13  --->  Accuracy = 74.04%\n",
      "M_pca =  249 , M_lda =  14  --->  Accuracy = 76.92%\n",
      "M_pca =  249 , M_lda =  15  --->  Accuracy = 78.85%\n",
      "M_pca =  249 , M_lda =  16  --->  Accuracy = 77.88%\n",
      "M_pca =  249 , M_lda =  17  --->  Accuracy = 80.77%\n",
      "M_pca =  249 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  249 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  249 , M_lda =  20  --->  Accuracy = 79.81%\n",
      "M_pca =  249 , M_lda =  21  --->  Accuracy = 79.81%\n",
      "M_pca =  249 , M_lda =  22  --->  Accuracy = 79.81%\n",
      "M_pca =  249 , M_lda =  23  --->  Accuracy = 83.65%\n",
      "M_pca =  249 , M_lda =  24  --->  Accuracy = 83.65%\n",
      "M_pca =  249 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  249 , M_lda =  26  --->  Accuracy = 81.73%\n",
      "M_pca =  249 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  249 , M_lda =  28  --->  Accuracy = 84.62%\n",
      "M_pca =  249 , M_lda =  29  --->  Accuracy = 84.62%\n",
      "M_pca =  249 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  249 , M_lda =  31  --->  Accuracy = 83.65%\n",
      "M_pca =  249 , M_lda =  32  --->  Accuracy = 83.65%\n",
      "M_pca =  249 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  249 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  249 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  249 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  249 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  249 , M_lda =  38  --->  Accuracy = 83.65%\n",
      "M_pca =  249 , M_lda =  39  --->  Accuracy = 83.65%\n",
      "M_pca =  249 , M_lda =  40  --->  Accuracy = 85.58%\n",
      "M_pca =  249 , M_lda =  41  --->  Accuracy = 86.54%\n",
      "M_pca =  249 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  249 , M_lda =  43  --->  Accuracy = 86.54%\n",
      "M_pca =  249 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  249 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  249 , M_lda =  46  --->  Accuracy = 86.54%\n",
      "M_pca =  249 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  249 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  249 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  249 , M_lda =  50  --->  Accuracy = 88.46%\n",
      "M_pca =  249 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  250 , M_lda =  1  --->  Accuracy = 11.54%\n",
      "M_pca =  250 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  250 , M_lda =  3  --->  Accuracy = 24.04%\n",
      "M_pca =  250 , M_lda =  4  --->  Accuracy = 34.62%\n",
      "M_pca =  250 , M_lda =  5  --->  Accuracy = 46.15%\n",
      "M_pca =  250 , M_lda =  6  --->  Accuracy = 54.81%\n",
      "M_pca =  250 , M_lda =  7  --->  Accuracy = 62.50%\n",
      "M_pca =  250 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  250 , M_lda =  9  --->  Accuracy = 68.27%\n",
      "M_pca =  250 , M_lda =  10  --->  Accuracy = 68.27%\n",
      "M_pca =  250 , M_lda =  11  --->  Accuracy = 69.23%\n",
      "M_pca =  250 , M_lda =  12  --->  Accuracy = 71.15%\n",
      "M_pca =  250 , M_lda =  13  --->  Accuracy = 75.00%\n",
      "M_pca =  250 , M_lda =  14  --->  Accuracy = 74.04%\n",
      "M_pca =  250 , M_lda =  15  --->  Accuracy = 76.92%\n",
      "M_pca =  250 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  250 , M_lda =  17  --->  Accuracy = 77.88%\n",
      "M_pca =  250 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  250 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  250 , M_lda =  20  --->  Accuracy = 77.88%\n",
      "M_pca =  250 , M_lda =  21  --->  Accuracy = 80.77%\n",
      "M_pca =  250 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  250 , M_lda =  23  --->  Accuracy = 82.69%\n",
      "M_pca =  250 , M_lda =  24  --->  Accuracy = 82.69%\n",
      "M_pca =  250 , M_lda =  25  --->  Accuracy = 81.73%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  250 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  250 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  250 , M_lda =  28  --->  Accuracy = 84.62%\n",
      "M_pca =  250 , M_lda =  29  --->  Accuracy = 84.62%\n",
      "M_pca =  250 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  250 , M_lda =  31  --->  Accuracy = 83.65%\n",
      "M_pca =  250 , M_lda =  32  --->  Accuracy = 83.65%\n",
      "M_pca =  250 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  250 , M_lda =  34  --->  Accuracy = 83.65%\n",
      "M_pca =  250 , M_lda =  35  --->  Accuracy = 82.69%\n",
      "M_pca =  250 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  250 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  250 , M_lda =  38  --->  Accuracy = 82.69%\n",
      "M_pca =  250 , M_lda =  39  --->  Accuracy = 82.69%\n",
      "M_pca =  250 , M_lda =  40  --->  Accuracy = 84.62%\n",
      "M_pca =  250 , M_lda =  41  --->  Accuracy = 86.54%\n",
      "M_pca =  250 , M_lda =  42  --->  Accuracy = 86.54%\n",
      "M_pca =  250 , M_lda =  43  --->  Accuracy = 86.54%\n",
      "M_pca =  250 , M_lda =  44  --->  Accuracy = 86.54%\n",
      "M_pca =  250 , M_lda =  45  --->  Accuracy = 86.54%\n",
      "M_pca =  250 , M_lda =  46  --->  Accuracy = 85.58%\n",
      "M_pca =  250 , M_lda =  47  --->  Accuracy = 85.58%\n",
      "M_pca =  250 , M_lda =  48  --->  Accuracy = 85.58%\n",
      "M_pca =  250 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  250 , M_lda =  50  --->  Accuracy = 87.50%\n",
      "M_pca =  250 , M_lda =  51  --->  Accuracy = 87.50%\n",
      "M_pca =  251 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  251 , M_lda =  2  --->  Accuracy = 22.12%\n",
      "M_pca =  251 , M_lda =  3  --->  Accuracy = 25.00%\n",
      "M_pca =  251 , M_lda =  4  --->  Accuracy = 34.62%\n",
      "M_pca =  251 , M_lda =  5  --->  Accuracy = 43.27%\n",
      "M_pca =  251 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  251 , M_lda =  7  --->  Accuracy = 60.58%\n",
      "M_pca =  251 , M_lda =  8  --->  Accuracy = 68.27%\n",
      "M_pca =  251 , M_lda =  9  --->  Accuracy = 69.23%\n",
      "M_pca =  251 , M_lda =  10  --->  Accuracy = 68.27%\n",
      "M_pca =  251 , M_lda =  11  --->  Accuracy = 69.23%\n",
      "M_pca =  251 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  251 , M_lda =  13  --->  Accuracy = 75.00%\n",
      "M_pca =  251 , M_lda =  14  --->  Accuracy = 75.96%\n",
      "M_pca =  251 , M_lda =  15  --->  Accuracy = 75.00%\n",
      "M_pca =  251 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  251 , M_lda =  17  --->  Accuracy = 76.92%\n",
      "M_pca =  251 , M_lda =  18  --->  Accuracy = 79.81%\n",
      "M_pca =  251 , M_lda =  19  --->  Accuracy = 78.85%\n",
      "M_pca =  251 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  251 , M_lda =  21  --->  Accuracy = 79.81%\n",
      "M_pca =  251 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  251 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  251 , M_lda =  24  --->  Accuracy = 81.73%\n",
      "M_pca =  251 , M_lda =  25  --->  Accuracy = 80.77%\n",
      "M_pca =  251 , M_lda =  26  --->  Accuracy = 81.73%\n",
      "M_pca =  251 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  251 , M_lda =  28  --->  Accuracy = 83.65%\n",
      "M_pca =  251 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  251 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  251 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  251 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  251 , M_lda =  33  --->  Accuracy = 83.65%\n",
      "M_pca =  251 , M_lda =  34  --->  Accuracy = 82.69%\n",
      "M_pca =  251 , M_lda =  35  --->  Accuracy = 82.69%\n",
      "M_pca =  251 , M_lda =  36  --->  Accuracy = 82.69%\n",
      "M_pca =  251 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  251 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  251 , M_lda =  39  --->  Accuracy = 82.69%\n",
      "M_pca =  251 , M_lda =  40  --->  Accuracy = 83.65%\n",
      "M_pca =  251 , M_lda =  41  --->  Accuracy = 84.62%\n",
      "M_pca =  251 , M_lda =  42  --->  Accuracy = 84.62%\n",
      "M_pca =  251 , M_lda =  43  --->  Accuracy = 85.58%\n",
      "M_pca =  251 , M_lda =  44  --->  Accuracy = 86.54%\n",
      "M_pca =  251 , M_lda =  45  --->  Accuracy = 86.54%\n",
      "M_pca =  251 , M_lda =  46  --->  Accuracy = 86.54%\n",
      "M_pca =  251 , M_lda =  47  --->  Accuracy = 86.54%\n",
      "M_pca =  251 , M_lda =  48  --->  Accuracy = 86.54%\n",
      "M_pca =  251 , M_lda =  49  --->  Accuracy = 86.54%\n",
      "M_pca =  251 , M_lda =  50  --->  Accuracy = 86.54%\n",
      "M_pca =  251 , M_lda =  51  --->  Accuracy = 86.54%\n",
      "M_pca =  252 , M_lda =  1  --->  Accuracy = 11.54%\n",
      "M_pca =  252 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  252 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  252 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  252 , M_lda =  5  --->  Accuracy = 42.31%\n",
      "M_pca =  252 , M_lda =  6  --->  Accuracy = 56.73%\n",
      "M_pca =  252 , M_lda =  7  --->  Accuracy = 59.62%\n",
      "M_pca =  252 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  252 , M_lda =  9  --->  Accuracy = 69.23%\n",
      "M_pca =  252 , M_lda =  10  --->  Accuracy = 70.19%\n",
      "M_pca =  252 , M_lda =  11  --->  Accuracy = 69.23%\n",
      "M_pca =  252 , M_lda =  12  --->  Accuracy = 70.19%\n",
      "M_pca =  252 , M_lda =  13  --->  Accuracy = 75.00%\n",
      "M_pca =  252 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  252 , M_lda =  15  --->  Accuracy = 79.81%\n",
      "M_pca =  252 , M_lda =  16  --->  Accuracy = 79.81%\n",
      "M_pca =  252 , M_lda =  17  --->  Accuracy = 78.85%\n",
      "M_pca =  252 , M_lda =  18  --->  Accuracy = 79.81%\n",
      "M_pca =  252 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  252 , M_lda =  20  --->  Accuracy = 79.81%\n",
      "M_pca =  252 , M_lda =  21  --->  Accuracy = 80.77%\n",
      "M_pca =  252 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  252 , M_lda =  23  --->  Accuracy = 80.77%\n",
      "M_pca =  252 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  252 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  252 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  252 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  252 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  252 , M_lda =  29  --->  Accuracy = 81.73%\n",
      "M_pca =  252 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  252 , M_lda =  31  --->  Accuracy = 81.73%\n",
      "M_pca =  252 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  252 , M_lda =  33  --->  Accuracy = 83.65%\n",
      "M_pca =  252 , M_lda =  34  --->  Accuracy = 82.69%\n",
      "M_pca =  252 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  252 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  252 , M_lda =  37  --->  Accuracy = 84.62%\n",
      "M_pca =  252 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  252 , M_lda =  39  --->  Accuracy = 84.62%\n",
      "M_pca =  252 , M_lda =  40  --->  Accuracy = 85.58%\n",
      "M_pca =  252 , M_lda =  41  --->  Accuracy = 85.58%\n",
      "M_pca =  252 , M_lda =  42  --->  Accuracy = 86.54%\n",
      "M_pca =  252 , M_lda =  43  --->  Accuracy = 85.58%\n",
      "M_pca =  252 , M_lda =  44  --->  Accuracy = 85.58%\n",
      "M_pca =  252 , M_lda =  45  --->  Accuracy = 86.54%\n",
      "M_pca =  252 , M_lda =  46  --->  Accuracy = 86.54%\n",
      "M_pca =  252 , M_lda =  47  --->  Accuracy = 86.54%\n",
      "M_pca =  252 , M_lda =  48  --->  Accuracy = 86.54%\n",
      "M_pca =  252 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  252 , M_lda =  50  --->  Accuracy = 87.50%\n",
      "M_pca =  252 , M_lda =  51  --->  Accuracy = 87.50%\n",
      "M_pca =  253 , M_lda =  1  --->  Accuracy = 16.35%\n",
      "M_pca =  253 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  253 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  253 , M_lda =  4  --->  Accuracy = 33.65%\n",
      "M_pca =  253 , M_lda =  5  --->  Accuracy = 40.38%\n",
      "M_pca =  253 , M_lda =  6  --->  Accuracy = 55.77%\n",
      "M_pca =  253 , M_lda =  7  --->  Accuracy = 59.62%\n",
      "M_pca =  253 , M_lda =  8  --->  Accuracy = 67.31%\n",
      "M_pca =  253 , M_lda =  9  --->  Accuracy = 69.23%\n",
      "M_pca =  253 , M_lda =  10  --->  Accuracy = 69.23%\n",
      "M_pca =  253 , M_lda =  11  --->  Accuracy = 68.27%\n",
      "M_pca =  253 , M_lda =  12  --->  Accuracy = 68.27%\n",
      "M_pca =  253 , M_lda =  13  --->  Accuracy = 75.00%\n",
      "M_pca =  253 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  253 , M_lda =  15  --->  Accuracy = 80.77%\n",
      "M_pca =  253 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  253 , M_lda =  17  --->  Accuracy = 77.88%\n",
      "M_pca =  253 , M_lda =  18  --->  Accuracy = 79.81%\n",
      "M_pca =  253 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  253 , M_lda =  20  --->  Accuracy = 79.81%\n",
      "M_pca =  253 , M_lda =  21  --->  Accuracy = 79.81%\n",
      "M_pca =  253 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  253 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  253 , M_lda =  24  --->  Accuracy = 80.77%\n",
      "M_pca =  253 , M_lda =  25  --->  Accuracy = 82.69%\n",
      "M_pca =  253 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  253 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  253 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  253 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  253 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  253 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  253 , M_lda =  32  --->  Accuracy = 83.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  253 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  253 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  253 , M_lda =  35  --->  Accuracy = 83.65%\n",
      "M_pca =  253 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  253 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  253 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  253 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  253 , M_lda =  40  --->  Accuracy = 85.58%\n",
      "M_pca =  253 , M_lda =  41  --->  Accuracy = 86.54%\n",
      "M_pca =  253 , M_lda =  42  --->  Accuracy = 86.54%\n",
      "M_pca =  253 , M_lda =  43  --->  Accuracy = 86.54%\n",
      "M_pca =  253 , M_lda =  44  --->  Accuracy = 85.58%\n",
      "M_pca =  253 , M_lda =  45  --->  Accuracy = 86.54%\n",
      "M_pca =  253 , M_lda =  46  --->  Accuracy = 86.54%\n",
      "M_pca =  253 , M_lda =  47  --->  Accuracy = 86.54%\n",
      "M_pca =  253 , M_lda =  48  --->  Accuracy = 86.54%\n",
      "M_pca =  253 , M_lda =  49  --->  Accuracy = 86.54%\n",
      "M_pca =  253 , M_lda =  50  --->  Accuracy = 86.54%\n",
      "M_pca =  253 , M_lda =  51  --->  Accuracy = 86.54%\n",
      "M_pca =  254 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  254 , M_lda =  2  --->  Accuracy = 22.12%\n",
      "M_pca =  254 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  254 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  254 , M_lda =  5  --->  Accuracy = 42.31%\n",
      "M_pca =  254 , M_lda =  6  --->  Accuracy = 50.96%\n",
      "M_pca =  254 , M_lda =  7  --->  Accuracy = 59.62%\n",
      "M_pca =  254 , M_lda =  8  --->  Accuracy = 65.38%\n",
      "M_pca =  254 , M_lda =  9  --->  Accuracy = 67.31%\n",
      "M_pca =  254 , M_lda =  10  --->  Accuracy = 67.31%\n",
      "M_pca =  254 , M_lda =  11  --->  Accuracy = 68.27%\n",
      "M_pca =  254 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  254 , M_lda =  13  --->  Accuracy = 76.92%\n",
      "M_pca =  254 , M_lda =  14  --->  Accuracy = 76.92%\n",
      "M_pca =  254 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  254 , M_lda =  16  --->  Accuracy = 79.81%\n",
      "M_pca =  254 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  254 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  254 , M_lda =  19  --->  Accuracy = 78.85%\n",
      "M_pca =  254 , M_lda =  20  --->  Accuracy = 79.81%\n",
      "M_pca =  254 , M_lda =  21  --->  Accuracy = 81.73%\n",
      "M_pca =  254 , M_lda =  22  --->  Accuracy = 82.69%\n",
      "M_pca =  254 , M_lda =  23  --->  Accuracy = 82.69%\n",
      "M_pca =  254 , M_lda =  24  --->  Accuracy = 82.69%\n",
      "M_pca =  254 , M_lda =  25  --->  Accuracy = 82.69%\n",
      "M_pca =  254 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  254 , M_lda =  27  --->  Accuracy = 83.65%\n",
      "M_pca =  254 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  254 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  254 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  254 , M_lda =  31  --->  Accuracy = 81.73%\n",
      "M_pca =  254 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  254 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  254 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  254 , M_lda =  35  --->  Accuracy = 82.69%\n",
      "M_pca =  254 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  254 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  254 , M_lda =  38  --->  Accuracy = 86.54%\n",
      "M_pca =  254 , M_lda =  39  --->  Accuracy = 86.54%\n",
      "M_pca =  254 , M_lda =  40  --->  Accuracy = 85.58%\n",
      "M_pca =  254 , M_lda =  41  --->  Accuracy = 86.54%\n",
      "M_pca =  254 , M_lda =  42  --->  Accuracy = 86.54%\n",
      "M_pca =  254 , M_lda =  43  --->  Accuracy = 86.54%\n",
      "M_pca =  254 , M_lda =  44  --->  Accuracy = 85.58%\n",
      "M_pca =  254 , M_lda =  45  --->  Accuracy = 85.58%\n",
      "M_pca =  254 , M_lda =  46  --->  Accuracy = 85.58%\n",
      "M_pca =  254 , M_lda =  47  --->  Accuracy = 86.54%\n",
      "M_pca =  254 , M_lda =  48  --->  Accuracy = 86.54%\n",
      "M_pca =  254 , M_lda =  49  --->  Accuracy = 86.54%\n",
      "M_pca =  254 , M_lda =  50  --->  Accuracy = 86.54%\n",
      "M_pca =  254 , M_lda =  51  --->  Accuracy = 86.54%\n",
      "M_pca =  255 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  255 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  255 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  255 , M_lda =  4  --->  Accuracy = 37.50%\n",
      "M_pca =  255 , M_lda =  5  --->  Accuracy = 42.31%\n",
      "M_pca =  255 , M_lda =  6  --->  Accuracy = 49.04%\n",
      "M_pca =  255 , M_lda =  7  --->  Accuracy = 58.65%\n",
      "M_pca =  255 , M_lda =  8  --->  Accuracy = 61.54%\n",
      "M_pca =  255 , M_lda =  9  --->  Accuracy = 67.31%\n",
      "M_pca =  255 , M_lda =  10  --->  Accuracy = 68.27%\n",
      "M_pca =  255 , M_lda =  11  --->  Accuracy = 69.23%\n",
      "M_pca =  255 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  255 , M_lda =  13  --->  Accuracy = 74.04%\n",
      "M_pca =  255 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  255 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  255 , M_lda =  16  --->  Accuracy = 79.81%\n",
      "M_pca =  255 , M_lda =  17  --->  Accuracy = 78.85%\n",
      "M_pca =  255 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  255 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  255 , M_lda =  20  --->  Accuracy = 80.77%\n",
      "M_pca =  255 , M_lda =  21  --->  Accuracy = 81.73%\n",
      "M_pca =  255 , M_lda =  22  --->  Accuracy = 81.73%\n",
      "M_pca =  255 , M_lda =  23  --->  Accuracy = 80.77%\n",
      "M_pca =  255 , M_lda =  24  --->  Accuracy = 80.77%\n",
      "M_pca =  255 , M_lda =  25  --->  Accuracy = 82.69%\n",
      "M_pca =  255 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  255 , M_lda =  27  --->  Accuracy = 83.65%\n",
      "M_pca =  255 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  255 , M_lda =  29  --->  Accuracy = 81.73%\n",
      "M_pca =  255 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  255 , M_lda =  31  --->  Accuracy = 83.65%\n",
      "M_pca =  255 , M_lda =  32  --->  Accuracy = 84.62%\n",
      "M_pca =  255 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  255 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  255 , M_lda =  35  --->  Accuracy = 83.65%\n",
      "M_pca =  255 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  255 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  255 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  255 , M_lda =  39  --->  Accuracy = 85.58%\n",
      "M_pca =  255 , M_lda =  40  --->  Accuracy = 85.58%\n",
      "M_pca =  255 , M_lda =  41  --->  Accuracy = 85.58%\n",
      "M_pca =  255 , M_lda =  42  --->  Accuracy = 86.54%\n",
      "M_pca =  255 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  255 , M_lda =  44  --->  Accuracy = 85.58%\n",
      "M_pca =  255 , M_lda =  45  --->  Accuracy = 85.58%\n",
      "M_pca =  255 , M_lda =  46  --->  Accuracy = 85.58%\n",
      "M_pca =  255 , M_lda =  47  --->  Accuracy = 86.54%\n",
      "M_pca =  255 , M_lda =  48  --->  Accuracy = 86.54%\n",
      "M_pca =  255 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  255 , M_lda =  50  --->  Accuracy = 87.50%\n",
      "M_pca =  255 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  256 , M_lda =  1  --->  Accuracy = 10.58%\n",
      "M_pca =  256 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  256 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  256 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  256 , M_lda =  5  --->  Accuracy = 43.27%\n",
      "M_pca =  256 , M_lda =  6  --->  Accuracy = 54.81%\n",
      "M_pca =  256 , M_lda =  7  --->  Accuracy = 58.65%\n",
      "M_pca =  256 , M_lda =  8  --->  Accuracy = 58.65%\n",
      "M_pca =  256 , M_lda =  9  --->  Accuracy = 65.38%\n",
      "M_pca =  256 , M_lda =  10  --->  Accuracy = 67.31%\n",
      "M_pca =  256 , M_lda =  11  --->  Accuracy = 68.27%\n",
      "M_pca =  256 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  256 , M_lda =  13  --->  Accuracy = 75.00%\n",
      "M_pca =  256 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  256 , M_lda =  15  --->  Accuracy = 78.85%\n",
      "M_pca =  256 , M_lda =  16  --->  Accuracy = 79.81%\n",
      "M_pca =  256 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  256 , M_lda =  18  --->  Accuracy = 81.73%\n",
      "M_pca =  256 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  256 , M_lda =  20  --->  Accuracy = 81.73%\n",
      "M_pca =  256 , M_lda =  21  --->  Accuracy = 82.69%\n",
      "M_pca =  256 , M_lda =  22  --->  Accuracy = 81.73%\n",
      "M_pca =  256 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  256 , M_lda =  24  --->  Accuracy = 80.77%\n",
      "M_pca =  256 , M_lda =  25  --->  Accuracy = 82.69%\n",
      "M_pca =  256 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  256 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  256 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  256 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  256 , M_lda =  30  --->  Accuracy = 81.73%\n",
      "M_pca =  256 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  256 , M_lda =  32  --->  Accuracy = 83.65%\n",
      "M_pca =  256 , M_lda =  33  --->  Accuracy = 83.65%\n",
      "M_pca =  256 , M_lda =  34  --->  Accuracy = 83.65%\n",
      "M_pca =  256 , M_lda =  35  --->  Accuracy = 82.69%\n",
      "M_pca =  256 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  256 , M_lda =  37  --->  Accuracy = 82.69%\n",
      "M_pca =  256 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  256 , M_lda =  39  --->  Accuracy = 84.62%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  256 , M_lda =  40  --->  Accuracy = 84.62%\n",
      "M_pca =  256 , M_lda =  41  --->  Accuracy = 86.54%\n",
      "M_pca =  256 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  256 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  256 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  256 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  256 , M_lda =  46  --->  Accuracy = 86.54%\n",
      "M_pca =  256 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  256 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  256 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  256 , M_lda =  50  --->  Accuracy = 88.46%\n",
      "M_pca =  256 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  257 , M_lda =  1  --->  Accuracy = 10.58%\n",
      "M_pca =  257 , M_lda =  2  --->  Accuracy = 22.12%\n",
      "M_pca =  257 , M_lda =  3  --->  Accuracy = 27.88%\n",
      "M_pca =  257 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  257 , M_lda =  5  --->  Accuracy = 43.27%\n",
      "M_pca =  257 , M_lda =  6  --->  Accuracy = 50.00%\n",
      "M_pca =  257 , M_lda =  7  --->  Accuracy = 57.69%\n",
      "M_pca =  257 , M_lda =  8  --->  Accuracy = 58.65%\n",
      "M_pca =  257 , M_lda =  9  --->  Accuracy = 65.38%\n",
      "M_pca =  257 , M_lda =  10  --->  Accuracy = 67.31%\n",
      "M_pca =  257 , M_lda =  11  --->  Accuracy = 67.31%\n",
      "M_pca =  257 , M_lda =  12  --->  Accuracy = 70.19%\n",
      "M_pca =  257 , M_lda =  13  --->  Accuracy = 73.08%\n",
      "M_pca =  257 , M_lda =  14  --->  Accuracy = 74.04%\n",
      "M_pca =  257 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  257 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  257 , M_lda =  17  --->  Accuracy = 80.77%\n",
      "M_pca =  257 , M_lda =  18  --->  Accuracy = 80.77%\n",
      "M_pca =  257 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  257 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  257 , M_lda =  21  --->  Accuracy = 82.69%\n",
      "M_pca =  257 , M_lda =  22  --->  Accuracy = 82.69%\n",
      "M_pca =  257 , M_lda =  23  --->  Accuracy = 83.65%\n",
      "M_pca =  257 , M_lda =  24  --->  Accuracy = 81.73%\n",
      "M_pca =  257 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  257 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  257 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  257 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  257 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  257 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  257 , M_lda =  31  --->  Accuracy = 83.65%\n",
      "M_pca =  257 , M_lda =  32  --->  Accuracy = 83.65%\n",
      "M_pca =  257 , M_lda =  33  --->  Accuracy = 83.65%\n",
      "M_pca =  257 , M_lda =  34  --->  Accuracy = 83.65%\n",
      "M_pca =  257 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  257 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  257 , M_lda =  37  --->  Accuracy = 84.62%\n",
      "M_pca =  257 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  257 , M_lda =  39  --->  Accuracy = 85.58%\n",
      "M_pca =  257 , M_lda =  40  --->  Accuracy = 85.58%\n",
      "M_pca =  257 , M_lda =  41  --->  Accuracy = 86.54%\n",
      "M_pca =  257 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  257 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  257 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  257 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  257 , M_lda =  46  --->  Accuracy = 86.54%\n",
      "M_pca =  257 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  257 , M_lda =  48  --->  Accuracy = 86.54%\n",
      "M_pca =  257 , M_lda =  49  --->  Accuracy = 88.46%\n",
      "M_pca =  257 , M_lda =  50  --->  Accuracy = 88.46%\n",
      "M_pca =  257 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  258 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  258 , M_lda =  2  --->  Accuracy = 22.12%\n",
      "M_pca =  258 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  258 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  258 , M_lda =  5  --->  Accuracy = 42.31%\n",
      "M_pca =  258 , M_lda =  6  --->  Accuracy = 50.00%\n",
      "M_pca =  258 , M_lda =  7  --->  Accuracy = 56.73%\n",
      "M_pca =  258 , M_lda =  8  --->  Accuracy = 62.50%\n",
      "M_pca =  258 , M_lda =  9  --->  Accuracy = 65.38%\n",
      "M_pca =  258 , M_lda =  10  --->  Accuracy = 66.35%\n",
      "M_pca =  258 , M_lda =  11  --->  Accuracy = 67.31%\n",
      "M_pca =  258 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  258 , M_lda =  13  --->  Accuracy = 70.19%\n",
      "M_pca =  258 , M_lda =  14  --->  Accuracy = 74.04%\n",
      "M_pca =  258 , M_lda =  15  --->  Accuracy = 76.92%\n",
      "M_pca =  258 , M_lda =  16  --->  Accuracy = 79.81%\n",
      "M_pca =  258 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  258 , M_lda =  18  --->  Accuracy = 78.85%\n",
      "M_pca =  258 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  258 , M_lda =  20  --->  Accuracy = 81.73%\n",
      "M_pca =  258 , M_lda =  21  --->  Accuracy = 82.69%\n",
      "M_pca =  258 , M_lda =  22  --->  Accuracy = 82.69%\n",
      "M_pca =  258 , M_lda =  23  --->  Accuracy = 83.65%\n",
      "M_pca =  258 , M_lda =  24  --->  Accuracy = 80.77%\n",
      "M_pca =  258 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  258 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  258 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  258 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  258 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  258 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  258 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  258 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  258 , M_lda =  33  --->  Accuracy = 83.65%\n",
      "M_pca =  258 , M_lda =  34  --->  Accuracy = 83.65%\n",
      "M_pca =  258 , M_lda =  35  --->  Accuracy = 82.69%\n",
      "M_pca =  258 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  258 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  258 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  258 , M_lda =  39  --->  Accuracy = 85.58%\n",
      "M_pca =  258 , M_lda =  40  --->  Accuracy = 85.58%\n",
      "M_pca =  258 , M_lda =  41  --->  Accuracy = 86.54%\n",
      "M_pca =  258 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  258 , M_lda =  43  --->  Accuracy = 88.46%\n",
      "M_pca =  258 , M_lda =  44  --->  Accuracy = 88.46%\n",
      "M_pca =  258 , M_lda =  45  --->  Accuracy = 86.54%\n",
      "M_pca =  258 , M_lda =  46  --->  Accuracy = 86.54%\n",
      "M_pca =  258 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  258 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  258 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  258 , M_lda =  50  --->  Accuracy = 87.50%\n",
      "M_pca =  258 , M_lda =  51  --->  Accuracy = 88.46%\n",
      "M_pca =  259 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  259 , M_lda =  2  --->  Accuracy = 23.08%\n",
      "M_pca =  259 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  259 , M_lda =  4  --->  Accuracy = 34.62%\n",
      "M_pca =  259 , M_lda =  5  --->  Accuracy = 44.23%\n",
      "M_pca =  259 , M_lda =  6  --->  Accuracy = 50.00%\n",
      "M_pca =  259 , M_lda =  7  --->  Accuracy = 56.73%\n",
      "M_pca =  259 , M_lda =  8  --->  Accuracy = 63.46%\n",
      "M_pca =  259 , M_lda =  9  --->  Accuracy = 64.42%\n",
      "M_pca =  259 , M_lda =  10  --->  Accuracy = 64.42%\n",
      "M_pca =  259 , M_lda =  11  --->  Accuracy = 68.27%\n",
      "M_pca =  259 , M_lda =  12  --->  Accuracy = 71.15%\n",
      "M_pca =  259 , M_lda =  13  --->  Accuracy = 69.23%\n",
      "M_pca =  259 , M_lda =  14  --->  Accuracy = 75.00%\n",
      "M_pca =  259 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  259 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  259 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  259 , M_lda =  18  --->  Accuracy = 78.85%\n",
      "M_pca =  259 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  259 , M_lda =  20  --->  Accuracy = 81.73%\n",
      "M_pca =  259 , M_lda =  21  --->  Accuracy = 81.73%\n",
      "M_pca =  259 , M_lda =  22  --->  Accuracy = 81.73%\n",
      "M_pca =  259 , M_lda =  23  --->  Accuracy = 80.77%\n",
      "M_pca =  259 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  259 , M_lda =  25  --->  Accuracy = 80.77%\n",
      "M_pca =  259 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  259 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  259 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  259 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  259 , M_lda =  30  --->  Accuracy = 83.65%\n",
      "M_pca =  259 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  259 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  259 , M_lda =  33  --->  Accuracy = 83.65%\n",
      "M_pca =  259 , M_lda =  34  --->  Accuracy = 83.65%\n",
      "M_pca =  259 , M_lda =  35  --->  Accuracy = 83.65%\n",
      "M_pca =  259 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  259 , M_lda =  37  --->  Accuracy = 83.65%\n",
      "M_pca =  259 , M_lda =  38  --->  Accuracy = 83.65%\n",
      "M_pca =  259 , M_lda =  39  --->  Accuracy = 85.58%\n",
      "M_pca =  259 , M_lda =  40  --->  Accuracy = 85.58%\n",
      "M_pca =  259 , M_lda =  41  --->  Accuracy = 86.54%\n",
      "M_pca =  259 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  259 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  259 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  259 , M_lda =  45  --->  Accuracy = 86.54%\n",
      "M_pca =  259 , M_lda =  46  --->  Accuracy = 86.54%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  259 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  259 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  259 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  259 , M_lda =  50  --->  Accuracy = 87.50%\n",
      "M_pca =  259 , M_lda =  51  --->  Accuracy = 87.50%\n",
      "M_pca =  260 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  260 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  260 , M_lda =  3  --->  Accuracy = 32.69%\n",
      "M_pca =  260 , M_lda =  4  --->  Accuracy = 34.62%\n",
      "M_pca =  260 , M_lda =  5  --->  Accuracy = 43.27%\n",
      "M_pca =  260 , M_lda =  6  --->  Accuracy = 50.96%\n",
      "M_pca =  260 , M_lda =  7  --->  Accuracy = 55.77%\n",
      "M_pca =  260 , M_lda =  8  --->  Accuracy = 64.42%\n",
      "M_pca =  260 , M_lda =  9  --->  Accuracy = 64.42%\n",
      "M_pca =  260 , M_lda =  10  --->  Accuracy = 64.42%\n",
      "M_pca =  260 , M_lda =  11  --->  Accuracy = 66.35%\n",
      "M_pca =  260 , M_lda =  12  --->  Accuracy = 65.38%\n",
      "M_pca =  260 , M_lda =  13  --->  Accuracy = 72.12%\n",
      "M_pca =  260 , M_lda =  14  --->  Accuracy = 76.92%\n",
      "M_pca =  260 , M_lda =  15  --->  Accuracy = 75.96%\n",
      "M_pca =  260 , M_lda =  16  --->  Accuracy = 76.92%\n",
      "M_pca =  260 , M_lda =  17  --->  Accuracy = 79.81%\n",
      "M_pca =  260 , M_lda =  18  --->  Accuracy = 79.81%\n",
      "M_pca =  260 , M_lda =  19  --->  Accuracy = 81.73%\n",
      "M_pca =  260 , M_lda =  20  --->  Accuracy = 82.69%\n",
      "M_pca =  260 , M_lda =  21  --->  Accuracy = 82.69%\n",
      "M_pca =  260 , M_lda =  22  --->  Accuracy = 82.69%\n",
      "M_pca =  260 , M_lda =  23  --->  Accuracy = 81.73%\n",
      "M_pca =  260 , M_lda =  24  --->  Accuracy = 80.77%\n",
      "M_pca =  260 , M_lda =  25  --->  Accuracy = 82.69%\n",
      "M_pca =  260 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  260 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  260 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  260 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  260 , M_lda =  30  --->  Accuracy = 84.62%\n",
      "M_pca =  260 , M_lda =  31  --->  Accuracy = 83.65%\n",
      "M_pca =  260 , M_lda =  32  --->  Accuracy = 83.65%\n",
      "M_pca =  260 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  260 , M_lda =  34  --->  Accuracy = 85.58%\n",
      "M_pca =  260 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  260 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  260 , M_lda =  37  --->  Accuracy = 86.54%\n",
      "M_pca =  260 , M_lda =  38  --->  Accuracy = 85.58%\n",
      "M_pca =  260 , M_lda =  39  --->  Accuracy = 85.58%\n",
      "M_pca =  260 , M_lda =  40  --->  Accuracy = 85.58%\n",
      "M_pca =  260 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  260 , M_lda =  42  --->  Accuracy = 88.46%\n",
      "M_pca =  260 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  260 , M_lda =  44  --->  Accuracy = 86.54%\n",
      "M_pca =  260 , M_lda =  45  --->  Accuracy = 86.54%\n",
      "M_pca =  260 , M_lda =  46  --->  Accuracy = 86.54%\n",
      "M_pca =  260 , M_lda =  47  --->  Accuracy = 86.54%\n",
      "M_pca =  260 , M_lda =  48  --->  Accuracy = 86.54%\n",
      "M_pca =  260 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  260 , M_lda =  50  --->  Accuracy = 87.50%\n",
      "M_pca =  260 , M_lda =  51  --->  Accuracy = 87.50%\n",
      "M_pca =  261 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  261 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  261 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  261 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  261 , M_lda =  5  --->  Accuracy = 44.23%\n",
      "M_pca =  261 , M_lda =  6  --->  Accuracy = 48.08%\n",
      "M_pca =  261 , M_lda =  7  --->  Accuracy = 55.77%\n",
      "M_pca =  261 , M_lda =  8  --->  Accuracy = 63.46%\n",
      "M_pca =  261 , M_lda =  9  --->  Accuracy = 62.50%\n",
      "M_pca =  261 , M_lda =  10  --->  Accuracy = 67.31%\n",
      "M_pca =  261 , M_lda =  11  --->  Accuracy = 68.27%\n",
      "M_pca =  261 , M_lda =  12  --->  Accuracy = 67.31%\n",
      "M_pca =  261 , M_lda =  13  --->  Accuracy = 74.04%\n",
      "M_pca =  261 , M_lda =  14  --->  Accuracy = 76.92%\n",
      "M_pca =  261 , M_lda =  15  --->  Accuracy = 76.92%\n",
      "M_pca =  261 , M_lda =  16  --->  Accuracy = 77.88%\n",
      "M_pca =  261 , M_lda =  17  --->  Accuracy = 77.88%\n",
      "M_pca =  261 , M_lda =  18  --->  Accuracy = 79.81%\n",
      "M_pca =  261 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  261 , M_lda =  20  --->  Accuracy = 81.73%\n",
      "M_pca =  261 , M_lda =  21  --->  Accuracy = 80.77%\n",
      "M_pca =  261 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  261 , M_lda =  23  --->  Accuracy = 80.77%\n",
      "M_pca =  261 , M_lda =  24  --->  Accuracy = 78.85%\n",
      "M_pca =  261 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  261 , M_lda =  26  --->  Accuracy = 79.81%\n",
      "M_pca =  261 , M_lda =  27  --->  Accuracy = 80.77%\n",
      "M_pca =  261 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  261 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  261 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  261 , M_lda =  31  --->  Accuracy = 81.73%\n",
      "M_pca =  261 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  261 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  261 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  261 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  261 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  261 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  261 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  261 , M_lda =  39  --->  Accuracy = 83.65%\n",
      "M_pca =  261 , M_lda =  40  --->  Accuracy = 83.65%\n",
      "M_pca =  261 , M_lda =  41  --->  Accuracy = 87.50%\n",
      "M_pca =  261 , M_lda =  42  --->  Accuracy = 87.50%\n",
      "M_pca =  261 , M_lda =  43  --->  Accuracy = 87.50%\n",
      "M_pca =  261 , M_lda =  44  --->  Accuracy = 87.50%\n",
      "M_pca =  261 , M_lda =  45  --->  Accuracy = 87.50%\n",
      "M_pca =  261 , M_lda =  46  --->  Accuracy = 87.50%\n",
      "M_pca =  261 , M_lda =  47  --->  Accuracy = 86.54%\n",
      "M_pca =  261 , M_lda =  48  --->  Accuracy = 86.54%\n",
      "M_pca =  261 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  261 , M_lda =  50  --->  Accuracy = 87.50%\n",
      "M_pca =  261 , M_lda =  51  --->  Accuracy = 87.50%\n",
      "M_pca =  262 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  262 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  262 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  262 , M_lda =  4  --->  Accuracy = 33.65%\n",
      "M_pca =  262 , M_lda =  5  --->  Accuracy = 42.31%\n",
      "M_pca =  262 , M_lda =  6  --->  Accuracy = 49.04%\n",
      "M_pca =  262 , M_lda =  7  --->  Accuracy = 55.77%\n",
      "M_pca =  262 , M_lda =  8  --->  Accuracy = 60.58%\n",
      "M_pca =  262 , M_lda =  9  --->  Accuracy = 62.50%\n",
      "M_pca =  262 , M_lda =  10  --->  Accuracy = 66.35%\n",
      "M_pca =  262 , M_lda =  11  --->  Accuracy = 69.23%\n",
      "M_pca =  262 , M_lda =  12  --->  Accuracy = 67.31%\n",
      "M_pca =  262 , M_lda =  13  --->  Accuracy = 74.04%\n",
      "M_pca =  262 , M_lda =  14  --->  Accuracy = 76.92%\n",
      "M_pca =  262 , M_lda =  15  --->  Accuracy = 77.88%\n",
      "M_pca =  262 , M_lda =  16  --->  Accuracy = 77.88%\n",
      "M_pca =  262 , M_lda =  17  --->  Accuracy = 78.85%\n",
      "M_pca =  262 , M_lda =  18  --->  Accuracy = 79.81%\n",
      "M_pca =  262 , M_lda =  19  --->  Accuracy = 80.77%\n",
      "M_pca =  262 , M_lda =  20  --->  Accuracy = 79.81%\n",
      "M_pca =  262 , M_lda =  21  --->  Accuracy = 80.77%\n",
      "M_pca =  262 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  262 , M_lda =  23  --->  Accuracy = 80.77%\n",
      "M_pca =  262 , M_lda =  24  --->  Accuracy = 78.85%\n",
      "M_pca =  262 , M_lda =  25  --->  Accuracy = 80.77%\n",
      "M_pca =  262 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  262 , M_lda =  27  --->  Accuracy = 80.77%\n",
      "M_pca =  262 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  262 , M_lda =  29  --->  Accuracy = 81.73%\n",
      "M_pca =  262 , M_lda =  30  --->  Accuracy = 81.73%\n",
      "M_pca =  262 , M_lda =  31  --->  Accuracy = 81.73%\n",
      "M_pca =  262 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  262 , M_lda =  33  --->  Accuracy = 85.58%\n",
      "M_pca =  262 , M_lda =  34  --->  Accuracy = 86.54%\n",
      "M_pca =  262 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  262 , M_lda =  36  --->  Accuracy = 85.58%\n",
      "M_pca =  262 , M_lda =  37  --->  Accuracy = 85.58%\n",
      "M_pca =  262 , M_lda =  38  --->  Accuracy = 84.62%\n",
      "M_pca =  262 , M_lda =  39  --->  Accuracy = 83.65%\n",
      "M_pca =  262 , M_lda =  40  --->  Accuracy = 83.65%\n",
      "M_pca =  262 , M_lda =  41  --->  Accuracy = 85.58%\n",
      "M_pca =  262 , M_lda =  42  --->  Accuracy = 85.58%\n",
      "M_pca =  262 , M_lda =  43  --->  Accuracy = 85.58%\n",
      "M_pca =  262 , M_lda =  44  --->  Accuracy = 86.54%\n",
      "M_pca =  262 , M_lda =  45  --->  Accuracy = 86.54%\n",
      "M_pca =  262 , M_lda =  46  --->  Accuracy = 86.54%\n",
      "M_pca =  262 , M_lda =  47  --->  Accuracy = 87.50%\n",
      "M_pca =  262 , M_lda =  48  --->  Accuracy = 87.50%\n",
      "M_pca =  262 , M_lda =  49  --->  Accuracy = 87.50%\n",
      "M_pca =  262 , M_lda =  50  --->  Accuracy = 87.50%\n",
      "M_pca =  262 , M_lda =  51  --->  Accuracy = 87.50%\n",
      "M_pca =  263 , M_lda =  1  --->  Accuracy = 9.62%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  263 , M_lda =  2  --->  Accuracy = 21.15%\n",
      "M_pca =  263 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  263 , M_lda =  4  --->  Accuracy = 34.62%\n",
      "M_pca =  263 , M_lda =  5  --->  Accuracy = 40.38%\n",
      "M_pca =  263 , M_lda =  6  --->  Accuracy = 46.15%\n",
      "M_pca =  263 , M_lda =  7  --->  Accuracy = 54.81%\n",
      "M_pca =  263 , M_lda =  8  --->  Accuracy = 58.65%\n",
      "M_pca =  263 , M_lda =  9  --->  Accuracy = 65.38%\n",
      "M_pca =  263 , M_lda =  10  --->  Accuracy = 66.35%\n",
      "M_pca =  263 , M_lda =  11  --->  Accuracy = 69.23%\n",
      "M_pca =  263 , M_lda =  12  --->  Accuracy = 65.38%\n",
      "M_pca =  263 , M_lda =  13  --->  Accuracy = 71.15%\n",
      "M_pca =  263 , M_lda =  14  --->  Accuracy = 74.04%\n",
      "M_pca =  263 , M_lda =  15  --->  Accuracy = 75.96%\n",
      "M_pca =  263 , M_lda =  16  --->  Accuracy = 76.92%\n",
      "M_pca =  263 , M_lda =  17  --->  Accuracy = 78.85%\n",
      "M_pca =  263 , M_lda =  18  --->  Accuracy = 79.81%\n",
      "M_pca =  263 , M_lda =  19  --->  Accuracy = 79.81%\n",
      "M_pca =  263 , M_lda =  20  --->  Accuracy = 79.81%\n",
      "M_pca =  263 , M_lda =  21  --->  Accuracy = 79.81%\n",
      "M_pca =  263 , M_lda =  22  --->  Accuracy = 78.85%\n",
      "M_pca =  263 , M_lda =  23  --->  Accuracy = 78.85%\n",
      "M_pca =  263 , M_lda =  24  --->  Accuracy = 78.85%\n",
      "M_pca =  263 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  263 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  263 , M_lda =  27  --->  Accuracy = 80.77%\n",
      "M_pca =  263 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  263 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  263 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  263 , M_lda =  31  --->  Accuracy = 81.73%\n",
      "M_pca =  263 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  263 , M_lda =  33  --->  Accuracy = 84.62%\n",
      "M_pca =  263 , M_lda =  34  --->  Accuracy = 82.69%\n",
      "M_pca =  263 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  263 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  263 , M_lda =  37  --->  Accuracy = 84.62%\n",
      "M_pca =  263 , M_lda =  38  --->  Accuracy = 82.69%\n",
      "M_pca =  263 , M_lda =  39  --->  Accuracy = 82.69%\n",
      "M_pca =  263 , M_lda =  40  --->  Accuracy = 82.69%\n",
      "M_pca =  263 , M_lda =  41  --->  Accuracy = 85.58%\n",
      "M_pca =  263 , M_lda =  42  --->  Accuracy = 84.62%\n",
      "M_pca =  263 , M_lda =  43  --->  Accuracy = 84.62%\n",
      "M_pca =  263 , M_lda =  44  --->  Accuracy = 84.62%\n",
      "M_pca =  263 , M_lda =  45  --->  Accuracy = 84.62%\n",
      "M_pca =  263 , M_lda =  46  --->  Accuracy = 84.62%\n",
      "M_pca =  263 , M_lda =  47  --->  Accuracy = 85.58%\n",
      "M_pca =  263 , M_lda =  48  --->  Accuracy = 86.54%\n",
      "M_pca =  263 , M_lda =  49  --->  Accuracy = 86.54%\n",
      "M_pca =  263 , M_lda =  50  --->  Accuracy = 86.54%\n",
      "M_pca =  263 , M_lda =  51  --->  Accuracy = 86.54%\n",
      "M_pca =  264 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  264 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  264 , M_lda =  3  --->  Accuracy = 25.96%\n",
      "M_pca =  264 , M_lda =  4  --->  Accuracy = 37.50%\n",
      "M_pca =  264 , M_lda =  5  --->  Accuracy = 45.19%\n",
      "M_pca =  264 , M_lda =  6  --->  Accuracy = 51.92%\n",
      "M_pca =  264 , M_lda =  7  --->  Accuracy = 53.85%\n",
      "M_pca =  264 , M_lda =  8  --->  Accuracy = 56.73%\n",
      "M_pca =  264 , M_lda =  9  --->  Accuracy = 60.58%\n",
      "M_pca =  264 , M_lda =  10  --->  Accuracy = 65.38%\n",
      "M_pca =  264 , M_lda =  11  --->  Accuracy = 66.35%\n",
      "M_pca =  264 , M_lda =  12  --->  Accuracy = 64.42%\n",
      "M_pca =  264 , M_lda =  13  --->  Accuracy = 71.15%\n",
      "M_pca =  264 , M_lda =  14  --->  Accuracy = 75.96%\n",
      "M_pca =  264 , M_lda =  15  --->  Accuracy = 75.96%\n",
      "M_pca =  264 , M_lda =  16  --->  Accuracy = 77.88%\n",
      "M_pca =  264 , M_lda =  17  --->  Accuracy = 77.88%\n",
      "M_pca =  264 , M_lda =  18  --->  Accuracy = 76.92%\n",
      "M_pca =  264 , M_lda =  19  --->  Accuracy = 76.92%\n",
      "M_pca =  264 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  264 , M_lda =  21  --->  Accuracy = 78.85%\n",
      "M_pca =  264 , M_lda =  22  --->  Accuracy = 77.88%\n",
      "M_pca =  264 , M_lda =  23  --->  Accuracy = 78.85%\n",
      "M_pca =  264 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  264 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  264 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  264 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  264 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  264 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  264 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  264 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  264 , M_lda =  32  --->  Accuracy = 83.65%\n",
      "M_pca =  264 , M_lda =  33  --->  Accuracy = 83.65%\n",
      "M_pca =  264 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  264 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  264 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  264 , M_lda =  37  --->  Accuracy = 84.62%\n",
      "M_pca =  264 , M_lda =  38  --->  Accuracy = 83.65%\n",
      "M_pca =  264 , M_lda =  39  --->  Accuracy = 83.65%\n",
      "M_pca =  264 , M_lda =  40  --->  Accuracy = 83.65%\n",
      "M_pca =  264 , M_lda =  41  --->  Accuracy = 84.62%\n",
      "M_pca =  264 , M_lda =  42  --->  Accuracy = 84.62%\n",
      "M_pca =  264 , M_lda =  43  --->  Accuracy = 84.62%\n",
      "M_pca =  264 , M_lda =  44  --->  Accuracy = 83.65%\n",
      "M_pca =  264 , M_lda =  45  --->  Accuracy = 83.65%\n",
      "M_pca =  264 , M_lda =  46  --->  Accuracy = 83.65%\n",
      "M_pca =  264 , M_lda =  47  --->  Accuracy = 84.62%\n",
      "M_pca =  264 , M_lda =  48  --->  Accuracy = 84.62%\n",
      "M_pca =  264 , M_lda =  49  --->  Accuracy = 85.58%\n",
      "M_pca =  264 , M_lda =  50  --->  Accuracy = 85.58%\n",
      "M_pca =  264 , M_lda =  51  --->  Accuracy = 85.58%\n",
      "M_pca =  265 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  265 , M_lda =  2  --->  Accuracy = 8.65%\n",
      "M_pca =  265 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  265 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  265 , M_lda =  5  --->  Accuracy = 41.35%\n",
      "M_pca =  265 , M_lda =  6  --->  Accuracy = 54.81%\n",
      "M_pca =  265 , M_lda =  7  --->  Accuracy = 56.73%\n",
      "M_pca =  265 , M_lda =  8  --->  Accuracy = 57.69%\n",
      "M_pca =  265 , M_lda =  9  --->  Accuracy = 63.46%\n",
      "M_pca =  265 , M_lda =  10  --->  Accuracy = 64.42%\n",
      "M_pca =  265 , M_lda =  11  --->  Accuracy = 65.38%\n",
      "M_pca =  265 , M_lda =  12  --->  Accuracy = 64.42%\n",
      "M_pca =  265 , M_lda =  13  --->  Accuracy = 69.23%\n",
      "M_pca =  265 , M_lda =  14  --->  Accuracy = 72.12%\n",
      "M_pca =  265 , M_lda =  15  --->  Accuracy = 75.00%\n",
      "M_pca =  265 , M_lda =  16  --->  Accuracy = 75.00%\n",
      "M_pca =  265 , M_lda =  17  --->  Accuracy = 75.96%\n",
      "M_pca =  265 , M_lda =  18  --->  Accuracy = 76.92%\n",
      "M_pca =  265 , M_lda =  19  --->  Accuracy = 76.92%\n",
      "M_pca =  265 , M_lda =  20  --->  Accuracy = 79.81%\n",
      "M_pca =  265 , M_lda =  21  --->  Accuracy = 79.81%\n",
      "M_pca =  265 , M_lda =  22  --->  Accuracy = 78.85%\n",
      "M_pca =  265 , M_lda =  23  --->  Accuracy = 80.77%\n",
      "M_pca =  265 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  265 , M_lda =  25  --->  Accuracy = 78.85%\n",
      "M_pca =  265 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  265 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  265 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  265 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  265 , M_lda =  30  --->  Accuracy = 82.69%\n",
      "M_pca =  265 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  265 , M_lda =  32  --->  Accuracy = 81.73%\n",
      "M_pca =  265 , M_lda =  33  --->  Accuracy = 81.73%\n",
      "M_pca =  265 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  265 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  265 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  265 , M_lda =  37  --->  Accuracy = 84.62%\n",
      "M_pca =  265 , M_lda =  38  --->  Accuracy = 82.69%\n",
      "M_pca =  265 , M_lda =  39  --->  Accuracy = 82.69%\n",
      "M_pca =  265 , M_lda =  40  --->  Accuracy = 83.65%\n",
      "M_pca =  265 , M_lda =  41  --->  Accuracy = 83.65%\n",
      "M_pca =  265 , M_lda =  42  --->  Accuracy = 83.65%\n",
      "M_pca =  265 , M_lda =  43  --->  Accuracy = 84.62%\n",
      "M_pca =  265 , M_lda =  44  --->  Accuracy = 83.65%\n",
      "M_pca =  265 , M_lda =  45  --->  Accuracy = 83.65%\n",
      "M_pca =  265 , M_lda =  46  --->  Accuracy = 83.65%\n",
      "M_pca =  265 , M_lda =  47  --->  Accuracy = 84.62%\n",
      "M_pca =  265 , M_lda =  48  --->  Accuracy = 84.62%\n",
      "M_pca =  265 , M_lda =  49  --->  Accuracy = 85.58%\n",
      "M_pca =  265 , M_lda =  50  --->  Accuracy = 85.58%\n",
      "M_pca =  265 , M_lda =  51  --->  Accuracy = 85.58%\n",
      "M_pca =  266 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  266 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  266 , M_lda =  3  --->  Accuracy = 27.88%\n",
      "M_pca =  266 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  266 , M_lda =  5  --->  Accuracy = 41.35%\n",
      "M_pca =  266 , M_lda =  6  --->  Accuracy = 51.92%\n",
      "M_pca =  266 , M_lda =  7  --->  Accuracy = 52.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  266 , M_lda =  8  --->  Accuracy = 58.65%\n",
      "M_pca =  266 , M_lda =  9  --->  Accuracy = 61.54%\n",
      "M_pca =  266 , M_lda =  10  --->  Accuracy = 66.35%\n",
      "M_pca =  266 , M_lda =  11  --->  Accuracy = 66.35%\n",
      "M_pca =  266 , M_lda =  12  --->  Accuracy = 69.23%\n",
      "M_pca =  266 , M_lda =  13  --->  Accuracy = 69.23%\n",
      "M_pca =  266 , M_lda =  14  --->  Accuracy = 71.15%\n",
      "M_pca =  266 , M_lda =  15  --->  Accuracy = 75.00%\n",
      "M_pca =  266 , M_lda =  16  --->  Accuracy = 75.00%\n",
      "M_pca =  266 , M_lda =  17  --->  Accuracy = 77.88%\n",
      "M_pca =  266 , M_lda =  18  --->  Accuracy = 76.92%\n",
      "M_pca =  266 , M_lda =  19  --->  Accuracy = 77.88%\n",
      "M_pca =  266 , M_lda =  20  --->  Accuracy = 79.81%\n",
      "M_pca =  266 , M_lda =  21  --->  Accuracy = 80.77%\n",
      "M_pca =  266 , M_lda =  22  --->  Accuracy = 81.73%\n",
      "M_pca =  266 , M_lda =  23  --->  Accuracy = 80.77%\n",
      "M_pca =  266 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  266 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  266 , M_lda =  26  --->  Accuracy = 79.81%\n",
      "M_pca =  266 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  266 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  266 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  266 , M_lda =  30  --->  Accuracy = 81.73%\n",
      "M_pca =  266 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  266 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  266 , M_lda =  33  --->  Accuracy = 83.65%\n",
      "M_pca =  266 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  266 , M_lda =  35  --->  Accuracy = 85.58%\n",
      "M_pca =  266 , M_lda =  36  --->  Accuracy = 84.62%\n",
      "M_pca =  266 , M_lda =  37  --->  Accuracy = 84.62%\n",
      "M_pca =  266 , M_lda =  38  --->  Accuracy = 82.69%\n",
      "M_pca =  266 , M_lda =  39  --->  Accuracy = 84.62%\n",
      "M_pca =  266 , M_lda =  40  --->  Accuracy = 83.65%\n",
      "M_pca =  266 , M_lda =  41  --->  Accuracy = 82.69%\n",
      "M_pca =  266 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  266 , M_lda =  43  --->  Accuracy = 84.62%\n",
      "M_pca =  266 , M_lda =  44  --->  Accuracy = 83.65%\n",
      "M_pca =  266 , M_lda =  45  --->  Accuracy = 83.65%\n",
      "M_pca =  266 , M_lda =  46  --->  Accuracy = 83.65%\n",
      "M_pca =  266 , M_lda =  47  --->  Accuracy = 84.62%\n",
      "M_pca =  266 , M_lda =  48  --->  Accuracy = 84.62%\n",
      "M_pca =  266 , M_lda =  49  --->  Accuracy = 85.58%\n",
      "M_pca =  266 , M_lda =  50  --->  Accuracy = 85.58%\n",
      "M_pca =  266 , M_lda =  51  --->  Accuracy = 85.58%\n",
      "M_pca =  267 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  267 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  267 , M_lda =  3  --->  Accuracy = 25.96%\n",
      "M_pca =  267 , M_lda =  4  --->  Accuracy = 32.69%\n",
      "M_pca =  267 , M_lda =  5  --->  Accuracy = 37.50%\n",
      "M_pca =  267 , M_lda =  6  --->  Accuracy = 52.88%\n",
      "M_pca =  267 , M_lda =  7  --->  Accuracy = 51.92%\n",
      "M_pca =  267 , M_lda =  8  --->  Accuracy = 58.65%\n",
      "M_pca =  267 , M_lda =  9  --->  Accuracy = 62.50%\n",
      "M_pca =  267 , M_lda =  10  --->  Accuracy = 66.35%\n",
      "M_pca =  267 , M_lda =  11  --->  Accuracy = 65.38%\n",
      "M_pca =  267 , M_lda =  12  --->  Accuracy = 67.31%\n",
      "M_pca =  267 , M_lda =  13  --->  Accuracy = 71.15%\n",
      "M_pca =  267 , M_lda =  14  --->  Accuracy = 74.04%\n",
      "M_pca =  267 , M_lda =  15  --->  Accuracy = 75.96%\n",
      "M_pca =  267 , M_lda =  16  --->  Accuracy = 77.88%\n",
      "M_pca =  267 , M_lda =  17  --->  Accuracy = 76.92%\n",
      "M_pca =  267 , M_lda =  18  --->  Accuracy = 77.88%\n",
      "M_pca =  267 , M_lda =  19  --->  Accuracy = 78.85%\n",
      "M_pca =  267 , M_lda =  20  --->  Accuracy = 80.77%\n",
      "M_pca =  267 , M_lda =  21  --->  Accuracy = 80.77%\n",
      "M_pca =  267 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  267 , M_lda =  23  --->  Accuracy = 80.77%\n",
      "M_pca =  267 , M_lda =  24  --->  Accuracy = 80.77%\n",
      "M_pca =  267 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  267 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  267 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  267 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  267 , M_lda =  29  --->  Accuracy = 81.73%\n",
      "M_pca =  267 , M_lda =  30  --->  Accuracy = 81.73%\n",
      "M_pca =  267 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  267 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  267 , M_lda =  33  --->  Accuracy = 83.65%\n",
      "M_pca =  267 , M_lda =  34  --->  Accuracy = 84.62%\n",
      "M_pca =  267 , M_lda =  35  --->  Accuracy = 84.62%\n",
      "M_pca =  267 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  267 , M_lda =  37  --->  Accuracy = 84.62%\n",
      "M_pca =  267 , M_lda =  38  --->  Accuracy = 83.65%\n",
      "M_pca =  267 , M_lda =  39  --->  Accuracy = 84.62%\n",
      "M_pca =  267 , M_lda =  40  --->  Accuracy = 84.62%\n",
      "M_pca =  267 , M_lda =  41  --->  Accuracy = 83.65%\n",
      "M_pca =  267 , M_lda =  42  --->  Accuracy = 84.62%\n",
      "M_pca =  267 , M_lda =  43  --->  Accuracy = 84.62%\n",
      "M_pca =  267 , M_lda =  44  --->  Accuracy = 83.65%\n",
      "M_pca =  267 , M_lda =  45  --->  Accuracy = 83.65%\n",
      "M_pca =  267 , M_lda =  46  --->  Accuracy = 83.65%\n",
      "M_pca =  267 , M_lda =  47  --->  Accuracy = 84.62%\n",
      "M_pca =  267 , M_lda =  48  --->  Accuracy = 85.58%\n",
      "M_pca =  267 , M_lda =  49  --->  Accuracy = 85.58%\n",
      "M_pca =  267 , M_lda =  50  --->  Accuracy = 85.58%\n",
      "M_pca =  267 , M_lda =  51  --->  Accuracy = 85.58%\n",
      "M_pca =  268 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  268 , M_lda =  2  --->  Accuracy = 11.54%\n",
      "M_pca =  268 , M_lda =  3  --->  Accuracy = 23.08%\n",
      "M_pca =  268 , M_lda =  4  --->  Accuracy = 33.65%\n",
      "M_pca =  268 , M_lda =  5  --->  Accuracy = 38.46%\n",
      "M_pca =  268 , M_lda =  6  --->  Accuracy = 48.08%\n",
      "M_pca =  268 , M_lda =  7  --->  Accuracy = 54.81%\n",
      "M_pca =  268 , M_lda =  8  --->  Accuracy = 56.73%\n",
      "M_pca =  268 , M_lda =  9  --->  Accuracy = 62.50%\n",
      "M_pca =  268 , M_lda =  10  --->  Accuracy = 63.46%\n",
      "M_pca =  268 , M_lda =  11  --->  Accuracy = 64.42%\n",
      "M_pca =  268 , M_lda =  12  --->  Accuracy = 69.23%\n",
      "M_pca =  268 , M_lda =  13  --->  Accuracy = 74.04%\n",
      "M_pca =  268 , M_lda =  14  --->  Accuracy = 74.04%\n",
      "M_pca =  268 , M_lda =  15  --->  Accuracy = 76.92%\n",
      "M_pca =  268 , M_lda =  16  --->  Accuracy = 75.96%\n",
      "M_pca =  268 , M_lda =  17  --->  Accuracy = 77.88%\n",
      "M_pca =  268 , M_lda =  18  --->  Accuracy = 77.88%\n",
      "M_pca =  268 , M_lda =  19  --->  Accuracy = 77.88%\n",
      "M_pca =  268 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  268 , M_lda =  21  --->  Accuracy = 80.77%\n",
      "M_pca =  268 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  268 , M_lda =  23  --->  Accuracy = 82.69%\n",
      "M_pca =  268 , M_lda =  24  --->  Accuracy = 81.73%\n",
      "M_pca =  268 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  268 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  268 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  268 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  268 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  268 , M_lda =  30  --->  Accuracy = 81.73%\n",
      "M_pca =  268 , M_lda =  31  --->  Accuracy = 81.73%\n",
      "M_pca =  268 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  268 , M_lda =  33  --->  Accuracy = 82.69%\n",
      "M_pca =  268 , M_lda =  34  --->  Accuracy = 82.69%\n",
      "M_pca =  268 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  268 , M_lda =  36  --->  Accuracy = 81.73%\n",
      "M_pca =  268 , M_lda =  37  --->  Accuracy = 82.69%\n",
      "M_pca =  268 , M_lda =  38  --->  Accuracy = 82.69%\n",
      "M_pca =  268 , M_lda =  39  --->  Accuracy = 83.65%\n",
      "M_pca =  268 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  268 , M_lda =  41  --->  Accuracy = 83.65%\n",
      "M_pca =  268 , M_lda =  42  --->  Accuracy = 84.62%\n",
      "M_pca =  268 , M_lda =  43  --->  Accuracy = 82.69%\n",
      "M_pca =  268 , M_lda =  44  --->  Accuracy = 82.69%\n",
      "M_pca =  268 , M_lda =  45  --->  Accuracy = 83.65%\n",
      "M_pca =  268 , M_lda =  46  --->  Accuracy = 83.65%\n",
      "M_pca =  268 , M_lda =  47  --->  Accuracy = 84.62%\n",
      "M_pca =  268 , M_lda =  48  --->  Accuracy = 85.58%\n",
      "M_pca =  268 , M_lda =  49  --->  Accuracy = 85.58%\n",
      "M_pca =  268 , M_lda =  50  --->  Accuracy = 85.58%\n",
      "M_pca =  268 , M_lda =  51  --->  Accuracy = 85.58%\n",
      "M_pca =  269 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  269 , M_lda =  2  --->  Accuracy = 13.46%\n",
      "M_pca =  269 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  269 , M_lda =  4  --->  Accuracy = 32.69%\n",
      "M_pca =  269 , M_lda =  5  --->  Accuracy = 41.35%\n",
      "M_pca =  269 , M_lda =  6  --->  Accuracy = 48.08%\n",
      "M_pca =  269 , M_lda =  7  --->  Accuracy = 54.81%\n",
      "M_pca =  269 , M_lda =  8  --->  Accuracy = 59.62%\n",
      "M_pca =  269 , M_lda =  9  --->  Accuracy = 64.42%\n",
      "M_pca =  269 , M_lda =  10  --->  Accuracy = 62.50%\n",
      "M_pca =  269 , M_lda =  11  --->  Accuracy = 65.38%\n",
      "M_pca =  269 , M_lda =  12  --->  Accuracy = 68.27%\n",
      "M_pca =  269 , M_lda =  13  --->  Accuracy = 74.04%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  269 , M_lda =  14  --->  Accuracy = 74.04%\n",
      "M_pca =  269 , M_lda =  15  --->  Accuracy = 76.92%\n",
      "M_pca =  269 , M_lda =  16  --->  Accuracy = 76.92%\n",
      "M_pca =  269 , M_lda =  17  --->  Accuracy = 77.88%\n",
      "M_pca =  269 , M_lda =  18  --->  Accuracy = 76.92%\n",
      "M_pca =  269 , M_lda =  19  --->  Accuracy = 75.96%\n",
      "M_pca =  269 , M_lda =  20  --->  Accuracy = 77.88%\n",
      "M_pca =  269 , M_lda =  21  --->  Accuracy = 78.85%\n",
      "M_pca =  269 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  269 , M_lda =  23  --->  Accuracy = 79.81%\n",
      "M_pca =  269 , M_lda =  24  --->  Accuracy = 81.73%\n",
      "M_pca =  269 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  269 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  269 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  269 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  269 , M_lda =  29  --->  Accuracy = 81.73%\n",
      "M_pca =  269 , M_lda =  30  --->  Accuracy = 81.73%\n",
      "M_pca =  269 , M_lda =  31  --->  Accuracy = 80.77%\n",
      "M_pca =  269 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  269 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  269 , M_lda =  34  --->  Accuracy = 80.77%\n",
      "M_pca =  269 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  269 , M_lda =  36  --->  Accuracy = 82.69%\n",
      "M_pca =  269 , M_lda =  37  --->  Accuracy = 82.69%\n",
      "M_pca =  269 , M_lda =  38  --->  Accuracy = 80.77%\n",
      "M_pca =  269 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  269 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  269 , M_lda =  41  --->  Accuracy = 82.69%\n",
      "M_pca =  269 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  269 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  269 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  269 , M_lda =  45  --->  Accuracy = 81.73%\n",
      "M_pca =  269 , M_lda =  46  --->  Accuracy = 81.73%\n",
      "M_pca =  269 , M_lda =  47  --->  Accuracy = 82.69%\n",
      "M_pca =  269 , M_lda =  48  --->  Accuracy = 83.65%\n",
      "M_pca =  269 , M_lda =  49  --->  Accuracy = 84.62%\n",
      "M_pca =  269 , M_lda =  50  --->  Accuracy = 84.62%\n",
      "M_pca =  269 , M_lda =  51  --->  Accuracy = 84.62%\n",
      "M_pca =  270 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  270 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  270 , M_lda =  3  --->  Accuracy = 25.00%\n",
      "M_pca =  270 , M_lda =  4  --->  Accuracy = 34.62%\n",
      "M_pca =  270 , M_lda =  5  --->  Accuracy = 42.31%\n",
      "M_pca =  270 , M_lda =  6  --->  Accuracy = 49.04%\n",
      "M_pca =  270 , M_lda =  7  --->  Accuracy = 52.88%\n",
      "M_pca =  270 , M_lda =  8  --->  Accuracy = 57.69%\n",
      "M_pca =  270 , M_lda =  9  --->  Accuracy = 65.38%\n",
      "M_pca =  270 , M_lda =  10  --->  Accuracy = 61.54%\n",
      "M_pca =  270 , M_lda =  11  --->  Accuracy = 65.38%\n",
      "M_pca =  270 , M_lda =  12  --->  Accuracy = 67.31%\n",
      "M_pca =  270 , M_lda =  13  --->  Accuracy = 72.12%\n",
      "M_pca =  270 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  270 , M_lda =  15  --->  Accuracy = 76.92%\n",
      "M_pca =  270 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  270 , M_lda =  17  --->  Accuracy = 77.88%\n",
      "M_pca =  270 , M_lda =  18  --->  Accuracy = 75.96%\n",
      "M_pca =  270 , M_lda =  19  --->  Accuracy = 76.92%\n",
      "M_pca =  270 , M_lda =  20  --->  Accuracy = 76.92%\n",
      "M_pca =  270 , M_lda =  21  --->  Accuracy = 77.88%\n",
      "M_pca =  270 , M_lda =  22  --->  Accuracy = 80.77%\n",
      "M_pca =  270 , M_lda =  23  --->  Accuracy = 79.81%\n",
      "M_pca =  270 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  270 , M_lda =  25  --->  Accuracy = 80.77%\n",
      "M_pca =  270 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  270 , M_lda =  27  --->  Accuracy = 80.77%\n",
      "M_pca =  270 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  270 , M_lda =  29  --->  Accuracy = 80.77%\n",
      "M_pca =  270 , M_lda =  30  --->  Accuracy = 80.77%\n",
      "M_pca =  270 , M_lda =  31  --->  Accuracy = 80.77%\n",
      "M_pca =  270 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  270 , M_lda =  33  --->  Accuracy = 79.81%\n",
      "M_pca =  270 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  270 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  270 , M_lda =  36  --->  Accuracy = 81.73%\n",
      "M_pca =  270 , M_lda =  37  --->  Accuracy = 81.73%\n",
      "M_pca =  270 , M_lda =  38  --->  Accuracy = 80.77%\n",
      "M_pca =  270 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  270 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  270 , M_lda =  41  --->  Accuracy = 82.69%\n",
      "M_pca =  270 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  270 , M_lda =  43  --->  Accuracy = 82.69%\n",
      "M_pca =  270 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  270 , M_lda =  45  --->  Accuracy = 81.73%\n",
      "M_pca =  270 , M_lda =  46  --->  Accuracy = 81.73%\n",
      "M_pca =  270 , M_lda =  47  --->  Accuracy = 82.69%\n",
      "M_pca =  270 , M_lda =  48  --->  Accuracy = 83.65%\n",
      "M_pca =  270 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  270 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  270 , M_lda =  51  --->  Accuracy = 83.65%\n",
      "M_pca =  271 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  271 , M_lda =  2  --->  Accuracy = 11.54%\n",
      "M_pca =  271 , M_lda =  3  --->  Accuracy = 25.00%\n",
      "M_pca =  271 , M_lda =  4  --->  Accuracy = 34.62%\n",
      "M_pca =  271 , M_lda =  5  --->  Accuracy = 45.19%\n",
      "M_pca =  271 , M_lda =  6  --->  Accuracy = 49.04%\n",
      "M_pca =  271 , M_lda =  7  --->  Accuracy = 50.96%\n",
      "M_pca =  271 , M_lda =  8  --->  Accuracy = 56.73%\n",
      "M_pca =  271 , M_lda =  9  --->  Accuracy = 65.38%\n",
      "M_pca =  271 , M_lda =  10  --->  Accuracy = 62.50%\n",
      "M_pca =  271 , M_lda =  11  --->  Accuracy = 68.27%\n",
      "M_pca =  271 , M_lda =  12  --->  Accuracy = 75.00%\n",
      "M_pca =  271 , M_lda =  13  --->  Accuracy = 74.04%\n",
      "M_pca =  271 , M_lda =  14  --->  Accuracy = 77.88%\n",
      "M_pca =  271 , M_lda =  15  --->  Accuracy = 78.85%\n",
      "M_pca =  271 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  271 , M_lda =  17  --->  Accuracy = 78.85%\n",
      "M_pca =  271 , M_lda =  18  --->  Accuracy = 77.88%\n",
      "M_pca =  271 , M_lda =  19  --->  Accuracy = 77.88%\n",
      "M_pca =  271 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  271 , M_lda =  21  --->  Accuracy = 80.77%\n",
      "M_pca =  271 , M_lda =  22  --->  Accuracy = 81.73%\n",
      "M_pca =  271 , M_lda =  23  --->  Accuracy = 82.69%\n",
      "M_pca =  271 , M_lda =  24  --->  Accuracy = 81.73%\n",
      "M_pca =  271 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  271 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  271 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  271 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  271 , M_lda =  29  --->  Accuracy = 80.77%\n",
      "M_pca =  271 , M_lda =  30  --->  Accuracy = 80.77%\n",
      "M_pca =  271 , M_lda =  31  --->  Accuracy = 80.77%\n",
      "M_pca =  271 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  271 , M_lda =  33  --->  Accuracy = 79.81%\n",
      "M_pca =  271 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  271 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  271 , M_lda =  36  --->  Accuracy = 80.77%\n",
      "M_pca =  271 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  271 , M_lda =  38  --->  Accuracy = 80.77%\n",
      "M_pca =  271 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  271 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  271 , M_lda =  41  --->  Accuracy = 82.69%\n",
      "M_pca =  271 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  271 , M_lda =  43  --->  Accuracy = 82.69%\n",
      "M_pca =  271 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  271 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  271 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  271 , M_lda =  47  --->  Accuracy = 83.65%\n",
      "M_pca =  271 , M_lda =  48  --->  Accuracy = 83.65%\n",
      "M_pca =  271 , M_lda =  49  --->  Accuracy = 83.65%\n",
      "M_pca =  271 , M_lda =  50  --->  Accuracy = 83.65%\n",
      "M_pca =  271 , M_lda =  51  --->  Accuracy = 83.65%\n",
      "M_pca =  272 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  272 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  272 , M_lda =  3  --->  Accuracy = 25.96%\n",
      "M_pca =  272 , M_lda =  4  --->  Accuracy = 34.62%\n",
      "M_pca =  272 , M_lda =  5  --->  Accuracy = 45.19%\n",
      "M_pca =  272 , M_lda =  6  --->  Accuracy = 50.00%\n",
      "M_pca =  272 , M_lda =  7  --->  Accuracy = 53.85%\n",
      "M_pca =  272 , M_lda =  8  --->  Accuracy = 58.65%\n",
      "M_pca =  272 , M_lda =  9  --->  Accuracy = 65.38%\n",
      "M_pca =  272 , M_lda =  10  --->  Accuracy = 64.42%\n",
      "M_pca =  272 , M_lda =  11  --->  Accuracy = 68.27%\n",
      "M_pca =  272 , M_lda =  12  --->  Accuracy = 74.04%\n",
      "M_pca =  272 , M_lda =  13  --->  Accuracy = 72.12%\n",
      "M_pca =  272 , M_lda =  14  --->  Accuracy = 76.92%\n",
      "M_pca =  272 , M_lda =  15  --->  Accuracy = 76.92%\n",
      "M_pca =  272 , M_lda =  16  --->  Accuracy = 78.85%\n",
      "M_pca =  272 , M_lda =  17  --->  Accuracy = 78.85%\n",
      "M_pca =  272 , M_lda =  18  --->  Accuracy = 77.88%\n",
      "M_pca =  272 , M_lda =  19  --->  Accuracy = 77.88%\n",
      "M_pca =  272 , M_lda =  20  --->  Accuracy = 77.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  272 , M_lda =  21  --->  Accuracy = 77.88%\n",
      "M_pca =  272 , M_lda =  22  --->  Accuracy = 78.85%\n",
      "M_pca =  272 , M_lda =  23  --->  Accuracy = 80.77%\n",
      "M_pca =  272 , M_lda =  24  --->  Accuracy = 80.77%\n",
      "M_pca =  272 , M_lda =  25  --->  Accuracy = 80.77%\n",
      "M_pca =  272 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  272 , M_lda =  27  --->  Accuracy = 80.77%\n",
      "M_pca =  272 , M_lda =  28  --->  Accuracy = 80.77%\n",
      "M_pca =  272 , M_lda =  29  --->  Accuracy = 80.77%\n",
      "M_pca =  272 , M_lda =  30  --->  Accuracy = 79.81%\n",
      "M_pca =  272 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  272 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  272 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  272 , M_lda =  34  --->  Accuracy = 80.77%\n",
      "M_pca =  272 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  272 , M_lda =  36  --->  Accuracy = 81.73%\n",
      "M_pca =  272 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  272 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  272 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  272 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  272 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  272 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  272 , M_lda =  43  --->  Accuracy = 80.77%\n",
      "M_pca =  272 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  272 , M_lda =  45  --->  Accuracy = 81.73%\n",
      "M_pca =  272 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  272 , M_lda =  47  --->  Accuracy = 82.69%\n",
      "M_pca =  272 , M_lda =  48  --->  Accuracy = 82.69%\n",
      "M_pca =  272 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  272 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  272 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  273 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  273 , M_lda =  2  --->  Accuracy = 13.46%\n",
      "M_pca =  273 , M_lda =  3  --->  Accuracy = 27.88%\n",
      "M_pca =  273 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  273 , M_lda =  5  --->  Accuracy = 50.00%\n",
      "M_pca =  273 , M_lda =  6  --->  Accuracy = 54.81%\n",
      "M_pca =  273 , M_lda =  7  --->  Accuracy = 54.81%\n",
      "M_pca =  273 , M_lda =  8  --->  Accuracy = 58.65%\n",
      "M_pca =  273 , M_lda =  9  --->  Accuracy = 65.38%\n",
      "M_pca =  273 , M_lda =  10  --->  Accuracy = 65.38%\n",
      "M_pca =  273 , M_lda =  11  --->  Accuracy = 67.31%\n",
      "M_pca =  273 , M_lda =  12  --->  Accuracy = 67.31%\n",
      "M_pca =  273 , M_lda =  13  --->  Accuracy = 69.23%\n",
      "M_pca =  273 , M_lda =  14  --->  Accuracy = 73.08%\n",
      "M_pca =  273 , M_lda =  15  --->  Accuracy = 74.04%\n",
      "M_pca =  273 , M_lda =  16  --->  Accuracy = 75.96%\n",
      "M_pca =  273 , M_lda =  17  --->  Accuracy = 76.92%\n",
      "M_pca =  273 , M_lda =  18  --->  Accuracy = 75.96%\n",
      "M_pca =  273 , M_lda =  19  --->  Accuracy = 77.88%\n",
      "M_pca =  273 , M_lda =  20  --->  Accuracy = 76.92%\n",
      "M_pca =  273 , M_lda =  21  --->  Accuracy = 77.88%\n",
      "M_pca =  273 , M_lda =  22  --->  Accuracy = 79.81%\n",
      "M_pca =  273 , M_lda =  23  --->  Accuracy = 79.81%\n",
      "M_pca =  273 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  273 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  273 , M_lda =  26  --->  Accuracy = 79.81%\n",
      "M_pca =  273 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  273 , M_lda =  28  --->  Accuracy = 80.77%\n",
      "M_pca =  273 , M_lda =  29  --->  Accuracy = 79.81%\n",
      "M_pca =  273 , M_lda =  30  --->  Accuracy = 79.81%\n",
      "M_pca =  273 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  273 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  273 , M_lda =  33  --->  Accuracy = 79.81%\n",
      "M_pca =  273 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  273 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  273 , M_lda =  36  --->  Accuracy = 80.77%\n",
      "M_pca =  273 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  273 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  273 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  273 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  273 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  273 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  273 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  273 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  273 , M_lda =  45  --->  Accuracy = 81.73%\n",
      "M_pca =  273 , M_lda =  46  --->  Accuracy = 81.73%\n",
      "M_pca =  273 , M_lda =  47  --->  Accuracy = 81.73%\n",
      "M_pca =  273 , M_lda =  48  --->  Accuracy = 82.69%\n",
      "M_pca =  273 , M_lda =  49  --->  Accuracy = 83.65%\n",
      "M_pca =  273 , M_lda =  50  --->  Accuracy = 83.65%\n",
      "M_pca =  273 , M_lda =  51  --->  Accuracy = 83.65%\n",
      "M_pca =  274 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  274 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  274 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  274 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  274 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  274 , M_lda =  6  --->  Accuracy = 51.92%\n",
      "M_pca =  274 , M_lda =  7  --->  Accuracy = 51.92%\n",
      "M_pca =  274 , M_lda =  8  --->  Accuracy = 56.73%\n",
      "M_pca =  274 , M_lda =  9  --->  Accuracy = 63.46%\n",
      "M_pca =  274 , M_lda =  10  --->  Accuracy = 66.35%\n",
      "M_pca =  274 , M_lda =  11  --->  Accuracy = 68.27%\n",
      "M_pca =  274 , M_lda =  12  --->  Accuracy = 65.38%\n",
      "M_pca =  274 , M_lda =  13  --->  Accuracy = 68.27%\n",
      "M_pca =  274 , M_lda =  14  --->  Accuracy = 72.12%\n",
      "M_pca =  274 , M_lda =  15  --->  Accuracy = 72.12%\n",
      "M_pca =  274 , M_lda =  16  --->  Accuracy = 75.96%\n",
      "M_pca =  274 , M_lda =  17  --->  Accuracy = 76.92%\n",
      "M_pca =  274 , M_lda =  18  --->  Accuracy = 75.96%\n",
      "M_pca =  274 , M_lda =  19  --->  Accuracy = 77.88%\n",
      "M_pca =  274 , M_lda =  20  --->  Accuracy = 76.92%\n",
      "M_pca =  274 , M_lda =  21  --->  Accuracy = 77.88%\n",
      "M_pca =  274 , M_lda =  22  --->  Accuracy = 79.81%\n",
      "M_pca =  274 , M_lda =  23  --->  Accuracy = 79.81%\n",
      "M_pca =  274 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  274 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  274 , M_lda =  26  --->  Accuracy = 79.81%\n",
      "M_pca =  274 , M_lda =  27  --->  Accuracy = 80.77%\n",
      "M_pca =  274 , M_lda =  28  --->  Accuracy = 79.81%\n",
      "M_pca =  274 , M_lda =  29  --->  Accuracy = 80.77%\n",
      "M_pca =  274 , M_lda =  30  --->  Accuracy = 79.81%\n",
      "M_pca =  274 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  274 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  274 , M_lda =  33  --->  Accuracy = 79.81%\n",
      "M_pca =  274 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  274 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  274 , M_lda =  36  --->  Accuracy = 81.73%\n",
      "M_pca =  274 , M_lda =  37  --->  Accuracy = 81.73%\n",
      "M_pca =  274 , M_lda =  38  --->  Accuracy = 80.77%\n",
      "M_pca =  274 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  274 , M_lda =  40  --->  Accuracy = 79.81%\n",
      "M_pca =  274 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  274 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  274 , M_lda =  43  --->  Accuracy = 82.69%\n",
      "M_pca =  274 , M_lda =  44  --->  Accuracy = 82.69%\n",
      "M_pca =  274 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  274 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  274 , M_lda =  47  --->  Accuracy = 82.69%\n",
      "M_pca =  274 , M_lda =  48  --->  Accuracy = 83.65%\n",
      "M_pca =  274 , M_lda =  49  --->  Accuracy = 83.65%\n",
      "M_pca =  274 , M_lda =  50  --->  Accuracy = 83.65%\n",
      "M_pca =  274 , M_lda =  51  --->  Accuracy = 83.65%\n",
      "M_pca =  275 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  275 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  275 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  275 , M_lda =  4  --->  Accuracy = 37.50%\n",
      "M_pca =  275 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  275 , M_lda =  6  --->  Accuracy = 51.92%\n",
      "M_pca =  275 , M_lda =  7  --->  Accuracy = 50.00%\n",
      "M_pca =  275 , M_lda =  8  --->  Accuracy = 59.62%\n",
      "M_pca =  275 , M_lda =  9  --->  Accuracy = 62.50%\n",
      "M_pca =  275 , M_lda =  10  --->  Accuracy = 63.46%\n",
      "M_pca =  275 , M_lda =  11  --->  Accuracy = 67.31%\n",
      "M_pca =  275 , M_lda =  12  --->  Accuracy = 67.31%\n",
      "M_pca =  275 , M_lda =  13  --->  Accuracy = 70.19%\n",
      "M_pca =  275 , M_lda =  14  --->  Accuracy = 72.12%\n",
      "M_pca =  275 , M_lda =  15  --->  Accuracy = 72.12%\n",
      "M_pca =  275 , M_lda =  16  --->  Accuracy = 75.00%\n",
      "M_pca =  275 , M_lda =  17  --->  Accuracy = 76.92%\n",
      "M_pca =  275 , M_lda =  18  --->  Accuracy = 75.96%\n",
      "M_pca =  275 , M_lda =  19  --->  Accuracy = 77.88%\n",
      "M_pca =  275 , M_lda =  20  --->  Accuracy = 76.92%\n",
      "M_pca =  275 , M_lda =  21  --->  Accuracy = 77.88%\n",
      "M_pca =  275 , M_lda =  22  --->  Accuracy = 77.88%\n",
      "M_pca =  275 , M_lda =  23  --->  Accuracy = 79.81%\n",
      "M_pca =  275 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  275 , M_lda =  25  --->  Accuracy = 78.85%\n",
      "M_pca =  275 , M_lda =  26  --->  Accuracy = 78.85%\n",
      "M_pca =  275 , M_lda =  27  --->  Accuracy = 78.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  275 , M_lda =  28  --->  Accuracy = 79.81%\n",
      "M_pca =  275 , M_lda =  29  --->  Accuracy = 78.85%\n",
      "M_pca =  275 , M_lda =  30  --->  Accuracy = 78.85%\n",
      "M_pca =  275 , M_lda =  31  --->  Accuracy = 78.85%\n",
      "M_pca =  275 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  275 , M_lda =  33  --->  Accuracy = 79.81%\n",
      "M_pca =  275 , M_lda =  34  --->  Accuracy = 80.77%\n",
      "M_pca =  275 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  275 , M_lda =  36  --->  Accuracy = 80.77%\n",
      "M_pca =  275 , M_lda =  37  --->  Accuracy = 79.81%\n",
      "M_pca =  275 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  275 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  275 , M_lda =  40  --->  Accuracy = 78.85%\n",
      "M_pca =  275 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  275 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  275 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  275 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  275 , M_lda =  45  --->  Accuracy = 81.73%\n",
      "M_pca =  275 , M_lda =  46  --->  Accuracy = 81.73%\n",
      "M_pca =  275 , M_lda =  47  --->  Accuracy = 81.73%\n",
      "M_pca =  275 , M_lda =  48  --->  Accuracy = 82.69%\n",
      "M_pca =  275 , M_lda =  49  --->  Accuracy = 81.73%\n",
      "M_pca =  275 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  275 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  276 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  276 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  276 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  276 , M_lda =  4  --->  Accuracy = 33.65%\n",
      "M_pca =  276 , M_lda =  5  --->  Accuracy = 43.27%\n",
      "M_pca =  276 , M_lda =  6  --->  Accuracy = 50.00%\n",
      "M_pca =  276 , M_lda =  7  --->  Accuracy = 50.96%\n",
      "M_pca =  276 , M_lda =  8  --->  Accuracy = 58.65%\n",
      "M_pca =  276 , M_lda =  9  --->  Accuracy = 62.50%\n",
      "M_pca =  276 , M_lda =  10  --->  Accuracy = 65.38%\n",
      "M_pca =  276 , M_lda =  11  --->  Accuracy = 68.27%\n",
      "M_pca =  276 , M_lda =  12  --->  Accuracy = 68.27%\n",
      "M_pca =  276 , M_lda =  13  --->  Accuracy = 67.31%\n",
      "M_pca =  276 , M_lda =  14  --->  Accuracy = 72.12%\n",
      "M_pca =  276 , M_lda =  15  --->  Accuracy = 73.08%\n",
      "M_pca =  276 , M_lda =  16  --->  Accuracy = 74.04%\n",
      "M_pca =  276 , M_lda =  17  --->  Accuracy = 74.04%\n",
      "M_pca =  276 , M_lda =  18  --->  Accuracy = 75.00%\n",
      "M_pca =  276 , M_lda =  19  --->  Accuracy = 77.88%\n",
      "M_pca =  276 , M_lda =  20  --->  Accuracy = 77.88%\n",
      "M_pca =  276 , M_lda =  21  --->  Accuracy = 79.81%\n",
      "M_pca =  276 , M_lda =  22  --->  Accuracy = 79.81%\n",
      "M_pca =  276 , M_lda =  23  --->  Accuracy = 79.81%\n",
      "M_pca =  276 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  276 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  276 , M_lda =  26  --->  Accuracy = 79.81%\n",
      "M_pca =  276 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  276 , M_lda =  28  --->  Accuracy = 79.81%\n",
      "M_pca =  276 , M_lda =  29  --->  Accuracy = 79.81%\n",
      "M_pca =  276 , M_lda =  30  --->  Accuracy = 79.81%\n",
      "M_pca =  276 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  276 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  276 , M_lda =  33  --->  Accuracy = 79.81%\n",
      "M_pca =  276 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  276 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  276 , M_lda =  36  --->  Accuracy = 81.73%\n",
      "M_pca =  276 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  276 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  276 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  276 , M_lda =  40  --->  Accuracy = 79.81%\n",
      "M_pca =  276 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  276 , M_lda =  42  --->  Accuracy = 80.77%\n",
      "M_pca =  276 , M_lda =  43  --->  Accuracy = 80.77%\n",
      "M_pca =  276 , M_lda =  44  --->  Accuracy = 80.77%\n",
      "M_pca =  276 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  276 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  276 , M_lda =  47  --->  Accuracy = 82.69%\n",
      "M_pca =  276 , M_lda =  48  --->  Accuracy = 82.69%\n",
      "M_pca =  276 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  276 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  276 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  277 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  277 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  277 , M_lda =  3  --->  Accuracy = 29.81%\n",
      "M_pca =  277 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  277 , M_lda =  5  --->  Accuracy = 49.04%\n",
      "M_pca =  277 , M_lda =  6  --->  Accuracy = 53.85%\n",
      "M_pca =  277 , M_lda =  7  --->  Accuracy = 52.88%\n",
      "M_pca =  277 , M_lda =  8  --->  Accuracy = 59.62%\n",
      "M_pca =  277 , M_lda =  9  --->  Accuracy = 64.42%\n",
      "M_pca =  277 , M_lda =  10  --->  Accuracy = 68.27%\n",
      "M_pca =  277 , M_lda =  11  --->  Accuracy = 70.19%\n",
      "M_pca =  277 , M_lda =  12  --->  Accuracy = 69.23%\n",
      "M_pca =  277 , M_lda =  13  --->  Accuracy = 71.15%\n",
      "M_pca =  277 , M_lda =  14  --->  Accuracy = 72.12%\n",
      "M_pca =  277 , M_lda =  15  --->  Accuracy = 73.08%\n",
      "M_pca =  277 , M_lda =  16  --->  Accuracy = 74.04%\n",
      "M_pca =  277 , M_lda =  17  --->  Accuracy = 76.92%\n",
      "M_pca =  277 , M_lda =  18  --->  Accuracy = 79.81%\n",
      "M_pca =  277 , M_lda =  19  --->  Accuracy = 78.85%\n",
      "M_pca =  277 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  277 , M_lda =  21  --->  Accuracy = 78.85%\n",
      "M_pca =  277 , M_lda =  22  --->  Accuracy = 78.85%\n",
      "M_pca =  277 , M_lda =  23  --->  Accuracy = 79.81%\n",
      "M_pca =  277 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  277 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  277 , M_lda =  26  --->  Accuracy = 79.81%\n",
      "M_pca =  277 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  277 , M_lda =  28  --->  Accuracy = 79.81%\n",
      "M_pca =  277 , M_lda =  29  --->  Accuracy = 80.77%\n",
      "M_pca =  277 , M_lda =  30  --->  Accuracy = 80.77%\n",
      "M_pca =  277 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  277 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  277 , M_lda =  33  --->  Accuracy = 79.81%\n",
      "M_pca =  277 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  277 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  277 , M_lda =  36  --->  Accuracy = 80.77%\n",
      "M_pca =  277 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  277 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  277 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  277 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  277 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  277 , M_lda =  42  --->  Accuracy = 80.77%\n",
      "M_pca =  277 , M_lda =  43  --->  Accuracy = 80.77%\n",
      "M_pca =  277 , M_lda =  44  --->  Accuracy = 80.77%\n",
      "M_pca =  277 , M_lda =  45  --->  Accuracy = 81.73%\n",
      "M_pca =  277 , M_lda =  46  --->  Accuracy = 81.73%\n",
      "M_pca =  277 , M_lda =  47  --->  Accuracy = 81.73%\n",
      "M_pca =  277 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  277 , M_lda =  49  --->  Accuracy = 81.73%\n",
      "M_pca =  277 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  277 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  278 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  278 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  278 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  278 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  278 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  278 , M_lda =  6  --->  Accuracy = 50.96%\n",
      "M_pca =  278 , M_lda =  7  --->  Accuracy = 51.92%\n",
      "M_pca =  278 , M_lda =  8  --->  Accuracy = 58.65%\n",
      "M_pca =  278 , M_lda =  9  --->  Accuracy = 63.46%\n",
      "M_pca =  278 , M_lda =  10  --->  Accuracy = 68.27%\n",
      "M_pca =  278 , M_lda =  11  --->  Accuracy = 69.23%\n",
      "M_pca =  278 , M_lda =  12  --->  Accuracy = 69.23%\n",
      "M_pca =  278 , M_lda =  13  --->  Accuracy = 72.12%\n",
      "M_pca =  278 , M_lda =  14  --->  Accuracy = 71.15%\n",
      "M_pca =  278 , M_lda =  15  --->  Accuracy = 74.04%\n",
      "M_pca =  278 , M_lda =  16  --->  Accuracy = 75.00%\n",
      "M_pca =  278 , M_lda =  17  --->  Accuracy = 76.92%\n",
      "M_pca =  278 , M_lda =  18  --->  Accuracy = 77.88%\n",
      "M_pca =  278 , M_lda =  19  --->  Accuracy = 77.88%\n",
      "M_pca =  278 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  278 , M_lda =  21  --->  Accuracy = 78.85%\n",
      "M_pca =  278 , M_lda =  22  --->  Accuracy = 78.85%\n",
      "M_pca =  278 , M_lda =  23  --->  Accuracy = 79.81%\n",
      "M_pca =  278 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  278 , M_lda =  25  --->  Accuracy = 80.77%\n",
      "M_pca =  278 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  278 , M_lda =  27  --->  Accuracy = 80.77%\n",
      "M_pca =  278 , M_lda =  28  --->  Accuracy = 80.77%\n",
      "M_pca =  278 , M_lda =  29  --->  Accuracy = 80.77%\n",
      "M_pca =  278 , M_lda =  30  --->  Accuracy = 80.77%\n",
      "M_pca =  278 , M_lda =  31  --->  Accuracy = 80.77%\n",
      "M_pca =  278 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  278 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  278 , M_lda =  34  --->  Accuracy = 80.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  278 , M_lda =  35  --->  Accuracy = 82.69%\n",
      "M_pca =  278 , M_lda =  36  --->  Accuracy = 82.69%\n",
      "M_pca =  278 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  278 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  278 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  278 , M_lda =  40  --->  Accuracy = 79.81%\n",
      "M_pca =  278 , M_lda =  41  --->  Accuracy = 82.69%\n",
      "M_pca =  278 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  278 , M_lda =  43  --->  Accuracy = 82.69%\n",
      "M_pca =  278 , M_lda =  44  --->  Accuracy = 82.69%\n",
      "M_pca =  278 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  278 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  278 , M_lda =  47  --->  Accuracy = 83.65%\n",
      "M_pca =  278 , M_lda =  48  --->  Accuracy = 83.65%\n",
      "M_pca =  278 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  278 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  278 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  279 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  279 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  279 , M_lda =  3  --->  Accuracy = 31.73%\n",
      "M_pca =  279 , M_lda =  4  --->  Accuracy = 34.62%\n",
      "M_pca =  279 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  279 , M_lda =  6  --->  Accuracy = 54.81%\n",
      "M_pca =  279 , M_lda =  7  --->  Accuracy = 55.77%\n",
      "M_pca =  279 , M_lda =  8  --->  Accuracy = 57.69%\n",
      "M_pca =  279 , M_lda =  9  --->  Accuracy = 62.50%\n",
      "M_pca =  279 , M_lda =  10  --->  Accuracy = 69.23%\n",
      "M_pca =  279 , M_lda =  11  --->  Accuracy = 68.27%\n",
      "M_pca =  279 , M_lda =  12  --->  Accuracy = 69.23%\n",
      "M_pca =  279 , M_lda =  13  --->  Accuracy = 72.12%\n",
      "M_pca =  279 , M_lda =  14  --->  Accuracy = 73.08%\n",
      "M_pca =  279 , M_lda =  15  --->  Accuracy = 75.96%\n",
      "M_pca =  279 , M_lda =  16  --->  Accuracy = 75.00%\n",
      "M_pca =  279 , M_lda =  17  --->  Accuracy = 75.96%\n",
      "M_pca =  279 , M_lda =  18  --->  Accuracy = 77.88%\n",
      "M_pca =  279 , M_lda =  19  --->  Accuracy = 78.85%\n",
      "M_pca =  279 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  279 , M_lda =  21  --->  Accuracy = 77.88%\n",
      "M_pca =  279 , M_lda =  22  --->  Accuracy = 77.88%\n",
      "M_pca =  279 , M_lda =  23  --->  Accuracy = 77.88%\n",
      "M_pca =  279 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  279 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  279 , M_lda =  26  --->  Accuracy = 79.81%\n",
      "M_pca =  279 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  279 , M_lda =  28  --->  Accuracy = 80.77%\n",
      "M_pca =  279 , M_lda =  29  --->  Accuracy = 80.77%\n",
      "M_pca =  279 , M_lda =  30  --->  Accuracy = 80.77%\n",
      "M_pca =  279 , M_lda =  31  --->  Accuracy = 80.77%\n",
      "M_pca =  279 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  279 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  279 , M_lda =  34  --->  Accuracy = 80.77%\n",
      "M_pca =  279 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  279 , M_lda =  36  --->  Accuracy = 81.73%\n",
      "M_pca =  279 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  279 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  279 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  279 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  279 , M_lda =  41  --->  Accuracy = 82.69%\n",
      "M_pca =  279 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  279 , M_lda =  43  --->  Accuracy = 82.69%\n",
      "M_pca =  279 , M_lda =  44  --->  Accuracy = 82.69%\n",
      "M_pca =  279 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  279 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  279 , M_lda =  47  --->  Accuracy = 82.69%\n",
      "M_pca =  279 , M_lda =  48  --->  Accuracy = 82.69%\n",
      "M_pca =  279 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  279 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  279 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  280 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  280 , M_lda =  2  --->  Accuracy = 19.23%\n",
      "M_pca =  280 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  280 , M_lda =  4  --->  Accuracy = 34.62%\n",
      "M_pca =  280 , M_lda =  5  --->  Accuracy = 44.23%\n",
      "M_pca =  280 , M_lda =  6  --->  Accuracy = 49.04%\n",
      "M_pca =  280 , M_lda =  7  --->  Accuracy = 54.81%\n",
      "M_pca =  280 , M_lda =  8  --->  Accuracy = 57.69%\n",
      "M_pca =  280 , M_lda =  9  --->  Accuracy = 61.54%\n",
      "M_pca =  280 , M_lda =  10  --->  Accuracy = 67.31%\n",
      "M_pca =  280 , M_lda =  11  --->  Accuracy = 68.27%\n",
      "M_pca =  280 , M_lda =  12  --->  Accuracy = 69.23%\n",
      "M_pca =  280 , M_lda =  13  --->  Accuracy = 71.15%\n",
      "M_pca =  280 , M_lda =  14  --->  Accuracy = 72.12%\n",
      "M_pca =  280 , M_lda =  15  --->  Accuracy = 73.08%\n",
      "M_pca =  280 , M_lda =  16  --->  Accuracy = 74.04%\n",
      "M_pca =  280 , M_lda =  17  --->  Accuracy = 74.04%\n",
      "M_pca =  280 , M_lda =  18  --->  Accuracy = 76.92%\n",
      "M_pca =  280 , M_lda =  19  --->  Accuracy = 77.88%\n",
      "M_pca =  280 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  280 , M_lda =  21  --->  Accuracy = 77.88%\n",
      "M_pca =  280 , M_lda =  22  --->  Accuracy = 77.88%\n",
      "M_pca =  280 , M_lda =  23  --->  Accuracy = 77.88%\n",
      "M_pca =  280 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  280 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  280 , M_lda =  26  --->  Accuracy = 79.81%\n",
      "M_pca =  280 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  280 , M_lda =  28  --->  Accuracy = 79.81%\n",
      "M_pca =  280 , M_lda =  29  --->  Accuracy = 80.77%\n",
      "M_pca =  280 , M_lda =  30  --->  Accuracy = 80.77%\n",
      "M_pca =  280 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  280 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  280 , M_lda =  33  --->  Accuracy = 79.81%\n",
      "M_pca =  280 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  280 , M_lda =  35  --->  Accuracy = 79.81%\n",
      "M_pca =  280 , M_lda =  36  --->  Accuracy = 80.77%\n",
      "M_pca =  280 , M_lda =  37  --->  Accuracy = 81.73%\n",
      "M_pca =  280 , M_lda =  38  --->  Accuracy = 80.77%\n",
      "M_pca =  280 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  280 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  280 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  280 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  280 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  280 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  280 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  280 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  280 , M_lda =  47  --->  Accuracy = 82.69%\n",
      "M_pca =  280 , M_lda =  48  --->  Accuracy = 82.69%\n",
      "M_pca =  280 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  280 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  280 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  281 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  281 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  281 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  281 , M_lda =  4  --->  Accuracy = 38.46%\n",
      "M_pca =  281 , M_lda =  5  --->  Accuracy = 48.08%\n",
      "M_pca =  281 , M_lda =  6  --->  Accuracy = 52.88%\n",
      "M_pca =  281 , M_lda =  7  --->  Accuracy = 52.88%\n",
      "M_pca =  281 , M_lda =  8  --->  Accuracy = 56.73%\n",
      "M_pca =  281 , M_lda =  9  --->  Accuracy = 64.42%\n",
      "M_pca =  281 , M_lda =  10  --->  Accuracy = 66.35%\n",
      "M_pca =  281 , M_lda =  11  --->  Accuracy = 66.35%\n",
      "M_pca =  281 , M_lda =  12  --->  Accuracy = 67.31%\n",
      "M_pca =  281 , M_lda =  13  --->  Accuracy = 69.23%\n",
      "M_pca =  281 , M_lda =  14  --->  Accuracy = 72.12%\n",
      "M_pca =  281 , M_lda =  15  --->  Accuracy = 73.08%\n",
      "M_pca =  281 , M_lda =  16  --->  Accuracy = 74.04%\n",
      "M_pca =  281 , M_lda =  17  --->  Accuracy = 75.00%\n",
      "M_pca =  281 , M_lda =  18  --->  Accuracy = 75.00%\n",
      "M_pca =  281 , M_lda =  19  --->  Accuracy = 76.92%\n",
      "M_pca =  281 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  281 , M_lda =  21  --->  Accuracy = 77.88%\n",
      "M_pca =  281 , M_lda =  22  --->  Accuracy = 77.88%\n",
      "M_pca =  281 , M_lda =  23  --->  Accuracy = 77.88%\n",
      "M_pca =  281 , M_lda =  24  --->  Accuracy = 80.77%\n",
      "M_pca =  281 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  281 , M_lda =  26  --->  Accuracy = 79.81%\n",
      "M_pca =  281 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  281 , M_lda =  28  --->  Accuracy = 79.81%\n",
      "M_pca =  281 , M_lda =  29  --->  Accuracy = 79.81%\n",
      "M_pca =  281 , M_lda =  30  --->  Accuracy = 80.77%\n",
      "M_pca =  281 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  281 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  281 , M_lda =  33  --->  Accuracy = 79.81%\n",
      "M_pca =  281 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  281 , M_lda =  35  --->  Accuracy = 79.81%\n",
      "M_pca =  281 , M_lda =  36  --->  Accuracy = 80.77%\n",
      "M_pca =  281 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  281 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  281 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  281 , M_lda =  40  --->  Accuracy = 82.69%\n",
      "M_pca =  281 , M_lda =  41  --->  Accuracy = 81.73%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  281 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  281 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  281 , M_lda =  44  --->  Accuracy = 82.69%\n",
      "M_pca =  281 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  281 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  281 , M_lda =  47  --->  Accuracy = 82.69%\n",
      "M_pca =  281 , M_lda =  48  --->  Accuracy = 82.69%\n",
      "M_pca =  281 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  281 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  281 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  282 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  282 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  282 , M_lda =  3  --->  Accuracy = 25.96%\n",
      "M_pca =  282 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  282 , M_lda =  5  --->  Accuracy = 47.12%\n",
      "M_pca =  282 , M_lda =  6  --->  Accuracy = 52.88%\n",
      "M_pca =  282 , M_lda =  7  --->  Accuracy = 54.81%\n",
      "M_pca =  282 , M_lda =  8  --->  Accuracy = 61.54%\n",
      "M_pca =  282 , M_lda =  9  --->  Accuracy = 64.42%\n",
      "M_pca =  282 , M_lda =  10  --->  Accuracy = 67.31%\n",
      "M_pca =  282 , M_lda =  11  --->  Accuracy = 67.31%\n",
      "M_pca =  282 , M_lda =  12  --->  Accuracy = 70.19%\n",
      "M_pca =  282 , M_lda =  13  --->  Accuracy = 70.19%\n",
      "M_pca =  282 , M_lda =  14  --->  Accuracy = 71.15%\n",
      "M_pca =  282 , M_lda =  15  --->  Accuracy = 72.12%\n",
      "M_pca =  282 , M_lda =  16  --->  Accuracy = 73.08%\n",
      "M_pca =  282 , M_lda =  17  --->  Accuracy = 75.96%\n",
      "M_pca =  282 , M_lda =  18  --->  Accuracy = 76.92%\n",
      "M_pca =  282 , M_lda =  19  --->  Accuracy = 77.88%\n",
      "M_pca =  282 , M_lda =  20  --->  Accuracy = 78.85%\n",
      "M_pca =  282 , M_lda =  21  --->  Accuracy = 76.92%\n",
      "M_pca =  282 , M_lda =  22  --->  Accuracy = 77.88%\n",
      "M_pca =  282 , M_lda =  23  --->  Accuracy = 76.92%\n",
      "M_pca =  282 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  282 , M_lda =  25  --->  Accuracy = 78.85%\n",
      "M_pca =  282 , M_lda =  26  --->  Accuracy = 79.81%\n",
      "M_pca =  282 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  282 , M_lda =  28  --->  Accuracy = 79.81%\n",
      "M_pca =  282 , M_lda =  29  --->  Accuracy = 79.81%\n",
      "M_pca =  282 , M_lda =  30  --->  Accuracy = 78.85%\n",
      "M_pca =  282 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  282 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  282 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  282 , M_lda =  34  --->  Accuracy = 81.73%\n",
      "M_pca =  282 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  282 , M_lda =  36  --->  Accuracy = 81.73%\n",
      "M_pca =  282 , M_lda =  37  --->  Accuracy = 81.73%\n",
      "M_pca =  282 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  282 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  282 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  282 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  282 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  282 , M_lda =  43  --->  Accuracy = 82.69%\n",
      "M_pca =  282 , M_lda =  44  --->  Accuracy = 82.69%\n",
      "M_pca =  282 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  282 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  282 , M_lda =  47  --->  Accuracy = 82.69%\n",
      "M_pca =  282 , M_lda =  48  --->  Accuracy = 82.69%\n",
      "M_pca =  282 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  282 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  282 , M_lda =  51  --->  Accuracy = 83.65%\n",
      "M_pca =  283 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  283 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  283 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  283 , M_lda =  4  --->  Accuracy = 33.65%\n",
      "M_pca =  283 , M_lda =  5  --->  Accuracy = 44.23%\n",
      "M_pca =  283 , M_lda =  6  --->  Accuracy = 44.23%\n",
      "M_pca =  283 , M_lda =  7  --->  Accuracy = 50.00%\n",
      "M_pca =  283 , M_lda =  8  --->  Accuracy = 55.77%\n",
      "M_pca =  283 , M_lda =  9  --->  Accuracy = 61.54%\n",
      "M_pca =  283 , M_lda =  10  --->  Accuracy = 65.38%\n",
      "M_pca =  283 , M_lda =  11  --->  Accuracy = 69.23%\n",
      "M_pca =  283 , M_lda =  12  --->  Accuracy = 69.23%\n",
      "M_pca =  283 , M_lda =  13  --->  Accuracy = 69.23%\n",
      "M_pca =  283 , M_lda =  14  --->  Accuracy = 71.15%\n",
      "M_pca =  283 , M_lda =  15  --->  Accuracy = 70.19%\n",
      "M_pca =  283 , M_lda =  16  --->  Accuracy = 71.15%\n",
      "M_pca =  283 , M_lda =  17  --->  Accuracy = 74.04%\n",
      "M_pca =  283 , M_lda =  18  --->  Accuracy = 75.00%\n",
      "M_pca =  283 , M_lda =  19  --->  Accuracy = 75.96%\n",
      "M_pca =  283 , M_lda =  20  --->  Accuracy = 75.96%\n",
      "M_pca =  283 , M_lda =  21  --->  Accuracy = 77.88%\n",
      "M_pca =  283 , M_lda =  22  --->  Accuracy = 78.85%\n",
      "M_pca =  283 , M_lda =  23  --->  Accuracy = 77.88%\n",
      "M_pca =  283 , M_lda =  24  --->  Accuracy = 80.77%\n",
      "M_pca =  283 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  283 , M_lda =  26  --->  Accuracy = 78.85%\n",
      "M_pca =  283 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  283 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  283 , M_lda =  29  --->  Accuracy = 81.73%\n",
      "M_pca =  283 , M_lda =  30  --->  Accuracy = 81.73%\n",
      "M_pca =  283 , M_lda =  31  --->  Accuracy = 80.77%\n",
      "M_pca =  283 , M_lda =  32  --->  Accuracy = 81.73%\n",
      "M_pca =  283 , M_lda =  33  --->  Accuracy = 81.73%\n",
      "M_pca =  283 , M_lda =  34  --->  Accuracy = 81.73%\n",
      "M_pca =  283 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  283 , M_lda =  36  --->  Accuracy = 81.73%\n",
      "M_pca =  283 , M_lda =  37  --->  Accuracy = 81.73%\n",
      "M_pca =  283 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  283 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  283 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  283 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  283 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  283 , M_lda =  43  --->  Accuracy = 82.69%\n",
      "M_pca =  283 , M_lda =  44  --->  Accuracy = 82.69%\n",
      "M_pca =  283 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  283 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  283 , M_lda =  47  --->  Accuracy = 82.69%\n",
      "M_pca =  283 , M_lda =  48  --->  Accuracy = 82.69%\n",
      "M_pca =  283 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  283 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  283 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  284 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  284 , M_lda =  2  --->  Accuracy = 20.19%\n",
      "M_pca =  284 , M_lda =  3  --->  Accuracy = 26.92%\n",
      "M_pca =  284 , M_lda =  4  --->  Accuracy = 34.62%\n",
      "M_pca =  284 , M_lda =  5  --->  Accuracy = 43.27%\n",
      "M_pca =  284 , M_lda =  6  --->  Accuracy = 44.23%\n",
      "M_pca =  284 , M_lda =  7  --->  Accuracy = 50.96%\n",
      "M_pca =  284 , M_lda =  8  --->  Accuracy = 56.73%\n",
      "M_pca =  284 , M_lda =  9  --->  Accuracy = 63.46%\n",
      "M_pca =  284 , M_lda =  10  --->  Accuracy = 66.35%\n",
      "M_pca =  284 , M_lda =  11  --->  Accuracy = 67.31%\n",
      "M_pca =  284 , M_lda =  12  --->  Accuracy = 67.31%\n",
      "M_pca =  284 , M_lda =  13  --->  Accuracy = 68.27%\n",
      "M_pca =  284 , M_lda =  14  --->  Accuracy = 72.12%\n",
      "M_pca =  284 , M_lda =  15  --->  Accuracy = 71.15%\n",
      "M_pca =  284 , M_lda =  16  --->  Accuracy = 73.08%\n",
      "M_pca =  284 , M_lda =  17  --->  Accuracy = 73.08%\n",
      "M_pca =  284 , M_lda =  18  --->  Accuracy = 74.04%\n",
      "M_pca =  284 , M_lda =  19  --->  Accuracy = 75.00%\n",
      "M_pca =  284 , M_lda =  20  --->  Accuracy = 75.00%\n",
      "M_pca =  284 , M_lda =  21  --->  Accuracy = 75.00%\n",
      "M_pca =  284 , M_lda =  22  --->  Accuracy = 75.96%\n",
      "M_pca =  284 , M_lda =  23  --->  Accuracy = 77.88%\n",
      "M_pca =  284 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  284 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  284 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  284 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  284 , M_lda =  28  --->  Accuracy = 80.77%\n",
      "M_pca =  284 , M_lda =  29  --->  Accuracy = 80.77%\n",
      "M_pca =  284 , M_lda =  30  --->  Accuracy = 79.81%\n",
      "M_pca =  284 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  284 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  284 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  284 , M_lda =  34  --->  Accuracy = 81.73%\n",
      "M_pca =  284 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  284 , M_lda =  36  --->  Accuracy = 81.73%\n",
      "M_pca =  284 , M_lda =  37  --->  Accuracy = 81.73%\n",
      "M_pca =  284 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  284 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  284 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  284 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  284 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  284 , M_lda =  43  --->  Accuracy = 82.69%\n",
      "M_pca =  284 , M_lda =  44  --->  Accuracy = 82.69%\n",
      "M_pca =  284 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  284 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  284 , M_lda =  47  --->  Accuracy = 82.69%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  284 , M_lda =  48  --->  Accuracy = 82.69%\n",
      "M_pca =  284 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  284 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  284 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  285 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  285 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  285 , M_lda =  3  --->  Accuracy = 25.96%\n",
      "M_pca =  285 , M_lda =  4  --->  Accuracy = 36.54%\n",
      "M_pca =  285 , M_lda =  5  --->  Accuracy = 44.23%\n",
      "M_pca =  285 , M_lda =  6  --->  Accuracy = 46.15%\n",
      "M_pca =  285 , M_lda =  7  --->  Accuracy = 48.08%\n",
      "M_pca =  285 , M_lda =  8  --->  Accuracy = 56.73%\n",
      "M_pca =  285 , M_lda =  9  --->  Accuracy = 57.69%\n",
      "M_pca =  285 , M_lda =  10  --->  Accuracy = 62.50%\n",
      "M_pca =  285 , M_lda =  11  --->  Accuracy = 67.31%\n",
      "M_pca =  285 , M_lda =  12  --->  Accuracy = 69.23%\n",
      "M_pca =  285 , M_lda =  13  --->  Accuracy = 71.15%\n",
      "M_pca =  285 , M_lda =  14  --->  Accuracy = 72.12%\n",
      "M_pca =  285 , M_lda =  15  --->  Accuracy = 73.08%\n",
      "M_pca =  285 , M_lda =  16  --->  Accuracy = 72.12%\n",
      "M_pca =  285 , M_lda =  17  --->  Accuracy = 74.04%\n",
      "M_pca =  285 , M_lda =  18  --->  Accuracy = 75.96%\n",
      "M_pca =  285 , M_lda =  19  --->  Accuracy = 75.00%\n",
      "M_pca =  285 , M_lda =  20  --->  Accuracy = 76.92%\n",
      "M_pca =  285 , M_lda =  21  --->  Accuracy = 75.96%\n",
      "M_pca =  285 , M_lda =  22  --->  Accuracy = 75.96%\n",
      "M_pca =  285 , M_lda =  23  --->  Accuracy = 77.88%\n",
      "M_pca =  285 , M_lda =  24  --->  Accuracy = 81.73%\n",
      "M_pca =  285 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  285 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  285 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  285 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  285 , M_lda =  29  --->  Accuracy = 82.69%\n",
      "M_pca =  285 , M_lda =  30  --->  Accuracy = 81.73%\n",
      "M_pca =  285 , M_lda =  31  --->  Accuracy = 80.77%\n",
      "M_pca =  285 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  285 , M_lda =  33  --->  Accuracy = 82.69%\n",
      "M_pca =  285 , M_lda =  34  --->  Accuracy = 82.69%\n",
      "M_pca =  285 , M_lda =  35  --->  Accuracy = 82.69%\n",
      "M_pca =  285 , M_lda =  36  --->  Accuracy = 83.65%\n",
      "M_pca =  285 , M_lda =  37  --->  Accuracy = 82.69%\n",
      "M_pca =  285 , M_lda =  38  --->  Accuracy = 82.69%\n",
      "M_pca =  285 , M_lda =  39  --->  Accuracy = 82.69%\n",
      "M_pca =  285 , M_lda =  40  --->  Accuracy = 82.69%\n",
      "M_pca =  285 , M_lda =  41  --->  Accuracy = 82.69%\n",
      "M_pca =  285 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  285 , M_lda =  43  --->  Accuracy = 82.69%\n",
      "M_pca =  285 , M_lda =  44  --->  Accuracy = 82.69%\n",
      "M_pca =  285 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  285 , M_lda =  46  --->  Accuracy = 83.65%\n",
      "M_pca =  285 , M_lda =  47  --->  Accuracy = 83.65%\n",
      "M_pca =  285 , M_lda =  48  --->  Accuracy = 84.62%\n",
      "M_pca =  285 , M_lda =  49  --->  Accuracy = 84.62%\n",
      "M_pca =  285 , M_lda =  50  --->  Accuracy = 84.62%\n",
      "M_pca =  285 , M_lda =  51  --->  Accuracy = 84.62%\n",
      "M_pca =  286 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  286 , M_lda =  2  --->  Accuracy = 18.27%\n",
      "M_pca =  286 , M_lda =  3  --->  Accuracy = 30.77%\n",
      "M_pca =  286 , M_lda =  4  --->  Accuracy = 31.73%\n",
      "M_pca =  286 , M_lda =  5  --->  Accuracy = 40.38%\n",
      "M_pca =  286 , M_lda =  6  --->  Accuracy = 46.15%\n",
      "M_pca =  286 , M_lda =  7  --->  Accuracy = 48.08%\n",
      "M_pca =  286 , M_lda =  8  --->  Accuracy = 54.81%\n",
      "M_pca =  286 , M_lda =  9  --->  Accuracy = 56.73%\n",
      "M_pca =  286 , M_lda =  10  --->  Accuracy = 63.46%\n",
      "M_pca =  286 , M_lda =  11  --->  Accuracy = 67.31%\n",
      "M_pca =  286 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  286 , M_lda =  13  --->  Accuracy = 70.19%\n",
      "M_pca =  286 , M_lda =  14  --->  Accuracy = 72.12%\n",
      "M_pca =  286 , M_lda =  15  --->  Accuracy = 74.04%\n",
      "M_pca =  286 , M_lda =  16  --->  Accuracy = 72.12%\n",
      "M_pca =  286 , M_lda =  17  --->  Accuracy = 72.12%\n",
      "M_pca =  286 , M_lda =  18  --->  Accuracy = 75.00%\n",
      "M_pca =  286 , M_lda =  19  --->  Accuracy = 73.08%\n",
      "M_pca =  286 , M_lda =  20  --->  Accuracy = 74.04%\n",
      "M_pca =  286 , M_lda =  21  --->  Accuracy = 75.00%\n",
      "M_pca =  286 , M_lda =  22  --->  Accuracy = 75.96%\n",
      "M_pca =  286 , M_lda =  23  --->  Accuracy = 75.96%\n",
      "M_pca =  286 , M_lda =  24  --->  Accuracy = 77.88%\n",
      "M_pca =  286 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  286 , M_lda =  26  --->  Accuracy = 81.73%\n",
      "M_pca =  286 , M_lda =  27  --->  Accuracy = 82.69%\n",
      "M_pca =  286 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  286 , M_lda =  29  --->  Accuracy = 81.73%\n",
      "M_pca =  286 , M_lda =  30  --->  Accuracy = 79.81%\n",
      "M_pca =  286 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  286 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  286 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  286 , M_lda =  34  --->  Accuracy = 80.77%\n",
      "M_pca =  286 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  286 , M_lda =  36  --->  Accuracy = 81.73%\n",
      "M_pca =  286 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  286 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  286 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  286 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  286 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  286 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  286 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  286 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  286 , M_lda =  45  --->  Accuracy = 81.73%\n",
      "M_pca =  286 , M_lda =  46  --->  Accuracy = 81.73%\n",
      "M_pca =  286 , M_lda =  47  --->  Accuracy = 81.73%\n",
      "M_pca =  286 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  286 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  286 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  286 , M_lda =  51  --->  Accuracy = 83.65%\n",
      "M_pca =  287 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  287 , M_lda =  2  --->  Accuracy = 13.46%\n",
      "M_pca =  287 , M_lda =  3  --->  Accuracy = 28.85%\n",
      "M_pca =  287 , M_lda =  4  --->  Accuracy = 31.73%\n",
      "M_pca =  287 , M_lda =  5  --->  Accuracy = 40.38%\n",
      "M_pca =  287 , M_lda =  6  --->  Accuracy = 47.12%\n",
      "M_pca =  287 , M_lda =  7  --->  Accuracy = 50.00%\n",
      "M_pca =  287 , M_lda =  8  --->  Accuracy = 56.73%\n",
      "M_pca =  287 , M_lda =  9  --->  Accuracy = 55.77%\n",
      "M_pca =  287 , M_lda =  10  --->  Accuracy = 59.62%\n",
      "M_pca =  287 , M_lda =  11  --->  Accuracy = 69.23%\n",
      "M_pca =  287 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  287 , M_lda =  13  --->  Accuracy = 71.15%\n",
      "M_pca =  287 , M_lda =  14  --->  Accuracy = 72.12%\n",
      "M_pca =  287 , M_lda =  15  --->  Accuracy = 73.08%\n",
      "M_pca =  287 , M_lda =  16  --->  Accuracy = 70.19%\n",
      "M_pca =  287 , M_lda =  17  --->  Accuracy = 72.12%\n",
      "M_pca =  287 , M_lda =  18  --->  Accuracy = 75.00%\n",
      "M_pca =  287 , M_lda =  19  --->  Accuracy = 74.04%\n",
      "M_pca =  287 , M_lda =  20  --->  Accuracy = 75.96%\n",
      "M_pca =  287 , M_lda =  21  --->  Accuracy = 76.92%\n",
      "M_pca =  287 , M_lda =  22  --->  Accuracy = 76.92%\n",
      "M_pca =  287 , M_lda =  23  --->  Accuracy = 77.88%\n",
      "M_pca =  287 , M_lda =  24  --->  Accuracy = 79.81%\n",
      "M_pca =  287 , M_lda =  25  --->  Accuracy = 80.77%\n",
      "M_pca =  287 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  287 , M_lda =  27  --->  Accuracy = 80.77%\n",
      "M_pca =  287 , M_lda =  28  --->  Accuracy = 80.77%\n",
      "M_pca =  287 , M_lda =  29  --->  Accuracy = 81.73%\n",
      "M_pca =  287 , M_lda =  30  --->  Accuracy = 81.73%\n",
      "M_pca =  287 , M_lda =  31  --->  Accuracy = 81.73%\n",
      "M_pca =  287 , M_lda =  32  --->  Accuracy = 81.73%\n",
      "M_pca =  287 , M_lda =  33  --->  Accuracy = 81.73%\n",
      "M_pca =  287 , M_lda =  34  --->  Accuracy = 80.77%\n",
      "M_pca =  287 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  287 , M_lda =  36  --->  Accuracy = 81.73%\n",
      "M_pca =  287 , M_lda =  37  --->  Accuracy = 81.73%\n",
      "M_pca =  287 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  287 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  287 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  287 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  287 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  287 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  287 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  287 , M_lda =  45  --->  Accuracy = 81.73%\n",
      "M_pca =  287 , M_lda =  46  --->  Accuracy = 81.73%\n",
      "M_pca =  287 , M_lda =  47  --->  Accuracy = 81.73%\n",
      "M_pca =  287 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  287 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  287 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  287 , M_lda =  51  --->  Accuracy = 83.65%\n",
      "M_pca =  288 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  288 , M_lda =  2  --->  Accuracy = 12.50%\n",
      "M_pca =  288 , M_lda =  3  --->  Accuracy = 26.92%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  288 , M_lda =  4  --->  Accuracy = 32.69%\n",
      "M_pca =  288 , M_lda =  5  --->  Accuracy = 42.31%\n",
      "M_pca =  288 , M_lda =  6  --->  Accuracy = 46.15%\n",
      "M_pca =  288 , M_lda =  7  --->  Accuracy = 51.92%\n",
      "M_pca =  288 , M_lda =  8  --->  Accuracy = 56.73%\n",
      "M_pca =  288 , M_lda =  9  --->  Accuracy = 54.81%\n",
      "M_pca =  288 , M_lda =  10  --->  Accuracy = 60.58%\n",
      "M_pca =  288 , M_lda =  11  --->  Accuracy = 69.23%\n",
      "M_pca =  288 , M_lda =  12  --->  Accuracy = 72.12%\n",
      "M_pca =  288 , M_lda =  13  --->  Accuracy = 72.12%\n",
      "M_pca =  288 , M_lda =  14  --->  Accuracy = 73.08%\n",
      "M_pca =  288 , M_lda =  15  --->  Accuracy = 73.08%\n",
      "M_pca =  288 , M_lda =  16  --->  Accuracy = 72.12%\n",
      "M_pca =  288 , M_lda =  17  --->  Accuracy = 74.04%\n",
      "M_pca =  288 , M_lda =  18  --->  Accuracy = 75.96%\n",
      "M_pca =  288 , M_lda =  19  --->  Accuracy = 74.04%\n",
      "M_pca =  288 , M_lda =  20  --->  Accuracy = 76.92%\n",
      "M_pca =  288 , M_lda =  21  --->  Accuracy = 77.88%\n",
      "M_pca =  288 , M_lda =  22  --->  Accuracy = 75.96%\n",
      "M_pca =  288 , M_lda =  23  --->  Accuracy = 76.92%\n",
      "M_pca =  288 , M_lda =  24  --->  Accuracy = 78.85%\n",
      "M_pca =  288 , M_lda =  25  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  26  --->  Accuracy = 82.69%\n",
      "M_pca =  288 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  29  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  30  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  31  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  32  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  33  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  34  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  36  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  37  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  45  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  46  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  47  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  49  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  288 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  289 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  289 , M_lda =  2  --->  Accuracy = 13.46%\n",
      "M_pca =  289 , M_lda =  3  --->  Accuracy = 22.12%\n",
      "M_pca =  289 , M_lda =  4  --->  Accuracy = 30.77%\n",
      "M_pca =  289 , M_lda =  5  --->  Accuracy = 44.23%\n",
      "M_pca =  289 , M_lda =  6  --->  Accuracy = 45.19%\n",
      "M_pca =  289 , M_lda =  7  --->  Accuracy = 48.08%\n",
      "M_pca =  289 , M_lda =  8  --->  Accuracy = 54.81%\n",
      "M_pca =  289 , M_lda =  9  --->  Accuracy = 55.77%\n",
      "M_pca =  289 , M_lda =  10  --->  Accuracy = 60.58%\n",
      "M_pca =  289 , M_lda =  11  --->  Accuracy = 67.31%\n",
      "M_pca =  289 , M_lda =  12  --->  Accuracy = 70.19%\n",
      "M_pca =  289 , M_lda =  13  --->  Accuracy = 69.23%\n",
      "M_pca =  289 , M_lda =  14  --->  Accuracy = 72.12%\n",
      "M_pca =  289 , M_lda =  15  --->  Accuracy = 72.12%\n",
      "M_pca =  289 , M_lda =  16  --->  Accuracy = 73.08%\n",
      "M_pca =  289 , M_lda =  17  --->  Accuracy = 74.04%\n",
      "M_pca =  289 , M_lda =  18  --->  Accuracy = 74.04%\n",
      "M_pca =  289 , M_lda =  19  --->  Accuracy = 75.96%\n",
      "M_pca =  289 , M_lda =  20  --->  Accuracy = 75.96%\n",
      "M_pca =  289 , M_lda =  21  --->  Accuracy = 75.00%\n",
      "M_pca =  289 , M_lda =  22  --->  Accuracy = 76.92%\n",
      "M_pca =  289 , M_lda =  23  --->  Accuracy = 77.88%\n",
      "M_pca =  289 , M_lda =  24  --->  Accuracy = 78.85%\n",
      "M_pca =  289 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  289 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  289 , M_lda =  27  --->  Accuracy = 80.77%\n",
      "M_pca =  289 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  29  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  30  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  31  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  32  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  33  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  34  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  36  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  37  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  38  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  45  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  46  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  47  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  49  --->  Accuracy = 81.73%\n",
      "M_pca =  289 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  289 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  290 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  290 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  290 , M_lda =  3  --->  Accuracy = 23.08%\n",
      "M_pca =  290 , M_lda =  4  --->  Accuracy = 30.77%\n",
      "M_pca =  290 , M_lda =  5  --->  Accuracy = 42.31%\n",
      "M_pca =  290 , M_lda =  6  --->  Accuracy = 48.08%\n",
      "M_pca =  290 , M_lda =  7  --->  Accuracy = 53.85%\n",
      "M_pca =  290 , M_lda =  8  --->  Accuracy = 55.77%\n",
      "M_pca =  290 , M_lda =  9  --->  Accuracy = 55.77%\n",
      "M_pca =  290 , M_lda =  10  --->  Accuracy = 64.42%\n",
      "M_pca =  290 , M_lda =  11  --->  Accuracy = 67.31%\n",
      "M_pca =  290 , M_lda =  12  --->  Accuracy = 70.19%\n",
      "M_pca =  290 , M_lda =  13  --->  Accuracy = 71.15%\n",
      "M_pca =  290 , M_lda =  14  --->  Accuracy = 72.12%\n",
      "M_pca =  290 , M_lda =  15  --->  Accuracy = 73.08%\n",
      "M_pca =  290 , M_lda =  16  --->  Accuracy = 73.08%\n",
      "M_pca =  290 , M_lda =  17  --->  Accuracy = 74.04%\n",
      "M_pca =  290 , M_lda =  18  --->  Accuracy = 73.08%\n",
      "M_pca =  290 , M_lda =  19  --->  Accuracy = 75.96%\n",
      "M_pca =  290 , M_lda =  20  --->  Accuracy = 75.00%\n",
      "M_pca =  290 , M_lda =  21  --->  Accuracy = 75.96%\n",
      "M_pca =  290 , M_lda =  22  --->  Accuracy = 75.96%\n",
      "M_pca =  290 , M_lda =  23  --->  Accuracy = 75.96%\n",
      "M_pca =  290 , M_lda =  24  --->  Accuracy = 76.92%\n",
      "M_pca =  290 , M_lda =  25  --->  Accuracy = 78.85%\n",
      "M_pca =  290 , M_lda =  26  --->  Accuracy = 80.77%\n",
      "M_pca =  290 , M_lda =  27  --->  Accuracy = 81.73%\n",
      "M_pca =  290 , M_lda =  28  --->  Accuracy = 82.69%\n",
      "M_pca =  290 , M_lda =  29  --->  Accuracy = 83.65%\n",
      "M_pca =  290 , M_lda =  30  --->  Accuracy = 81.73%\n",
      "M_pca =  290 , M_lda =  31  --->  Accuracy = 82.69%\n",
      "M_pca =  290 , M_lda =  32  --->  Accuracy = 82.69%\n",
      "M_pca =  290 , M_lda =  33  --->  Accuracy = 81.73%\n",
      "M_pca =  290 , M_lda =  34  --->  Accuracy = 82.69%\n",
      "M_pca =  290 , M_lda =  35  --->  Accuracy = 81.73%\n",
      "M_pca =  290 , M_lda =  36  --->  Accuracy = 82.69%\n",
      "M_pca =  290 , M_lda =  37  --->  Accuracy = 82.69%\n",
      "M_pca =  290 , M_lda =  38  --->  Accuracy = 82.69%\n",
      "M_pca =  290 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  290 , M_lda =  40  --->  Accuracy = 82.69%\n",
      "M_pca =  290 , M_lda =  41  --->  Accuracy = 82.69%\n",
      "M_pca =  290 , M_lda =  42  --->  Accuracy = 82.69%\n",
      "M_pca =  290 , M_lda =  43  --->  Accuracy = 83.65%\n",
      "M_pca =  290 , M_lda =  44  --->  Accuracy = 83.65%\n",
      "M_pca =  290 , M_lda =  45  --->  Accuracy = 83.65%\n",
      "M_pca =  290 , M_lda =  46  --->  Accuracy = 84.62%\n",
      "M_pca =  290 , M_lda =  47  --->  Accuracy = 84.62%\n",
      "M_pca =  290 , M_lda =  48  --->  Accuracy = 84.62%\n",
      "M_pca =  290 , M_lda =  49  --->  Accuracy = 84.62%\n",
      "M_pca =  290 , M_lda =  50  --->  Accuracy = 84.62%\n",
      "M_pca =  290 , M_lda =  51  --->  Accuracy = 85.58%\n",
      "M_pca =  291 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  291 , M_lda =  2  --->  Accuracy = 13.46%\n",
      "M_pca =  291 , M_lda =  3  --->  Accuracy = 23.08%\n",
      "M_pca =  291 , M_lda =  4  --->  Accuracy = 31.73%\n",
      "M_pca =  291 , M_lda =  5  --->  Accuracy = 39.42%\n",
      "M_pca =  291 , M_lda =  6  --->  Accuracy = 43.27%\n",
      "M_pca =  291 , M_lda =  7  --->  Accuracy = 49.04%\n",
      "M_pca =  291 , M_lda =  8  --->  Accuracy = 55.77%\n",
      "M_pca =  291 , M_lda =  9  --->  Accuracy = 55.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  291 , M_lda =  10  --->  Accuracy = 63.46%\n",
      "M_pca =  291 , M_lda =  11  --->  Accuracy = 65.38%\n",
      "M_pca =  291 , M_lda =  12  --->  Accuracy = 66.35%\n",
      "M_pca =  291 , M_lda =  13  --->  Accuracy = 69.23%\n",
      "M_pca =  291 , M_lda =  14  --->  Accuracy = 71.15%\n",
      "M_pca =  291 , M_lda =  15  --->  Accuracy = 73.08%\n",
      "M_pca =  291 , M_lda =  16  --->  Accuracy = 73.08%\n",
      "M_pca =  291 , M_lda =  17  --->  Accuracy = 74.04%\n",
      "M_pca =  291 , M_lda =  18  --->  Accuracy = 70.19%\n",
      "M_pca =  291 , M_lda =  19  --->  Accuracy = 73.08%\n",
      "M_pca =  291 , M_lda =  20  --->  Accuracy = 73.08%\n",
      "M_pca =  291 , M_lda =  21  --->  Accuracy = 75.00%\n",
      "M_pca =  291 , M_lda =  22  --->  Accuracy = 75.96%\n",
      "M_pca =  291 , M_lda =  23  --->  Accuracy = 77.88%\n",
      "M_pca =  291 , M_lda =  24  --->  Accuracy = 78.85%\n",
      "M_pca =  291 , M_lda =  25  --->  Accuracy = 77.88%\n",
      "M_pca =  291 , M_lda =  26  --->  Accuracy = 79.81%\n",
      "M_pca =  291 , M_lda =  27  --->  Accuracy = 80.77%\n",
      "M_pca =  291 , M_lda =  28  --->  Accuracy = 81.73%\n",
      "M_pca =  291 , M_lda =  29  --->  Accuracy = 81.73%\n",
      "M_pca =  291 , M_lda =  30  --->  Accuracy = 81.73%\n",
      "M_pca =  291 , M_lda =  31  --->  Accuracy = 80.77%\n",
      "M_pca =  291 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  291 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  291 , M_lda =  34  --->  Accuracy = 81.73%\n",
      "M_pca =  291 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  291 , M_lda =  36  --->  Accuracy = 80.77%\n",
      "M_pca =  291 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  291 , M_lda =  38  --->  Accuracy = 80.77%\n",
      "M_pca =  291 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  291 , M_lda =  40  --->  Accuracy = 81.73%\n",
      "M_pca =  291 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  291 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  291 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  291 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  291 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  291 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  291 , M_lda =  47  --->  Accuracy = 82.69%\n",
      "M_pca =  291 , M_lda =  48  --->  Accuracy = 83.65%\n",
      "M_pca =  291 , M_lda =  49  --->  Accuracy = 83.65%\n",
      "M_pca =  291 , M_lda =  50  --->  Accuracy = 83.65%\n",
      "M_pca =  291 , M_lda =  51  --->  Accuracy = 84.62%\n",
      "M_pca =  292 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  292 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  292 , M_lda =  3  --->  Accuracy = 22.12%\n",
      "M_pca =  292 , M_lda =  4  --->  Accuracy = 29.81%\n",
      "M_pca =  292 , M_lda =  5  --->  Accuracy = 39.42%\n",
      "M_pca =  292 , M_lda =  6  --->  Accuracy = 39.42%\n",
      "M_pca =  292 , M_lda =  7  --->  Accuracy = 47.12%\n",
      "M_pca =  292 , M_lda =  8  --->  Accuracy = 55.77%\n",
      "M_pca =  292 , M_lda =  9  --->  Accuracy = 52.88%\n",
      "M_pca =  292 , M_lda =  10  --->  Accuracy = 62.50%\n",
      "M_pca =  292 , M_lda =  11  --->  Accuracy = 62.50%\n",
      "M_pca =  292 , M_lda =  12  --->  Accuracy = 66.35%\n",
      "M_pca =  292 , M_lda =  13  --->  Accuracy = 69.23%\n",
      "M_pca =  292 , M_lda =  14  --->  Accuracy = 72.12%\n",
      "M_pca =  292 , M_lda =  15  --->  Accuracy = 69.23%\n",
      "M_pca =  292 , M_lda =  16  --->  Accuracy = 70.19%\n",
      "M_pca =  292 , M_lda =  17  --->  Accuracy = 71.15%\n",
      "M_pca =  292 , M_lda =  18  --->  Accuracy = 69.23%\n",
      "M_pca =  292 , M_lda =  19  --->  Accuracy = 73.08%\n",
      "M_pca =  292 , M_lda =  20  --->  Accuracy = 74.04%\n",
      "M_pca =  292 , M_lda =  21  --->  Accuracy = 75.00%\n",
      "M_pca =  292 , M_lda =  22  --->  Accuracy = 75.00%\n",
      "M_pca =  292 , M_lda =  23  --->  Accuracy = 76.92%\n",
      "M_pca =  292 , M_lda =  24  --->  Accuracy = 77.88%\n",
      "M_pca =  292 , M_lda =  25  --->  Accuracy = 77.88%\n",
      "M_pca =  292 , M_lda =  26  --->  Accuracy = 77.88%\n",
      "M_pca =  292 , M_lda =  27  --->  Accuracy = 78.85%\n",
      "M_pca =  292 , M_lda =  28  --->  Accuracy = 78.85%\n",
      "M_pca =  292 , M_lda =  29  --->  Accuracy = 80.77%\n",
      "M_pca =  292 , M_lda =  30  --->  Accuracy = 80.77%\n",
      "M_pca =  292 , M_lda =  31  --->  Accuracy = 80.77%\n",
      "M_pca =  292 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  292 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  292 , M_lda =  34  --->  Accuracy = 80.77%\n",
      "M_pca =  292 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  292 , M_lda =  36  --->  Accuracy = 80.77%\n",
      "M_pca =  292 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  292 , M_lda =  38  --->  Accuracy = 80.77%\n",
      "M_pca =  292 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  292 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  292 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  292 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  292 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  292 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  292 , M_lda =  45  --->  Accuracy = 81.73%\n",
      "M_pca =  292 , M_lda =  46  --->  Accuracy = 81.73%\n",
      "M_pca =  292 , M_lda =  47  --->  Accuracy = 82.69%\n",
      "M_pca =  292 , M_lda =  48  --->  Accuracy = 82.69%\n",
      "M_pca =  292 , M_lda =  49  --->  Accuracy = 83.65%\n",
      "M_pca =  292 , M_lda =  50  --->  Accuracy = 83.65%\n",
      "M_pca =  292 , M_lda =  51  --->  Accuracy = 83.65%\n",
      "M_pca =  293 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  293 , M_lda =  2  --->  Accuracy = 13.46%\n",
      "M_pca =  293 , M_lda =  3  --->  Accuracy = 22.12%\n",
      "M_pca =  293 , M_lda =  4  --->  Accuracy = 31.73%\n",
      "M_pca =  293 , M_lda =  5  --->  Accuracy = 38.46%\n",
      "M_pca =  293 , M_lda =  6  --->  Accuracy = 41.35%\n",
      "M_pca =  293 , M_lda =  7  --->  Accuracy = 50.00%\n",
      "M_pca =  293 , M_lda =  8  --->  Accuracy = 52.88%\n",
      "M_pca =  293 , M_lda =  9  --->  Accuracy = 55.77%\n",
      "M_pca =  293 , M_lda =  10  --->  Accuracy = 64.42%\n",
      "M_pca =  293 , M_lda =  11  --->  Accuracy = 63.46%\n",
      "M_pca =  293 , M_lda =  12  --->  Accuracy = 66.35%\n",
      "M_pca =  293 , M_lda =  13  --->  Accuracy = 68.27%\n",
      "M_pca =  293 , M_lda =  14  --->  Accuracy = 68.27%\n",
      "M_pca =  293 , M_lda =  15  --->  Accuracy = 69.23%\n",
      "M_pca =  293 , M_lda =  16  --->  Accuracy = 69.23%\n",
      "M_pca =  293 , M_lda =  17  --->  Accuracy = 71.15%\n",
      "M_pca =  293 , M_lda =  18  --->  Accuracy = 70.19%\n",
      "M_pca =  293 , M_lda =  19  --->  Accuracy = 71.15%\n",
      "M_pca =  293 , M_lda =  20  --->  Accuracy = 72.12%\n",
      "M_pca =  293 , M_lda =  21  --->  Accuracy = 72.12%\n",
      "M_pca =  293 , M_lda =  22  --->  Accuracy = 75.00%\n",
      "M_pca =  293 , M_lda =  23  --->  Accuracy = 75.00%\n",
      "M_pca =  293 , M_lda =  24  --->  Accuracy = 77.88%\n",
      "M_pca =  293 , M_lda =  25  --->  Accuracy = 78.85%\n",
      "M_pca =  293 , M_lda =  26  --->  Accuracy = 77.88%\n",
      "M_pca =  293 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  293 , M_lda =  28  --->  Accuracy = 80.77%\n",
      "M_pca =  293 , M_lda =  29  --->  Accuracy = 80.77%\n",
      "M_pca =  293 , M_lda =  30  --->  Accuracy = 80.77%\n",
      "M_pca =  293 , M_lda =  31  --->  Accuracy = 80.77%\n",
      "M_pca =  293 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  293 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  293 , M_lda =  34  --->  Accuracy = 80.77%\n",
      "M_pca =  293 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  293 , M_lda =  36  --->  Accuracy = 80.77%\n",
      "M_pca =  293 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  293 , M_lda =  38  --->  Accuracy = 80.77%\n",
      "M_pca =  293 , M_lda =  39  --->  Accuracy = 81.73%\n",
      "M_pca =  293 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  293 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  293 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  293 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  293 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  293 , M_lda =  45  --->  Accuracy = 81.73%\n",
      "M_pca =  293 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  293 , M_lda =  47  --->  Accuracy = 82.69%\n",
      "M_pca =  293 , M_lda =  48  --->  Accuracy = 83.65%\n",
      "M_pca =  293 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  293 , M_lda =  50  --->  Accuracy = 83.65%\n",
      "M_pca =  293 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  294 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  294 , M_lda =  2  --->  Accuracy = 13.46%\n",
      "M_pca =  294 , M_lda =  3  --->  Accuracy = 22.12%\n",
      "M_pca =  294 , M_lda =  4  --->  Accuracy = 30.77%\n",
      "M_pca =  294 , M_lda =  5  --->  Accuracy = 38.46%\n",
      "M_pca =  294 , M_lda =  6  --->  Accuracy = 41.35%\n",
      "M_pca =  294 , M_lda =  7  --->  Accuracy = 50.00%\n",
      "M_pca =  294 , M_lda =  8  --->  Accuracy = 50.96%\n",
      "M_pca =  294 , M_lda =  9  --->  Accuracy = 54.81%\n",
      "M_pca =  294 , M_lda =  10  --->  Accuracy = 65.38%\n",
      "M_pca =  294 , M_lda =  11  --->  Accuracy = 65.38%\n",
      "M_pca =  294 , M_lda =  12  --->  Accuracy = 69.23%\n",
      "M_pca =  294 , M_lda =  13  --->  Accuracy = 68.27%\n",
      "M_pca =  294 , M_lda =  14  --->  Accuracy = 67.31%\n",
      "M_pca =  294 , M_lda =  15  --->  Accuracy = 68.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  294 , M_lda =  16  --->  Accuracy = 68.27%\n",
      "M_pca =  294 , M_lda =  17  --->  Accuracy = 73.08%\n",
      "M_pca =  294 , M_lda =  18  --->  Accuracy = 72.12%\n",
      "M_pca =  294 , M_lda =  19  --->  Accuracy = 74.04%\n",
      "M_pca =  294 , M_lda =  20  --->  Accuracy = 74.04%\n",
      "M_pca =  294 , M_lda =  21  --->  Accuracy = 75.00%\n",
      "M_pca =  294 , M_lda =  22  --->  Accuracy = 75.00%\n",
      "M_pca =  294 , M_lda =  23  --->  Accuracy = 75.96%\n",
      "M_pca =  294 , M_lda =  24  --->  Accuracy = 75.96%\n",
      "M_pca =  294 , M_lda =  25  --->  Accuracy = 78.85%\n",
      "M_pca =  294 , M_lda =  26  --->  Accuracy = 77.88%\n",
      "M_pca =  294 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  294 , M_lda =  28  --->  Accuracy = 79.81%\n",
      "M_pca =  294 , M_lda =  29  --->  Accuracy = 80.77%\n",
      "M_pca =  294 , M_lda =  30  --->  Accuracy = 80.77%\n",
      "M_pca =  294 , M_lda =  31  --->  Accuracy = 80.77%\n",
      "M_pca =  294 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  294 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  294 , M_lda =  34  --->  Accuracy = 80.77%\n",
      "M_pca =  294 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  294 , M_lda =  36  --->  Accuracy = 80.77%\n",
      "M_pca =  294 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  294 , M_lda =  38  --->  Accuracy = 80.77%\n",
      "M_pca =  294 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  294 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  294 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  294 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  294 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  294 , M_lda =  44  --->  Accuracy = 82.69%\n",
      "M_pca =  294 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  294 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  294 , M_lda =  47  --->  Accuracy = 82.69%\n",
      "M_pca =  294 , M_lda =  48  --->  Accuracy = 82.69%\n",
      "M_pca =  294 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  294 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  294 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  295 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  295 , M_lda =  2  --->  Accuracy = 13.46%\n",
      "M_pca =  295 , M_lda =  3  --->  Accuracy = 24.04%\n",
      "M_pca =  295 , M_lda =  4  --->  Accuracy = 28.85%\n",
      "M_pca =  295 , M_lda =  5  --->  Accuracy = 36.54%\n",
      "M_pca =  295 , M_lda =  6  --->  Accuracy = 43.27%\n",
      "M_pca =  295 , M_lda =  7  --->  Accuracy = 48.08%\n",
      "M_pca =  295 , M_lda =  8  --->  Accuracy = 50.00%\n",
      "M_pca =  295 , M_lda =  9  --->  Accuracy = 53.85%\n",
      "M_pca =  295 , M_lda =  10  --->  Accuracy = 61.54%\n",
      "M_pca =  295 , M_lda =  11  --->  Accuracy = 62.50%\n",
      "M_pca =  295 , M_lda =  12  --->  Accuracy = 65.38%\n",
      "M_pca =  295 , M_lda =  13  --->  Accuracy = 65.38%\n",
      "M_pca =  295 , M_lda =  14  --->  Accuracy = 68.27%\n",
      "M_pca =  295 , M_lda =  15  --->  Accuracy = 69.23%\n",
      "M_pca =  295 , M_lda =  16  --->  Accuracy = 67.31%\n",
      "M_pca =  295 , M_lda =  17  --->  Accuracy = 70.19%\n",
      "M_pca =  295 , M_lda =  18  --->  Accuracy = 72.12%\n",
      "M_pca =  295 , M_lda =  19  --->  Accuracy = 74.04%\n",
      "M_pca =  295 , M_lda =  20  --->  Accuracy = 75.00%\n",
      "M_pca =  295 , M_lda =  21  --->  Accuracy = 75.00%\n",
      "M_pca =  295 , M_lda =  22  --->  Accuracy = 75.00%\n",
      "M_pca =  295 , M_lda =  23  --->  Accuracy = 75.00%\n",
      "M_pca =  295 , M_lda =  24  --->  Accuracy = 76.92%\n",
      "M_pca =  295 , M_lda =  25  --->  Accuracy = 79.81%\n",
      "M_pca =  295 , M_lda =  26  --->  Accuracy = 79.81%\n",
      "M_pca =  295 , M_lda =  27  --->  Accuracy = 78.85%\n",
      "M_pca =  295 , M_lda =  28  --->  Accuracy = 79.81%\n",
      "M_pca =  295 , M_lda =  29  --->  Accuracy = 79.81%\n",
      "M_pca =  295 , M_lda =  30  --->  Accuracy = 79.81%\n",
      "M_pca =  295 , M_lda =  31  --->  Accuracy = 80.77%\n",
      "M_pca =  295 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  295 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  295 , M_lda =  34  --->  Accuracy = 80.77%\n",
      "M_pca =  295 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  295 , M_lda =  36  --->  Accuracy = 80.77%\n",
      "M_pca =  295 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  295 , M_lda =  38  --->  Accuracy = 80.77%\n",
      "M_pca =  295 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  295 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  295 , M_lda =  41  --->  Accuracy = 81.73%\n",
      "M_pca =  295 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  295 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  295 , M_lda =  44  --->  Accuracy = 82.69%\n",
      "M_pca =  295 , M_lda =  45  --->  Accuracy = 82.69%\n",
      "M_pca =  295 , M_lda =  46  --->  Accuracy = 82.69%\n",
      "M_pca =  295 , M_lda =  47  --->  Accuracy = 82.69%\n",
      "M_pca =  295 , M_lda =  48  --->  Accuracy = 82.69%\n",
      "M_pca =  295 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  295 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  295 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  296 , M_lda =  1  --->  Accuracy = 10.58%\n",
      "M_pca =  296 , M_lda =  2  --->  Accuracy = 13.46%\n",
      "M_pca =  296 , M_lda =  3  --->  Accuracy = 22.12%\n",
      "M_pca =  296 , M_lda =  4  --->  Accuracy = 30.77%\n",
      "M_pca =  296 , M_lda =  5  --->  Accuracy = 36.54%\n",
      "M_pca =  296 , M_lda =  6  --->  Accuracy = 42.31%\n",
      "M_pca =  296 , M_lda =  7  --->  Accuracy = 50.00%\n",
      "M_pca =  296 , M_lda =  8  --->  Accuracy = 50.00%\n",
      "M_pca =  296 , M_lda =  9  --->  Accuracy = 52.88%\n",
      "M_pca =  296 , M_lda =  10  --->  Accuracy = 61.54%\n",
      "M_pca =  296 , M_lda =  11  --->  Accuracy = 62.50%\n",
      "M_pca =  296 , M_lda =  12  --->  Accuracy = 66.35%\n",
      "M_pca =  296 , M_lda =  13  --->  Accuracy = 66.35%\n",
      "M_pca =  296 , M_lda =  14  --->  Accuracy = 68.27%\n",
      "M_pca =  296 , M_lda =  15  --->  Accuracy = 68.27%\n",
      "M_pca =  296 , M_lda =  16  --->  Accuracy = 68.27%\n",
      "M_pca =  296 , M_lda =  17  --->  Accuracy = 72.12%\n",
      "M_pca =  296 , M_lda =  18  --->  Accuracy = 72.12%\n",
      "M_pca =  296 , M_lda =  19  --->  Accuracy = 74.04%\n",
      "M_pca =  296 , M_lda =  20  --->  Accuracy = 75.00%\n",
      "M_pca =  296 , M_lda =  21  --->  Accuracy = 75.96%\n",
      "M_pca =  296 , M_lda =  22  --->  Accuracy = 75.96%\n",
      "M_pca =  296 , M_lda =  23  --->  Accuracy = 76.92%\n",
      "M_pca =  296 , M_lda =  24  --->  Accuracy = 76.92%\n",
      "M_pca =  296 , M_lda =  25  --->  Accuracy = 78.85%\n",
      "M_pca =  296 , M_lda =  26  --->  Accuracy = 79.81%\n",
      "M_pca =  296 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  296 , M_lda =  28  --->  Accuracy = 79.81%\n",
      "M_pca =  296 , M_lda =  29  --->  Accuracy = 79.81%\n",
      "M_pca =  296 , M_lda =  30  --->  Accuracy = 80.77%\n",
      "M_pca =  296 , M_lda =  31  --->  Accuracy = 80.77%\n",
      "M_pca =  296 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  296 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  296 , M_lda =  34  --->  Accuracy = 80.77%\n",
      "M_pca =  296 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  296 , M_lda =  36  --->  Accuracy = 80.77%\n",
      "M_pca =  296 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  296 , M_lda =  38  --->  Accuracy = 80.77%\n",
      "M_pca =  296 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  296 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  296 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  296 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  296 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  296 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  296 , M_lda =  45  --->  Accuracy = 81.73%\n",
      "M_pca =  296 , M_lda =  46  --->  Accuracy = 81.73%\n",
      "M_pca =  296 , M_lda =  47  --->  Accuracy = 81.73%\n",
      "M_pca =  296 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  296 , M_lda =  49  --->  Accuracy = 81.73%\n",
      "M_pca =  296 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  296 , M_lda =  51  --->  Accuracy = 81.73%\n",
      "M_pca =  297 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  297 , M_lda =  2  --->  Accuracy = 11.54%\n",
      "M_pca =  297 , M_lda =  3  --->  Accuracy = 22.12%\n",
      "M_pca =  297 , M_lda =  4  --->  Accuracy = 30.77%\n",
      "M_pca =  297 , M_lda =  5  --->  Accuracy = 36.54%\n",
      "M_pca =  297 , M_lda =  6  --->  Accuracy = 42.31%\n",
      "M_pca =  297 , M_lda =  7  --->  Accuracy = 49.04%\n",
      "M_pca =  297 , M_lda =  8  --->  Accuracy = 54.81%\n",
      "M_pca =  297 , M_lda =  9  --->  Accuracy = 59.62%\n",
      "M_pca =  297 , M_lda =  10  --->  Accuracy = 61.54%\n",
      "M_pca =  297 , M_lda =  11  --->  Accuracy = 62.50%\n",
      "M_pca =  297 , M_lda =  12  --->  Accuracy = 63.46%\n",
      "M_pca =  297 , M_lda =  13  --->  Accuracy = 65.38%\n",
      "M_pca =  297 , M_lda =  14  --->  Accuracy = 67.31%\n",
      "M_pca =  297 , M_lda =  15  --->  Accuracy = 68.27%\n",
      "M_pca =  297 , M_lda =  16  --->  Accuracy = 68.27%\n",
      "M_pca =  297 , M_lda =  17  --->  Accuracy = 70.19%\n",
      "M_pca =  297 , M_lda =  18  --->  Accuracy = 72.12%\n",
      "M_pca =  297 , M_lda =  19  --->  Accuracy = 73.08%\n",
      "M_pca =  297 , M_lda =  20  --->  Accuracy = 75.00%\n",
      "M_pca =  297 , M_lda =  21  --->  Accuracy = 75.96%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  297 , M_lda =  22  --->  Accuracy = 75.96%\n",
      "M_pca =  297 , M_lda =  23  --->  Accuracy = 76.92%\n",
      "M_pca =  297 , M_lda =  24  --->  Accuracy = 75.00%\n",
      "M_pca =  297 , M_lda =  25  --->  Accuracy = 76.92%\n",
      "M_pca =  297 , M_lda =  26  --->  Accuracy = 76.92%\n",
      "M_pca =  297 , M_lda =  27  --->  Accuracy = 77.88%\n",
      "M_pca =  297 , M_lda =  28  --->  Accuracy = 79.81%\n",
      "M_pca =  297 , M_lda =  29  --->  Accuracy = 79.81%\n",
      "M_pca =  297 , M_lda =  30  --->  Accuracy = 78.85%\n",
      "M_pca =  297 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  297 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  297 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  297 , M_lda =  34  --->  Accuracy = 80.77%\n",
      "M_pca =  297 , M_lda =  35  --->  Accuracy = 79.81%\n",
      "M_pca =  297 , M_lda =  36  --->  Accuracy = 79.81%\n",
      "M_pca =  297 , M_lda =  37  --->  Accuracy = 79.81%\n",
      "M_pca =  297 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  297 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  297 , M_lda =  40  --->  Accuracy = 79.81%\n",
      "M_pca =  297 , M_lda =  41  --->  Accuracy = 79.81%\n",
      "M_pca =  297 , M_lda =  42  --->  Accuracy = 80.77%\n",
      "M_pca =  297 , M_lda =  43  --->  Accuracy = 80.77%\n",
      "M_pca =  297 , M_lda =  44  --->  Accuracy = 80.77%\n",
      "M_pca =  297 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  297 , M_lda =  46  --->  Accuracy = 81.73%\n",
      "M_pca =  297 , M_lda =  47  --->  Accuracy = 81.73%\n",
      "M_pca =  297 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  297 , M_lda =  49  --->  Accuracy = 81.73%\n",
      "M_pca =  297 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  297 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  298 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  298 , M_lda =  2  --->  Accuracy = 10.58%\n",
      "M_pca =  298 , M_lda =  3  --->  Accuracy = 23.08%\n",
      "M_pca =  298 , M_lda =  4  --->  Accuracy = 30.77%\n",
      "M_pca =  298 , M_lda =  5  --->  Accuracy = 38.46%\n",
      "M_pca =  298 , M_lda =  6  --->  Accuracy = 39.42%\n",
      "M_pca =  298 , M_lda =  7  --->  Accuracy = 46.15%\n",
      "M_pca =  298 , M_lda =  8  --->  Accuracy = 50.00%\n",
      "M_pca =  298 , M_lda =  9  --->  Accuracy = 54.81%\n",
      "M_pca =  298 , M_lda =  10  --->  Accuracy = 55.77%\n",
      "M_pca =  298 , M_lda =  11  --->  Accuracy = 62.50%\n",
      "M_pca =  298 , M_lda =  12  --->  Accuracy = 63.46%\n",
      "M_pca =  298 , M_lda =  13  --->  Accuracy = 66.35%\n",
      "M_pca =  298 , M_lda =  14  --->  Accuracy = 68.27%\n",
      "M_pca =  298 , M_lda =  15  --->  Accuracy = 66.35%\n",
      "M_pca =  298 , M_lda =  16  --->  Accuracy = 65.38%\n",
      "M_pca =  298 , M_lda =  17  --->  Accuracy = 68.27%\n",
      "M_pca =  298 , M_lda =  18  --->  Accuracy = 70.19%\n",
      "M_pca =  298 , M_lda =  19  --->  Accuracy = 73.08%\n",
      "M_pca =  298 , M_lda =  20  --->  Accuracy = 75.00%\n",
      "M_pca =  298 , M_lda =  21  --->  Accuracy = 74.04%\n",
      "M_pca =  298 , M_lda =  22  --->  Accuracy = 74.04%\n",
      "M_pca =  298 , M_lda =  23  --->  Accuracy = 75.00%\n",
      "M_pca =  298 , M_lda =  24  --->  Accuracy = 75.00%\n",
      "M_pca =  298 , M_lda =  25  --->  Accuracy = 76.92%\n",
      "M_pca =  298 , M_lda =  26  --->  Accuracy = 75.00%\n",
      "M_pca =  298 , M_lda =  27  --->  Accuracy = 75.00%\n",
      "M_pca =  298 , M_lda =  28  --->  Accuracy = 76.92%\n",
      "M_pca =  298 , M_lda =  29  --->  Accuracy = 77.88%\n",
      "M_pca =  298 , M_lda =  30  --->  Accuracy = 79.81%\n",
      "M_pca =  298 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  298 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  298 , M_lda =  33  --->  Accuracy = 79.81%\n",
      "M_pca =  298 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  298 , M_lda =  35  --->  Accuracy = 79.81%\n",
      "M_pca =  298 , M_lda =  36  --->  Accuracy = 79.81%\n",
      "M_pca =  298 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  298 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  298 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  298 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  298 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  298 , M_lda =  42  --->  Accuracy = 81.73%\n",
      "M_pca =  298 , M_lda =  43  --->  Accuracy = 81.73%\n",
      "M_pca =  298 , M_lda =  44  --->  Accuracy = 81.73%\n",
      "M_pca =  298 , M_lda =  45  --->  Accuracy = 81.73%\n",
      "M_pca =  298 , M_lda =  46  --->  Accuracy = 81.73%\n",
      "M_pca =  298 , M_lda =  47  --->  Accuracy = 81.73%\n",
      "M_pca =  298 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  298 , M_lda =  49  --->  Accuracy = 81.73%\n",
      "M_pca =  298 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  298 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  299 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  299 , M_lda =  2  --->  Accuracy = 9.62%\n",
      "M_pca =  299 , M_lda =  3  --->  Accuracy = 20.19%\n",
      "M_pca =  299 , M_lda =  4  --->  Accuracy = 31.73%\n",
      "M_pca =  299 , M_lda =  5  --->  Accuracy = 39.42%\n",
      "M_pca =  299 , M_lda =  6  --->  Accuracy = 47.12%\n",
      "M_pca =  299 , M_lda =  7  --->  Accuracy = 46.15%\n",
      "M_pca =  299 , M_lda =  8  --->  Accuracy = 50.00%\n",
      "M_pca =  299 , M_lda =  9  --->  Accuracy = 56.73%\n",
      "M_pca =  299 , M_lda =  10  --->  Accuracy = 57.69%\n",
      "M_pca =  299 , M_lda =  11  --->  Accuracy = 60.58%\n",
      "M_pca =  299 , M_lda =  12  --->  Accuracy = 63.46%\n",
      "M_pca =  299 , M_lda =  13  --->  Accuracy = 67.31%\n",
      "M_pca =  299 , M_lda =  14  --->  Accuracy = 70.19%\n",
      "M_pca =  299 , M_lda =  15  --->  Accuracy = 69.23%\n",
      "M_pca =  299 , M_lda =  16  --->  Accuracy = 69.23%\n",
      "M_pca =  299 , M_lda =  17  --->  Accuracy = 70.19%\n",
      "M_pca =  299 , M_lda =  18  --->  Accuracy = 72.12%\n",
      "M_pca =  299 , M_lda =  19  --->  Accuracy = 71.15%\n",
      "M_pca =  299 , M_lda =  20  --->  Accuracy = 75.96%\n",
      "M_pca =  299 , M_lda =  21  --->  Accuracy = 75.96%\n",
      "M_pca =  299 , M_lda =  22  --->  Accuracy = 75.96%\n",
      "M_pca =  299 , M_lda =  23  --->  Accuracy = 76.92%\n",
      "M_pca =  299 , M_lda =  24  --->  Accuracy = 75.96%\n",
      "M_pca =  299 , M_lda =  25  --->  Accuracy = 75.96%\n",
      "M_pca =  299 , M_lda =  26  --->  Accuracy = 75.96%\n",
      "M_pca =  299 , M_lda =  27  --->  Accuracy = 76.92%\n",
      "M_pca =  299 , M_lda =  28  --->  Accuracy = 78.85%\n",
      "M_pca =  299 , M_lda =  29  --->  Accuracy = 78.85%\n",
      "M_pca =  299 , M_lda =  30  --->  Accuracy = 78.85%\n",
      "M_pca =  299 , M_lda =  31  --->  Accuracy = 78.85%\n",
      "M_pca =  299 , M_lda =  32  --->  Accuracy = 78.85%\n",
      "M_pca =  299 , M_lda =  33  --->  Accuracy = 78.85%\n",
      "M_pca =  299 , M_lda =  34  --->  Accuracy = 78.85%\n",
      "M_pca =  299 , M_lda =  35  --->  Accuracy = 78.85%\n",
      "M_pca =  299 , M_lda =  36  --->  Accuracy = 79.81%\n",
      "M_pca =  299 , M_lda =  37  --->  Accuracy = 79.81%\n",
      "M_pca =  299 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  299 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  299 , M_lda =  40  --->  Accuracy = 79.81%\n",
      "M_pca =  299 , M_lda =  41  --->  Accuracy = 79.81%\n",
      "M_pca =  299 , M_lda =  42  --->  Accuracy = 79.81%\n",
      "M_pca =  299 , M_lda =  43  --->  Accuracy = 80.77%\n",
      "M_pca =  299 , M_lda =  44  --->  Accuracy = 80.77%\n",
      "M_pca =  299 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  299 , M_lda =  46  --->  Accuracy = 81.73%\n",
      "M_pca =  299 , M_lda =  47  --->  Accuracy = 81.73%\n",
      "M_pca =  299 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  299 , M_lda =  49  --->  Accuracy = 81.73%\n",
      "M_pca =  299 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  299 , M_lda =  51  --->  Accuracy = 81.73%\n",
      "M_pca =  300 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  300 , M_lda =  2  --->  Accuracy = 9.62%\n",
      "M_pca =  300 , M_lda =  3  --->  Accuracy = 23.08%\n",
      "M_pca =  300 , M_lda =  4  --->  Accuracy = 34.62%\n",
      "M_pca =  300 , M_lda =  5  --->  Accuracy = 39.42%\n",
      "M_pca =  300 , M_lda =  6  --->  Accuracy = 46.15%\n",
      "M_pca =  300 , M_lda =  7  --->  Accuracy = 45.19%\n",
      "M_pca =  300 , M_lda =  8  --->  Accuracy = 50.96%\n",
      "M_pca =  300 , M_lda =  9  --->  Accuracy = 56.73%\n",
      "M_pca =  300 , M_lda =  10  --->  Accuracy = 56.73%\n",
      "M_pca =  300 , M_lda =  11  --->  Accuracy = 60.58%\n",
      "M_pca =  300 , M_lda =  12  --->  Accuracy = 64.42%\n",
      "M_pca =  300 , M_lda =  13  --->  Accuracy = 67.31%\n",
      "M_pca =  300 , M_lda =  14  --->  Accuracy = 67.31%\n",
      "M_pca =  300 , M_lda =  15  --->  Accuracy = 67.31%\n",
      "M_pca =  300 , M_lda =  16  --->  Accuracy = 70.19%\n",
      "M_pca =  300 , M_lda =  17  --->  Accuracy = 72.12%\n",
      "M_pca =  300 , M_lda =  18  --->  Accuracy = 72.12%\n",
      "M_pca =  300 , M_lda =  19  --->  Accuracy = 73.08%\n",
      "M_pca =  300 , M_lda =  20  --->  Accuracy = 75.96%\n",
      "M_pca =  300 , M_lda =  21  --->  Accuracy = 75.00%\n",
      "M_pca =  300 , M_lda =  22  --->  Accuracy = 75.00%\n",
      "M_pca =  300 , M_lda =  23  --->  Accuracy = 76.92%\n",
      "M_pca =  300 , M_lda =  24  --->  Accuracy = 76.92%\n",
      "M_pca =  300 , M_lda =  25  --->  Accuracy = 75.00%\n",
      "M_pca =  300 , M_lda =  26  --->  Accuracy = 75.96%\n",
      "M_pca =  300 , M_lda =  27  --->  Accuracy = 75.96%\n",
      "M_pca =  300 , M_lda =  28  --->  Accuracy = 77.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  300 , M_lda =  29  --->  Accuracy = 77.88%\n",
      "M_pca =  300 , M_lda =  30  --->  Accuracy = 78.85%\n",
      "M_pca =  300 , M_lda =  31  --->  Accuracy = 78.85%\n",
      "M_pca =  300 , M_lda =  32  --->  Accuracy = 78.85%\n",
      "M_pca =  300 , M_lda =  33  --->  Accuracy = 78.85%\n",
      "M_pca =  300 , M_lda =  34  --->  Accuracy = 78.85%\n",
      "M_pca =  300 , M_lda =  35  --->  Accuracy = 78.85%\n",
      "M_pca =  300 , M_lda =  36  --->  Accuracy = 79.81%\n",
      "M_pca =  300 , M_lda =  37  --->  Accuracy = 79.81%\n",
      "M_pca =  300 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  300 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  300 , M_lda =  40  --->  Accuracy = 79.81%\n",
      "M_pca =  300 , M_lda =  41  --->  Accuracy = 79.81%\n",
      "M_pca =  300 , M_lda =  42  --->  Accuracy = 79.81%\n",
      "M_pca =  300 , M_lda =  43  --->  Accuracy = 80.77%\n",
      "M_pca =  300 , M_lda =  44  --->  Accuracy = 80.77%\n",
      "M_pca =  300 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  300 , M_lda =  46  --->  Accuracy = 81.73%\n",
      "M_pca =  300 , M_lda =  47  --->  Accuracy = 81.73%\n",
      "M_pca =  300 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  300 , M_lda =  49  --->  Accuracy = 81.73%\n",
      "M_pca =  300 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  300 , M_lda =  51  --->  Accuracy = 81.73%\n",
      "M_pca =  301 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  301 , M_lda =  2  --->  Accuracy = 10.58%\n",
      "M_pca =  301 , M_lda =  3  --->  Accuracy = 22.12%\n",
      "M_pca =  301 , M_lda =  4  --->  Accuracy = 33.65%\n",
      "M_pca =  301 , M_lda =  5  --->  Accuracy = 36.54%\n",
      "M_pca =  301 , M_lda =  6  --->  Accuracy = 46.15%\n",
      "M_pca =  301 , M_lda =  7  --->  Accuracy = 50.96%\n",
      "M_pca =  301 , M_lda =  8  --->  Accuracy = 50.00%\n",
      "M_pca =  301 , M_lda =  9  --->  Accuracy = 53.85%\n",
      "M_pca =  301 , M_lda =  10  --->  Accuracy = 60.58%\n",
      "M_pca =  301 , M_lda =  11  --->  Accuracy = 61.54%\n",
      "M_pca =  301 , M_lda =  12  --->  Accuracy = 61.54%\n",
      "M_pca =  301 , M_lda =  13  --->  Accuracy = 65.38%\n",
      "M_pca =  301 , M_lda =  14  --->  Accuracy = 68.27%\n",
      "M_pca =  301 , M_lda =  15  --->  Accuracy = 68.27%\n",
      "M_pca =  301 , M_lda =  16  --->  Accuracy = 70.19%\n",
      "M_pca =  301 , M_lda =  17  --->  Accuracy = 71.15%\n",
      "M_pca =  301 , M_lda =  18  --->  Accuracy = 73.08%\n",
      "M_pca =  301 , M_lda =  19  --->  Accuracy = 74.04%\n",
      "M_pca =  301 , M_lda =  20  --->  Accuracy = 75.00%\n",
      "M_pca =  301 , M_lda =  21  --->  Accuracy = 75.96%\n",
      "M_pca =  301 , M_lda =  22  --->  Accuracy = 75.00%\n",
      "M_pca =  301 , M_lda =  23  --->  Accuracy = 75.96%\n",
      "M_pca =  301 , M_lda =  24  --->  Accuracy = 75.96%\n",
      "M_pca =  301 , M_lda =  25  --->  Accuracy = 75.00%\n",
      "M_pca =  301 , M_lda =  26  --->  Accuracy = 75.00%\n",
      "M_pca =  301 , M_lda =  27  --->  Accuracy = 77.88%\n",
      "M_pca =  301 , M_lda =  28  --->  Accuracy = 78.85%\n",
      "M_pca =  301 , M_lda =  29  --->  Accuracy = 78.85%\n",
      "M_pca =  301 , M_lda =  30  --->  Accuracy = 78.85%\n",
      "M_pca =  301 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  301 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  301 , M_lda =  33  --->  Accuracy = 79.81%\n",
      "M_pca =  301 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  301 , M_lda =  35  --->  Accuracy = 78.85%\n",
      "M_pca =  301 , M_lda =  36  --->  Accuracy = 78.85%\n",
      "M_pca =  301 , M_lda =  37  --->  Accuracy = 79.81%\n",
      "M_pca =  301 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  301 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  301 , M_lda =  40  --->  Accuracy = 79.81%\n",
      "M_pca =  301 , M_lda =  41  --->  Accuracy = 79.81%\n",
      "M_pca =  301 , M_lda =  42  --->  Accuracy = 79.81%\n",
      "M_pca =  301 , M_lda =  43  --->  Accuracy = 80.77%\n",
      "M_pca =  301 , M_lda =  44  --->  Accuracy = 80.77%\n",
      "M_pca =  301 , M_lda =  45  --->  Accuracy = 79.81%\n",
      "M_pca =  301 , M_lda =  46  --->  Accuracy = 80.77%\n",
      "M_pca =  301 , M_lda =  47  --->  Accuracy = 80.77%\n",
      "M_pca =  301 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  301 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  301 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  301 , M_lda =  51  --->  Accuracy = 81.73%\n",
      "M_pca =  302 , M_lda =  1  --->  Accuracy = 2.88%\n",
      "M_pca =  302 , M_lda =  2  --->  Accuracy = 12.50%\n",
      "M_pca =  302 , M_lda =  3  --->  Accuracy = 19.23%\n",
      "M_pca =  302 , M_lda =  4  --->  Accuracy = 25.00%\n",
      "M_pca =  302 , M_lda =  5  --->  Accuracy = 38.46%\n",
      "M_pca =  302 , M_lda =  6  --->  Accuracy = 46.15%\n",
      "M_pca =  302 , M_lda =  7  --->  Accuracy = 47.12%\n",
      "M_pca =  302 , M_lda =  8  --->  Accuracy = 48.08%\n",
      "M_pca =  302 , M_lda =  9  --->  Accuracy = 53.85%\n",
      "M_pca =  302 , M_lda =  10  --->  Accuracy = 57.69%\n",
      "M_pca =  302 , M_lda =  11  --->  Accuracy = 59.62%\n",
      "M_pca =  302 , M_lda =  12  --->  Accuracy = 63.46%\n",
      "M_pca =  302 , M_lda =  13  --->  Accuracy = 67.31%\n",
      "M_pca =  302 , M_lda =  14  --->  Accuracy = 66.35%\n",
      "M_pca =  302 , M_lda =  15  --->  Accuracy = 68.27%\n",
      "M_pca =  302 , M_lda =  16  --->  Accuracy = 70.19%\n",
      "M_pca =  302 , M_lda =  17  --->  Accuracy = 69.23%\n",
      "M_pca =  302 , M_lda =  18  --->  Accuracy = 70.19%\n",
      "M_pca =  302 , M_lda =  19  --->  Accuracy = 73.08%\n",
      "M_pca =  302 , M_lda =  20  --->  Accuracy = 75.00%\n",
      "M_pca =  302 , M_lda =  21  --->  Accuracy = 76.92%\n",
      "M_pca =  302 , M_lda =  22  --->  Accuracy = 75.00%\n",
      "M_pca =  302 , M_lda =  23  --->  Accuracy = 76.92%\n",
      "M_pca =  302 , M_lda =  24  --->  Accuracy = 76.92%\n",
      "M_pca =  302 , M_lda =  25  --->  Accuracy = 75.00%\n",
      "M_pca =  302 , M_lda =  26  --->  Accuracy = 75.00%\n",
      "M_pca =  302 , M_lda =  27  --->  Accuracy = 76.92%\n",
      "M_pca =  302 , M_lda =  28  --->  Accuracy = 77.88%\n",
      "M_pca =  302 , M_lda =  29  --->  Accuracy = 77.88%\n",
      "M_pca =  302 , M_lda =  30  --->  Accuracy = 78.85%\n",
      "M_pca =  302 , M_lda =  31  --->  Accuracy = 78.85%\n",
      "M_pca =  302 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  302 , M_lda =  33  --->  Accuracy = 79.81%\n",
      "M_pca =  302 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  302 , M_lda =  35  --->  Accuracy = 78.85%\n",
      "M_pca =  302 , M_lda =  36  --->  Accuracy = 78.85%\n",
      "M_pca =  302 , M_lda =  37  --->  Accuracy = 78.85%\n",
      "M_pca =  302 , M_lda =  38  --->  Accuracy = 78.85%\n",
      "M_pca =  302 , M_lda =  39  --->  Accuracy = 78.85%\n",
      "M_pca =  302 , M_lda =  40  --->  Accuracy = 78.85%\n",
      "M_pca =  302 , M_lda =  41  --->  Accuracy = 78.85%\n",
      "M_pca =  302 , M_lda =  42  --->  Accuracy = 78.85%\n",
      "M_pca =  302 , M_lda =  43  --->  Accuracy = 80.77%\n",
      "M_pca =  302 , M_lda =  44  --->  Accuracy = 79.81%\n",
      "M_pca =  302 , M_lda =  45  --->  Accuracy = 78.85%\n",
      "M_pca =  302 , M_lda =  46  --->  Accuracy = 79.81%\n",
      "M_pca =  302 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  302 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  302 , M_lda =  49  --->  Accuracy = 79.81%\n",
      "M_pca =  302 , M_lda =  50  --->  Accuracy = 81.73%\n",
      "M_pca =  302 , M_lda =  51  --->  Accuracy = 81.73%\n",
      "M_pca =  303 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  303 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  303 , M_lda =  3  --->  Accuracy = 23.08%\n",
      "M_pca =  303 , M_lda =  4  --->  Accuracy = 30.77%\n",
      "M_pca =  303 , M_lda =  5  --->  Accuracy = 44.23%\n",
      "M_pca =  303 , M_lda =  6  --->  Accuracy = 49.04%\n",
      "M_pca =  303 , M_lda =  7  --->  Accuracy = 52.88%\n",
      "M_pca =  303 , M_lda =  8  --->  Accuracy = 50.96%\n",
      "M_pca =  303 , M_lda =  9  --->  Accuracy = 57.69%\n",
      "M_pca =  303 , M_lda =  10  --->  Accuracy = 64.42%\n",
      "M_pca =  303 , M_lda =  11  --->  Accuracy = 61.54%\n",
      "M_pca =  303 , M_lda =  12  --->  Accuracy = 64.42%\n",
      "M_pca =  303 , M_lda =  13  --->  Accuracy = 68.27%\n",
      "M_pca =  303 , M_lda =  14  --->  Accuracy = 68.27%\n",
      "M_pca =  303 , M_lda =  15  --->  Accuracy = 68.27%\n",
      "M_pca =  303 , M_lda =  16  --->  Accuracy = 70.19%\n",
      "M_pca =  303 , M_lda =  17  --->  Accuracy = 69.23%\n",
      "M_pca =  303 , M_lda =  18  --->  Accuracy = 69.23%\n",
      "M_pca =  303 , M_lda =  19  --->  Accuracy = 71.15%\n",
      "M_pca =  303 , M_lda =  20  --->  Accuracy = 73.08%\n",
      "M_pca =  303 , M_lda =  21  --->  Accuracy = 74.04%\n",
      "M_pca =  303 , M_lda =  22  --->  Accuracy = 75.00%\n",
      "M_pca =  303 , M_lda =  23  --->  Accuracy = 76.92%\n",
      "M_pca =  303 , M_lda =  24  --->  Accuracy = 75.96%\n",
      "M_pca =  303 , M_lda =  25  --->  Accuracy = 75.96%\n",
      "M_pca =  303 , M_lda =  26  --->  Accuracy = 76.92%\n",
      "M_pca =  303 , M_lda =  27  --->  Accuracy = 76.92%\n",
      "M_pca =  303 , M_lda =  28  --->  Accuracy = 77.88%\n",
      "M_pca =  303 , M_lda =  29  --->  Accuracy = 77.88%\n",
      "M_pca =  303 , M_lda =  30  --->  Accuracy = 77.88%\n",
      "M_pca =  303 , M_lda =  31  --->  Accuracy = 77.88%\n",
      "M_pca =  303 , M_lda =  32  --->  Accuracy = 78.85%\n",
      "M_pca =  303 , M_lda =  33  --->  Accuracy = 78.85%\n",
      "M_pca =  303 , M_lda =  34  --->  Accuracy = 78.85%\n",
      "M_pca =  303 , M_lda =  35  --->  Accuracy = 77.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  303 , M_lda =  36  --->  Accuracy = 77.88%\n",
      "M_pca =  303 , M_lda =  37  --->  Accuracy = 78.85%\n",
      "M_pca =  303 , M_lda =  38  --->  Accuracy = 78.85%\n",
      "M_pca =  303 , M_lda =  39  --->  Accuracy = 78.85%\n",
      "M_pca =  303 , M_lda =  40  --->  Accuracy = 79.81%\n",
      "M_pca =  303 , M_lda =  41  --->  Accuracy = 79.81%\n",
      "M_pca =  303 , M_lda =  42  --->  Accuracy = 79.81%\n",
      "M_pca =  303 , M_lda =  43  --->  Accuracy = 79.81%\n",
      "M_pca =  303 , M_lda =  44  --->  Accuracy = 79.81%\n",
      "M_pca =  303 , M_lda =  45  --->  Accuracy = 79.81%\n",
      "M_pca =  303 , M_lda =  46  --->  Accuracy = 79.81%\n",
      "M_pca =  303 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  303 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  303 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  303 , M_lda =  50  --->  Accuracy = 80.77%\n",
      "M_pca =  303 , M_lda =  51  --->  Accuracy = 80.77%\n",
      "M_pca =  304 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  304 , M_lda =  2  --->  Accuracy = 10.58%\n",
      "M_pca =  304 , M_lda =  3  --->  Accuracy = 22.12%\n",
      "M_pca =  304 , M_lda =  4  --->  Accuracy = 35.58%\n",
      "M_pca =  304 , M_lda =  5  --->  Accuracy = 39.42%\n",
      "M_pca =  304 , M_lda =  6  --->  Accuracy = 46.15%\n",
      "M_pca =  304 , M_lda =  7  --->  Accuracy = 47.12%\n",
      "M_pca =  304 , M_lda =  8  --->  Accuracy = 49.04%\n",
      "M_pca =  304 , M_lda =  9  --->  Accuracy = 53.85%\n",
      "M_pca =  304 , M_lda =  10  --->  Accuracy = 58.65%\n",
      "M_pca =  304 , M_lda =  11  --->  Accuracy = 58.65%\n",
      "M_pca =  304 , M_lda =  12  --->  Accuracy = 59.62%\n",
      "M_pca =  304 , M_lda =  13  --->  Accuracy = 66.35%\n",
      "M_pca =  304 , M_lda =  14  --->  Accuracy = 64.42%\n",
      "M_pca =  304 , M_lda =  15  --->  Accuracy = 68.27%\n",
      "M_pca =  304 , M_lda =  16  --->  Accuracy = 69.23%\n",
      "M_pca =  304 , M_lda =  17  --->  Accuracy = 70.19%\n",
      "M_pca =  304 , M_lda =  18  --->  Accuracy = 71.15%\n",
      "M_pca =  304 , M_lda =  19  --->  Accuracy = 74.04%\n",
      "M_pca =  304 , M_lda =  20  --->  Accuracy = 74.04%\n",
      "M_pca =  304 , M_lda =  21  --->  Accuracy = 75.00%\n",
      "M_pca =  304 , M_lda =  22  --->  Accuracy = 75.00%\n",
      "M_pca =  304 , M_lda =  23  --->  Accuracy = 76.92%\n",
      "M_pca =  304 , M_lda =  24  --->  Accuracy = 75.96%\n",
      "M_pca =  304 , M_lda =  25  --->  Accuracy = 75.96%\n",
      "M_pca =  304 , M_lda =  26  --->  Accuracy = 75.96%\n",
      "M_pca =  304 , M_lda =  27  --->  Accuracy = 75.00%\n",
      "M_pca =  304 , M_lda =  28  --->  Accuracy = 75.96%\n",
      "M_pca =  304 , M_lda =  29  --->  Accuracy = 75.96%\n",
      "M_pca =  304 , M_lda =  30  --->  Accuracy = 75.96%\n",
      "M_pca =  304 , M_lda =  31  --->  Accuracy = 75.96%\n",
      "M_pca =  304 , M_lda =  32  --->  Accuracy = 76.92%\n",
      "M_pca =  304 , M_lda =  33  --->  Accuracy = 77.88%\n",
      "M_pca =  304 , M_lda =  34  --->  Accuracy = 77.88%\n",
      "M_pca =  304 , M_lda =  35  --->  Accuracy = 76.92%\n",
      "M_pca =  304 , M_lda =  36  --->  Accuracy = 76.92%\n",
      "M_pca =  304 , M_lda =  37  --->  Accuracy = 76.92%\n",
      "M_pca =  304 , M_lda =  38  --->  Accuracy = 77.88%\n",
      "M_pca =  304 , M_lda =  39  --->  Accuracy = 76.92%\n",
      "M_pca =  304 , M_lda =  40  --->  Accuracy = 79.81%\n",
      "M_pca =  304 , M_lda =  41  --->  Accuracy = 79.81%\n",
      "M_pca =  304 , M_lda =  42  --->  Accuracy = 79.81%\n",
      "M_pca =  304 , M_lda =  43  --->  Accuracy = 79.81%\n",
      "M_pca =  304 , M_lda =  44  --->  Accuracy = 80.77%\n",
      "M_pca =  304 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  304 , M_lda =  46  --->  Accuracy = 80.77%\n",
      "M_pca =  304 , M_lda =  47  --->  Accuracy = 81.73%\n",
      "M_pca =  304 , M_lda =  48  --->  Accuracy = 81.73%\n",
      "M_pca =  304 , M_lda =  49  --->  Accuracy = 82.69%\n",
      "M_pca =  304 , M_lda =  50  --->  Accuracy = 82.69%\n",
      "M_pca =  304 , M_lda =  51  --->  Accuracy = 82.69%\n",
      "M_pca =  305 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  305 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  305 , M_lda =  3  --->  Accuracy = 23.08%\n",
      "M_pca =  305 , M_lda =  4  --->  Accuracy = 29.81%\n",
      "M_pca =  305 , M_lda =  5  --->  Accuracy = 42.31%\n",
      "M_pca =  305 , M_lda =  6  --->  Accuracy = 49.04%\n",
      "M_pca =  305 , M_lda =  7  --->  Accuracy = 50.00%\n",
      "M_pca =  305 , M_lda =  8  --->  Accuracy = 50.00%\n",
      "M_pca =  305 , M_lda =  9  --->  Accuracy = 54.81%\n",
      "M_pca =  305 , M_lda =  10  --->  Accuracy = 58.65%\n",
      "M_pca =  305 , M_lda =  11  --->  Accuracy = 60.58%\n",
      "M_pca =  305 , M_lda =  12  --->  Accuracy = 61.54%\n",
      "M_pca =  305 , M_lda =  13  --->  Accuracy = 64.42%\n",
      "M_pca =  305 , M_lda =  14  --->  Accuracy = 64.42%\n",
      "M_pca =  305 , M_lda =  15  --->  Accuracy = 67.31%\n",
      "M_pca =  305 , M_lda =  16  --->  Accuracy = 68.27%\n",
      "M_pca =  305 , M_lda =  17  --->  Accuracy = 69.23%\n",
      "M_pca =  305 , M_lda =  18  --->  Accuracy = 70.19%\n",
      "M_pca =  305 , M_lda =  19  --->  Accuracy = 72.12%\n",
      "M_pca =  305 , M_lda =  20  --->  Accuracy = 74.04%\n",
      "M_pca =  305 , M_lda =  21  --->  Accuracy = 74.04%\n",
      "M_pca =  305 , M_lda =  22  --->  Accuracy = 75.00%\n",
      "M_pca =  305 , M_lda =  23  --->  Accuracy = 75.96%\n",
      "M_pca =  305 , M_lda =  24  --->  Accuracy = 75.00%\n",
      "M_pca =  305 , M_lda =  25  --->  Accuracy = 75.00%\n",
      "M_pca =  305 , M_lda =  26  --->  Accuracy = 75.00%\n",
      "M_pca =  305 , M_lda =  27  --->  Accuracy = 74.04%\n",
      "M_pca =  305 , M_lda =  28  --->  Accuracy = 75.00%\n",
      "M_pca =  305 , M_lda =  29  --->  Accuracy = 75.00%\n",
      "M_pca =  305 , M_lda =  30  --->  Accuracy = 75.96%\n",
      "M_pca =  305 , M_lda =  31  --->  Accuracy = 75.96%\n",
      "M_pca =  305 , M_lda =  32  --->  Accuracy = 75.00%\n",
      "M_pca =  305 , M_lda =  33  --->  Accuracy = 75.96%\n",
      "M_pca =  305 , M_lda =  34  --->  Accuracy = 75.96%\n",
      "M_pca =  305 , M_lda =  35  --->  Accuracy = 76.92%\n",
      "M_pca =  305 , M_lda =  36  --->  Accuracy = 76.92%\n",
      "M_pca =  305 , M_lda =  37  --->  Accuracy = 76.92%\n",
      "M_pca =  305 , M_lda =  38  --->  Accuracy = 77.88%\n",
      "M_pca =  305 , M_lda =  39  --->  Accuracy = 77.88%\n",
      "M_pca =  305 , M_lda =  40  --->  Accuracy = 78.85%\n",
      "M_pca =  305 , M_lda =  41  --->  Accuracy = 78.85%\n",
      "M_pca =  305 , M_lda =  42  --->  Accuracy = 78.85%\n",
      "M_pca =  305 , M_lda =  43  --->  Accuracy = 77.88%\n",
      "M_pca =  305 , M_lda =  44  --->  Accuracy = 77.88%\n",
      "M_pca =  305 , M_lda =  45  --->  Accuracy = 78.85%\n",
      "M_pca =  305 , M_lda =  46  --->  Accuracy = 77.88%\n",
      "M_pca =  305 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  305 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  305 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  305 , M_lda =  50  --->  Accuracy = 80.77%\n",
      "M_pca =  305 , M_lda =  51  --->  Accuracy = 81.73%\n",
      "M_pca =  306 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  306 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  306 , M_lda =  3  --->  Accuracy = 27.88%\n",
      "M_pca =  306 , M_lda =  4  --->  Accuracy = 31.73%\n",
      "M_pca =  306 , M_lda =  5  --->  Accuracy = 42.31%\n",
      "M_pca =  306 , M_lda =  6  --->  Accuracy = 49.04%\n",
      "M_pca =  306 , M_lda =  7  --->  Accuracy = 48.08%\n",
      "M_pca =  306 , M_lda =  8  --->  Accuracy = 50.00%\n",
      "M_pca =  306 , M_lda =  9  --->  Accuracy = 55.77%\n",
      "M_pca =  306 , M_lda =  10  --->  Accuracy = 60.58%\n",
      "M_pca =  306 , M_lda =  11  --->  Accuracy = 58.65%\n",
      "M_pca =  306 , M_lda =  12  --->  Accuracy = 62.50%\n",
      "M_pca =  306 , M_lda =  13  --->  Accuracy = 64.42%\n",
      "M_pca =  306 , M_lda =  14  --->  Accuracy = 65.38%\n",
      "M_pca =  306 , M_lda =  15  --->  Accuracy = 66.35%\n",
      "M_pca =  306 , M_lda =  16  --->  Accuracy = 68.27%\n",
      "M_pca =  306 , M_lda =  17  --->  Accuracy = 68.27%\n",
      "M_pca =  306 , M_lda =  18  --->  Accuracy = 69.23%\n",
      "M_pca =  306 , M_lda =  19  --->  Accuracy = 72.12%\n",
      "M_pca =  306 , M_lda =  20  --->  Accuracy = 74.04%\n",
      "M_pca =  306 , M_lda =  21  --->  Accuracy = 74.04%\n",
      "M_pca =  306 , M_lda =  22  --->  Accuracy = 74.04%\n",
      "M_pca =  306 , M_lda =  23  --->  Accuracy = 75.96%\n",
      "M_pca =  306 , M_lda =  24  --->  Accuracy = 74.04%\n",
      "M_pca =  306 , M_lda =  25  --->  Accuracy = 75.00%\n",
      "M_pca =  306 , M_lda =  26  --->  Accuracy = 75.00%\n",
      "M_pca =  306 , M_lda =  27  --->  Accuracy = 74.04%\n",
      "M_pca =  306 , M_lda =  28  --->  Accuracy = 74.04%\n",
      "M_pca =  306 , M_lda =  29  --->  Accuracy = 75.00%\n",
      "M_pca =  306 , M_lda =  30  --->  Accuracy = 75.00%\n",
      "M_pca =  306 , M_lda =  31  --->  Accuracy = 75.00%\n",
      "M_pca =  306 , M_lda =  32  --->  Accuracy = 75.00%\n",
      "M_pca =  306 , M_lda =  33  --->  Accuracy = 75.96%\n",
      "M_pca =  306 , M_lda =  34  --->  Accuracy = 75.96%\n",
      "M_pca =  306 , M_lda =  35  --->  Accuracy = 76.92%\n",
      "M_pca =  306 , M_lda =  36  --->  Accuracy = 75.96%\n",
      "M_pca =  306 , M_lda =  37  --->  Accuracy = 77.88%\n",
      "M_pca =  306 , M_lda =  38  --->  Accuracy = 77.88%\n",
      "M_pca =  306 , M_lda =  39  --->  Accuracy = 77.88%\n",
      "M_pca =  306 , M_lda =  40  --->  Accuracy = 78.85%\n",
      "M_pca =  306 , M_lda =  41  --->  Accuracy = 78.85%\n",
      "M_pca =  306 , M_lda =  42  --->  Accuracy = 78.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  306 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  306 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  306 , M_lda =  45  --->  Accuracy = 79.81%\n",
      "M_pca =  306 , M_lda =  46  --->  Accuracy = 79.81%\n",
      "M_pca =  306 , M_lda =  47  --->  Accuracy = 80.77%\n",
      "M_pca =  306 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  306 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  306 , M_lda =  50  --->  Accuracy = 80.77%\n",
      "M_pca =  306 , M_lda =  51  --->  Accuracy = 81.73%\n",
      "M_pca =  307 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  307 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  307 , M_lda =  3  --->  Accuracy = 22.12%\n",
      "M_pca =  307 , M_lda =  4  --->  Accuracy = 30.77%\n",
      "M_pca =  307 , M_lda =  5  --->  Accuracy = 38.46%\n",
      "M_pca =  307 , M_lda =  6  --->  Accuracy = 44.23%\n",
      "M_pca =  307 , M_lda =  7  --->  Accuracy = 48.08%\n",
      "M_pca =  307 , M_lda =  8  --->  Accuracy = 49.04%\n",
      "M_pca =  307 , M_lda =  9  --->  Accuracy = 53.85%\n",
      "M_pca =  307 , M_lda =  10  --->  Accuracy = 57.69%\n",
      "M_pca =  307 , M_lda =  11  --->  Accuracy = 56.73%\n",
      "M_pca =  307 , M_lda =  12  --->  Accuracy = 62.50%\n",
      "M_pca =  307 , M_lda =  13  --->  Accuracy = 64.42%\n",
      "M_pca =  307 , M_lda =  14  --->  Accuracy = 65.38%\n",
      "M_pca =  307 , M_lda =  15  --->  Accuracy = 67.31%\n",
      "M_pca =  307 , M_lda =  16  --->  Accuracy = 68.27%\n",
      "M_pca =  307 , M_lda =  17  --->  Accuracy = 68.27%\n",
      "M_pca =  307 , M_lda =  18  --->  Accuracy = 68.27%\n",
      "M_pca =  307 , M_lda =  19  --->  Accuracy = 71.15%\n",
      "M_pca =  307 , M_lda =  20  --->  Accuracy = 74.04%\n",
      "M_pca =  307 , M_lda =  21  --->  Accuracy = 73.08%\n",
      "M_pca =  307 , M_lda =  22  --->  Accuracy = 74.04%\n",
      "M_pca =  307 , M_lda =  23  --->  Accuracy = 74.04%\n",
      "M_pca =  307 , M_lda =  24  --->  Accuracy = 75.00%\n",
      "M_pca =  307 , M_lda =  25  --->  Accuracy = 75.96%\n",
      "M_pca =  307 , M_lda =  26  --->  Accuracy = 75.96%\n",
      "M_pca =  307 , M_lda =  27  --->  Accuracy = 75.00%\n",
      "M_pca =  307 , M_lda =  28  --->  Accuracy = 75.96%\n",
      "M_pca =  307 , M_lda =  29  --->  Accuracy = 75.96%\n",
      "M_pca =  307 , M_lda =  30  --->  Accuracy = 76.92%\n",
      "M_pca =  307 , M_lda =  31  --->  Accuracy = 76.92%\n",
      "M_pca =  307 , M_lda =  32  --->  Accuracy = 76.92%\n",
      "M_pca =  307 , M_lda =  33  --->  Accuracy = 76.92%\n",
      "M_pca =  307 , M_lda =  34  --->  Accuracy = 75.96%\n",
      "M_pca =  307 , M_lda =  35  --->  Accuracy = 75.96%\n",
      "M_pca =  307 , M_lda =  36  --->  Accuracy = 75.96%\n",
      "M_pca =  307 , M_lda =  37  --->  Accuracy = 76.92%\n",
      "M_pca =  307 , M_lda =  38  --->  Accuracy = 76.92%\n",
      "M_pca =  307 , M_lda =  39  --->  Accuracy = 76.92%\n",
      "M_pca =  307 , M_lda =  40  --->  Accuracy = 76.92%\n",
      "M_pca =  307 , M_lda =  41  --->  Accuracy = 77.88%\n",
      "M_pca =  307 , M_lda =  42  --->  Accuracy = 77.88%\n",
      "M_pca =  307 , M_lda =  43  --->  Accuracy = 77.88%\n",
      "M_pca =  307 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  307 , M_lda =  45  --->  Accuracy = 78.85%\n",
      "M_pca =  307 , M_lda =  46  --->  Accuracy = 77.88%\n",
      "M_pca =  307 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  307 , M_lda =  48  --->  Accuracy = 78.85%\n",
      "M_pca =  307 , M_lda =  49  --->  Accuracy = 77.88%\n",
      "M_pca =  307 , M_lda =  50  --->  Accuracy = 78.85%\n",
      "M_pca =  307 , M_lda =  51  --->  Accuracy = 77.88%\n",
      "M_pca =  308 , M_lda =  1  --->  Accuracy = 11.54%\n",
      "M_pca =  308 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  308 , M_lda =  3  --->  Accuracy = 19.23%\n",
      "M_pca =  308 , M_lda =  4  --->  Accuracy = 28.85%\n",
      "M_pca =  308 , M_lda =  5  --->  Accuracy = 36.54%\n",
      "M_pca =  308 , M_lda =  6  --->  Accuracy = 42.31%\n",
      "M_pca =  308 , M_lda =  7  --->  Accuracy = 49.04%\n",
      "M_pca =  308 , M_lda =  8  --->  Accuracy = 51.92%\n",
      "M_pca =  308 , M_lda =  9  --->  Accuracy = 58.65%\n",
      "M_pca =  308 , M_lda =  10  --->  Accuracy = 56.73%\n",
      "M_pca =  308 , M_lda =  11  --->  Accuracy = 55.77%\n",
      "M_pca =  308 , M_lda =  12  --->  Accuracy = 61.54%\n",
      "M_pca =  308 , M_lda =  13  --->  Accuracy = 63.46%\n",
      "M_pca =  308 , M_lda =  14  --->  Accuracy = 63.46%\n",
      "M_pca =  308 , M_lda =  15  --->  Accuracy = 67.31%\n",
      "M_pca =  308 , M_lda =  16  --->  Accuracy = 68.27%\n",
      "M_pca =  308 , M_lda =  17  --->  Accuracy = 69.23%\n",
      "M_pca =  308 , M_lda =  18  --->  Accuracy = 68.27%\n",
      "M_pca =  308 , M_lda =  19  --->  Accuracy = 71.15%\n",
      "M_pca =  308 , M_lda =  20  --->  Accuracy = 72.12%\n",
      "M_pca =  308 , M_lda =  21  --->  Accuracy = 71.15%\n",
      "M_pca =  308 , M_lda =  22  --->  Accuracy = 72.12%\n",
      "M_pca =  308 , M_lda =  23  --->  Accuracy = 74.04%\n",
      "M_pca =  308 , M_lda =  24  --->  Accuracy = 75.00%\n",
      "M_pca =  308 , M_lda =  25  --->  Accuracy = 75.00%\n",
      "M_pca =  308 , M_lda =  26  --->  Accuracy = 76.92%\n",
      "M_pca =  308 , M_lda =  27  --->  Accuracy = 75.00%\n",
      "M_pca =  308 , M_lda =  28  --->  Accuracy = 75.96%\n",
      "M_pca =  308 , M_lda =  29  --->  Accuracy = 75.96%\n",
      "M_pca =  308 , M_lda =  30  --->  Accuracy = 75.96%\n",
      "M_pca =  308 , M_lda =  31  --->  Accuracy = 75.96%\n",
      "M_pca =  308 , M_lda =  32  --->  Accuracy = 76.92%\n",
      "M_pca =  308 , M_lda =  33  --->  Accuracy = 76.92%\n",
      "M_pca =  308 , M_lda =  34  --->  Accuracy = 75.96%\n",
      "M_pca =  308 , M_lda =  35  --->  Accuracy = 76.92%\n",
      "M_pca =  308 , M_lda =  36  --->  Accuracy = 75.96%\n",
      "M_pca =  308 , M_lda =  37  --->  Accuracy = 75.96%\n",
      "M_pca =  308 , M_lda =  38  --->  Accuracy = 75.96%\n",
      "M_pca =  308 , M_lda =  39  --->  Accuracy = 75.96%\n",
      "M_pca =  308 , M_lda =  40  --->  Accuracy = 75.96%\n",
      "M_pca =  308 , M_lda =  41  --->  Accuracy = 75.96%\n",
      "M_pca =  308 , M_lda =  42  --->  Accuracy = 76.92%\n",
      "M_pca =  308 , M_lda =  43  --->  Accuracy = 77.88%\n",
      "M_pca =  308 , M_lda =  44  --->  Accuracy = 77.88%\n",
      "M_pca =  308 , M_lda =  45  --->  Accuracy = 77.88%\n",
      "M_pca =  308 , M_lda =  46  --->  Accuracy = 76.92%\n",
      "M_pca =  308 , M_lda =  47  --->  Accuracy = 76.92%\n",
      "M_pca =  308 , M_lda =  48  --->  Accuracy = 76.92%\n",
      "M_pca =  308 , M_lda =  49  --->  Accuracy = 76.92%\n",
      "M_pca =  308 , M_lda =  50  --->  Accuracy = 77.88%\n",
      "M_pca =  308 , M_lda =  51  --->  Accuracy = 77.88%\n",
      "M_pca =  309 , M_lda =  1  --->  Accuracy = 12.50%\n",
      "M_pca =  309 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  309 , M_lda =  3  --->  Accuracy = 17.31%\n",
      "M_pca =  309 , M_lda =  4  --->  Accuracy = 28.85%\n",
      "M_pca =  309 , M_lda =  5  --->  Accuracy = 34.62%\n",
      "M_pca =  309 , M_lda =  6  --->  Accuracy = 42.31%\n",
      "M_pca =  309 , M_lda =  7  --->  Accuracy = 44.23%\n",
      "M_pca =  309 , M_lda =  8  --->  Accuracy = 50.00%\n",
      "M_pca =  309 , M_lda =  9  --->  Accuracy = 55.77%\n",
      "M_pca =  309 , M_lda =  10  --->  Accuracy = 60.58%\n",
      "M_pca =  309 , M_lda =  11  --->  Accuracy = 65.38%\n",
      "M_pca =  309 , M_lda =  12  --->  Accuracy = 61.54%\n",
      "M_pca =  309 , M_lda =  13  --->  Accuracy = 61.54%\n",
      "M_pca =  309 , M_lda =  14  --->  Accuracy = 65.38%\n",
      "M_pca =  309 , M_lda =  15  --->  Accuracy = 68.27%\n",
      "M_pca =  309 , M_lda =  16  --->  Accuracy = 68.27%\n",
      "M_pca =  309 , M_lda =  17  --->  Accuracy = 71.15%\n",
      "M_pca =  309 , M_lda =  18  --->  Accuracy = 70.19%\n",
      "M_pca =  309 , M_lda =  19  --->  Accuracy = 72.12%\n",
      "M_pca =  309 , M_lda =  20  --->  Accuracy = 72.12%\n",
      "M_pca =  309 , M_lda =  21  --->  Accuracy = 75.00%\n",
      "M_pca =  309 , M_lda =  22  --->  Accuracy = 74.04%\n",
      "M_pca =  309 , M_lda =  23  --->  Accuracy = 75.00%\n",
      "M_pca =  309 , M_lda =  24  --->  Accuracy = 75.00%\n",
      "M_pca =  309 , M_lda =  25  --->  Accuracy = 76.92%\n",
      "M_pca =  309 , M_lda =  26  --->  Accuracy = 77.88%\n",
      "M_pca =  309 , M_lda =  27  --->  Accuracy = 75.00%\n",
      "M_pca =  309 , M_lda =  28  --->  Accuracy = 75.96%\n",
      "M_pca =  309 , M_lda =  29  --->  Accuracy = 77.88%\n",
      "M_pca =  309 , M_lda =  30  --->  Accuracy = 77.88%\n",
      "M_pca =  309 , M_lda =  31  --->  Accuracy = 76.92%\n",
      "M_pca =  309 , M_lda =  32  --->  Accuracy = 77.88%\n",
      "M_pca =  309 , M_lda =  33  --->  Accuracy = 77.88%\n",
      "M_pca =  309 , M_lda =  34  --->  Accuracy = 76.92%\n",
      "M_pca =  309 , M_lda =  35  --->  Accuracy = 76.92%\n",
      "M_pca =  309 , M_lda =  36  --->  Accuracy = 76.92%\n",
      "M_pca =  309 , M_lda =  37  --->  Accuracy = 76.92%\n",
      "M_pca =  309 , M_lda =  38  --->  Accuracy = 75.96%\n",
      "M_pca =  309 , M_lda =  39  --->  Accuracy = 76.92%\n",
      "M_pca =  309 , M_lda =  40  --->  Accuracy = 76.92%\n",
      "M_pca =  309 , M_lda =  41  --->  Accuracy = 76.92%\n",
      "M_pca =  309 , M_lda =  42  --->  Accuracy = 77.88%\n",
      "M_pca =  309 , M_lda =  43  --->  Accuracy = 77.88%\n",
      "M_pca =  309 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  309 , M_lda =  45  --->  Accuracy = 77.88%\n",
      "M_pca =  309 , M_lda =  46  --->  Accuracy = 77.88%\n",
      "M_pca =  309 , M_lda =  47  --->  Accuracy = 77.88%\n",
      "M_pca =  309 , M_lda =  48  --->  Accuracy = 77.88%\n",
      "M_pca =  309 , M_lda =  49  --->  Accuracy = 77.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  309 , M_lda =  50  --->  Accuracy = 77.88%\n",
      "M_pca =  309 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  310 , M_lda =  1  --->  Accuracy = 2.88%\n",
      "M_pca =  310 , M_lda =  2  --->  Accuracy = 16.35%\n",
      "M_pca =  310 , M_lda =  3  --->  Accuracy = 19.23%\n",
      "M_pca =  310 , M_lda =  4  --->  Accuracy = 26.92%\n",
      "M_pca =  310 , M_lda =  5  --->  Accuracy = 35.58%\n",
      "M_pca =  310 , M_lda =  6  --->  Accuracy = 43.27%\n",
      "M_pca =  310 , M_lda =  7  --->  Accuracy = 46.15%\n",
      "M_pca =  310 , M_lda =  8  --->  Accuracy = 50.96%\n",
      "M_pca =  310 , M_lda =  9  --->  Accuracy = 53.85%\n",
      "M_pca =  310 , M_lda =  10  --->  Accuracy = 55.77%\n",
      "M_pca =  310 , M_lda =  11  --->  Accuracy = 60.58%\n",
      "M_pca =  310 , M_lda =  12  --->  Accuracy = 63.46%\n",
      "M_pca =  310 , M_lda =  13  --->  Accuracy = 65.38%\n",
      "M_pca =  310 , M_lda =  14  --->  Accuracy = 67.31%\n",
      "M_pca =  310 , M_lda =  15  --->  Accuracy = 68.27%\n",
      "M_pca =  310 , M_lda =  16  --->  Accuracy = 67.31%\n",
      "M_pca =  310 , M_lda =  17  --->  Accuracy = 73.08%\n",
      "M_pca =  310 , M_lda =  18  --->  Accuracy = 72.12%\n",
      "M_pca =  310 , M_lda =  19  --->  Accuracy = 74.04%\n",
      "M_pca =  310 , M_lda =  20  --->  Accuracy = 76.92%\n",
      "M_pca =  310 , M_lda =  21  --->  Accuracy = 76.92%\n",
      "M_pca =  310 , M_lda =  22  --->  Accuracy = 75.96%\n",
      "M_pca =  310 , M_lda =  23  --->  Accuracy = 75.00%\n",
      "M_pca =  310 , M_lda =  24  --->  Accuracy = 76.92%\n",
      "M_pca =  310 , M_lda =  25  --->  Accuracy = 77.88%\n",
      "M_pca =  310 , M_lda =  26  --->  Accuracy = 77.88%\n",
      "M_pca =  310 , M_lda =  27  --->  Accuracy = 78.85%\n",
      "M_pca =  310 , M_lda =  28  --->  Accuracy = 77.88%\n",
      "M_pca =  310 , M_lda =  29  --->  Accuracy = 77.88%\n",
      "M_pca =  310 , M_lda =  30  --->  Accuracy = 77.88%\n",
      "M_pca =  310 , M_lda =  31  --->  Accuracy = 77.88%\n",
      "M_pca =  310 , M_lda =  32  --->  Accuracy = 76.92%\n",
      "M_pca =  310 , M_lda =  33  --->  Accuracy = 77.88%\n",
      "M_pca =  310 , M_lda =  34  --->  Accuracy = 75.96%\n",
      "M_pca =  310 , M_lda =  35  --->  Accuracy = 75.96%\n",
      "M_pca =  310 , M_lda =  36  --->  Accuracy = 76.92%\n",
      "M_pca =  310 , M_lda =  37  --->  Accuracy = 77.88%\n",
      "M_pca =  310 , M_lda =  38  --->  Accuracy = 77.88%\n",
      "M_pca =  310 , M_lda =  39  --->  Accuracy = 77.88%\n",
      "M_pca =  310 , M_lda =  40  --->  Accuracy = 77.88%\n",
      "M_pca =  310 , M_lda =  41  --->  Accuracy = 77.88%\n",
      "M_pca =  310 , M_lda =  42  --->  Accuracy = 78.85%\n",
      "M_pca =  310 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  310 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  310 , M_lda =  45  --->  Accuracy = 77.88%\n",
      "M_pca =  310 , M_lda =  46  --->  Accuracy = 77.88%\n",
      "M_pca =  310 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  310 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  310 , M_lda =  49  --->  Accuracy = 79.81%\n",
      "M_pca =  310 , M_lda =  50  --->  Accuracy = 79.81%\n",
      "M_pca =  310 , M_lda =  51  --->  Accuracy = 79.81%\n",
      "M_pca =  311 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  311 , M_lda =  2  --->  Accuracy = 10.58%\n",
      "M_pca =  311 , M_lda =  3  --->  Accuracy = 20.19%\n",
      "M_pca =  311 , M_lda =  4  --->  Accuracy = 24.04%\n",
      "M_pca =  311 , M_lda =  5  --->  Accuracy = 34.62%\n",
      "M_pca =  311 , M_lda =  6  --->  Accuracy = 42.31%\n",
      "M_pca =  311 , M_lda =  7  --->  Accuracy = 48.08%\n",
      "M_pca =  311 , M_lda =  8  --->  Accuracy = 48.08%\n",
      "M_pca =  311 , M_lda =  9  --->  Accuracy = 53.85%\n",
      "M_pca =  311 , M_lda =  10  --->  Accuracy = 54.81%\n",
      "M_pca =  311 , M_lda =  11  --->  Accuracy = 61.54%\n",
      "M_pca =  311 , M_lda =  12  --->  Accuracy = 63.46%\n",
      "M_pca =  311 , M_lda =  13  --->  Accuracy = 62.50%\n",
      "M_pca =  311 , M_lda =  14  --->  Accuracy = 64.42%\n",
      "M_pca =  311 , M_lda =  15  --->  Accuracy = 65.38%\n",
      "M_pca =  311 , M_lda =  16  --->  Accuracy = 69.23%\n",
      "M_pca =  311 , M_lda =  17  --->  Accuracy = 71.15%\n",
      "M_pca =  311 , M_lda =  18  --->  Accuracy = 73.08%\n",
      "M_pca =  311 , M_lda =  19  --->  Accuracy = 73.08%\n",
      "M_pca =  311 , M_lda =  20  --->  Accuracy = 75.96%\n",
      "M_pca =  311 , M_lda =  21  --->  Accuracy = 75.96%\n",
      "M_pca =  311 , M_lda =  22  --->  Accuracy = 75.96%\n",
      "M_pca =  311 , M_lda =  23  --->  Accuracy = 75.96%\n",
      "M_pca =  311 , M_lda =  24  --->  Accuracy = 75.96%\n",
      "M_pca =  311 , M_lda =  25  --->  Accuracy = 77.88%\n",
      "M_pca =  311 , M_lda =  26  --->  Accuracy = 76.92%\n",
      "M_pca =  311 , M_lda =  27  --->  Accuracy = 77.88%\n",
      "M_pca =  311 , M_lda =  28  --->  Accuracy = 77.88%\n",
      "M_pca =  311 , M_lda =  29  --->  Accuracy = 77.88%\n",
      "M_pca =  311 , M_lda =  30  --->  Accuracy = 76.92%\n",
      "M_pca =  311 , M_lda =  31  --->  Accuracy = 77.88%\n",
      "M_pca =  311 , M_lda =  32  --->  Accuracy = 76.92%\n",
      "M_pca =  311 , M_lda =  33  --->  Accuracy = 76.92%\n",
      "M_pca =  311 , M_lda =  34  --->  Accuracy = 76.92%\n",
      "M_pca =  311 , M_lda =  35  --->  Accuracy = 76.92%\n",
      "M_pca =  311 , M_lda =  36  --->  Accuracy = 77.88%\n",
      "M_pca =  311 , M_lda =  37  --->  Accuracy = 78.85%\n",
      "M_pca =  311 , M_lda =  38  --->  Accuracy = 78.85%\n",
      "M_pca =  311 , M_lda =  39  --->  Accuracy = 78.85%\n",
      "M_pca =  311 , M_lda =  40  --->  Accuracy = 78.85%\n",
      "M_pca =  311 , M_lda =  41  --->  Accuracy = 78.85%\n",
      "M_pca =  311 , M_lda =  42  --->  Accuracy = 78.85%\n",
      "M_pca =  311 , M_lda =  43  --->  Accuracy = 79.81%\n",
      "M_pca =  311 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  311 , M_lda =  45  --->  Accuracy = 78.85%\n",
      "M_pca =  311 , M_lda =  46  --->  Accuracy = 78.85%\n",
      "M_pca =  311 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  311 , M_lda =  48  --->  Accuracy = 78.85%\n",
      "M_pca =  311 , M_lda =  49  --->  Accuracy = 78.85%\n",
      "M_pca =  311 , M_lda =  50  --->  Accuracy = 78.85%\n",
      "M_pca =  311 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  312 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  312 , M_lda =  2  --->  Accuracy = 10.58%\n",
      "M_pca =  312 , M_lda =  3  --->  Accuracy = 19.23%\n",
      "M_pca =  312 , M_lda =  4  --->  Accuracy = 22.12%\n",
      "M_pca =  312 , M_lda =  5  --->  Accuracy = 33.65%\n",
      "M_pca =  312 , M_lda =  6  --->  Accuracy = 43.27%\n",
      "M_pca =  312 , M_lda =  7  --->  Accuracy = 50.00%\n",
      "M_pca =  312 , M_lda =  8  --->  Accuracy = 47.12%\n",
      "M_pca =  312 , M_lda =  9  --->  Accuracy = 51.92%\n",
      "M_pca =  312 , M_lda =  10  --->  Accuracy = 54.81%\n",
      "M_pca =  312 , M_lda =  11  --->  Accuracy = 61.54%\n",
      "M_pca =  312 , M_lda =  12  --->  Accuracy = 65.38%\n",
      "M_pca =  312 , M_lda =  13  --->  Accuracy = 65.38%\n",
      "M_pca =  312 , M_lda =  14  --->  Accuracy = 66.35%\n",
      "M_pca =  312 , M_lda =  15  --->  Accuracy = 67.31%\n",
      "M_pca =  312 , M_lda =  16  --->  Accuracy = 70.19%\n",
      "M_pca =  312 , M_lda =  17  --->  Accuracy = 71.15%\n",
      "M_pca =  312 , M_lda =  18  --->  Accuracy = 72.12%\n",
      "M_pca =  312 , M_lda =  19  --->  Accuracy = 73.08%\n",
      "M_pca =  312 , M_lda =  20  --->  Accuracy = 75.96%\n",
      "M_pca =  312 , M_lda =  21  --->  Accuracy = 76.92%\n",
      "M_pca =  312 , M_lda =  22  --->  Accuracy = 76.92%\n",
      "M_pca =  312 , M_lda =  23  --->  Accuracy = 75.96%\n",
      "M_pca =  312 , M_lda =  24  --->  Accuracy = 75.96%\n",
      "M_pca =  312 , M_lda =  25  --->  Accuracy = 76.92%\n",
      "M_pca =  312 , M_lda =  26  --->  Accuracy = 76.92%\n",
      "M_pca =  312 , M_lda =  27  --->  Accuracy = 76.92%\n",
      "M_pca =  312 , M_lda =  28  --->  Accuracy = 76.92%\n",
      "M_pca =  312 , M_lda =  29  --->  Accuracy = 77.88%\n",
      "M_pca =  312 , M_lda =  30  --->  Accuracy = 77.88%\n",
      "M_pca =  312 , M_lda =  31  --->  Accuracy = 77.88%\n",
      "M_pca =  312 , M_lda =  32  --->  Accuracy = 77.88%\n",
      "M_pca =  312 , M_lda =  33  --->  Accuracy = 76.92%\n",
      "M_pca =  312 , M_lda =  34  --->  Accuracy = 76.92%\n",
      "M_pca =  312 , M_lda =  35  --->  Accuracy = 77.88%\n",
      "M_pca =  312 , M_lda =  36  --->  Accuracy = 79.81%\n",
      "M_pca =  312 , M_lda =  37  --->  Accuracy = 79.81%\n",
      "M_pca =  312 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  312 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  312 , M_lda =  40  --->  Accuracy = 79.81%\n",
      "M_pca =  312 , M_lda =  41  --->  Accuracy = 79.81%\n",
      "M_pca =  312 , M_lda =  42  --->  Accuracy = 79.81%\n",
      "M_pca =  312 , M_lda =  43  --->  Accuracy = 79.81%\n",
      "M_pca =  312 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  312 , M_lda =  45  --->  Accuracy = 79.81%\n",
      "M_pca =  312 , M_lda =  46  --->  Accuracy = 79.81%\n",
      "M_pca =  312 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  312 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  312 , M_lda =  49  --->  Accuracy = 78.85%\n",
      "M_pca =  312 , M_lda =  50  --->  Accuracy = 79.81%\n",
      "M_pca =  312 , M_lda =  51  --->  Accuracy = 79.81%\n",
      "M_pca =  313 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  313 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  313 , M_lda =  3  --->  Accuracy = 22.12%\n",
      "M_pca =  313 , M_lda =  4  --->  Accuracy = 23.08%\n",
      "M_pca =  313 , M_lda =  5  --->  Accuracy = 35.58%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  313 , M_lda =  6  --->  Accuracy = 41.35%\n",
      "M_pca =  313 , M_lda =  7  --->  Accuracy = 46.15%\n",
      "M_pca =  313 , M_lda =  8  --->  Accuracy = 48.08%\n",
      "M_pca =  313 , M_lda =  9  --->  Accuracy = 49.04%\n",
      "M_pca =  313 , M_lda =  10  --->  Accuracy = 53.85%\n",
      "M_pca =  313 , M_lda =  11  --->  Accuracy = 54.81%\n",
      "M_pca =  313 , M_lda =  12  --->  Accuracy = 64.42%\n",
      "M_pca =  313 , M_lda =  13  --->  Accuracy = 67.31%\n",
      "M_pca =  313 , M_lda =  14  --->  Accuracy = 67.31%\n",
      "M_pca =  313 , M_lda =  15  --->  Accuracy = 67.31%\n",
      "M_pca =  313 , M_lda =  16  --->  Accuracy = 72.12%\n",
      "M_pca =  313 , M_lda =  17  --->  Accuracy = 71.15%\n",
      "M_pca =  313 , M_lda =  18  --->  Accuracy = 74.04%\n",
      "M_pca =  313 , M_lda =  19  --->  Accuracy = 75.00%\n",
      "M_pca =  313 , M_lda =  20  --->  Accuracy = 75.96%\n",
      "M_pca =  313 , M_lda =  21  --->  Accuracy = 76.92%\n",
      "M_pca =  313 , M_lda =  22  --->  Accuracy = 75.00%\n",
      "M_pca =  313 , M_lda =  23  --->  Accuracy = 75.96%\n",
      "M_pca =  313 , M_lda =  24  --->  Accuracy = 76.92%\n",
      "M_pca =  313 , M_lda =  25  --->  Accuracy = 76.92%\n",
      "M_pca =  313 , M_lda =  26  --->  Accuracy = 76.92%\n",
      "M_pca =  313 , M_lda =  27  --->  Accuracy = 76.92%\n",
      "M_pca =  313 , M_lda =  28  --->  Accuracy = 76.92%\n",
      "M_pca =  313 , M_lda =  29  --->  Accuracy = 76.92%\n",
      "M_pca =  313 , M_lda =  30  --->  Accuracy = 76.92%\n",
      "M_pca =  313 , M_lda =  31  --->  Accuracy = 76.92%\n",
      "M_pca =  313 , M_lda =  32  --->  Accuracy = 76.92%\n",
      "M_pca =  313 , M_lda =  33  --->  Accuracy = 76.92%\n",
      "M_pca =  313 , M_lda =  34  --->  Accuracy = 77.88%\n",
      "M_pca =  313 , M_lda =  35  --->  Accuracy = 78.85%\n",
      "M_pca =  313 , M_lda =  36  --->  Accuracy = 77.88%\n",
      "M_pca =  313 , M_lda =  37  --->  Accuracy = 78.85%\n",
      "M_pca =  313 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  313 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  313 , M_lda =  40  --->  Accuracy = 79.81%\n",
      "M_pca =  313 , M_lda =  41  --->  Accuracy = 79.81%\n",
      "M_pca =  313 , M_lda =  42  --->  Accuracy = 79.81%\n",
      "M_pca =  313 , M_lda =  43  --->  Accuracy = 79.81%\n",
      "M_pca =  313 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  313 , M_lda =  45  --->  Accuracy = 79.81%\n",
      "M_pca =  313 , M_lda =  46  --->  Accuracy = 79.81%\n",
      "M_pca =  313 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  313 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  313 , M_lda =  49  --->  Accuracy = 78.85%\n",
      "M_pca =  313 , M_lda =  50  --->  Accuracy = 79.81%\n",
      "M_pca =  313 , M_lda =  51  --->  Accuracy = 79.81%\n",
      "M_pca =  314 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  314 , M_lda =  2  --->  Accuracy = 12.50%\n",
      "M_pca =  314 , M_lda =  3  --->  Accuracy = 20.19%\n",
      "M_pca =  314 , M_lda =  4  --->  Accuracy = 23.08%\n",
      "M_pca =  314 , M_lda =  5  --->  Accuracy = 35.58%\n",
      "M_pca =  314 , M_lda =  6  --->  Accuracy = 43.27%\n",
      "M_pca =  314 , M_lda =  7  --->  Accuracy = 48.08%\n",
      "M_pca =  314 , M_lda =  8  --->  Accuracy = 49.04%\n",
      "M_pca =  314 , M_lda =  9  --->  Accuracy = 56.73%\n",
      "M_pca =  314 , M_lda =  10  --->  Accuracy = 54.81%\n",
      "M_pca =  314 , M_lda =  11  --->  Accuracy = 56.73%\n",
      "M_pca =  314 , M_lda =  12  --->  Accuracy = 63.46%\n",
      "M_pca =  314 , M_lda =  13  --->  Accuracy = 65.38%\n",
      "M_pca =  314 , M_lda =  14  --->  Accuracy = 67.31%\n",
      "M_pca =  314 , M_lda =  15  --->  Accuracy = 68.27%\n",
      "M_pca =  314 , M_lda =  16  --->  Accuracy = 69.23%\n",
      "M_pca =  314 , M_lda =  17  --->  Accuracy = 70.19%\n",
      "M_pca =  314 , M_lda =  18  --->  Accuracy = 73.08%\n",
      "M_pca =  314 , M_lda =  19  --->  Accuracy = 73.08%\n",
      "M_pca =  314 , M_lda =  20  --->  Accuracy = 75.00%\n",
      "M_pca =  314 , M_lda =  21  --->  Accuracy = 76.92%\n",
      "M_pca =  314 , M_lda =  22  --->  Accuracy = 75.00%\n",
      "M_pca =  314 , M_lda =  23  --->  Accuracy = 75.96%\n",
      "M_pca =  314 , M_lda =  24  --->  Accuracy = 76.92%\n",
      "M_pca =  314 , M_lda =  25  --->  Accuracy = 76.92%\n",
      "M_pca =  314 , M_lda =  26  --->  Accuracy = 77.88%\n",
      "M_pca =  314 , M_lda =  27  --->  Accuracy = 77.88%\n",
      "M_pca =  314 , M_lda =  28  --->  Accuracy = 76.92%\n",
      "M_pca =  314 , M_lda =  29  --->  Accuracy = 76.92%\n",
      "M_pca =  314 , M_lda =  30  --->  Accuracy = 76.92%\n",
      "M_pca =  314 , M_lda =  31  --->  Accuracy = 77.88%\n",
      "M_pca =  314 , M_lda =  32  --->  Accuracy = 77.88%\n",
      "M_pca =  314 , M_lda =  33  --->  Accuracy = 77.88%\n",
      "M_pca =  314 , M_lda =  34  --->  Accuracy = 77.88%\n",
      "M_pca =  314 , M_lda =  35  --->  Accuracy = 77.88%\n",
      "M_pca =  314 , M_lda =  36  --->  Accuracy = 78.85%\n",
      "M_pca =  314 , M_lda =  37  --->  Accuracy = 78.85%\n",
      "M_pca =  314 , M_lda =  38  --->  Accuracy = 78.85%\n",
      "M_pca =  314 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  314 , M_lda =  40  --->  Accuracy = 79.81%\n",
      "M_pca =  314 , M_lda =  41  --->  Accuracy = 79.81%\n",
      "M_pca =  314 , M_lda =  42  --->  Accuracy = 78.85%\n",
      "M_pca =  314 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  314 , M_lda =  44  --->  Accuracy = 77.88%\n",
      "M_pca =  314 , M_lda =  45  --->  Accuracy = 78.85%\n",
      "M_pca =  314 , M_lda =  46  --->  Accuracy = 80.77%\n",
      "M_pca =  314 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  314 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  314 , M_lda =  49  --->  Accuracy = 79.81%\n",
      "M_pca =  314 , M_lda =  50  --->  Accuracy = 79.81%\n",
      "M_pca =  314 , M_lda =  51  --->  Accuracy = 80.77%\n",
      "M_pca =  315 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  315 , M_lda =  2  --->  Accuracy = 10.58%\n",
      "M_pca =  315 , M_lda =  3  --->  Accuracy = 19.23%\n",
      "M_pca =  315 , M_lda =  4  --->  Accuracy = 23.08%\n",
      "M_pca =  315 , M_lda =  5  --->  Accuracy = 32.69%\n",
      "M_pca =  315 , M_lda =  6  --->  Accuracy = 43.27%\n",
      "M_pca =  315 , M_lda =  7  --->  Accuracy = 50.96%\n",
      "M_pca =  315 , M_lda =  8  --->  Accuracy = 51.92%\n",
      "M_pca =  315 , M_lda =  9  --->  Accuracy = 56.73%\n",
      "M_pca =  315 , M_lda =  10  --->  Accuracy = 55.77%\n",
      "M_pca =  315 , M_lda =  11  --->  Accuracy = 57.69%\n",
      "M_pca =  315 , M_lda =  12  --->  Accuracy = 64.42%\n",
      "M_pca =  315 , M_lda =  13  --->  Accuracy = 67.31%\n",
      "M_pca =  315 , M_lda =  14  --->  Accuracy = 68.27%\n",
      "M_pca =  315 , M_lda =  15  --->  Accuracy = 66.35%\n",
      "M_pca =  315 , M_lda =  16  --->  Accuracy = 68.27%\n",
      "M_pca =  315 , M_lda =  17  --->  Accuracy = 70.19%\n",
      "M_pca =  315 , M_lda =  18  --->  Accuracy = 71.15%\n",
      "M_pca =  315 , M_lda =  19  --->  Accuracy = 73.08%\n",
      "M_pca =  315 , M_lda =  20  --->  Accuracy = 75.00%\n",
      "M_pca =  315 , M_lda =  21  --->  Accuracy = 75.00%\n",
      "M_pca =  315 , M_lda =  22  --->  Accuracy = 76.92%\n",
      "M_pca =  315 , M_lda =  23  --->  Accuracy = 76.92%\n",
      "M_pca =  315 , M_lda =  24  --->  Accuracy = 75.96%\n",
      "M_pca =  315 , M_lda =  25  --->  Accuracy = 75.96%\n",
      "M_pca =  315 , M_lda =  26  --->  Accuracy = 76.92%\n",
      "M_pca =  315 , M_lda =  27  --->  Accuracy = 76.92%\n",
      "M_pca =  315 , M_lda =  28  --->  Accuracy = 76.92%\n",
      "M_pca =  315 , M_lda =  29  --->  Accuracy = 76.92%\n",
      "M_pca =  315 , M_lda =  30  --->  Accuracy = 77.88%\n",
      "M_pca =  315 , M_lda =  31  --->  Accuracy = 77.88%\n",
      "M_pca =  315 , M_lda =  32  --->  Accuracy = 77.88%\n",
      "M_pca =  315 , M_lda =  33  --->  Accuracy = 77.88%\n",
      "M_pca =  315 , M_lda =  34  --->  Accuracy = 77.88%\n",
      "M_pca =  315 , M_lda =  35  --->  Accuracy = 78.85%\n",
      "M_pca =  315 , M_lda =  36  --->  Accuracy = 77.88%\n",
      "M_pca =  315 , M_lda =  37  --->  Accuracy = 78.85%\n",
      "M_pca =  315 , M_lda =  38  --->  Accuracy = 78.85%\n",
      "M_pca =  315 , M_lda =  39  --->  Accuracy = 78.85%\n",
      "M_pca =  315 , M_lda =  40  --->  Accuracy = 78.85%\n",
      "M_pca =  315 , M_lda =  41  --->  Accuracy = 77.88%\n",
      "M_pca =  315 , M_lda =  42  --->  Accuracy = 78.85%\n",
      "M_pca =  315 , M_lda =  43  --->  Accuracy = 77.88%\n",
      "M_pca =  315 , M_lda =  44  --->  Accuracy = 77.88%\n",
      "M_pca =  315 , M_lda =  45  --->  Accuracy = 77.88%\n",
      "M_pca =  315 , M_lda =  46  --->  Accuracy = 78.85%\n",
      "M_pca =  315 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  315 , M_lda =  48  --->  Accuracy = 78.85%\n",
      "M_pca =  315 , M_lda =  49  --->  Accuracy = 78.85%\n",
      "M_pca =  315 , M_lda =  50  --->  Accuracy = 78.85%\n",
      "M_pca =  315 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  316 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  316 , M_lda =  2  --->  Accuracy = 17.31%\n",
      "M_pca =  316 , M_lda =  3  --->  Accuracy = 19.23%\n",
      "M_pca =  316 , M_lda =  4  --->  Accuracy = 25.96%\n",
      "M_pca =  316 , M_lda =  5  --->  Accuracy = 32.69%\n",
      "M_pca =  316 , M_lda =  6  --->  Accuracy = 43.27%\n",
      "M_pca =  316 , M_lda =  7  --->  Accuracy = 50.00%\n",
      "M_pca =  316 , M_lda =  8  --->  Accuracy = 54.81%\n",
      "M_pca =  316 , M_lda =  9  --->  Accuracy = 57.69%\n",
      "M_pca =  316 , M_lda =  10  --->  Accuracy = 54.81%\n",
      "M_pca =  316 , M_lda =  11  --->  Accuracy = 59.62%\n",
      "M_pca =  316 , M_lda =  12  --->  Accuracy = 67.31%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  316 , M_lda =  13  --->  Accuracy = 70.19%\n",
      "M_pca =  316 , M_lda =  14  --->  Accuracy = 71.15%\n",
      "M_pca =  316 , M_lda =  15  --->  Accuracy = 69.23%\n",
      "M_pca =  316 , M_lda =  16  --->  Accuracy = 70.19%\n",
      "M_pca =  316 , M_lda =  17  --->  Accuracy = 71.15%\n",
      "M_pca =  316 , M_lda =  18  --->  Accuracy = 72.12%\n",
      "M_pca =  316 , M_lda =  19  --->  Accuracy = 75.00%\n",
      "M_pca =  316 , M_lda =  20  --->  Accuracy = 75.00%\n",
      "M_pca =  316 , M_lda =  21  --->  Accuracy = 75.96%\n",
      "M_pca =  316 , M_lda =  22  --->  Accuracy = 77.88%\n",
      "M_pca =  316 , M_lda =  23  --->  Accuracy = 76.92%\n",
      "M_pca =  316 , M_lda =  24  --->  Accuracy = 76.92%\n",
      "M_pca =  316 , M_lda =  25  --->  Accuracy = 76.92%\n",
      "M_pca =  316 , M_lda =  26  --->  Accuracy = 77.88%\n",
      "M_pca =  316 , M_lda =  27  --->  Accuracy = 77.88%\n",
      "M_pca =  316 , M_lda =  28  --->  Accuracy = 77.88%\n",
      "M_pca =  316 , M_lda =  29  --->  Accuracy = 77.88%\n",
      "M_pca =  316 , M_lda =  30  --->  Accuracy = 77.88%\n",
      "M_pca =  316 , M_lda =  31  --->  Accuracy = 78.85%\n",
      "M_pca =  316 , M_lda =  32  --->  Accuracy = 77.88%\n",
      "M_pca =  316 , M_lda =  33  --->  Accuracy = 78.85%\n",
      "M_pca =  316 , M_lda =  34  --->  Accuracy = 77.88%\n",
      "M_pca =  316 , M_lda =  35  --->  Accuracy = 77.88%\n",
      "M_pca =  316 , M_lda =  36  --->  Accuracy = 78.85%\n",
      "M_pca =  316 , M_lda =  37  --->  Accuracy = 79.81%\n",
      "M_pca =  316 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  316 , M_lda =  39  --->  Accuracy = 80.77%\n",
      "M_pca =  316 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  316 , M_lda =  41  --->  Accuracy = 79.81%\n",
      "M_pca =  316 , M_lda =  42  --->  Accuracy = 79.81%\n",
      "M_pca =  316 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  316 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  316 , M_lda =  45  --->  Accuracy = 78.85%\n",
      "M_pca =  316 , M_lda =  46  --->  Accuracy = 79.81%\n",
      "M_pca =  316 , M_lda =  47  --->  Accuracy = 80.77%\n",
      "M_pca =  316 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  316 , M_lda =  49  --->  Accuracy = 79.81%\n",
      "M_pca =  316 , M_lda =  50  --->  Accuracy = 79.81%\n",
      "M_pca =  316 , M_lda =  51  --->  Accuracy = 80.77%\n",
      "M_pca =  317 , M_lda =  1  --->  Accuracy = 9.62%\n",
      "M_pca =  317 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  317 , M_lda =  3  --->  Accuracy = 19.23%\n",
      "M_pca =  317 , M_lda =  4  --->  Accuracy = 22.12%\n",
      "M_pca =  317 , M_lda =  5  --->  Accuracy = 30.77%\n",
      "M_pca =  317 , M_lda =  6  --->  Accuracy = 40.38%\n",
      "M_pca =  317 , M_lda =  7  --->  Accuracy = 50.00%\n",
      "M_pca =  317 , M_lda =  8  --->  Accuracy = 50.96%\n",
      "M_pca =  317 , M_lda =  9  --->  Accuracy = 57.69%\n",
      "M_pca =  317 , M_lda =  10  --->  Accuracy = 59.62%\n",
      "M_pca =  317 , M_lda =  11  --->  Accuracy = 62.50%\n",
      "M_pca =  317 , M_lda =  12  --->  Accuracy = 68.27%\n",
      "M_pca =  317 , M_lda =  13  --->  Accuracy = 69.23%\n",
      "M_pca =  317 , M_lda =  14  --->  Accuracy = 70.19%\n",
      "M_pca =  317 , M_lda =  15  --->  Accuracy = 72.12%\n",
      "M_pca =  317 , M_lda =  16  --->  Accuracy = 70.19%\n",
      "M_pca =  317 , M_lda =  17  --->  Accuracy = 70.19%\n",
      "M_pca =  317 , M_lda =  18  --->  Accuracy = 72.12%\n",
      "M_pca =  317 , M_lda =  19  --->  Accuracy = 75.00%\n",
      "M_pca =  317 , M_lda =  20  --->  Accuracy = 76.92%\n",
      "M_pca =  317 , M_lda =  21  --->  Accuracy = 76.92%\n",
      "M_pca =  317 , M_lda =  22  --->  Accuracy = 76.92%\n",
      "M_pca =  317 , M_lda =  23  --->  Accuracy = 76.92%\n",
      "M_pca =  317 , M_lda =  24  --->  Accuracy = 76.92%\n",
      "M_pca =  317 , M_lda =  25  --->  Accuracy = 77.88%\n",
      "M_pca =  317 , M_lda =  26  --->  Accuracy = 77.88%\n",
      "M_pca =  317 , M_lda =  27  --->  Accuracy = 78.85%\n",
      "M_pca =  317 , M_lda =  28  --->  Accuracy = 78.85%\n",
      "M_pca =  317 , M_lda =  29  --->  Accuracy = 78.85%\n",
      "M_pca =  317 , M_lda =  30  --->  Accuracy = 79.81%\n",
      "M_pca =  317 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  317 , M_lda =  32  --->  Accuracy = 78.85%\n",
      "M_pca =  317 , M_lda =  33  --->  Accuracy = 79.81%\n",
      "M_pca =  317 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  317 , M_lda =  35  --->  Accuracy = 79.81%\n",
      "M_pca =  317 , M_lda =  36  --->  Accuracy = 79.81%\n",
      "M_pca =  317 , M_lda =  37  --->  Accuracy = 79.81%\n",
      "M_pca =  317 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  317 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  317 , M_lda =  40  --->  Accuracy = 79.81%\n",
      "M_pca =  317 , M_lda =  41  --->  Accuracy = 78.85%\n",
      "M_pca =  317 , M_lda =  42  --->  Accuracy = 78.85%\n",
      "M_pca =  317 , M_lda =  43  --->  Accuracy = 79.81%\n",
      "M_pca =  317 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  317 , M_lda =  45  --->  Accuracy = 79.81%\n",
      "M_pca =  317 , M_lda =  46  --->  Accuracy = 79.81%\n",
      "M_pca =  317 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  317 , M_lda =  48  --->  Accuracy = 79.81%\n",
      "M_pca =  317 , M_lda =  49  --->  Accuracy = 79.81%\n",
      "M_pca =  317 , M_lda =  50  --->  Accuracy = 79.81%\n",
      "M_pca =  317 , M_lda =  51  --->  Accuracy = 79.81%\n",
      "M_pca =  318 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  318 , M_lda =  2  --->  Accuracy = 9.62%\n",
      "M_pca =  318 , M_lda =  3  --->  Accuracy = 17.31%\n",
      "M_pca =  318 , M_lda =  4  --->  Accuracy = 25.00%\n",
      "M_pca =  318 , M_lda =  5  --->  Accuracy = 34.62%\n",
      "M_pca =  318 , M_lda =  6  --->  Accuracy = 44.23%\n",
      "M_pca =  318 , M_lda =  7  --->  Accuracy = 48.08%\n",
      "M_pca =  318 , M_lda =  8  --->  Accuracy = 52.88%\n",
      "M_pca =  318 , M_lda =  9  --->  Accuracy = 55.77%\n",
      "M_pca =  318 , M_lda =  10  --->  Accuracy = 57.69%\n",
      "M_pca =  318 , M_lda =  11  --->  Accuracy = 60.58%\n",
      "M_pca =  318 , M_lda =  12  --->  Accuracy = 67.31%\n",
      "M_pca =  318 , M_lda =  13  --->  Accuracy = 70.19%\n",
      "M_pca =  318 , M_lda =  14  --->  Accuracy = 67.31%\n",
      "M_pca =  318 , M_lda =  15  --->  Accuracy = 70.19%\n",
      "M_pca =  318 , M_lda =  16  --->  Accuracy = 71.15%\n",
      "M_pca =  318 , M_lda =  17  --->  Accuracy = 70.19%\n",
      "M_pca =  318 , M_lda =  18  --->  Accuracy = 72.12%\n",
      "M_pca =  318 , M_lda =  19  --->  Accuracy = 74.04%\n",
      "M_pca =  318 , M_lda =  20  --->  Accuracy = 75.96%\n",
      "M_pca =  318 , M_lda =  21  --->  Accuracy = 77.88%\n",
      "M_pca =  318 , M_lda =  22  --->  Accuracy = 77.88%\n",
      "M_pca =  318 , M_lda =  23  --->  Accuracy = 77.88%\n",
      "M_pca =  318 , M_lda =  24  --->  Accuracy = 77.88%\n",
      "M_pca =  318 , M_lda =  25  --->  Accuracy = 76.92%\n",
      "M_pca =  318 , M_lda =  26  --->  Accuracy = 77.88%\n",
      "M_pca =  318 , M_lda =  27  --->  Accuracy = 77.88%\n",
      "M_pca =  318 , M_lda =  28  --->  Accuracy = 77.88%\n",
      "M_pca =  318 , M_lda =  29  --->  Accuracy = 77.88%\n",
      "M_pca =  318 , M_lda =  30  --->  Accuracy = 77.88%\n",
      "M_pca =  318 , M_lda =  31  --->  Accuracy = 77.88%\n",
      "M_pca =  318 , M_lda =  32  --->  Accuracy = 77.88%\n",
      "M_pca =  318 , M_lda =  33  --->  Accuracy = 76.92%\n",
      "M_pca =  318 , M_lda =  34  --->  Accuracy = 76.92%\n",
      "M_pca =  318 , M_lda =  35  --->  Accuracy = 77.88%\n",
      "M_pca =  318 , M_lda =  36  --->  Accuracy = 77.88%\n",
      "M_pca =  318 , M_lda =  37  --->  Accuracy = 77.88%\n",
      "M_pca =  318 , M_lda =  38  --->  Accuracy = 77.88%\n",
      "M_pca =  318 , M_lda =  39  --->  Accuracy = 77.88%\n",
      "M_pca =  318 , M_lda =  40  --->  Accuracy = 77.88%\n",
      "M_pca =  318 , M_lda =  41  --->  Accuracy = 77.88%\n",
      "M_pca =  318 , M_lda =  42  --->  Accuracy = 77.88%\n",
      "M_pca =  318 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  318 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  318 , M_lda =  45  --->  Accuracy = 78.85%\n",
      "M_pca =  318 , M_lda =  46  --->  Accuracy = 78.85%\n",
      "M_pca =  318 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  318 , M_lda =  48  --->  Accuracy = 78.85%\n",
      "M_pca =  318 , M_lda =  49  --->  Accuracy = 78.85%\n",
      "M_pca =  318 , M_lda =  50  --->  Accuracy = 78.85%\n",
      "M_pca =  318 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  319 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  319 , M_lda =  2  --->  Accuracy = 8.65%\n",
      "M_pca =  319 , M_lda =  3  --->  Accuracy = 17.31%\n",
      "M_pca =  319 , M_lda =  4  --->  Accuracy = 25.96%\n",
      "M_pca =  319 , M_lda =  5  --->  Accuracy = 32.69%\n",
      "M_pca =  319 , M_lda =  6  --->  Accuracy = 40.38%\n",
      "M_pca =  319 , M_lda =  7  --->  Accuracy = 51.92%\n",
      "M_pca =  319 , M_lda =  8  --->  Accuracy = 54.81%\n",
      "M_pca =  319 , M_lda =  9  --->  Accuracy = 59.62%\n",
      "M_pca =  319 , M_lda =  10  --->  Accuracy = 61.54%\n",
      "M_pca =  319 , M_lda =  11  --->  Accuracy = 61.54%\n",
      "M_pca =  319 , M_lda =  12  --->  Accuracy = 67.31%\n",
      "M_pca =  319 , M_lda =  13  --->  Accuracy = 70.19%\n",
      "M_pca =  319 , M_lda =  14  --->  Accuracy = 68.27%\n",
      "M_pca =  319 , M_lda =  15  --->  Accuracy = 72.12%\n",
      "M_pca =  319 , M_lda =  16  --->  Accuracy = 72.12%\n",
      "M_pca =  319 , M_lda =  17  --->  Accuracy = 75.00%\n",
      "M_pca =  319 , M_lda =  18  --->  Accuracy = 72.12%\n",
      "M_pca =  319 , M_lda =  19  --->  Accuracy = 75.96%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  319 , M_lda =  20  --->  Accuracy = 75.96%\n",
      "M_pca =  319 , M_lda =  21  --->  Accuracy = 76.92%\n",
      "M_pca =  319 , M_lda =  22  --->  Accuracy = 77.88%\n",
      "M_pca =  319 , M_lda =  23  --->  Accuracy = 76.92%\n",
      "M_pca =  319 , M_lda =  24  --->  Accuracy = 76.92%\n",
      "M_pca =  319 , M_lda =  25  --->  Accuracy = 76.92%\n",
      "M_pca =  319 , M_lda =  26  --->  Accuracy = 77.88%\n",
      "M_pca =  319 , M_lda =  27  --->  Accuracy = 77.88%\n",
      "M_pca =  319 , M_lda =  28  --->  Accuracy = 77.88%\n",
      "M_pca =  319 , M_lda =  29  --->  Accuracy = 77.88%\n",
      "M_pca =  319 , M_lda =  30  --->  Accuracy = 77.88%\n",
      "M_pca =  319 , M_lda =  31  --->  Accuracy = 77.88%\n",
      "M_pca =  319 , M_lda =  32  --->  Accuracy = 77.88%\n",
      "M_pca =  319 , M_lda =  33  --->  Accuracy = 76.92%\n",
      "M_pca =  319 , M_lda =  34  --->  Accuracy = 77.88%\n",
      "M_pca =  319 , M_lda =  35  --->  Accuracy = 76.92%\n",
      "M_pca =  319 , M_lda =  36  --->  Accuracy = 76.92%\n",
      "M_pca =  319 , M_lda =  37  --->  Accuracy = 77.88%\n",
      "M_pca =  319 , M_lda =  38  --->  Accuracy = 77.88%\n",
      "M_pca =  319 , M_lda =  39  --->  Accuracy = 77.88%\n",
      "M_pca =  319 , M_lda =  40  --->  Accuracy = 77.88%\n",
      "M_pca =  319 , M_lda =  41  --->  Accuracy = 77.88%\n",
      "M_pca =  319 , M_lda =  42  --->  Accuracy = 77.88%\n",
      "M_pca =  319 , M_lda =  43  --->  Accuracy = 77.88%\n",
      "M_pca =  319 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  319 , M_lda =  45  --->  Accuracy = 78.85%\n",
      "M_pca =  319 , M_lda =  46  --->  Accuracy = 78.85%\n",
      "M_pca =  319 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  319 , M_lda =  48  --->  Accuracy = 78.85%\n",
      "M_pca =  319 , M_lda =  49  --->  Accuracy = 78.85%\n",
      "M_pca =  319 , M_lda =  50  --->  Accuracy = 78.85%\n",
      "M_pca =  319 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  320 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  320 , M_lda =  2  --->  Accuracy = 8.65%\n",
      "M_pca =  320 , M_lda =  3  --->  Accuracy = 18.27%\n",
      "M_pca =  320 , M_lda =  4  --->  Accuracy = 25.00%\n",
      "M_pca =  320 , M_lda =  5  --->  Accuracy = 33.65%\n",
      "M_pca =  320 , M_lda =  6  --->  Accuracy = 37.50%\n",
      "M_pca =  320 , M_lda =  7  --->  Accuracy = 50.00%\n",
      "M_pca =  320 , M_lda =  8  --->  Accuracy = 55.77%\n",
      "M_pca =  320 , M_lda =  9  --->  Accuracy = 60.58%\n",
      "M_pca =  320 , M_lda =  10  --->  Accuracy = 61.54%\n",
      "M_pca =  320 , M_lda =  11  --->  Accuracy = 59.62%\n",
      "M_pca =  320 , M_lda =  12  --->  Accuracy = 64.42%\n",
      "M_pca =  320 , M_lda =  13  --->  Accuracy = 67.31%\n",
      "M_pca =  320 , M_lda =  14  --->  Accuracy = 71.15%\n",
      "M_pca =  320 , M_lda =  15  --->  Accuracy = 72.12%\n",
      "M_pca =  320 , M_lda =  16  --->  Accuracy = 74.04%\n",
      "M_pca =  320 , M_lda =  17  --->  Accuracy = 74.04%\n",
      "M_pca =  320 , M_lda =  18  --->  Accuracy = 72.12%\n",
      "M_pca =  320 , M_lda =  19  --->  Accuracy = 74.04%\n",
      "M_pca =  320 , M_lda =  20  --->  Accuracy = 75.96%\n",
      "M_pca =  320 , M_lda =  21  --->  Accuracy = 75.96%\n",
      "M_pca =  320 , M_lda =  22  --->  Accuracy = 77.88%\n",
      "M_pca =  320 , M_lda =  23  --->  Accuracy = 75.96%\n",
      "M_pca =  320 , M_lda =  24  --->  Accuracy = 75.96%\n",
      "M_pca =  320 , M_lda =  25  --->  Accuracy = 77.88%\n",
      "M_pca =  320 , M_lda =  26  --->  Accuracy = 76.92%\n",
      "M_pca =  320 , M_lda =  27  --->  Accuracy = 77.88%\n",
      "M_pca =  320 , M_lda =  28  --->  Accuracy = 77.88%\n",
      "M_pca =  320 , M_lda =  29  --->  Accuracy = 77.88%\n",
      "M_pca =  320 , M_lda =  30  --->  Accuracy = 77.88%\n",
      "M_pca =  320 , M_lda =  31  --->  Accuracy = 77.88%\n",
      "M_pca =  320 , M_lda =  32  --->  Accuracy = 77.88%\n",
      "M_pca =  320 , M_lda =  33  --->  Accuracy = 76.92%\n",
      "M_pca =  320 , M_lda =  34  --->  Accuracy = 77.88%\n",
      "M_pca =  320 , M_lda =  35  --->  Accuracy = 77.88%\n",
      "M_pca =  320 , M_lda =  36  --->  Accuracy = 77.88%\n",
      "M_pca =  320 , M_lda =  37  --->  Accuracy = 77.88%\n",
      "M_pca =  320 , M_lda =  38  --->  Accuracy = 77.88%\n",
      "M_pca =  320 , M_lda =  39  --->  Accuracy = 77.88%\n",
      "M_pca =  320 , M_lda =  40  --->  Accuracy = 77.88%\n",
      "M_pca =  320 , M_lda =  41  --->  Accuracy = 78.85%\n",
      "M_pca =  320 , M_lda =  42  --->  Accuracy = 78.85%\n",
      "M_pca =  320 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  320 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  320 , M_lda =  45  --->  Accuracy = 78.85%\n",
      "M_pca =  320 , M_lda =  46  --->  Accuracy = 78.85%\n",
      "M_pca =  320 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  320 , M_lda =  48  --->  Accuracy = 78.85%\n",
      "M_pca =  320 , M_lda =  49  --->  Accuracy = 78.85%\n",
      "M_pca =  320 , M_lda =  50  --->  Accuracy = 78.85%\n",
      "M_pca =  320 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  321 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  321 , M_lda =  2  --->  Accuracy = 11.54%\n",
      "M_pca =  321 , M_lda =  3  --->  Accuracy = 19.23%\n",
      "M_pca =  321 , M_lda =  4  --->  Accuracy = 25.00%\n",
      "M_pca =  321 , M_lda =  5  --->  Accuracy = 32.69%\n",
      "M_pca =  321 , M_lda =  6  --->  Accuracy = 40.38%\n",
      "M_pca =  321 , M_lda =  7  --->  Accuracy = 50.96%\n",
      "M_pca =  321 , M_lda =  8  --->  Accuracy = 51.92%\n",
      "M_pca =  321 , M_lda =  9  --->  Accuracy = 55.77%\n",
      "M_pca =  321 , M_lda =  10  --->  Accuracy = 60.58%\n",
      "M_pca =  321 , M_lda =  11  --->  Accuracy = 60.58%\n",
      "M_pca =  321 , M_lda =  12  --->  Accuracy = 63.46%\n",
      "M_pca =  321 , M_lda =  13  --->  Accuracy = 67.31%\n",
      "M_pca =  321 , M_lda =  14  --->  Accuracy = 70.19%\n",
      "M_pca =  321 , M_lda =  15  --->  Accuracy = 72.12%\n",
      "M_pca =  321 , M_lda =  16  --->  Accuracy = 71.15%\n",
      "M_pca =  321 , M_lda =  17  --->  Accuracy = 74.04%\n",
      "M_pca =  321 , M_lda =  18  --->  Accuracy = 73.08%\n",
      "M_pca =  321 , M_lda =  19  --->  Accuracy = 75.00%\n",
      "M_pca =  321 , M_lda =  20  --->  Accuracy = 73.08%\n",
      "M_pca =  321 , M_lda =  21  --->  Accuracy = 75.00%\n",
      "M_pca =  321 , M_lda =  22  --->  Accuracy = 75.00%\n",
      "M_pca =  321 , M_lda =  23  --->  Accuracy = 75.96%\n",
      "M_pca =  321 , M_lda =  24  --->  Accuracy = 76.92%\n",
      "M_pca =  321 , M_lda =  25  --->  Accuracy = 75.96%\n",
      "M_pca =  321 , M_lda =  26  --->  Accuracy = 76.92%\n",
      "M_pca =  321 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  321 , M_lda =  28  --->  Accuracy = 78.85%\n",
      "M_pca =  321 , M_lda =  29  --->  Accuracy = 77.88%\n",
      "M_pca =  321 , M_lda =  30  --->  Accuracy = 77.88%\n",
      "M_pca =  321 , M_lda =  31  --->  Accuracy = 77.88%\n",
      "M_pca =  321 , M_lda =  32  --->  Accuracy = 77.88%\n",
      "M_pca =  321 , M_lda =  33  --->  Accuracy = 77.88%\n",
      "M_pca =  321 , M_lda =  34  --->  Accuracy = 77.88%\n",
      "M_pca =  321 , M_lda =  35  --->  Accuracy = 77.88%\n",
      "M_pca =  321 , M_lda =  36  --->  Accuracy = 77.88%\n",
      "M_pca =  321 , M_lda =  37  --->  Accuracy = 78.85%\n",
      "M_pca =  321 , M_lda =  38  --->  Accuracy = 78.85%\n",
      "M_pca =  321 , M_lda =  39  --->  Accuracy = 78.85%\n",
      "M_pca =  321 , M_lda =  40  --->  Accuracy = 78.85%\n",
      "M_pca =  321 , M_lda =  41  --->  Accuracy = 78.85%\n",
      "M_pca =  321 , M_lda =  42  --->  Accuracy = 78.85%\n",
      "M_pca =  321 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  321 , M_lda =  44  --->  Accuracy = 78.85%\n",
      "M_pca =  321 , M_lda =  45  --->  Accuracy = 78.85%\n",
      "M_pca =  321 , M_lda =  46  --->  Accuracy = 78.85%\n",
      "M_pca =  321 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  321 , M_lda =  48  --->  Accuracy = 78.85%\n",
      "M_pca =  321 , M_lda =  49  --->  Accuracy = 78.85%\n",
      "M_pca =  321 , M_lda =  50  --->  Accuracy = 78.85%\n",
      "M_pca =  321 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  322 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  322 , M_lda =  2  --->  Accuracy = 10.58%\n",
      "M_pca =  322 , M_lda =  3  --->  Accuracy = 18.27%\n",
      "M_pca =  322 , M_lda =  4  --->  Accuracy = 22.12%\n",
      "M_pca =  322 , M_lda =  5  --->  Accuracy = 32.69%\n",
      "M_pca =  322 , M_lda =  6  --->  Accuracy = 40.38%\n",
      "M_pca =  322 , M_lda =  7  --->  Accuracy = 49.04%\n",
      "M_pca =  322 , M_lda =  8  --->  Accuracy = 55.77%\n",
      "M_pca =  322 , M_lda =  9  --->  Accuracy = 57.69%\n",
      "M_pca =  322 , M_lda =  10  --->  Accuracy = 59.62%\n",
      "M_pca =  322 , M_lda =  11  --->  Accuracy = 61.54%\n",
      "M_pca =  322 , M_lda =  12  --->  Accuracy = 66.35%\n",
      "M_pca =  322 , M_lda =  13  --->  Accuracy = 68.27%\n",
      "M_pca =  322 , M_lda =  14  --->  Accuracy = 67.31%\n",
      "M_pca =  322 , M_lda =  15  --->  Accuracy = 70.19%\n",
      "M_pca =  322 , M_lda =  16  --->  Accuracy = 70.19%\n",
      "M_pca =  322 , M_lda =  17  --->  Accuracy = 72.12%\n",
      "M_pca =  322 , M_lda =  18  --->  Accuracy = 73.08%\n",
      "M_pca =  322 , M_lda =  19  --->  Accuracy = 73.08%\n",
      "M_pca =  322 , M_lda =  20  --->  Accuracy = 72.12%\n",
      "M_pca =  322 , M_lda =  21  --->  Accuracy = 74.04%\n",
      "M_pca =  322 , M_lda =  22  --->  Accuracy = 75.00%\n",
      "M_pca =  322 , M_lda =  23  --->  Accuracy = 76.92%\n",
      "M_pca =  322 , M_lda =  24  --->  Accuracy = 75.96%\n",
      "M_pca =  322 , M_lda =  25  --->  Accuracy = 75.00%\n",
      "M_pca =  322 , M_lda =  26  --->  Accuracy = 75.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  322 , M_lda =  27  --->  Accuracy = 76.92%\n",
      "M_pca =  322 , M_lda =  28  --->  Accuracy = 76.92%\n",
      "M_pca =  322 , M_lda =  29  --->  Accuracy = 77.88%\n",
      "M_pca =  322 , M_lda =  30  --->  Accuracy = 77.88%\n",
      "M_pca =  322 , M_lda =  31  --->  Accuracy = 76.92%\n",
      "M_pca =  322 , M_lda =  32  --->  Accuracy = 76.92%\n",
      "M_pca =  322 , M_lda =  33  --->  Accuracy = 76.92%\n",
      "M_pca =  322 , M_lda =  34  --->  Accuracy = 76.92%\n",
      "M_pca =  322 , M_lda =  35  --->  Accuracy = 78.85%\n",
      "M_pca =  322 , M_lda =  36  --->  Accuracy = 78.85%\n",
      "M_pca =  322 , M_lda =  37  --->  Accuracy = 78.85%\n",
      "M_pca =  322 , M_lda =  38  --->  Accuracy = 78.85%\n",
      "M_pca =  322 , M_lda =  39  --->  Accuracy = 78.85%\n",
      "M_pca =  322 , M_lda =  40  --->  Accuracy = 78.85%\n",
      "M_pca =  322 , M_lda =  41  --->  Accuracy = 79.81%\n",
      "M_pca =  322 , M_lda =  42  --->  Accuracy = 78.85%\n",
      "M_pca =  322 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  322 , M_lda =  44  --->  Accuracy = 79.81%\n",
      "M_pca =  322 , M_lda =  45  --->  Accuracy = 78.85%\n",
      "M_pca =  322 , M_lda =  46  --->  Accuracy = 78.85%\n",
      "M_pca =  322 , M_lda =  47  --->  Accuracy = 78.85%\n",
      "M_pca =  322 , M_lda =  48  --->  Accuracy = 78.85%\n",
      "M_pca =  322 , M_lda =  49  --->  Accuracy = 78.85%\n",
      "M_pca =  322 , M_lda =  50  --->  Accuracy = 78.85%\n",
      "M_pca =  322 , M_lda =  51  --->  Accuracy = 78.85%\n",
      "M_pca =  323 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  323 , M_lda =  2  --->  Accuracy = 9.62%\n",
      "M_pca =  323 , M_lda =  3  --->  Accuracy = 18.27%\n",
      "M_pca =  323 , M_lda =  4  --->  Accuracy = 21.15%\n",
      "M_pca =  323 , M_lda =  5  --->  Accuracy = 30.77%\n",
      "M_pca =  323 , M_lda =  6  --->  Accuracy = 38.46%\n",
      "M_pca =  323 , M_lda =  7  --->  Accuracy = 49.04%\n",
      "M_pca =  323 , M_lda =  8  --->  Accuracy = 54.81%\n",
      "M_pca =  323 , M_lda =  9  --->  Accuracy = 58.65%\n",
      "M_pca =  323 , M_lda =  10  --->  Accuracy = 60.58%\n",
      "M_pca =  323 , M_lda =  11  --->  Accuracy = 63.46%\n",
      "M_pca =  323 , M_lda =  12  --->  Accuracy = 64.42%\n",
      "M_pca =  323 , M_lda =  13  --->  Accuracy = 65.38%\n",
      "M_pca =  323 , M_lda =  14  --->  Accuracy = 67.31%\n",
      "M_pca =  323 , M_lda =  15  --->  Accuracy = 68.27%\n",
      "M_pca =  323 , M_lda =  16  --->  Accuracy = 70.19%\n",
      "M_pca =  323 , M_lda =  17  --->  Accuracy = 73.08%\n",
      "M_pca =  323 , M_lda =  18  --->  Accuracy = 73.08%\n",
      "M_pca =  323 , M_lda =  19  --->  Accuracy = 73.08%\n",
      "M_pca =  323 , M_lda =  20  --->  Accuracy = 75.00%\n",
      "M_pca =  323 , M_lda =  21  --->  Accuracy = 75.00%\n",
      "M_pca =  323 , M_lda =  22  --->  Accuracy = 74.04%\n",
      "M_pca =  323 , M_lda =  23  --->  Accuracy = 75.96%\n",
      "M_pca =  323 , M_lda =  24  --->  Accuracy = 77.88%\n",
      "M_pca =  323 , M_lda =  25  --->  Accuracy = 78.85%\n",
      "M_pca =  323 , M_lda =  26  --->  Accuracy = 77.88%\n",
      "M_pca =  323 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  323 , M_lda =  28  --->  Accuracy = 79.81%\n",
      "M_pca =  323 , M_lda =  29  --->  Accuracy = 79.81%\n",
      "M_pca =  323 , M_lda =  30  --->  Accuracy = 79.81%\n",
      "M_pca =  323 , M_lda =  31  --->  Accuracy = 80.77%\n",
      "M_pca =  323 , M_lda =  32  --->  Accuracy = 80.77%\n",
      "M_pca =  323 , M_lda =  33  --->  Accuracy = 80.77%\n",
      "M_pca =  323 , M_lda =  34  --->  Accuracy = 80.77%\n",
      "M_pca =  323 , M_lda =  35  --->  Accuracy = 80.77%\n",
      "M_pca =  323 , M_lda =  36  --->  Accuracy = 79.81%\n",
      "M_pca =  323 , M_lda =  37  --->  Accuracy = 80.77%\n",
      "M_pca =  323 , M_lda =  38  --->  Accuracy = 80.77%\n",
      "M_pca =  323 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  323 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  323 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  323 , M_lda =  42  --->  Accuracy = 79.81%\n",
      "M_pca =  323 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  323 , M_lda =  44  --->  Accuracy = 79.81%\n",
      "M_pca =  323 , M_lda =  45  --->  Accuracy = 78.85%\n",
      "M_pca =  323 , M_lda =  46  --->  Accuracy = 79.81%\n",
      "M_pca =  323 , M_lda =  47  --->  Accuracy = 79.81%\n",
      "M_pca =  323 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  323 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  323 , M_lda =  50  --->  Accuracy = 80.77%\n",
      "M_pca =  323 , M_lda =  51  --->  Accuracy = 80.77%\n",
      "M_pca =  324 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  324 , M_lda =  2  --->  Accuracy = 7.69%\n",
      "M_pca =  324 , M_lda =  3  --->  Accuracy = 18.27%\n",
      "M_pca =  324 , M_lda =  4  --->  Accuracy = 20.19%\n",
      "M_pca =  324 , M_lda =  5  --->  Accuracy = 31.73%\n",
      "M_pca =  324 , M_lda =  6  --->  Accuracy = 41.35%\n",
      "M_pca =  324 , M_lda =  7  --->  Accuracy = 47.12%\n",
      "M_pca =  324 , M_lda =  8  --->  Accuracy = 54.81%\n",
      "M_pca =  324 , M_lda =  9  --->  Accuracy = 57.69%\n",
      "M_pca =  324 , M_lda =  10  --->  Accuracy = 61.54%\n",
      "M_pca =  324 , M_lda =  11  --->  Accuracy = 62.50%\n",
      "M_pca =  324 , M_lda =  12  --->  Accuracy = 64.42%\n",
      "M_pca =  324 , M_lda =  13  --->  Accuracy = 65.38%\n",
      "M_pca =  324 , M_lda =  14  --->  Accuracy = 67.31%\n",
      "M_pca =  324 , M_lda =  15  --->  Accuracy = 68.27%\n",
      "M_pca =  324 , M_lda =  16  --->  Accuracy = 70.19%\n",
      "M_pca =  324 , M_lda =  17  --->  Accuracy = 72.12%\n",
      "M_pca =  324 , M_lda =  18  --->  Accuracy = 72.12%\n",
      "M_pca =  324 , M_lda =  19  --->  Accuracy = 72.12%\n",
      "M_pca =  324 , M_lda =  20  --->  Accuracy = 73.08%\n",
      "M_pca =  324 , M_lda =  21  --->  Accuracy = 75.96%\n",
      "M_pca =  324 , M_lda =  22  --->  Accuracy = 75.96%\n",
      "M_pca =  324 , M_lda =  23  --->  Accuracy = 75.96%\n",
      "M_pca =  324 , M_lda =  24  --->  Accuracy = 77.88%\n",
      "M_pca =  324 , M_lda =  25  --->  Accuracy = 78.85%\n",
      "M_pca =  324 , M_lda =  26  --->  Accuracy = 77.88%\n",
      "M_pca =  324 , M_lda =  27  --->  Accuracy = 79.81%\n",
      "M_pca =  324 , M_lda =  28  --->  Accuracy = 79.81%\n",
      "M_pca =  324 , M_lda =  29  --->  Accuracy = 80.77%\n",
      "M_pca =  324 , M_lda =  30  --->  Accuracy = 78.85%\n",
      "M_pca =  324 , M_lda =  31  --->  Accuracy = 78.85%\n",
      "M_pca =  324 , M_lda =  32  --->  Accuracy = 78.85%\n",
      "M_pca =  324 , M_lda =  33  --->  Accuracy = 78.85%\n",
      "M_pca =  324 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  324 , M_lda =  35  --->  Accuracy = 78.85%\n",
      "M_pca =  324 , M_lda =  36  --->  Accuracy = 77.88%\n",
      "M_pca =  324 , M_lda =  37  --->  Accuracy = 77.88%\n",
      "M_pca =  324 , M_lda =  38  --->  Accuracy = 77.88%\n",
      "M_pca =  324 , M_lda =  39  --->  Accuracy = 77.88%\n",
      "M_pca =  324 , M_lda =  40  --->  Accuracy = 78.85%\n",
      "M_pca =  324 , M_lda =  41  --->  Accuracy = 78.85%\n",
      "M_pca =  324 , M_lda =  42  --->  Accuracy = 77.88%\n",
      "M_pca =  324 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  324 , M_lda =  44  --->  Accuracy = 79.81%\n",
      "M_pca =  324 , M_lda =  45  --->  Accuracy = 79.81%\n",
      "M_pca =  324 , M_lda =  46  --->  Accuracy = 80.77%\n",
      "M_pca =  324 , M_lda =  47  --->  Accuracy = 80.77%\n",
      "M_pca =  324 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  324 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  324 , M_lda =  50  --->  Accuracy = 80.77%\n",
      "M_pca =  324 , M_lda =  51  --->  Accuracy = 80.77%\n",
      "M_pca =  325 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  325 , M_lda =  2  --->  Accuracy = 9.62%\n",
      "M_pca =  325 , M_lda =  3  --->  Accuracy = 22.12%\n",
      "M_pca =  325 , M_lda =  4  --->  Accuracy = 21.15%\n",
      "M_pca =  325 , M_lda =  5  --->  Accuracy = 28.85%\n",
      "M_pca =  325 , M_lda =  6  --->  Accuracy = 39.42%\n",
      "M_pca =  325 , M_lda =  7  --->  Accuracy = 48.08%\n",
      "M_pca =  325 , M_lda =  8  --->  Accuracy = 50.00%\n",
      "M_pca =  325 , M_lda =  9  --->  Accuracy = 53.85%\n",
      "M_pca =  325 , M_lda =  10  --->  Accuracy = 57.69%\n",
      "M_pca =  325 , M_lda =  11  --->  Accuracy = 57.69%\n",
      "M_pca =  325 , M_lda =  12  --->  Accuracy = 62.50%\n",
      "M_pca =  325 , M_lda =  13  --->  Accuracy = 62.50%\n",
      "M_pca =  325 , M_lda =  14  --->  Accuracy = 66.35%\n",
      "M_pca =  325 , M_lda =  15  --->  Accuracy = 68.27%\n",
      "M_pca =  325 , M_lda =  16  --->  Accuracy = 70.19%\n",
      "M_pca =  325 , M_lda =  17  --->  Accuracy = 72.12%\n",
      "M_pca =  325 , M_lda =  18  --->  Accuracy = 72.12%\n",
      "M_pca =  325 , M_lda =  19  --->  Accuracy = 73.08%\n",
      "M_pca =  325 , M_lda =  20  --->  Accuracy = 72.12%\n",
      "M_pca =  325 , M_lda =  21  --->  Accuracy = 74.04%\n",
      "M_pca =  325 , M_lda =  22  --->  Accuracy = 74.04%\n",
      "M_pca =  325 , M_lda =  23  --->  Accuracy = 75.96%\n",
      "M_pca =  325 , M_lda =  24  --->  Accuracy = 76.92%\n",
      "M_pca =  325 , M_lda =  25  --->  Accuracy = 77.88%\n",
      "M_pca =  325 , M_lda =  26  --->  Accuracy = 77.88%\n",
      "M_pca =  325 , M_lda =  27  --->  Accuracy = 78.85%\n",
      "M_pca =  325 , M_lda =  28  --->  Accuracy = 79.81%\n",
      "M_pca =  325 , M_lda =  29  --->  Accuracy = 80.77%\n",
      "M_pca =  325 , M_lda =  30  --->  Accuracy = 80.77%\n",
      "M_pca =  325 , M_lda =  31  --->  Accuracy = 80.77%\n",
      "M_pca =  325 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  325 , M_lda =  33  --->  Accuracy = 79.81%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  325 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  325 , M_lda =  35  --->  Accuracy = 79.81%\n",
      "M_pca =  325 , M_lda =  36  --->  Accuracy = 79.81%\n",
      "M_pca =  325 , M_lda =  37  --->  Accuracy = 79.81%\n",
      "M_pca =  325 , M_lda =  38  --->  Accuracy = 79.81%\n",
      "M_pca =  325 , M_lda =  39  --->  Accuracy = 79.81%\n",
      "M_pca =  325 , M_lda =  40  --->  Accuracy = 79.81%\n",
      "M_pca =  325 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  325 , M_lda =  42  --->  Accuracy = 80.77%\n",
      "M_pca =  325 , M_lda =  43  --->  Accuracy = 80.77%\n",
      "M_pca =  325 , M_lda =  44  --->  Accuracy = 80.77%\n",
      "M_pca =  325 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  325 , M_lda =  46  --->  Accuracy = 80.77%\n",
      "M_pca =  325 , M_lda =  47  --->  Accuracy = 80.77%\n",
      "M_pca =  325 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  325 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  325 , M_lda =  50  --->  Accuracy = 80.77%\n",
      "M_pca =  325 , M_lda =  51  --->  Accuracy = 80.77%\n",
      "M_pca =  326 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  326 , M_lda =  2  --->  Accuracy = 11.54%\n",
      "M_pca =  326 , M_lda =  3  --->  Accuracy = 20.19%\n",
      "M_pca =  326 , M_lda =  4  --->  Accuracy = 24.04%\n",
      "M_pca =  326 , M_lda =  5  --->  Accuracy = 31.73%\n",
      "M_pca =  326 , M_lda =  6  --->  Accuracy = 38.46%\n",
      "M_pca =  326 , M_lda =  7  --->  Accuracy = 49.04%\n",
      "M_pca =  326 , M_lda =  8  --->  Accuracy = 51.92%\n",
      "M_pca =  326 , M_lda =  9  --->  Accuracy = 53.85%\n",
      "M_pca =  326 , M_lda =  10  --->  Accuracy = 59.62%\n",
      "M_pca =  326 , M_lda =  11  --->  Accuracy = 58.65%\n",
      "M_pca =  326 , M_lda =  12  --->  Accuracy = 60.58%\n",
      "M_pca =  326 , M_lda =  13  --->  Accuracy = 62.50%\n",
      "M_pca =  326 , M_lda =  14  --->  Accuracy = 66.35%\n",
      "M_pca =  326 , M_lda =  15  --->  Accuracy = 67.31%\n",
      "M_pca =  326 , M_lda =  16  --->  Accuracy = 69.23%\n",
      "M_pca =  326 , M_lda =  17  --->  Accuracy = 71.15%\n",
      "M_pca =  326 , M_lda =  18  --->  Accuracy = 72.12%\n",
      "M_pca =  326 , M_lda =  19  --->  Accuracy = 74.04%\n",
      "M_pca =  326 , M_lda =  20  --->  Accuracy = 72.12%\n",
      "M_pca =  326 , M_lda =  21  --->  Accuracy = 75.96%\n",
      "M_pca =  326 , M_lda =  22  --->  Accuracy = 75.00%\n",
      "M_pca =  326 , M_lda =  23  --->  Accuracy = 77.88%\n",
      "M_pca =  326 , M_lda =  24  --->  Accuracy = 77.88%\n",
      "M_pca =  326 , M_lda =  25  --->  Accuracy = 78.85%\n",
      "M_pca =  326 , M_lda =  26  --->  Accuracy = 78.85%\n",
      "M_pca =  326 , M_lda =  27  --->  Accuracy = 78.85%\n",
      "M_pca =  326 , M_lda =  28  --->  Accuracy = 79.81%\n",
      "M_pca =  326 , M_lda =  29  --->  Accuracy = 79.81%\n",
      "M_pca =  326 , M_lda =  30  --->  Accuracy = 79.81%\n",
      "M_pca =  326 , M_lda =  31  --->  Accuracy = 79.81%\n",
      "M_pca =  326 , M_lda =  32  --->  Accuracy = 79.81%\n",
      "M_pca =  326 , M_lda =  33  --->  Accuracy = 79.81%\n",
      "M_pca =  326 , M_lda =  34  --->  Accuracy = 79.81%\n",
      "M_pca =  326 , M_lda =  35  --->  Accuracy = 79.81%\n",
      "M_pca =  326 , M_lda =  36  --->  Accuracy = 78.85%\n",
      "M_pca =  326 , M_lda =  37  --->  Accuracy = 78.85%\n",
      "M_pca =  326 , M_lda =  38  --->  Accuracy = 78.85%\n",
      "M_pca =  326 , M_lda =  39  --->  Accuracy = 78.85%\n",
      "M_pca =  326 , M_lda =  40  --->  Accuracy = 80.77%\n",
      "M_pca =  326 , M_lda =  41  --->  Accuracy = 80.77%\n",
      "M_pca =  326 , M_lda =  42  --->  Accuracy = 80.77%\n",
      "M_pca =  326 , M_lda =  43  --->  Accuracy = 80.77%\n",
      "M_pca =  326 , M_lda =  44  --->  Accuracy = 80.77%\n",
      "M_pca =  326 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  326 , M_lda =  46  --->  Accuracy = 80.77%\n",
      "M_pca =  326 , M_lda =  47  --->  Accuracy = 80.77%\n",
      "M_pca =  326 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  326 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  326 , M_lda =  50  --->  Accuracy = 80.77%\n",
      "M_pca =  326 , M_lda =  51  --->  Accuracy = 80.77%\n",
      "M_pca =  327 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  327 , M_lda =  2  --->  Accuracy = 11.54%\n",
      "M_pca =  327 , M_lda =  3  --->  Accuracy = 18.27%\n",
      "M_pca =  327 , M_lda =  4  --->  Accuracy = 23.08%\n",
      "M_pca =  327 , M_lda =  5  --->  Accuracy = 30.77%\n",
      "M_pca =  327 , M_lda =  6  --->  Accuracy = 39.42%\n",
      "M_pca =  327 , M_lda =  7  --->  Accuracy = 48.08%\n",
      "M_pca =  327 , M_lda =  8  --->  Accuracy = 54.81%\n",
      "M_pca =  327 , M_lda =  9  --->  Accuracy = 53.85%\n",
      "M_pca =  327 , M_lda =  10  --->  Accuracy = 58.65%\n",
      "M_pca =  327 , M_lda =  11  --->  Accuracy = 60.58%\n",
      "M_pca =  327 , M_lda =  12  --->  Accuracy = 61.54%\n",
      "M_pca =  327 , M_lda =  13  --->  Accuracy = 63.46%\n",
      "M_pca =  327 , M_lda =  14  --->  Accuracy = 66.35%\n",
      "M_pca =  327 , M_lda =  15  --->  Accuracy = 67.31%\n",
      "M_pca =  327 , M_lda =  16  --->  Accuracy = 68.27%\n",
      "M_pca =  327 , M_lda =  17  --->  Accuracy = 68.27%\n",
      "M_pca =  327 , M_lda =  18  --->  Accuracy = 68.27%\n",
      "M_pca =  327 , M_lda =  19  --->  Accuracy = 70.19%\n",
      "M_pca =  327 , M_lda =  20  --->  Accuracy = 69.23%\n",
      "M_pca =  327 , M_lda =  21  --->  Accuracy = 73.08%\n",
      "M_pca =  327 , M_lda =  22  --->  Accuracy = 75.00%\n",
      "M_pca =  327 , M_lda =  23  --->  Accuracy = 75.00%\n",
      "M_pca =  327 , M_lda =  24  --->  Accuracy = 75.96%\n",
      "M_pca =  327 , M_lda =  25  --->  Accuracy = 75.00%\n",
      "M_pca =  327 , M_lda =  26  --->  Accuracy = 76.92%\n",
      "M_pca =  327 , M_lda =  27  --->  Accuracy = 76.92%\n",
      "M_pca =  327 , M_lda =  28  --->  Accuracy = 76.92%\n",
      "M_pca =  327 , M_lda =  29  --->  Accuracy = 77.88%\n",
      "M_pca =  327 , M_lda =  30  --->  Accuracy = 77.88%\n",
      "M_pca =  327 , M_lda =  31  --->  Accuracy = 78.85%\n",
      "M_pca =  327 , M_lda =  32  --->  Accuracy = 77.88%\n",
      "M_pca =  327 , M_lda =  33  --->  Accuracy = 77.88%\n",
      "M_pca =  327 , M_lda =  34  --->  Accuracy = 77.88%\n",
      "M_pca =  327 , M_lda =  35  --->  Accuracy = 78.85%\n",
      "M_pca =  327 , M_lda =  36  --->  Accuracy = 79.81%\n",
      "M_pca =  327 , M_lda =  37  --->  Accuracy = 78.85%\n",
      "M_pca =  327 , M_lda =  38  --->  Accuracy = 78.85%\n",
      "M_pca =  327 , M_lda =  39  --->  Accuracy = 78.85%\n",
      "M_pca =  327 , M_lda =  40  --->  Accuracy = 78.85%\n",
      "M_pca =  327 , M_lda =  41  --->  Accuracy = 78.85%\n",
      "M_pca =  327 , M_lda =  42  --->  Accuracy = 80.77%\n",
      "M_pca =  327 , M_lda =  43  --->  Accuracy = 78.85%\n",
      "M_pca =  327 , M_lda =  44  --->  Accuracy = 80.77%\n",
      "M_pca =  327 , M_lda =  45  --->  Accuracy = 80.77%\n",
      "M_pca =  327 , M_lda =  46  --->  Accuracy = 80.77%\n",
      "M_pca =  327 , M_lda =  47  --->  Accuracy = 80.77%\n",
      "M_pca =  327 , M_lda =  48  --->  Accuracy = 80.77%\n",
      "M_pca =  327 , M_lda =  49  --->  Accuracy = 80.77%\n",
      "M_pca =  327 , M_lda =  50  --->  Accuracy = 80.77%\n",
      "M_pca =  327 , M_lda =  51  --->  Accuracy = 80.77%\n",
      "M_pca =  328 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  328 , M_lda =  2  --->  Accuracy = 8.65%\n",
      "M_pca =  328 , M_lda =  3  --->  Accuracy = 22.12%\n",
      "M_pca =  328 , M_lda =  4  --->  Accuracy = 24.04%\n",
      "M_pca =  328 , M_lda =  5  --->  Accuracy = 29.81%\n",
      "M_pca =  328 , M_lda =  6  --->  Accuracy = 38.46%\n",
      "M_pca =  328 , M_lda =  7  --->  Accuracy = 45.19%\n",
      "M_pca =  328 , M_lda =  8  --->  Accuracy = 51.92%\n",
      "M_pca =  328 , M_lda =  9  --->  Accuracy = 56.73%\n",
      "M_pca =  328 , M_lda =  10  --->  Accuracy = 55.77%\n",
      "M_pca =  328 , M_lda =  11  --->  Accuracy = 56.73%\n",
      "M_pca =  328 , M_lda =  12  --->  Accuracy = 59.62%\n",
      "M_pca =  328 , M_lda =  13  --->  Accuracy = 62.50%\n",
      "M_pca =  328 , M_lda =  14  --->  Accuracy = 64.42%\n",
      "M_pca =  328 , M_lda =  15  --->  Accuracy = 66.35%\n",
      "M_pca =  328 , M_lda =  16  --->  Accuracy = 66.35%\n",
      "M_pca =  328 , M_lda =  17  --->  Accuracy = 66.35%\n",
      "M_pca =  328 , M_lda =  18  --->  Accuracy = 68.27%\n",
      "M_pca =  328 , M_lda =  19  --->  Accuracy = 69.23%\n",
      "M_pca =  328 , M_lda =  20  --->  Accuracy = 68.27%\n",
      "M_pca =  328 , M_lda =  21  --->  Accuracy = 71.15%\n",
      "M_pca =  328 , M_lda =  22  --->  Accuracy = 71.15%\n",
      "M_pca =  328 , M_lda =  23  --->  Accuracy = 72.12%\n",
      "M_pca =  328 , M_lda =  24  --->  Accuracy = 73.08%\n",
      "M_pca =  328 , M_lda =  25  --->  Accuracy = 72.12%\n",
      "M_pca =  328 , M_lda =  26  --->  Accuracy = 73.08%\n",
      "M_pca =  328 , M_lda =  27  --->  Accuracy = 75.00%\n",
      "M_pca =  328 , M_lda =  28  --->  Accuracy = 74.04%\n",
      "M_pca =  328 , M_lda =  29  --->  Accuracy = 75.00%\n",
      "M_pca =  328 , M_lda =  30  --->  Accuracy = 75.00%\n",
      "M_pca =  328 , M_lda =  31  --->  Accuracy = 75.00%\n",
      "M_pca =  328 , M_lda =  32  --->  Accuracy = 75.00%\n",
      "M_pca =  328 , M_lda =  33  --->  Accuracy = 75.00%\n",
      "M_pca =  328 , M_lda =  34  --->  Accuracy = 75.00%\n",
      "M_pca =  328 , M_lda =  35  --->  Accuracy = 75.96%\n",
      "M_pca =  328 , M_lda =  36  --->  Accuracy = 75.96%\n",
      "M_pca =  328 , M_lda =  37  --->  Accuracy = 75.96%\n",
      "M_pca =  328 , M_lda =  38  --->  Accuracy = 76.92%\n",
      "M_pca =  328 , M_lda =  39  --->  Accuracy = 76.92%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  328 , M_lda =  40  --->  Accuracy = 76.92%\n",
      "M_pca =  328 , M_lda =  41  --->  Accuracy = 76.92%\n",
      "M_pca =  328 , M_lda =  42  --->  Accuracy = 77.88%\n",
      "M_pca =  328 , M_lda =  43  --->  Accuracy = 77.88%\n",
      "M_pca =  328 , M_lda =  44  --->  Accuracy = 77.88%\n",
      "M_pca =  328 , M_lda =  45  --->  Accuracy = 77.88%\n",
      "M_pca =  328 , M_lda =  46  --->  Accuracy = 77.88%\n",
      "M_pca =  328 , M_lda =  47  --->  Accuracy = 77.88%\n",
      "M_pca =  328 , M_lda =  48  --->  Accuracy = 77.88%\n",
      "M_pca =  328 , M_lda =  49  --->  Accuracy = 77.88%\n",
      "M_pca =  328 , M_lda =  50  --->  Accuracy = 77.88%\n",
      "M_pca =  328 , M_lda =  51  --->  Accuracy = 77.88%\n",
      "M_pca =  329 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  329 , M_lda =  2  --->  Accuracy = 10.58%\n",
      "M_pca =  329 , M_lda =  3  --->  Accuracy = 20.19%\n",
      "M_pca =  329 , M_lda =  4  --->  Accuracy = 25.00%\n",
      "M_pca =  329 , M_lda =  5  --->  Accuracy = 28.85%\n",
      "M_pca =  329 , M_lda =  6  --->  Accuracy = 35.58%\n",
      "M_pca =  329 , M_lda =  7  --->  Accuracy = 42.31%\n",
      "M_pca =  329 , M_lda =  8  --->  Accuracy = 46.15%\n",
      "M_pca =  329 , M_lda =  9  --->  Accuracy = 54.81%\n",
      "M_pca =  329 , M_lda =  10  --->  Accuracy = 57.69%\n",
      "M_pca =  329 , M_lda =  11  --->  Accuracy = 55.77%\n",
      "M_pca =  329 , M_lda =  12  --->  Accuracy = 59.62%\n",
      "M_pca =  329 , M_lda =  13  --->  Accuracy = 60.58%\n",
      "M_pca =  329 , M_lda =  14  --->  Accuracy = 61.54%\n",
      "M_pca =  329 , M_lda =  15  --->  Accuracy = 63.46%\n",
      "M_pca =  329 , M_lda =  16  --->  Accuracy = 65.38%\n",
      "M_pca =  329 , M_lda =  17  --->  Accuracy = 68.27%\n",
      "M_pca =  329 , M_lda =  18  --->  Accuracy = 68.27%\n",
      "M_pca =  329 , M_lda =  19  --->  Accuracy = 68.27%\n",
      "M_pca =  329 , M_lda =  20  --->  Accuracy = 69.23%\n",
      "M_pca =  329 , M_lda =  21  --->  Accuracy = 69.23%\n",
      "M_pca =  329 , M_lda =  22  --->  Accuracy = 69.23%\n",
      "M_pca =  329 , M_lda =  23  --->  Accuracy = 70.19%\n",
      "M_pca =  329 , M_lda =  24  --->  Accuracy = 71.15%\n",
      "M_pca =  329 , M_lda =  25  --->  Accuracy = 72.12%\n",
      "M_pca =  329 , M_lda =  26  --->  Accuracy = 72.12%\n",
      "M_pca =  329 , M_lda =  27  --->  Accuracy = 73.08%\n",
      "M_pca =  329 , M_lda =  28  --->  Accuracy = 73.08%\n",
      "M_pca =  329 , M_lda =  29  --->  Accuracy = 73.08%\n",
      "M_pca =  329 , M_lda =  30  --->  Accuracy = 73.08%\n",
      "M_pca =  329 , M_lda =  31  --->  Accuracy = 74.04%\n",
      "M_pca =  329 , M_lda =  32  --->  Accuracy = 75.00%\n",
      "M_pca =  329 , M_lda =  33  --->  Accuracy = 75.00%\n",
      "M_pca =  329 , M_lda =  34  --->  Accuracy = 75.00%\n",
      "M_pca =  329 , M_lda =  35  --->  Accuracy = 76.92%\n",
      "M_pca =  329 , M_lda =  36  --->  Accuracy = 76.92%\n",
      "M_pca =  329 , M_lda =  37  --->  Accuracy = 76.92%\n",
      "M_pca =  329 , M_lda =  38  --->  Accuracy = 76.92%\n",
      "M_pca =  329 , M_lda =  39  --->  Accuracy = 76.92%\n",
      "M_pca =  329 , M_lda =  40  --->  Accuracy = 76.92%\n",
      "M_pca =  329 , M_lda =  41  --->  Accuracy = 76.92%\n",
      "M_pca =  329 , M_lda =  42  --->  Accuracy = 76.92%\n",
      "M_pca =  329 , M_lda =  43  --->  Accuracy = 76.92%\n",
      "M_pca =  329 , M_lda =  44  --->  Accuracy = 76.92%\n",
      "M_pca =  329 , M_lda =  45  --->  Accuracy = 76.92%\n",
      "M_pca =  329 , M_lda =  46  --->  Accuracy = 76.92%\n",
      "M_pca =  329 , M_lda =  47  --->  Accuracy = 76.92%\n",
      "M_pca =  329 , M_lda =  48  --->  Accuracy = 76.92%\n",
      "M_pca =  329 , M_lda =  49  --->  Accuracy = 76.92%\n",
      "M_pca =  329 , M_lda =  50  --->  Accuracy = 76.92%\n",
      "M_pca =  329 , M_lda =  51  --->  Accuracy = 76.92%\n",
      "M_pca =  330 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  330 , M_lda =  2  --->  Accuracy = 12.50%\n",
      "M_pca =  330 , M_lda =  3  --->  Accuracy = 23.08%\n",
      "M_pca =  330 , M_lda =  4  --->  Accuracy = 28.85%\n",
      "M_pca =  330 , M_lda =  5  --->  Accuracy = 31.73%\n",
      "M_pca =  330 , M_lda =  6  --->  Accuracy = 31.73%\n",
      "M_pca =  330 , M_lda =  7  --->  Accuracy = 39.42%\n",
      "M_pca =  330 , M_lda =  8  --->  Accuracy = 44.23%\n",
      "M_pca =  330 , M_lda =  9  --->  Accuracy = 50.00%\n",
      "M_pca =  330 , M_lda =  10  --->  Accuracy = 51.92%\n",
      "M_pca =  330 , M_lda =  11  --->  Accuracy = 51.92%\n",
      "M_pca =  330 , M_lda =  12  --->  Accuracy = 57.69%\n",
      "M_pca =  330 , M_lda =  13  --->  Accuracy = 56.73%\n",
      "M_pca =  330 , M_lda =  14  --->  Accuracy = 59.62%\n",
      "M_pca =  330 , M_lda =  15  --->  Accuracy = 59.62%\n",
      "M_pca =  330 , M_lda =  16  --->  Accuracy = 61.54%\n",
      "M_pca =  330 , M_lda =  17  --->  Accuracy = 65.38%\n",
      "M_pca =  330 , M_lda =  18  --->  Accuracy = 65.38%\n",
      "M_pca =  330 , M_lda =  19  --->  Accuracy = 65.38%\n",
      "M_pca =  330 , M_lda =  20  --->  Accuracy = 65.38%\n",
      "M_pca =  330 , M_lda =  21  --->  Accuracy = 65.38%\n",
      "M_pca =  330 , M_lda =  22  --->  Accuracy = 67.31%\n",
      "M_pca =  330 , M_lda =  23  --->  Accuracy = 67.31%\n",
      "M_pca =  330 , M_lda =  24  --->  Accuracy = 67.31%\n",
      "M_pca =  330 , M_lda =  25  --->  Accuracy = 68.27%\n",
      "M_pca =  330 , M_lda =  26  --->  Accuracy = 69.23%\n",
      "M_pca =  330 , M_lda =  27  --->  Accuracy = 69.23%\n",
      "M_pca =  330 , M_lda =  28  --->  Accuracy = 68.27%\n",
      "M_pca =  330 , M_lda =  29  --->  Accuracy = 70.19%\n",
      "M_pca =  330 , M_lda =  30  --->  Accuracy = 70.19%\n",
      "M_pca =  330 , M_lda =  31  --->  Accuracy = 69.23%\n",
      "M_pca =  330 , M_lda =  32  --->  Accuracy = 71.15%\n",
      "M_pca =  330 , M_lda =  33  --->  Accuracy = 73.08%\n",
      "M_pca =  330 , M_lda =  34  --->  Accuracy = 72.12%\n",
      "M_pca =  330 , M_lda =  35  --->  Accuracy = 72.12%\n",
      "M_pca =  330 , M_lda =  36  --->  Accuracy = 73.08%\n",
      "M_pca =  330 , M_lda =  37  --->  Accuracy = 72.12%\n",
      "M_pca =  330 , M_lda =  38  --->  Accuracy = 72.12%\n",
      "M_pca =  330 , M_lda =  39  --->  Accuracy = 73.08%\n",
      "M_pca =  330 , M_lda =  40  --->  Accuracy = 74.04%\n",
      "M_pca =  330 , M_lda =  41  --->  Accuracy = 74.04%\n",
      "M_pca =  330 , M_lda =  42  --->  Accuracy = 74.04%\n",
      "M_pca =  330 , M_lda =  43  --->  Accuracy = 74.04%\n",
      "M_pca =  330 , M_lda =  44  --->  Accuracy = 74.04%\n",
      "M_pca =  330 , M_lda =  45  --->  Accuracy = 74.04%\n",
      "M_pca =  330 , M_lda =  46  --->  Accuracy = 74.04%\n",
      "M_pca =  330 , M_lda =  47  --->  Accuracy = 74.04%\n",
      "M_pca =  330 , M_lda =  48  --->  Accuracy = 74.04%\n",
      "M_pca =  330 , M_lda =  49  --->  Accuracy = 74.04%\n",
      "M_pca =  330 , M_lda =  50  --->  Accuracy = 74.04%\n",
      "M_pca =  330 , M_lda =  51  --->  Accuracy = 74.04%\n",
      "M_pca =  331 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  331 , M_lda =  2  --->  Accuracy = 10.58%\n",
      "M_pca =  331 , M_lda =  3  --->  Accuracy = 22.12%\n",
      "M_pca =  331 , M_lda =  4  --->  Accuracy = 28.85%\n",
      "M_pca =  331 , M_lda =  5  --->  Accuracy = 31.73%\n",
      "M_pca =  331 , M_lda =  6  --->  Accuracy = 33.65%\n",
      "M_pca =  331 , M_lda =  7  --->  Accuracy = 40.38%\n",
      "M_pca =  331 , M_lda =  8  --->  Accuracy = 42.31%\n",
      "M_pca =  331 , M_lda =  9  --->  Accuracy = 47.12%\n",
      "M_pca =  331 , M_lda =  10  --->  Accuracy = 49.04%\n",
      "M_pca =  331 , M_lda =  11  --->  Accuracy = 50.96%\n",
      "M_pca =  331 , M_lda =  12  --->  Accuracy = 55.77%\n",
      "M_pca =  331 , M_lda =  13  --->  Accuracy = 58.65%\n",
      "M_pca =  331 , M_lda =  14  --->  Accuracy = 56.73%\n",
      "M_pca =  331 , M_lda =  15  --->  Accuracy = 60.58%\n",
      "M_pca =  331 , M_lda =  16  --->  Accuracy = 60.58%\n",
      "M_pca =  331 , M_lda =  17  --->  Accuracy = 62.50%\n",
      "M_pca =  331 , M_lda =  18  --->  Accuracy = 64.42%\n",
      "M_pca =  331 , M_lda =  19  --->  Accuracy = 67.31%\n",
      "M_pca =  331 , M_lda =  20  --->  Accuracy = 66.35%\n",
      "M_pca =  331 , M_lda =  21  --->  Accuracy = 67.31%\n",
      "M_pca =  331 , M_lda =  22  --->  Accuracy = 68.27%\n",
      "M_pca =  331 , M_lda =  23  --->  Accuracy = 68.27%\n",
      "M_pca =  331 , M_lda =  24  --->  Accuracy = 68.27%\n",
      "M_pca =  331 , M_lda =  25  --->  Accuracy = 68.27%\n",
      "M_pca =  331 , M_lda =  26  --->  Accuracy = 69.23%\n",
      "M_pca =  331 , M_lda =  27  --->  Accuracy = 69.23%\n",
      "M_pca =  331 , M_lda =  28  --->  Accuracy = 69.23%\n",
      "M_pca =  331 , M_lda =  29  --->  Accuracy = 70.19%\n",
      "M_pca =  331 , M_lda =  30  --->  Accuracy = 70.19%\n",
      "M_pca =  331 , M_lda =  31  --->  Accuracy = 70.19%\n",
      "M_pca =  331 , M_lda =  32  --->  Accuracy = 70.19%\n",
      "M_pca =  331 , M_lda =  33  --->  Accuracy = 73.08%\n",
      "M_pca =  331 , M_lda =  34  --->  Accuracy = 73.08%\n",
      "M_pca =  331 , M_lda =  35  --->  Accuracy = 73.08%\n",
      "M_pca =  331 , M_lda =  36  --->  Accuracy = 73.08%\n",
      "M_pca =  331 , M_lda =  37  --->  Accuracy = 74.04%\n",
      "M_pca =  331 , M_lda =  38  --->  Accuracy = 74.04%\n",
      "M_pca =  331 , M_lda =  39  --->  Accuracy = 74.04%\n",
      "M_pca =  331 , M_lda =  40  --->  Accuracy = 74.04%\n",
      "M_pca =  331 , M_lda =  41  --->  Accuracy = 74.04%\n",
      "M_pca =  331 , M_lda =  42  --->  Accuracy = 74.04%\n",
      "M_pca =  331 , M_lda =  43  --->  Accuracy = 74.04%\n",
      "M_pca =  331 , M_lda =  44  --->  Accuracy = 74.04%\n",
      "M_pca =  331 , M_lda =  45  --->  Accuracy = 74.04%\n",
      "M_pca =  331 , M_lda =  46  --->  Accuracy = 75.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  331 , M_lda =  47  --->  Accuracy = 75.00%\n",
      "M_pca =  331 , M_lda =  48  --->  Accuracy = 74.04%\n",
      "M_pca =  331 , M_lda =  49  --->  Accuracy = 75.00%\n",
      "M_pca =  331 , M_lda =  50  --->  Accuracy = 75.00%\n",
      "M_pca =  331 , M_lda =  51  --->  Accuracy = 74.04%\n",
      "M_pca =  332 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  332 , M_lda =  2  --->  Accuracy = 10.58%\n",
      "M_pca =  332 , M_lda =  3  --->  Accuracy = 19.23%\n",
      "M_pca =  332 , M_lda =  4  --->  Accuracy = 25.00%\n",
      "M_pca =  332 , M_lda =  5  --->  Accuracy = 29.81%\n",
      "M_pca =  332 , M_lda =  6  --->  Accuracy = 34.62%\n",
      "M_pca =  332 , M_lda =  7  --->  Accuracy = 38.46%\n",
      "M_pca =  332 , M_lda =  8  --->  Accuracy = 41.35%\n",
      "M_pca =  332 , M_lda =  9  --->  Accuracy = 46.15%\n",
      "M_pca =  332 , M_lda =  10  --->  Accuracy = 51.92%\n",
      "M_pca =  332 , M_lda =  11  --->  Accuracy = 53.85%\n",
      "M_pca =  332 , M_lda =  12  --->  Accuracy = 58.65%\n",
      "M_pca =  332 , M_lda =  13  --->  Accuracy = 61.54%\n",
      "M_pca =  332 , M_lda =  14  --->  Accuracy = 60.58%\n",
      "M_pca =  332 , M_lda =  15  --->  Accuracy = 63.46%\n",
      "M_pca =  332 , M_lda =  16  --->  Accuracy = 62.50%\n",
      "M_pca =  332 , M_lda =  17  --->  Accuracy = 62.50%\n",
      "M_pca =  332 , M_lda =  18  --->  Accuracy = 64.42%\n",
      "M_pca =  332 , M_lda =  19  --->  Accuracy = 65.38%\n",
      "M_pca =  332 , M_lda =  20  --->  Accuracy = 65.38%\n",
      "M_pca =  332 , M_lda =  21  --->  Accuracy = 65.38%\n",
      "M_pca =  332 , M_lda =  22  --->  Accuracy = 67.31%\n",
      "M_pca =  332 , M_lda =  23  --->  Accuracy = 66.35%\n",
      "M_pca =  332 , M_lda =  24  --->  Accuracy = 69.23%\n",
      "M_pca =  332 , M_lda =  25  --->  Accuracy = 68.27%\n",
      "M_pca =  332 , M_lda =  26  --->  Accuracy = 69.23%\n",
      "M_pca =  332 , M_lda =  27  --->  Accuracy = 71.15%\n",
      "M_pca =  332 , M_lda =  28  --->  Accuracy = 69.23%\n",
      "M_pca =  332 , M_lda =  29  --->  Accuracy = 69.23%\n",
      "M_pca =  332 , M_lda =  30  --->  Accuracy = 70.19%\n",
      "M_pca =  332 , M_lda =  31  --->  Accuracy = 69.23%\n",
      "M_pca =  332 , M_lda =  32  --->  Accuracy = 70.19%\n",
      "M_pca =  332 , M_lda =  33  --->  Accuracy = 74.04%\n",
      "M_pca =  332 , M_lda =  34  --->  Accuracy = 74.04%\n",
      "M_pca =  332 , M_lda =  35  --->  Accuracy = 73.08%\n",
      "M_pca =  332 , M_lda =  36  --->  Accuracy = 73.08%\n",
      "M_pca =  332 , M_lda =  37  --->  Accuracy = 73.08%\n",
      "M_pca =  332 , M_lda =  38  --->  Accuracy = 75.00%\n",
      "M_pca =  332 , M_lda =  39  --->  Accuracy = 75.00%\n",
      "M_pca =  332 , M_lda =  40  --->  Accuracy = 75.00%\n",
      "M_pca =  332 , M_lda =  41  --->  Accuracy = 75.00%\n",
      "M_pca =  332 , M_lda =  42  --->  Accuracy = 75.00%\n",
      "M_pca =  332 , M_lda =  43  --->  Accuracy = 75.00%\n",
      "M_pca =  332 , M_lda =  44  --->  Accuracy = 75.00%\n",
      "M_pca =  332 , M_lda =  45  --->  Accuracy = 75.00%\n",
      "M_pca =  332 , M_lda =  46  --->  Accuracy = 75.96%\n",
      "M_pca =  332 , M_lda =  47  --->  Accuracy = 75.96%\n",
      "M_pca =  332 , M_lda =  48  --->  Accuracy = 75.96%\n",
      "M_pca =  332 , M_lda =  49  --->  Accuracy = 75.96%\n",
      "M_pca =  332 , M_lda =  50  --->  Accuracy = 75.96%\n",
      "M_pca =  332 , M_lda =  51  --->  Accuracy = 75.96%\n",
      "M_pca =  333 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  333 , M_lda =  2  --->  Accuracy = 15.38%\n",
      "M_pca =  333 , M_lda =  3  --->  Accuracy = 22.12%\n",
      "M_pca =  333 , M_lda =  4  --->  Accuracy = 25.96%\n",
      "M_pca =  333 , M_lda =  5  --->  Accuracy = 30.77%\n",
      "M_pca =  333 , M_lda =  6  --->  Accuracy = 33.65%\n",
      "M_pca =  333 , M_lda =  7  --->  Accuracy = 34.62%\n",
      "M_pca =  333 , M_lda =  8  --->  Accuracy = 44.23%\n",
      "M_pca =  333 , M_lda =  9  --->  Accuracy = 50.00%\n",
      "M_pca =  333 , M_lda =  10  --->  Accuracy = 52.88%\n",
      "M_pca =  333 , M_lda =  11  --->  Accuracy = 54.81%\n",
      "M_pca =  333 , M_lda =  12  --->  Accuracy = 53.85%\n",
      "M_pca =  333 , M_lda =  13  --->  Accuracy = 57.69%\n",
      "M_pca =  333 , M_lda =  14  --->  Accuracy = 61.54%\n",
      "M_pca =  333 , M_lda =  15  --->  Accuracy = 63.46%\n",
      "M_pca =  333 , M_lda =  16  --->  Accuracy = 63.46%\n",
      "M_pca =  333 , M_lda =  17  --->  Accuracy = 62.50%\n",
      "M_pca =  333 , M_lda =  18  --->  Accuracy = 63.46%\n",
      "M_pca =  333 , M_lda =  19  --->  Accuracy = 64.42%\n",
      "M_pca =  333 , M_lda =  20  --->  Accuracy = 66.35%\n",
      "M_pca =  333 , M_lda =  21  --->  Accuracy = 67.31%\n",
      "M_pca =  333 , M_lda =  22  --->  Accuracy = 68.27%\n",
      "M_pca =  333 , M_lda =  23  --->  Accuracy = 67.31%\n",
      "M_pca =  333 , M_lda =  24  --->  Accuracy = 68.27%\n",
      "M_pca =  333 , M_lda =  25  --->  Accuracy = 68.27%\n",
      "M_pca =  333 , M_lda =  26  --->  Accuracy = 69.23%\n",
      "M_pca =  333 , M_lda =  27  --->  Accuracy = 69.23%\n",
      "M_pca =  333 , M_lda =  28  --->  Accuracy = 69.23%\n",
      "M_pca =  333 , M_lda =  29  --->  Accuracy = 70.19%\n",
      "M_pca =  333 , M_lda =  30  --->  Accuracy = 70.19%\n",
      "M_pca =  333 , M_lda =  31  --->  Accuracy = 70.19%\n",
      "M_pca =  333 , M_lda =  32  --->  Accuracy = 70.19%\n",
      "M_pca =  333 , M_lda =  33  --->  Accuracy = 71.15%\n",
      "M_pca =  333 , M_lda =  34  --->  Accuracy = 71.15%\n",
      "M_pca =  333 , M_lda =  35  --->  Accuracy = 73.08%\n",
      "M_pca =  333 , M_lda =  36  --->  Accuracy = 72.12%\n",
      "M_pca =  333 , M_lda =  37  --->  Accuracy = 74.04%\n",
      "M_pca =  333 , M_lda =  38  --->  Accuracy = 74.04%\n",
      "M_pca =  333 , M_lda =  39  --->  Accuracy = 74.04%\n",
      "M_pca =  333 , M_lda =  40  --->  Accuracy = 75.00%\n",
      "M_pca =  333 , M_lda =  41  --->  Accuracy = 74.04%\n",
      "M_pca =  333 , M_lda =  42  --->  Accuracy = 74.04%\n",
      "M_pca =  333 , M_lda =  43  --->  Accuracy = 74.04%\n",
      "M_pca =  333 , M_lda =  44  --->  Accuracy = 75.00%\n",
      "M_pca =  333 , M_lda =  45  --->  Accuracy = 75.00%\n",
      "M_pca =  333 , M_lda =  46  --->  Accuracy = 75.96%\n",
      "M_pca =  333 , M_lda =  47  --->  Accuracy = 75.96%\n",
      "M_pca =  333 , M_lda =  48  --->  Accuracy = 75.96%\n",
      "M_pca =  333 , M_lda =  49  --->  Accuracy = 76.92%\n",
      "M_pca =  333 , M_lda =  50  --->  Accuracy = 75.96%\n",
      "M_pca =  333 , M_lda =  51  --->  Accuracy = 75.96%\n",
      "M_pca =  334 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  334 , M_lda =  2  --->  Accuracy = 10.58%\n",
      "M_pca =  334 , M_lda =  3  --->  Accuracy = 20.19%\n",
      "M_pca =  334 , M_lda =  4  --->  Accuracy = 27.88%\n",
      "M_pca =  334 , M_lda =  5  --->  Accuracy = 26.92%\n",
      "M_pca =  334 , M_lda =  6  --->  Accuracy = 37.50%\n",
      "M_pca =  334 , M_lda =  7  --->  Accuracy = 39.42%\n",
      "M_pca =  334 , M_lda =  8  --->  Accuracy = 45.19%\n",
      "M_pca =  334 , M_lda =  9  --->  Accuracy = 48.08%\n",
      "M_pca =  334 , M_lda =  10  --->  Accuracy = 52.88%\n",
      "M_pca =  334 , M_lda =  11  --->  Accuracy = 52.88%\n",
      "M_pca =  334 , M_lda =  12  --->  Accuracy = 54.81%\n",
      "M_pca =  334 , M_lda =  13  --->  Accuracy = 57.69%\n",
      "M_pca =  334 , M_lda =  14  --->  Accuracy = 58.65%\n",
      "M_pca =  334 , M_lda =  15  --->  Accuracy = 63.46%\n",
      "M_pca =  334 , M_lda =  16  --->  Accuracy = 61.54%\n",
      "M_pca =  334 , M_lda =  17  --->  Accuracy = 63.46%\n",
      "M_pca =  334 , M_lda =  18  --->  Accuracy = 64.42%\n",
      "M_pca =  334 , M_lda =  19  --->  Accuracy = 65.38%\n",
      "M_pca =  334 , M_lda =  20  --->  Accuracy = 65.38%\n",
      "M_pca =  334 , M_lda =  21  --->  Accuracy = 66.35%\n",
      "M_pca =  334 , M_lda =  22  --->  Accuracy = 65.38%\n",
      "M_pca =  334 , M_lda =  23  --->  Accuracy = 66.35%\n",
      "M_pca =  334 , M_lda =  24  --->  Accuracy = 66.35%\n",
      "M_pca =  334 , M_lda =  25  --->  Accuracy = 67.31%\n",
      "M_pca =  334 , M_lda =  26  --->  Accuracy = 67.31%\n",
      "M_pca =  334 , M_lda =  27  --->  Accuracy = 67.31%\n",
      "M_pca =  334 , M_lda =  28  --->  Accuracy = 67.31%\n",
      "M_pca =  334 , M_lda =  29  --->  Accuracy = 67.31%\n",
      "M_pca =  334 , M_lda =  30  --->  Accuracy = 68.27%\n",
      "M_pca =  334 , M_lda =  31  --->  Accuracy = 69.23%\n",
      "M_pca =  334 , M_lda =  32  --->  Accuracy = 71.15%\n",
      "M_pca =  334 , M_lda =  33  --->  Accuracy = 72.12%\n",
      "M_pca =  334 , M_lda =  34  --->  Accuracy = 72.12%\n",
      "M_pca =  334 , M_lda =  35  --->  Accuracy = 72.12%\n",
      "M_pca =  334 , M_lda =  36  --->  Accuracy = 72.12%\n",
      "M_pca =  334 , M_lda =  37  --->  Accuracy = 72.12%\n",
      "M_pca =  334 , M_lda =  38  --->  Accuracy = 72.12%\n",
      "M_pca =  334 , M_lda =  39  --->  Accuracy = 72.12%\n",
      "M_pca =  334 , M_lda =  40  --->  Accuracy = 72.12%\n",
      "M_pca =  334 , M_lda =  41  --->  Accuracy = 72.12%\n",
      "M_pca =  334 , M_lda =  42  --->  Accuracy = 72.12%\n",
      "M_pca =  334 , M_lda =  43  --->  Accuracy = 72.12%\n",
      "M_pca =  334 , M_lda =  44  --->  Accuracy = 73.08%\n",
      "M_pca =  334 , M_lda =  45  --->  Accuracy = 73.08%\n",
      "M_pca =  334 , M_lda =  46  --->  Accuracy = 74.04%\n",
      "M_pca =  334 , M_lda =  47  --->  Accuracy = 74.04%\n",
      "M_pca =  334 , M_lda =  48  --->  Accuracy = 74.04%\n",
      "M_pca =  334 , M_lda =  49  --->  Accuracy = 74.04%\n",
      "M_pca =  334 , M_lda =  50  --->  Accuracy = 74.04%\n",
      "M_pca =  334 , M_lda =  51  --->  Accuracy = 74.04%\n",
      "M_pca =  335 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  335 , M_lda =  2  --->  Accuracy = 14.42%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  335 , M_lda =  3  --->  Accuracy = 17.31%\n",
      "M_pca =  335 , M_lda =  4  --->  Accuracy = 26.92%\n",
      "M_pca =  335 , M_lda =  5  --->  Accuracy = 29.81%\n",
      "M_pca =  335 , M_lda =  6  --->  Accuracy = 35.58%\n",
      "M_pca =  335 , M_lda =  7  --->  Accuracy = 41.35%\n",
      "M_pca =  335 , M_lda =  8  --->  Accuracy = 47.12%\n",
      "M_pca =  335 , M_lda =  9  --->  Accuracy = 51.92%\n",
      "M_pca =  335 , M_lda =  10  --->  Accuracy = 53.85%\n",
      "M_pca =  335 , M_lda =  11  --->  Accuracy = 52.88%\n",
      "M_pca =  335 , M_lda =  12  --->  Accuracy = 54.81%\n",
      "M_pca =  335 , M_lda =  13  --->  Accuracy = 56.73%\n",
      "M_pca =  335 , M_lda =  14  --->  Accuracy = 57.69%\n",
      "M_pca =  335 , M_lda =  15  --->  Accuracy = 62.50%\n",
      "M_pca =  335 , M_lda =  16  --->  Accuracy = 63.46%\n",
      "M_pca =  335 , M_lda =  17  --->  Accuracy = 63.46%\n",
      "M_pca =  335 , M_lda =  18  --->  Accuracy = 65.38%\n",
      "M_pca =  335 , M_lda =  19  --->  Accuracy = 64.42%\n",
      "M_pca =  335 , M_lda =  20  --->  Accuracy = 65.38%\n",
      "M_pca =  335 , M_lda =  21  --->  Accuracy = 67.31%\n",
      "M_pca =  335 , M_lda =  22  --->  Accuracy = 69.23%\n",
      "M_pca =  335 , M_lda =  23  --->  Accuracy = 68.27%\n",
      "M_pca =  335 , M_lda =  24  --->  Accuracy = 68.27%\n",
      "M_pca =  335 , M_lda =  25  --->  Accuracy = 69.23%\n",
      "M_pca =  335 , M_lda =  26  --->  Accuracy = 68.27%\n",
      "M_pca =  335 , M_lda =  27  --->  Accuracy = 68.27%\n",
      "M_pca =  335 , M_lda =  28  --->  Accuracy = 68.27%\n",
      "M_pca =  335 , M_lda =  29  --->  Accuracy = 68.27%\n",
      "M_pca =  335 , M_lda =  30  --->  Accuracy = 69.23%\n",
      "M_pca =  335 , M_lda =  31  --->  Accuracy = 70.19%\n",
      "M_pca =  335 , M_lda =  32  --->  Accuracy = 71.15%\n",
      "M_pca =  335 , M_lda =  33  --->  Accuracy = 70.19%\n",
      "M_pca =  335 , M_lda =  34  --->  Accuracy = 70.19%\n",
      "M_pca =  335 , M_lda =  35  --->  Accuracy = 70.19%\n",
      "M_pca =  335 , M_lda =  36  --->  Accuracy = 70.19%\n",
      "M_pca =  335 , M_lda =  37  --->  Accuracy = 71.15%\n",
      "M_pca =  335 , M_lda =  38  --->  Accuracy = 71.15%\n",
      "M_pca =  335 , M_lda =  39  --->  Accuracy = 71.15%\n",
      "M_pca =  335 , M_lda =  40  --->  Accuracy = 70.19%\n",
      "M_pca =  335 , M_lda =  41  --->  Accuracy = 70.19%\n",
      "M_pca =  335 , M_lda =  42  --->  Accuracy = 72.12%\n",
      "M_pca =  335 , M_lda =  43  --->  Accuracy = 72.12%\n",
      "M_pca =  335 , M_lda =  44  --->  Accuracy = 73.08%\n",
      "M_pca =  335 , M_lda =  45  --->  Accuracy = 73.08%\n",
      "M_pca =  335 , M_lda =  46  --->  Accuracy = 73.08%\n",
      "M_pca =  335 , M_lda =  47  --->  Accuracy = 73.08%\n",
      "M_pca =  335 , M_lda =  48  --->  Accuracy = 74.04%\n",
      "M_pca =  335 , M_lda =  49  --->  Accuracy = 74.04%\n",
      "M_pca =  335 , M_lda =  50  --->  Accuracy = 75.00%\n",
      "M_pca =  335 , M_lda =  51  --->  Accuracy = 75.96%\n",
      "M_pca =  336 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  336 , M_lda =  2  --->  Accuracy = 9.62%\n",
      "M_pca =  336 , M_lda =  3  --->  Accuracy = 15.38%\n",
      "M_pca =  336 , M_lda =  4  --->  Accuracy = 27.88%\n",
      "M_pca =  336 , M_lda =  5  --->  Accuracy = 26.92%\n",
      "M_pca =  336 , M_lda =  6  --->  Accuracy = 36.54%\n",
      "M_pca =  336 , M_lda =  7  --->  Accuracy = 36.54%\n",
      "M_pca =  336 , M_lda =  8  --->  Accuracy = 45.19%\n",
      "M_pca =  336 , M_lda =  9  --->  Accuracy = 49.04%\n",
      "M_pca =  336 , M_lda =  10  --->  Accuracy = 50.00%\n",
      "M_pca =  336 , M_lda =  11  --->  Accuracy = 52.88%\n",
      "M_pca =  336 , M_lda =  12  --->  Accuracy = 50.96%\n",
      "M_pca =  336 , M_lda =  13  --->  Accuracy = 54.81%\n",
      "M_pca =  336 , M_lda =  14  --->  Accuracy = 59.62%\n",
      "M_pca =  336 , M_lda =  15  --->  Accuracy = 58.65%\n",
      "M_pca =  336 , M_lda =  16  --->  Accuracy = 60.58%\n",
      "M_pca =  336 , M_lda =  17  --->  Accuracy = 62.50%\n",
      "M_pca =  336 , M_lda =  18  --->  Accuracy = 62.50%\n",
      "M_pca =  336 , M_lda =  19  --->  Accuracy = 60.58%\n",
      "M_pca =  336 , M_lda =  20  --->  Accuracy = 60.58%\n",
      "M_pca =  336 , M_lda =  21  --->  Accuracy = 63.46%\n",
      "M_pca =  336 , M_lda =  22  --->  Accuracy = 64.42%\n",
      "M_pca =  336 , M_lda =  23  --->  Accuracy = 65.38%\n",
      "M_pca =  336 , M_lda =  24  --->  Accuracy = 66.35%\n",
      "M_pca =  336 , M_lda =  25  --->  Accuracy = 66.35%\n",
      "M_pca =  336 , M_lda =  26  --->  Accuracy = 66.35%\n",
      "M_pca =  336 , M_lda =  27  --->  Accuracy = 66.35%\n",
      "M_pca =  336 , M_lda =  28  --->  Accuracy = 67.31%\n",
      "M_pca =  336 , M_lda =  29  --->  Accuracy = 67.31%\n",
      "M_pca =  336 , M_lda =  30  --->  Accuracy = 69.23%\n",
      "M_pca =  336 , M_lda =  31  --->  Accuracy = 71.15%\n",
      "M_pca =  336 , M_lda =  32  --->  Accuracy = 71.15%\n",
      "M_pca =  336 , M_lda =  33  --->  Accuracy = 71.15%\n",
      "M_pca =  336 , M_lda =  34  --->  Accuracy = 71.15%\n",
      "M_pca =  336 , M_lda =  35  --->  Accuracy = 71.15%\n",
      "M_pca =  336 , M_lda =  36  --->  Accuracy = 71.15%\n",
      "M_pca =  336 , M_lda =  37  --->  Accuracy = 71.15%\n",
      "M_pca =  336 , M_lda =  38  --->  Accuracy = 71.15%\n",
      "M_pca =  336 , M_lda =  39  --->  Accuracy = 71.15%\n",
      "M_pca =  336 , M_lda =  40  --->  Accuracy = 71.15%\n",
      "M_pca =  336 , M_lda =  41  --->  Accuracy = 72.12%\n",
      "M_pca =  336 , M_lda =  42  --->  Accuracy = 72.12%\n",
      "M_pca =  336 , M_lda =  43  --->  Accuracy = 72.12%\n",
      "M_pca =  336 , M_lda =  44  --->  Accuracy = 73.08%\n",
      "M_pca =  336 , M_lda =  45  --->  Accuracy = 73.08%\n",
      "M_pca =  336 , M_lda =  46  --->  Accuracy = 73.08%\n",
      "M_pca =  336 , M_lda =  47  --->  Accuracy = 73.08%\n",
      "M_pca =  336 , M_lda =  48  --->  Accuracy = 73.08%\n",
      "M_pca =  336 , M_lda =  49  --->  Accuracy = 74.04%\n",
      "M_pca =  336 , M_lda =  50  --->  Accuracy = 74.04%\n",
      "M_pca =  336 , M_lda =  51  --->  Accuracy = 75.00%\n",
      "M_pca =  337 , M_lda =  1  --->  Accuracy = 6.73%\n",
      "M_pca =  337 , M_lda =  2  --->  Accuracy = 13.46%\n",
      "M_pca =  337 , M_lda =  3  --->  Accuracy = 18.27%\n",
      "M_pca =  337 , M_lda =  4  --->  Accuracy = 25.00%\n",
      "M_pca =  337 , M_lda =  5  --->  Accuracy = 30.77%\n",
      "M_pca =  337 , M_lda =  6  --->  Accuracy = 32.69%\n",
      "M_pca =  337 , M_lda =  7  --->  Accuracy = 37.50%\n",
      "M_pca =  337 , M_lda =  8  --->  Accuracy = 47.12%\n",
      "M_pca =  337 , M_lda =  9  --->  Accuracy = 50.00%\n",
      "M_pca =  337 , M_lda =  10  --->  Accuracy = 52.88%\n",
      "M_pca =  337 , M_lda =  11  --->  Accuracy = 52.88%\n",
      "M_pca =  337 , M_lda =  12  --->  Accuracy = 51.92%\n",
      "M_pca =  337 , M_lda =  13  --->  Accuracy = 54.81%\n",
      "M_pca =  337 , M_lda =  14  --->  Accuracy = 60.58%\n",
      "M_pca =  337 , M_lda =  15  --->  Accuracy = 61.54%\n",
      "M_pca =  337 , M_lda =  16  --->  Accuracy = 64.42%\n",
      "M_pca =  337 , M_lda =  17  --->  Accuracy = 64.42%\n",
      "M_pca =  337 , M_lda =  18  --->  Accuracy = 64.42%\n",
      "M_pca =  337 , M_lda =  19  --->  Accuracy = 64.42%\n",
      "M_pca =  337 , M_lda =  20  --->  Accuracy = 64.42%\n",
      "M_pca =  337 , M_lda =  21  --->  Accuracy = 64.42%\n",
      "M_pca =  337 , M_lda =  22  --->  Accuracy = 66.35%\n",
      "M_pca =  337 , M_lda =  23  --->  Accuracy = 65.38%\n",
      "M_pca =  337 , M_lda =  24  --->  Accuracy = 66.35%\n",
      "M_pca =  337 , M_lda =  25  --->  Accuracy = 68.27%\n",
      "M_pca =  337 , M_lda =  26  --->  Accuracy = 69.23%\n",
      "M_pca =  337 , M_lda =  27  --->  Accuracy = 69.23%\n",
      "M_pca =  337 , M_lda =  28  --->  Accuracy = 69.23%\n",
      "M_pca =  337 , M_lda =  29  --->  Accuracy = 69.23%\n",
      "M_pca =  337 , M_lda =  30  --->  Accuracy = 69.23%\n",
      "M_pca =  337 , M_lda =  31  --->  Accuracy = 69.23%\n",
      "M_pca =  337 , M_lda =  32  --->  Accuracy = 69.23%\n",
      "M_pca =  337 , M_lda =  33  --->  Accuracy = 68.27%\n",
      "M_pca =  337 , M_lda =  34  --->  Accuracy = 69.23%\n",
      "M_pca =  337 , M_lda =  35  --->  Accuracy = 69.23%\n",
      "M_pca =  337 , M_lda =  36  --->  Accuracy = 70.19%\n",
      "M_pca =  337 , M_lda =  37  --->  Accuracy = 70.19%\n",
      "M_pca =  337 , M_lda =  38  --->  Accuracy = 70.19%\n",
      "M_pca =  337 , M_lda =  39  --->  Accuracy = 70.19%\n",
      "M_pca =  337 , M_lda =  40  --->  Accuracy = 70.19%\n",
      "M_pca =  337 , M_lda =  41  --->  Accuracy = 71.15%\n",
      "M_pca =  337 , M_lda =  42  --->  Accuracy = 72.12%\n",
      "M_pca =  337 , M_lda =  43  --->  Accuracy = 72.12%\n",
      "M_pca =  337 , M_lda =  44  --->  Accuracy = 72.12%\n",
      "M_pca =  337 , M_lda =  45  --->  Accuracy = 72.12%\n",
      "M_pca =  337 , M_lda =  46  --->  Accuracy = 72.12%\n",
      "M_pca =  337 , M_lda =  47  --->  Accuracy = 72.12%\n",
      "M_pca =  337 , M_lda =  48  --->  Accuracy = 72.12%\n",
      "M_pca =  337 , M_lda =  49  --->  Accuracy = 72.12%\n",
      "M_pca =  337 , M_lda =  50  --->  Accuracy = 73.08%\n",
      "M_pca =  337 , M_lda =  51  --->  Accuracy = 73.08%\n",
      "M_pca =  338 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  338 , M_lda =  2  --->  Accuracy = 13.46%\n",
      "M_pca =  338 , M_lda =  3  --->  Accuracy = 20.19%\n",
      "M_pca =  338 , M_lda =  4  --->  Accuracy = 23.08%\n",
      "M_pca =  338 , M_lda =  5  --->  Accuracy = 25.00%\n",
      "M_pca =  338 , M_lda =  6  --->  Accuracy = 29.81%\n",
      "M_pca =  338 , M_lda =  7  --->  Accuracy = 38.46%\n",
      "M_pca =  338 , M_lda =  8  --->  Accuracy = 44.23%\n",
      "M_pca =  338 , M_lda =  9  --->  Accuracy = 45.19%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  338 , M_lda =  10  --->  Accuracy = 47.12%\n",
      "M_pca =  338 , M_lda =  11  --->  Accuracy = 50.00%\n",
      "M_pca =  338 , M_lda =  12  --->  Accuracy = 52.88%\n",
      "M_pca =  338 , M_lda =  13  --->  Accuracy = 53.85%\n",
      "M_pca =  338 , M_lda =  14  --->  Accuracy = 55.77%\n",
      "M_pca =  338 , M_lda =  15  --->  Accuracy = 61.54%\n",
      "M_pca =  338 , M_lda =  16  --->  Accuracy = 61.54%\n",
      "M_pca =  338 , M_lda =  17  --->  Accuracy = 61.54%\n",
      "M_pca =  338 , M_lda =  18  --->  Accuracy = 62.50%\n",
      "M_pca =  338 , M_lda =  19  --->  Accuracy = 62.50%\n",
      "M_pca =  338 , M_lda =  20  --->  Accuracy = 64.42%\n",
      "M_pca =  338 , M_lda =  21  --->  Accuracy = 63.46%\n",
      "M_pca =  338 , M_lda =  22  --->  Accuracy = 64.42%\n",
      "M_pca =  338 , M_lda =  23  --->  Accuracy = 63.46%\n",
      "M_pca =  338 , M_lda =  24  --->  Accuracy = 64.42%\n",
      "M_pca =  338 , M_lda =  25  --->  Accuracy = 65.38%\n",
      "M_pca =  338 , M_lda =  26  --->  Accuracy = 65.38%\n",
      "M_pca =  338 , M_lda =  27  --->  Accuracy = 66.35%\n",
      "M_pca =  338 , M_lda =  28  --->  Accuracy = 66.35%\n",
      "M_pca =  338 , M_lda =  29  --->  Accuracy = 67.31%\n",
      "M_pca =  338 , M_lda =  30  --->  Accuracy = 67.31%\n",
      "M_pca =  338 , M_lda =  31  --->  Accuracy = 66.35%\n",
      "M_pca =  338 , M_lda =  32  --->  Accuracy = 66.35%\n",
      "M_pca =  338 , M_lda =  33  --->  Accuracy = 66.35%\n",
      "M_pca =  338 , M_lda =  34  --->  Accuracy = 66.35%\n",
      "M_pca =  338 , M_lda =  35  --->  Accuracy = 67.31%\n",
      "M_pca =  338 , M_lda =  36  --->  Accuracy = 67.31%\n",
      "M_pca =  338 , M_lda =  37  --->  Accuracy = 66.35%\n",
      "M_pca =  338 , M_lda =  38  --->  Accuracy = 68.27%\n",
      "M_pca =  338 , M_lda =  39  --->  Accuracy = 69.23%\n",
      "M_pca =  338 , M_lda =  40  --->  Accuracy = 68.27%\n",
      "M_pca =  338 , M_lda =  41  --->  Accuracy = 68.27%\n",
      "M_pca =  338 , M_lda =  42  --->  Accuracy = 69.23%\n",
      "M_pca =  338 , M_lda =  43  --->  Accuracy = 69.23%\n",
      "M_pca =  338 , M_lda =  44  --->  Accuracy = 70.19%\n",
      "M_pca =  338 , M_lda =  45  --->  Accuracy = 70.19%\n",
      "M_pca =  338 , M_lda =  46  --->  Accuracy = 71.15%\n",
      "M_pca =  338 , M_lda =  47  --->  Accuracy = 71.15%\n",
      "M_pca =  338 , M_lda =  48  --->  Accuracy = 71.15%\n",
      "M_pca =  338 , M_lda =  49  --->  Accuracy = 71.15%\n",
      "M_pca =  338 , M_lda =  50  --->  Accuracy = 72.12%\n",
      "M_pca =  338 , M_lda =  51  --->  Accuracy = 73.08%\n",
      "M_pca =  339 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  339 , M_lda =  2  --->  Accuracy = 9.62%\n",
      "M_pca =  339 , M_lda =  3  --->  Accuracy = 18.27%\n",
      "M_pca =  339 , M_lda =  4  --->  Accuracy = 21.15%\n",
      "M_pca =  339 , M_lda =  5  --->  Accuracy = 24.04%\n",
      "M_pca =  339 , M_lda =  6  --->  Accuracy = 30.77%\n",
      "M_pca =  339 , M_lda =  7  --->  Accuracy = 35.58%\n",
      "M_pca =  339 , M_lda =  8  --->  Accuracy = 42.31%\n",
      "M_pca =  339 , M_lda =  9  --->  Accuracy = 46.15%\n",
      "M_pca =  339 , M_lda =  10  --->  Accuracy = 49.04%\n",
      "M_pca =  339 , M_lda =  11  --->  Accuracy = 50.00%\n",
      "M_pca =  339 , M_lda =  12  --->  Accuracy = 51.92%\n",
      "M_pca =  339 , M_lda =  13  --->  Accuracy = 54.81%\n",
      "M_pca =  339 , M_lda =  14  --->  Accuracy = 58.65%\n",
      "M_pca =  339 , M_lda =  15  --->  Accuracy = 61.54%\n",
      "M_pca =  339 , M_lda =  16  --->  Accuracy = 60.58%\n",
      "M_pca =  339 , M_lda =  17  --->  Accuracy = 60.58%\n",
      "M_pca =  339 , M_lda =  18  --->  Accuracy = 62.50%\n",
      "M_pca =  339 , M_lda =  19  --->  Accuracy = 64.42%\n",
      "M_pca =  339 , M_lda =  20  --->  Accuracy = 66.35%\n",
      "M_pca =  339 , M_lda =  21  --->  Accuracy = 65.38%\n",
      "M_pca =  339 , M_lda =  22  --->  Accuracy = 65.38%\n",
      "M_pca =  339 , M_lda =  23  --->  Accuracy = 66.35%\n",
      "M_pca =  339 , M_lda =  24  --->  Accuracy = 67.31%\n",
      "M_pca =  339 , M_lda =  25  --->  Accuracy = 67.31%\n",
      "M_pca =  339 , M_lda =  26  --->  Accuracy = 67.31%\n",
      "M_pca =  339 , M_lda =  27  --->  Accuracy = 67.31%\n",
      "M_pca =  339 , M_lda =  28  --->  Accuracy = 67.31%\n",
      "M_pca =  339 , M_lda =  29  --->  Accuracy = 68.27%\n",
      "M_pca =  339 , M_lda =  30  --->  Accuracy = 69.23%\n",
      "M_pca =  339 , M_lda =  31  --->  Accuracy = 70.19%\n",
      "M_pca =  339 , M_lda =  32  --->  Accuracy = 71.15%\n",
      "M_pca =  339 , M_lda =  33  --->  Accuracy = 69.23%\n",
      "M_pca =  339 , M_lda =  34  --->  Accuracy = 69.23%\n",
      "M_pca =  339 , M_lda =  35  --->  Accuracy = 70.19%\n",
      "M_pca =  339 , M_lda =  36  --->  Accuracy = 69.23%\n",
      "M_pca =  339 , M_lda =  37  --->  Accuracy = 69.23%\n",
      "M_pca =  339 , M_lda =  38  --->  Accuracy = 70.19%\n",
      "M_pca =  339 , M_lda =  39  --->  Accuracy = 71.15%\n",
      "M_pca =  339 , M_lda =  40  --->  Accuracy = 70.19%\n",
      "M_pca =  339 , M_lda =  41  --->  Accuracy = 72.12%\n",
      "M_pca =  339 , M_lda =  42  --->  Accuracy = 72.12%\n",
      "M_pca =  339 , M_lda =  43  --->  Accuracy = 72.12%\n",
      "M_pca =  339 , M_lda =  44  --->  Accuracy = 72.12%\n",
      "M_pca =  339 , M_lda =  45  --->  Accuracy = 72.12%\n",
      "M_pca =  339 , M_lda =  46  --->  Accuracy = 72.12%\n",
      "M_pca =  339 , M_lda =  47  --->  Accuracy = 72.12%\n",
      "M_pca =  339 , M_lda =  48  --->  Accuracy = 72.12%\n",
      "M_pca =  339 , M_lda =  49  --->  Accuracy = 72.12%\n",
      "M_pca =  339 , M_lda =  50  --->  Accuracy = 72.12%\n",
      "M_pca =  339 , M_lda =  51  --->  Accuracy = 72.12%\n",
      "M_pca =  340 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  340 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  340 , M_lda =  3  --->  Accuracy = 21.15%\n",
      "M_pca =  340 , M_lda =  4  --->  Accuracy = 24.04%\n",
      "M_pca =  340 , M_lda =  5  --->  Accuracy = 30.77%\n",
      "M_pca =  340 , M_lda =  6  --->  Accuracy = 29.81%\n",
      "M_pca =  340 , M_lda =  7  --->  Accuracy = 36.54%\n",
      "M_pca =  340 , M_lda =  8  --->  Accuracy = 45.19%\n",
      "M_pca =  340 , M_lda =  9  --->  Accuracy = 48.08%\n",
      "M_pca =  340 , M_lda =  10  --->  Accuracy = 52.88%\n",
      "M_pca =  340 , M_lda =  11  --->  Accuracy = 53.85%\n",
      "M_pca =  340 , M_lda =  12  --->  Accuracy = 53.85%\n",
      "M_pca =  340 , M_lda =  13  --->  Accuracy = 57.69%\n",
      "M_pca =  340 , M_lda =  14  --->  Accuracy = 59.62%\n",
      "M_pca =  340 , M_lda =  15  --->  Accuracy = 61.54%\n",
      "M_pca =  340 , M_lda =  16  --->  Accuracy = 61.54%\n",
      "M_pca =  340 , M_lda =  17  --->  Accuracy = 63.46%\n",
      "M_pca =  340 , M_lda =  18  --->  Accuracy = 63.46%\n",
      "M_pca =  340 , M_lda =  19  --->  Accuracy = 63.46%\n",
      "M_pca =  340 , M_lda =  20  --->  Accuracy = 63.46%\n",
      "M_pca =  340 , M_lda =  21  --->  Accuracy = 66.35%\n",
      "M_pca =  340 , M_lda =  22  --->  Accuracy = 65.38%\n",
      "M_pca =  340 , M_lda =  23  --->  Accuracy = 65.38%\n",
      "M_pca =  340 , M_lda =  24  --->  Accuracy = 66.35%\n",
      "M_pca =  340 , M_lda =  25  --->  Accuracy = 67.31%\n",
      "M_pca =  340 , M_lda =  26  --->  Accuracy = 67.31%\n",
      "M_pca =  340 , M_lda =  27  --->  Accuracy = 67.31%\n",
      "M_pca =  340 , M_lda =  28  --->  Accuracy = 67.31%\n",
      "M_pca =  340 , M_lda =  29  --->  Accuracy = 67.31%\n",
      "M_pca =  340 , M_lda =  30  --->  Accuracy = 68.27%\n",
      "M_pca =  340 , M_lda =  31  --->  Accuracy = 69.23%\n",
      "M_pca =  340 , M_lda =  32  --->  Accuracy = 69.23%\n",
      "M_pca =  340 , M_lda =  33  --->  Accuracy = 70.19%\n",
      "M_pca =  340 , M_lda =  34  --->  Accuracy = 70.19%\n",
      "M_pca =  340 , M_lda =  35  --->  Accuracy = 69.23%\n",
      "M_pca =  340 , M_lda =  36  --->  Accuracy = 69.23%\n",
      "M_pca =  340 , M_lda =  37  --->  Accuracy = 70.19%\n",
      "M_pca =  340 , M_lda =  38  --->  Accuracy = 70.19%\n",
      "M_pca =  340 , M_lda =  39  --->  Accuracy = 70.19%\n",
      "M_pca =  340 , M_lda =  40  --->  Accuracy = 70.19%\n",
      "M_pca =  340 , M_lda =  41  --->  Accuracy = 70.19%\n",
      "M_pca =  340 , M_lda =  42  --->  Accuracy = 70.19%\n",
      "M_pca =  340 , M_lda =  43  --->  Accuracy = 70.19%\n",
      "M_pca =  340 , M_lda =  44  --->  Accuracy = 71.15%\n",
      "M_pca =  340 , M_lda =  45  --->  Accuracy = 71.15%\n",
      "M_pca =  340 , M_lda =  46  --->  Accuracy = 71.15%\n",
      "M_pca =  340 , M_lda =  47  --->  Accuracy = 71.15%\n",
      "M_pca =  340 , M_lda =  48  --->  Accuracy = 71.15%\n",
      "M_pca =  340 , M_lda =  49  --->  Accuracy = 71.15%\n",
      "M_pca =  340 , M_lda =  50  --->  Accuracy = 71.15%\n",
      "M_pca =  340 , M_lda =  51  --->  Accuracy = 71.15%\n",
      "M_pca =  341 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  341 , M_lda =  2  --->  Accuracy = 10.58%\n",
      "M_pca =  341 , M_lda =  3  --->  Accuracy = 19.23%\n",
      "M_pca =  341 , M_lda =  4  --->  Accuracy = 23.08%\n",
      "M_pca =  341 , M_lda =  5  --->  Accuracy = 25.00%\n",
      "M_pca =  341 , M_lda =  6  --->  Accuracy = 30.77%\n",
      "M_pca =  341 , M_lda =  7  --->  Accuracy = 35.58%\n",
      "M_pca =  341 , M_lda =  8  --->  Accuracy = 43.27%\n",
      "M_pca =  341 , M_lda =  9  --->  Accuracy = 45.19%\n",
      "M_pca =  341 , M_lda =  10  --->  Accuracy = 50.00%\n",
      "M_pca =  341 , M_lda =  11  --->  Accuracy = 53.85%\n",
      "M_pca =  341 , M_lda =  12  --->  Accuracy = 53.85%\n",
      "M_pca =  341 , M_lda =  13  --->  Accuracy = 57.69%\n",
      "M_pca =  341 , M_lda =  14  --->  Accuracy = 61.54%\n",
      "M_pca =  341 , M_lda =  15  --->  Accuracy = 61.54%\n",
      "M_pca =  341 , M_lda =  16  --->  Accuracy = 60.58%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  341 , M_lda =  17  --->  Accuracy = 62.50%\n",
      "M_pca =  341 , M_lda =  18  --->  Accuracy = 62.50%\n",
      "M_pca =  341 , M_lda =  19  --->  Accuracy = 63.46%\n",
      "M_pca =  341 , M_lda =  20  --->  Accuracy = 62.50%\n",
      "M_pca =  341 , M_lda =  21  --->  Accuracy = 64.42%\n",
      "M_pca =  341 , M_lda =  22  --->  Accuracy = 65.38%\n",
      "M_pca =  341 , M_lda =  23  --->  Accuracy = 65.38%\n",
      "M_pca =  341 , M_lda =  24  --->  Accuracy = 67.31%\n",
      "M_pca =  341 , M_lda =  25  --->  Accuracy = 67.31%\n",
      "M_pca =  341 , M_lda =  26  --->  Accuracy = 68.27%\n",
      "M_pca =  341 , M_lda =  27  --->  Accuracy = 68.27%\n",
      "M_pca =  341 , M_lda =  28  --->  Accuracy = 68.27%\n",
      "M_pca =  341 , M_lda =  29  --->  Accuracy = 69.23%\n",
      "M_pca =  341 , M_lda =  30  --->  Accuracy = 69.23%\n",
      "M_pca =  341 , M_lda =  31  --->  Accuracy = 69.23%\n",
      "M_pca =  341 , M_lda =  32  --->  Accuracy = 69.23%\n",
      "M_pca =  341 , M_lda =  33  --->  Accuracy = 69.23%\n",
      "M_pca =  341 , M_lda =  34  --->  Accuracy = 70.19%\n",
      "M_pca =  341 , M_lda =  35  --->  Accuracy = 70.19%\n",
      "M_pca =  341 , M_lda =  36  --->  Accuracy = 71.15%\n",
      "M_pca =  341 , M_lda =  37  --->  Accuracy = 71.15%\n",
      "M_pca =  341 , M_lda =  38  --->  Accuracy = 71.15%\n",
      "M_pca =  341 , M_lda =  39  --->  Accuracy = 71.15%\n",
      "M_pca =  341 , M_lda =  40  --->  Accuracy = 71.15%\n",
      "M_pca =  341 , M_lda =  41  --->  Accuracy = 71.15%\n",
      "M_pca =  341 , M_lda =  42  --->  Accuracy = 71.15%\n",
      "M_pca =  341 , M_lda =  43  --->  Accuracy = 71.15%\n",
      "M_pca =  341 , M_lda =  44  --->  Accuracy = 71.15%\n",
      "M_pca =  341 , M_lda =  45  --->  Accuracy = 71.15%\n",
      "M_pca =  341 , M_lda =  46  --->  Accuracy = 71.15%\n",
      "M_pca =  341 , M_lda =  47  --->  Accuracy = 71.15%\n",
      "M_pca =  341 , M_lda =  48  --->  Accuracy = 71.15%\n",
      "M_pca =  341 , M_lda =  49  --->  Accuracy = 71.15%\n",
      "M_pca =  341 , M_lda =  50  --->  Accuracy = 71.15%\n",
      "M_pca =  341 , M_lda =  51  --->  Accuracy = 71.15%\n",
      "M_pca =  342 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  342 , M_lda =  2  --->  Accuracy = 10.58%\n",
      "M_pca =  342 , M_lda =  3  --->  Accuracy = 21.15%\n",
      "M_pca =  342 , M_lda =  4  --->  Accuracy = 27.88%\n",
      "M_pca =  342 , M_lda =  5  --->  Accuracy = 29.81%\n",
      "M_pca =  342 , M_lda =  6  --->  Accuracy = 31.73%\n",
      "M_pca =  342 , M_lda =  7  --->  Accuracy = 35.58%\n",
      "M_pca =  342 , M_lda =  8  --->  Accuracy = 43.27%\n",
      "M_pca =  342 , M_lda =  9  --->  Accuracy = 43.27%\n",
      "M_pca =  342 , M_lda =  10  --->  Accuracy = 47.12%\n",
      "M_pca =  342 , M_lda =  11  --->  Accuracy = 49.04%\n",
      "M_pca =  342 , M_lda =  12  --->  Accuracy = 58.65%\n",
      "M_pca =  342 , M_lda =  13  --->  Accuracy = 58.65%\n",
      "M_pca =  342 , M_lda =  14  --->  Accuracy = 59.62%\n",
      "M_pca =  342 , M_lda =  15  --->  Accuracy = 60.58%\n",
      "M_pca =  342 , M_lda =  16  --->  Accuracy = 60.58%\n",
      "M_pca =  342 , M_lda =  17  --->  Accuracy = 59.62%\n",
      "M_pca =  342 , M_lda =  18  --->  Accuracy = 61.54%\n",
      "M_pca =  342 , M_lda =  19  --->  Accuracy = 64.42%\n",
      "M_pca =  342 , M_lda =  20  --->  Accuracy = 64.42%\n",
      "M_pca =  342 , M_lda =  21  --->  Accuracy = 64.42%\n",
      "M_pca =  342 , M_lda =  22  --->  Accuracy = 65.38%\n",
      "M_pca =  342 , M_lda =  23  --->  Accuracy = 66.35%\n",
      "M_pca =  342 , M_lda =  24  --->  Accuracy = 65.38%\n",
      "M_pca =  342 , M_lda =  25  --->  Accuracy = 66.35%\n",
      "M_pca =  342 , M_lda =  26  --->  Accuracy = 66.35%\n",
      "M_pca =  342 , M_lda =  27  --->  Accuracy = 68.27%\n",
      "M_pca =  342 , M_lda =  28  --->  Accuracy = 68.27%\n",
      "M_pca =  342 , M_lda =  29  --->  Accuracy = 69.23%\n",
      "M_pca =  342 , M_lda =  30  --->  Accuracy = 69.23%\n",
      "M_pca =  342 , M_lda =  31  --->  Accuracy = 69.23%\n",
      "M_pca =  342 , M_lda =  32  --->  Accuracy = 70.19%\n",
      "M_pca =  342 , M_lda =  33  --->  Accuracy = 71.15%\n",
      "M_pca =  342 , M_lda =  34  --->  Accuracy = 71.15%\n",
      "M_pca =  342 , M_lda =  35  --->  Accuracy = 72.12%\n",
      "M_pca =  342 , M_lda =  36  --->  Accuracy = 72.12%\n",
      "M_pca =  342 , M_lda =  37  --->  Accuracy = 72.12%\n",
      "M_pca =  342 , M_lda =  38  --->  Accuracy = 71.15%\n",
      "M_pca =  342 , M_lda =  39  --->  Accuracy = 72.12%\n",
      "M_pca =  342 , M_lda =  40  --->  Accuracy = 72.12%\n",
      "M_pca =  342 , M_lda =  41  --->  Accuracy = 72.12%\n",
      "M_pca =  342 , M_lda =  42  --->  Accuracy = 73.08%\n",
      "M_pca =  342 , M_lda =  43  --->  Accuracy = 73.08%\n",
      "M_pca =  342 , M_lda =  44  --->  Accuracy = 73.08%\n",
      "M_pca =  342 , M_lda =  45  --->  Accuracy = 73.08%\n",
      "M_pca =  342 , M_lda =  46  --->  Accuracy = 73.08%\n",
      "M_pca =  342 , M_lda =  47  --->  Accuracy = 73.08%\n",
      "M_pca =  342 , M_lda =  48  --->  Accuracy = 73.08%\n",
      "M_pca =  342 , M_lda =  49  --->  Accuracy = 73.08%\n",
      "M_pca =  342 , M_lda =  50  --->  Accuracy = 73.08%\n",
      "M_pca =  342 , M_lda =  51  --->  Accuracy = 73.08%\n",
      "M_pca =  343 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  343 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  343 , M_lda =  3  --->  Accuracy = 17.31%\n",
      "M_pca =  343 , M_lda =  4  --->  Accuracy = 22.12%\n",
      "M_pca =  343 , M_lda =  5  --->  Accuracy = 29.81%\n",
      "M_pca =  343 , M_lda =  6  --->  Accuracy = 33.65%\n",
      "M_pca =  343 , M_lda =  7  --->  Accuracy = 33.65%\n",
      "M_pca =  343 , M_lda =  8  --->  Accuracy = 42.31%\n",
      "M_pca =  343 , M_lda =  9  --->  Accuracy = 48.08%\n",
      "M_pca =  343 , M_lda =  10  --->  Accuracy = 49.04%\n",
      "M_pca =  343 , M_lda =  11  --->  Accuracy = 50.00%\n",
      "M_pca =  343 , M_lda =  12  --->  Accuracy = 50.00%\n",
      "M_pca =  343 , M_lda =  13  --->  Accuracy = 56.73%\n",
      "M_pca =  343 , M_lda =  14  --->  Accuracy = 56.73%\n",
      "M_pca =  343 , M_lda =  15  --->  Accuracy = 59.62%\n",
      "M_pca =  343 , M_lda =  16  --->  Accuracy = 60.58%\n",
      "M_pca =  343 , M_lda =  17  --->  Accuracy = 62.50%\n",
      "M_pca =  343 , M_lda =  18  --->  Accuracy = 62.50%\n",
      "M_pca =  343 , M_lda =  19  --->  Accuracy = 63.46%\n",
      "M_pca =  343 , M_lda =  20  --->  Accuracy = 64.42%\n",
      "M_pca =  343 , M_lda =  21  --->  Accuracy = 63.46%\n",
      "M_pca =  343 , M_lda =  22  --->  Accuracy = 64.42%\n",
      "M_pca =  343 , M_lda =  23  --->  Accuracy = 66.35%\n",
      "M_pca =  343 , M_lda =  24  --->  Accuracy = 66.35%\n",
      "M_pca =  343 , M_lda =  25  --->  Accuracy = 66.35%\n",
      "M_pca =  343 , M_lda =  26  --->  Accuracy = 66.35%\n",
      "M_pca =  343 , M_lda =  27  --->  Accuracy = 66.35%\n",
      "M_pca =  343 , M_lda =  28  --->  Accuracy = 67.31%\n",
      "M_pca =  343 , M_lda =  29  --->  Accuracy = 67.31%\n",
      "M_pca =  343 , M_lda =  30  --->  Accuracy = 67.31%\n",
      "M_pca =  343 , M_lda =  31  --->  Accuracy = 67.31%\n",
      "M_pca =  343 , M_lda =  32  --->  Accuracy = 67.31%\n",
      "M_pca =  343 , M_lda =  33  --->  Accuracy = 66.35%\n",
      "M_pca =  343 , M_lda =  34  --->  Accuracy = 66.35%\n",
      "M_pca =  343 , M_lda =  35  --->  Accuracy = 67.31%\n",
      "M_pca =  343 , M_lda =  36  --->  Accuracy = 67.31%\n",
      "M_pca =  343 , M_lda =  37  --->  Accuracy = 68.27%\n",
      "M_pca =  343 , M_lda =  38  --->  Accuracy = 67.31%\n",
      "M_pca =  343 , M_lda =  39  --->  Accuracy = 66.35%\n",
      "M_pca =  343 , M_lda =  40  --->  Accuracy = 66.35%\n",
      "M_pca =  343 , M_lda =  41  --->  Accuracy = 67.31%\n",
      "M_pca =  343 , M_lda =  42  --->  Accuracy = 68.27%\n",
      "M_pca =  343 , M_lda =  43  --->  Accuracy = 68.27%\n",
      "M_pca =  343 , M_lda =  44  --->  Accuracy = 68.27%\n",
      "M_pca =  343 , M_lda =  45  --->  Accuracy = 67.31%\n",
      "M_pca =  343 , M_lda =  46  --->  Accuracy = 67.31%\n",
      "M_pca =  343 , M_lda =  47  --->  Accuracy = 68.27%\n",
      "M_pca =  343 , M_lda =  48  --->  Accuracy = 67.31%\n",
      "M_pca =  343 , M_lda =  49  --->  Accuracy = 67.31%\n",
      "M_pca =  343 , M_lda =  50  --->  Accuracy = 67.31%\n",
      "M_pca =  343 , M_lda =  51  --->  Accuracy = 67.31%\n",
      "M_pca =  344 , M_lda =  1  --->  Accuracy = 8.65%\n",
      "M_pca =  344 , M_lda =  2  --->  Accuracy = 14.42%\n",
      "M_pca =  344 , M_lda =  3  --->  Accuracy = 17.31%\n",
      "M_pca =  344 , M_lda =  4  --->  Accuracy = 25.00%\n",
      "M_pca =  344 , M_lda =  5  --->  Accuracy = 25.96%\n",
      "M_pca =  344 , M_lda =  6  --->  Accuracy = 32.69%\n",
      "M_pca =  344 , M_lda =  7  --->  Accuracy = 36.54%\n",
      "M_pca =  344 , M_lda =  8  --->  Accuracy = 37.50%\n",
      "M_pca =  344 , M_lda =  9  --->  Accuracy = 48.08%\n",
      "M_pca =  344 , M_lda =  10  --->  Accuracy = 50.96%\n",
      "M_pca =  344 , M_lda =  11  --->  Accuracy = 52.88%\n",
      "M_pca =  344 , M_lda =  12  --->  Accuracy = 53.85%\n",
      "M_pca =  344 , M_lda =  13  --->  Accuracy = 58.65%\n",
      "M_pca =  344 , M_lda =  14  --->  Accuracy = 58.65%\n",
      "M_pca =  344 , M_lda =  15  --->  Accuracy = 59.62%\n",
      "M_pca =  344 , M_lda =  16  --->  Accuracy = 59.62%\n",
      "M_pca =  344 , M_lda =  17  --->  Accuracy = 58.65%\n",
      "M_pca =  344 , M_lda =  18  --->  Accuracy = 60.58%\n",
      "M_pca =  344 , M_lda =  19  --->  Accuracy = 61.54%\n",
      "M_pca =  344 , M_lda =  20  --->  Accuracy = 62.50%\n",
      "M_pca =  344 , M_lda =  21  --->  Accuracy = 61.54%\n",
      "M_pca =  344 , M_lda =  22  --->  Accuracy = 62.50%\n",
      "M_pca =  344 , M_lda =  23  --->  Accuracy = 62.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  344 , M_lda =  24  --->  Accuracy = 63.46%\n",
      "M_pca =  344 , M_lda =  25  --->  Accuracy = 66.35%\n",
      "M_pca =  344 , M_lda =  26  --->  Accuracy = 67.31%\n",
      "M_pca =  344 , M_lda =  27  --->  Accuracy = 67.31%\n",
      "M_pca =  344 , M_lda =  28  --->  Accuracy = 66.35%\n",
      "M_pca =  344 , M_lda =  29  --->  Accuracy = 66.35%\n",
      "M_pca =  344 , M_lda =  30  --->  Accuracy = 66.35%\n",
      "M_pca =  344 , M_lda =  31  --->  Accuracy = 67.31%\n",
      "M_pca =  344 , M_lda =  32  --->  Accuracy = 68.27%\n",
      "M_pca =  344 , M_lda =  33  --->  Accuracy = 67.31%\n",
      "M_pca =  344 , M_lda =  34  --->  Accuracy = 68.27%\n",
      "M_pca =  344 , M_lda =  35  --->  Accuracy = 68.27%\n",
      "M_pca =  344 , M_lda =  36  --->  Accuracy = 68.27%\n",
      "M_pca =  344 , M_lda =  37  --->  Accuracy = 68.27%\n",
      "M_pca =  344 , M_lda =  38  --->  Accuracy = 68.27%\n",
      "M_pca =  344 , M_lda =  39  --->  Accuracy = 69.23%\n",
      "M_pca =  344 , M_lda =  40  --->  Accuracy = 69.23%\n",
      "M_pca =  344 , M_lda =  41  --->  Accuracy = 68.27%\n",
      "M_pca =  344 , M_lda =  42  --->  Accuracy = 69.23%\n",
      "M_pca =  344 , M_lda =  43  --->  Accuracy = 69.23%\n",
      "M_pca =  344 , M_lda =  44  --->  Accuracy = 69.23%\n",
      "M_pca =  344 , M_lda =  45  --->  Accuracy = 69.23%\n",
      "M_pca =  344 , M_lda =  46  --->  Accuracy = 69.23%\n",
      "M_pca =  344 , M_lda =  47  --->  Accuracy = 69.23%\n",
      "M_pca =  344 , M_lda =  48  --->  Accuracy = 69.23%\n",
      "M_pca =  344 , M_lda =  49  --->  Accuracy = 69.23%\n",
      "M_pca =  344 , M_lda =  50  --->  Accuracy = 69.23%\n",
      "M_pca =  344 , M_lda =  51  --->  Accuracy = 69.23%\n",
      "M_pca =  345 , M_lda =  1  --->  Accuracy = 3.85%\n",
      "M_pca =  345 , M_lda =  2  --->  Accuracy = 10.58%\n",
      "M_pca =  345 , M_lda =  3  --->  Accuracy = 16.35%\n",
      "M_pca =  345 , M_lda =  4  --->  Accuracy = 21.15%\n",
      "M_pca =  345 , M_lda =  5  --->  Accuracy = 21.15%\n",
      "M_pca =  345 , M_lda =  6  --->  Accuracy = 26.92%\n",
      "M_pca =  345 , M_lda =  7  --->  Accuracy = 31.73%\n",
      "M_pca =  345 , M_lda =  8  --->  Accuracy = 33.65%\n",
      "M_pca =  345 , M_lda =  9  --->  Accuracy = 49.04%\n",
      "M_pca =  345 , M_lda =  10  --->  Accuracy = 49.04%\n",
      "M_pca =  345 , M_lda =  11  --->  Accuracy = 50.96%\n",
      "M_pca =  345 , M_lda =  12  --->  Accuracy = 51.92%\n",
      "M_pca =  345 , M_lda =  13  --->  Accuracy = 58.65%\n",
      "M_pca =  345 , M_lda =  14  --->  Accuracy = 57.69%\n",
      "M_pca =  345 , M_lda =  15  --->  Accuracy = 59.62%\n",
      "M_pca =  345 , M_lda =  16  --->  Accuracy = 61.54%\n",
      "M_pca =  345 , M_lda =  17  --->  Accuracy = 60.58%\n",
      "M_pca =  345 , M_lda =  18  --->  Accuracy = 61.54%\n",
      "M_pca =  345 , M_lda =  19  --->  Accuracy = 62.50%\n",
      "M_pca =  345 , M_lda =  20  --->  Accuracy = 63.46%\n",
      "M_pca =  345 , M_lda =  21  --->  Accuracy = 63.46%\n",
      "M_pca =  345 , M_lda =  22  --->  Accuracy = 63.46%\n",
      "M_pca =  345 , M_lda =  23  --->  Accuracy = 63.46%\n",
      "M_pca =  345 , M_lda =  24  --->  Accuracy = 62.50%\n",
      "M_pca =  345 , M_lda =  25  --->  Accuracy = 66.35%\n",
      "M_pca =  345 , M_lda =  26  --->  Accuracy = 66.35%\n",
      "M_pca =  345 , M_lda =  27  --->  Accuracy = 66.35%\n",
      "M_pca =  345 , M_lda =  28  --->  Accuracy = 66.35%\n",
      "M_pca =  345 , M_lda =  29  --->  Accuracy = 66.35%\n",
      "M_pca =  345 , M_lda =  30  --->  Accuracy = 66.35%\n",
      "M_pca =  345 , M_lda =  31  --->  Accuracy = 67.31%\n",
      "M_pca =  345 , M_lda =  32  --->  Accuracy = 67.31%\n",
      "M_pca =  345 , M_lda =  33  --->  Accuracy = 67.31%\n",
      "M_pca =  345 , M_lda =  34  --->  Accuracy = 67.31%\n",
      "M_pca =  345 , M_lda =  35  --->  Accuracy = 67.31%\n",
      "M_pca =  345 , M_lda =  36  --->  Accuracy = 67.31%\n",
      "M_pca =  345 , M_lda =  37  --->  Accuracy = 68.27%\n",
      "M_pca =  345 , M_lda =  38  --->  Accuracy = 68.27%\n",
      "M_pca =  345 , M_lda =  39  --->  Accuracy = 68.27%\n",
      "M_pca =  345 , M_lda =  40  --->  Accuracy = 67.31%\n",
      "M_pca =  345 , M_lda =  41  --->  Accuracy = 67.31%\n",
      "M_pca =  345 , M_lda =  42  --->  Accuracy = 67.31%\n",
      "M_pca =  345 , M_lda =  43  --->  Accuracy = 67.31%\n",
      "M_pca =  345 , M_lda =  44  --->  Accuracy = 67.31%\n",
      "M_pca =  345 , M_lda =  45  --->  Accuracy = 67.31%\n",
      "M_pca =  345 , M_lda =  46  --->  Accuracy = 67.31%\n",
      "M_pca =  345 , M_lda =  47  --->  Accuracy = 67.31%\n",
      "M_pca =  345 , M_lda =  48  --->  Accuracy = 67.31%\n",
      "M_pca =  345 , M_lda =  49  --->  Accuracy = 67.31%\n",
      "M_pca =  345 , M_lda =  50  --->  Accuracy = 67.31%\n",
      "M_pca =  345 , M_lda =  51  --->  Accuracy = 68.27%\n",
      "M_pca =  346 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  346 , M_lda =  2  --->  Accuracy = 10.58%\n",
      "M_pca =  346 , M_lda =  3  --->  Accuracy = 14.42%\n",
      "M_pca =  346 , M_lda =  4  --->  Accuracy = 22.12%\n",
      "M_pca =  346 , M_lda =  5  --->  Accuracy = 23.08%\n",
      "M_pca =  346 , M_lda =  6  --->  Accuracy = 28.85%\n",
      "M_pca =  346 , M_lda =  7  --->  Accuracy = 34.62%\n",
      "M_pca =  346 , M_lda =  8  --->  Accuracy = 42.31%\n",
      "M_pca =  346 , M_lda =  9  --->  Accuracy = 42.31%\n",
      "M_pca =  346 , M_lda =  10  --->  Accuracy = 50.00%\n",
      "M_pca =  346 , M_lda =  11  --->  Accuracy = 50.96%\n",
      "M_pca =  346 , M_lda =  12  --->  Accuracy = 53.85%\n",
      "M_pca =  346 , M_lda =  13  --->  Accuracy = 56.73%\n",
      "M_pca =  346 , M_lda =  14  --->  Accuracy = 55.77%\n",
      "M_pca =  346 , M_lda =  15  --->  Accuracy = 57.69%\n",
      "M_pca =  346 , M_lda =  16  --->  Accuracy = 59.62%\n",
      "M_pca =  346 , M_lda =  17  --->  Accuracy = 60.58%\n",
      "M_pca =  346 , M_lda =  18  --->  Accuracy = 60.58%\n",
      "M_pca =  346 , M_lda =  19  --->  Accuracy = 59.62%\n",
      "M_pca =  346 , M_lda =  20  --->  Accuracy = 60.58%\n",
      "M_pca =  346 , M_lda =  21  --->  Accuracy = 60.58%\n",
      "M_pca =  346 , M_lda =  22  --->  Accuracy = 60.58%\n",
      "M_pca =  346 , M_lda =  23  --->  Accuracy = 60.58%\n",
      "M_pca =  346 , M_lda =  24  --->  Accuracy = 60.58%\n",
      "M_pca =  346 , M_lda =  25  --->  Accuracy = 62.50%\n",
      "M_pca =  346 , M_lda =  26  --->  Accuracy = 62.50%\n",
      "M_pca =  346 , M_lda =  27  --->  Accuracy = 62.50%\n",
      "M_pca =  346 , M_lda =  28  --->  Accuracy = 63.46%\n",
      "M_pca =  346 , M_lda =  29  --->  Accuracy = 64.42%\n",
      "M_pca =  346 , M_lda =  30  --->  Accuracy = 64.42%\n",
      "M_pca =  346 , M_lda =  31  --->  Accuracy = 64.42%\n",
      "M_pca =  346 , M_lda =  32  --->  Accuracy = 64.42%\n",
      "M_pca =  346 , M_lda =  33  --->  Accuracy = 64.42%\n",
      "M_pca =  346 , M_lda =  34  --->  Accuracy = 65.38%\n",
      "M_pca =  346 , M_lda =  35  --->  Accuracy = 65.38%\n",
      "M_pca =  346 , M_lda =  36  --->  Accuracy = 65.38%\n",
      "M_pca =  346 , M_lda =  37  --->  Accuracy = 66.35%\n",
      "M_pca =  346 , M_lda =  38  --->  Accuracy = 66.35%\n",
      "M_pca =  346 , M_lda =  39  --->  Accuracy = 66.35%\n",
      "M_pca =  346 , M_lda =  40  --->  Accuracy = 65.38%\n",
      "M_pca =  346 , M_lda =  41  --->  Accuracy = 64.42%\n",
      "M_pca =  346 , M_lda =  42  --->  Accuracy = 64.42%\n",
      "M_pca =  346 , M_lda =  43  --->  Accuracy = 64.42%\n",
      "M_pca =  346 , M_lda =  44  --->  Accuracy = 65.38%\n",
      "M_pca =  346 , M_lda =  45  --->  Accuracy = 65.38%\n",
      "M_pca =  346 , M_lda =  46  --->  Accuracy = 65.38%\n",
      "M_pca =  346 , M_lda =  47  --->  Accuracy = 65.38%\n",
      "M_pca =  346 , M_lda =  48  --->  Accuracy = 65.38%\n",
      "M_pca =  346 , M_lda =  49  --->  Accuracy = 66.35%\n",
      "M_pca =  346 , M_lda =  50  --->  Accuracy = 67.31%\n",
      "M_pca =  346 , M_lda =  51  --->  Accuracy = 67.31%\n",
      "M_pca =  347 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  347 , M_lda =  2  --->  Accuracy = 7.69%\n",
      "M_pca =  347 , M_lda =  3  --->  Accuracy = 11.54%\n",
      "M_pca =  347 , M_lda =  4  --->  Accuracy = 16.35%\n",
      "M_pca =  347 , M_lda =  5  --->  Accuracy = 24.04%\n",
      "M_pca =  347 , M_lda =  6  --->  Accuracy = 25.96%\n",
      "M_pca =  347 , M_lda =  7  --->  Accuracy = 31.73%\n",
      "M_pca =  347 , M_lda =  8  --->  Accuracy = 37.50%\n",
      "M_pca =  347 , M_lda =  9  --->  Accuracy = 40.38%\n",
      "M_pca =  347 , M_lda =  10  --->  Accuracy = 44.23%\n",
      "M_pca =  347 , M_lda =  11  --->  Accuracy = 46.15%\n",
      "M_pca =  347 , M_lda =  12  --->  Accuracy = 47.12%\n",
      "M_pca =  347 , M_lda =  13  --->  Accuracy = 48.08%\n",
      "M_pca =  347 , M_lda =  14  --->  Accuracy = 50.00%\n",
      "M_pca =  347 , M_lda =  15  --->  Accuracy = 50.00%\n",
      "M_pca =  347 , M_lda =  16  --->  Accuracy = 50.00%\n",
      "M_pca =  347 , M_lda =  17  --->  Accuracy = 50.96%\n",
      "M_pca =  347 , M_lda =  18  --->  Accuracy = 51.92%\n",
      "M_pca =  347 , M_lda =  19  --->  Accuracy = 51.92%\n",
      "M_pca =  347 , M_lda =  20  --->  Accuracy = 53.85%\n",
      "M_pca =  347 , M_lda =  21  --->  Accuracy = 54.81%\n",
      "M_pca =  347 , M_lda =  22  --->  Accuracy = 54.81%\n",
      "M_pca =  347 , M_lda =  23  --->  Accuracy = 55.77%\n",
      "M_pca =  347 , M_lda =  24  --->  Accuracy = 54.81%\n",
      "M_pca =  347 , M_lda =  25  --->  Accuracy = 55.77%\n",
      "M_pca =  347 , M_lda =  26  --->  Accuracy = 55.77%\n",
      "M_pca =  347 , M_lda =  27  --->  Accuracy = 55.77%\n",
      "M_pca =  347 , M_lda =  28  --->  Accuracy = 56.73%\n",
      "M_pca =  347 , M_lda =  29  --->  Accuracy = 57.69%\n",
      "M_pca =  347 , M_lda =  30  --->  Accuracy = 57.69%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  347 , M_lda =  31  --->  Accuracy = 58.65%\n",
      "M_pca =  347 , M_lda =  32  --->  Accuracy = 57.69%\n",
      "M_pca =  347 , M_lda =  33  --->  Accuracy = 58.65%\n",
      "M_pca =  347 , M_lda =  34  --->  Accuracy = 58.65%\n",
      "M_pca =  347 , M_lda =  35  --->  Accuracy = 59.62%\n",
      "M_pca =  347 , M_lda =  36  --->  Accuracy = 59.62%\n",
      "M_pca =  347 , M_lda =  37  --->  Accuracy = 59.62%\n",
      "M_pca =  347 , M_lda =  38  --->  Accuracy = 59.62%\n",
      "M_pca =  347 , M_lda =  39  --->  Accuracy = 59.62%\n",
      "M_pca =  347 , M_lda =  40  --->  Accuracy = 59.62%\n",
      "M_pca =  347 , M_lda =  41  --->  Accuracy = 61.54%\n",
      "M_pca =  347 , M_lda =  42  --->  Accuracy = 61.54%\n",
      "M_pca =  347 , M_lda =  43  --->  Accuracy = 61.54%\n",
      "M_pca =  347 , M_lda =  44  --->  Accuracy = 62.50%\n",
      "M_pca =  347 , M_lda =  45  --->  Accuracy = 61.54%\n",
      "M_pca =  347 , M_lda =  46  --->  Accuracy = 61.54%\n",
      "M_pca =  347 , M_lda =  47  --->  Accuracy = 61.54%\n",
      "M_pca =  347 , M_lda =  48  --->  Accuracy = 61.54%\n",
      "M_pca =  347 , M_lda =  49  --->  Accuracy = 61.54%\n",
      "M_pca =  347 , M_lda =  50  --->  Accuracy = 61.54%\n",
      "M_pca =  347 , M_lda =  51  --->  Accuracy = 61.54%\n",
      "M_pca =  348 , M_lda =  1  --->  Accuracy = 2.88%\n",
      "M_pca =  348 , M_lda =  2  --->  Accuracy = 6.73%\n",
      "M_pca =  348 , M_lda =  3  --->  Accuracy = 12.50%\n",
      "M_pca =  348 , M_lda =  4  --->  Accuracy = 18.27%\n",
      "M_pca =  348 , M_lda =  5  --->  Accuracy = 23.08%\n",
      "M_pca =  348 , M_lda =  6  --->  Accuracy = 27.88%\n",
      "M_pca =  348 , M_lda =  7  --->  Accuracy = 32.69%\n",
      "M_pca =  348 , M_lda =  8  --->  Accuracy = 37.50%\n",
      "M_pca =  348 , M_lda =  9  --->  Accuracy = 40.38%\n",
      "M_pca =  348 , M_lda =  10  --->  Accuracy = 41.35%\n",
      "M_pca =  348 , M_lda =  11  --->  Accuracy = 42.31%\n",
      "M_pca =  348 , M_lda =  12  --->  Accuracy = 46.15%\n",
      "M_pca =  348 , M_lda =  13  --->  Accuracy = 45.19%\n",
      "M_pca =  348 , M_lda =  14  --->  Accuracy = 46.15%\n",
      "M_pca =  348 , M_lda =  15  --->  Accuracy = 48.08%\n",
      "M_pca =  348 , M_lda =  16  --->  Accuracy = 49.04%\n",
      "M_pca =  348 , M_lda =  17  --->  Accuracy = 50.00%\n",
      "M_pca =  348 , M_lda =  18  --->  Accuracy = 49.04%\n",
      "M_pca =  348 , M_lda =  19  --->  Accuracy = 49.04%\n",
      "M_pca =  348 , M_lda =  20  --->  Accuracy = 51.92%\n",
      "M_pca =  348 , M_lda =  21  --->  Accuracy = 51.92%\n",
      "M_pca =  348 , M_lda =  22  --->  Accuracy = 53.85%\n",
      "M_pca =  348 , M_lda =  23  --->  Accuracy = 53.85%\n",
      "M_pca =  348 , M_lda =  24  --->  Accuracy = 53.85%\n",
      "M_pca =  348 , M_lda =  25  --->  Accuracy = 55.77%\n",
      "M_pca =  348 , M_lda =  26  --->  Accuracy = 55.77%\n",
      "M_pca =  348 , M_lda =  27  --->  Accuracy = 55.77%\n",
      "M_pca =  348 , M_lda =  28  --->  Accuracy = 56.73%\n",
      "M_pca =  348 , M_lda =  29  --->  Accuracy = 56.73%\n",
      "M_pca =  348 , M_lda =  30  --->  Accuracy = 56.73%\n",
      "M_pca =  348 , M_lda =  31  --->  Accuracy = 55.77%\n",
      "M_pca =  348 , M_lda =  32  --->  Accuracy = 55.77%\n",
      "M_pca =  348 , M_lda =  33  --->  Accuracy = 55.77%\n",
      "M_pca =  348 , M_lda =  34  --->  Accuracy = 55.77%\n",
      "M_pca =  348 , M_lda =  35  --->  Accuracy = 55.77%\n",
      "M_pca =  348 , M_lda =  36  --->  Accuracy = 55.77%\n",
      "M_pca =  348 , M_lda =  37  --->  Accuracy = 55.77%\n",
      "M_pca =  348 , M_lda =  38  --->  Accuracy = 55.77%\n",
      "M_pca =  348 , M_lda =  39  --->  Accuracy = 55.77%\n",
      "M_pca =  348 , M_lda =  40  --->  Accuracy = 55.77%\n",
      "M_pca =  348 , M_lda =  41  --->  Accuracy = 55.77%\n",
      "M_pca =  348 , M_lda =  42  --->  Accuracy = 56.73%\n",
      "M_pca =  348 , M_lda =  43  --->  Accuracy = 56.73%\n",
      "M_pca =  348 , M_lda =  44  --->  Accuracy = 56.73%\n",
      "M_pca =  348 , M_lda =  45  --->  Accuracy = 56.73%\n",
      "M_pca =  348 , M_lda =  46  --->  Accuracy = 56.73%\n",
      "M_pca =  348 , M_lda =  47  --->  Accuracy = 56.73%\n",
      "M_pca =  348 , M_lda =  48  --->  Accuracy = 56.73%\n",
      "M_pca =  348 , M_lda =  49  --->  Accuracy = 56.73%\n",
      "M_pca =  348 , M_lda =  50  --->  Accuracy = 56.73%\n",
      "M_pca =  348 , M_lda =  51  --->  Accuracy = 56.73%\n",
      "M_pca =  349 , M_lda =  1  --->  Accuracy = 7.69%\n",
      "M_pca =  349 , M_lda =  2  --->  Accuracy = 5.77%\n",
      "M_pca =  349 , M_lda =  3  --->  Accuracy = 12.50%\n",
      "M_pca =  349 , M_lda =  4  --->  Accuracy = 16.35%\n",
      "M_pca =  349 , M_lda =  5  --->  Accuracy = 22.12%\n",
      "M_pca =  349 , M_lda =  6  --->  Accuracy = 26.92%\n",
      "M_pca =  349 , M_lda =  7  --->  Accuracy = 28.85%\n",
      "M_pca =  349 , M_lda =  8  --->  Accuracy = 30.77%\n",
      "M_pca =  349 , M_lda =  9  --->  Accuracy = 37.50%\n",
      "M_pca =  349 , M_lda =  10  --->  Accuracy = 38.46%\n",
      "M_pca =  349 , M_lda =  11  --->  Accuracy = 40.38%\n",
      "M_pca =  349 , M_lda =  12  --->  Accuracy = 44.23%\n",
      "M_pca =  349 , M_lda =  13  --->  Accuracy = 44.23%\n",
      "M_pca =  349 , M_lda =  14  --->  Accuracy = 44.23%\n",
      "M_pca =  349 , M_lda =  15  --->  Accuracy = 46.15%\n",
      "M_pca =  349 , M_lda =  16  --->  Accuracy = 47.12%\n",
      "M_pca =  349 , M_lda =  17  --->  Accuracy = 49.04%\n",
      "M_pca =  349 , M_lda =  18  --->  Accuracy = 49.04%\n",
      "M_pca =  349 , M_lda =  19  --->  Accuracy = 50.96%\n",
      "M_pca =  349 , M_lda =  20  --->  Accuracy = 51.92%\n",
      "M_pca =  349 , M_lda =  21  --->  Accuracy = 51.92%\n",
      "M_pca =  349 , M_lda =  22  --->  Accuracy = 52.88%\n",
      "M_pca =  349 , M_lda =  23  --->  Accuracy = 53.85%\n",
      "M_pca =  349 , M_lda =  24  --->  Accuracy = 53.85%\n",
      "M_pca =  349 , M_lda =  25  --->  Accuracy = 53.85%\n",
      "M_pca =  349 , M_lda =  26  --->  Accuracy = 54.81%\n",
      "M_pca =  349 , M_lda =  27  --->  Accuracy = 54.81%\n",
      "M_pca =  349 , M_lda =  28  --->  Accuracy = 53.85%\n",
      "M_pca =  349 , M_lda =  29  --->  Accuracy = 54.81%\n",
      "M_pca =  349 , M_lda =  30  --->  Accuracy = 54.81%\n",
      "M_pca =  349 , M_lda =  31  --->  Accuracy = 54.81%\n",
      "M_pca =  349 , M_lda =  32  --->  Accuracy = 56.73%\n",
      "M_pca =  349 , M_lda =  33  --->  Accuracy = 57.69%\n",
      "M_pca =  349 , M_lda =  34  --->  Accuracy = 57.69%\n",
      "M_pca =  349 , M_lda =  35  --->  Accuracy = 57.69%\n",
      "M_pca =  349 , M_lda =  36  --->  Accuracy = 57.69%\n",
      "M_pca =  349 , M_lda =  37  --->  Accuracy = 58.65%\n",
      "M_pca =  349 , M_lda =  38  --->  Accuracy = 58.65%\n",
      "M_pca =  349 , M_lda =  39  --->  Accuracy = 57.69%\n",
      "M_pca =  349 , M_lda =  40  --->  Accuracy = 57.69%\n",
      "M_pca =  349 , M_lda =  41  --->  Accuracy = 58.65%\n",
      "M_pca =  349 , M_lda =  42  --->  Accuracy = 58.65%\n",
      "M_pca =  349 , M_lda =  43  --->  Accuracy = 59.62%\n",
      "M_pca =  349 , M_lda =  44  --->  Accuracy = 59.62%\n",
      "M_pca =  349 , M_lda =  45  --->  Accuracy = 59.62%\n",
      "M_pca =  349 , M_lda =  46  --->  Accuracy = 59.62%\n",
      "M_pca =  349 , M_lda =  47  --->  Accuracy = 59.62%\n",
      "M_pca =  349 , M_lda =  48  --->  Accuracy = 59.62%\n",
      "M_pca =  349 , M_lda =  49  --->  Accuracy = 59.62%\n",
      "M_pca =  349 , M_lda =  50  --->  Accuracy = 59.62%\n",
      "M_pca =  349 , M_lda =  51  --->  Accuracy = 59.62%\n",
      "M_pca =  350 , M_lda =  1  --->  Accuracy = 1.92%\n",
      "M_pca =  350 , M_lda =  2  --->  Accuracy = 6.73%\n",
      "M_pca =  350 , M_lda =  3  --->  Accuracy = 10.58%\n",
      "M_pca =  350 , M_lda =  4  --->  Accuracy = 14.42%\n",
      "M_pca =  350 , M_lda =  5  --->  Accuracy = 22.12%\n",
      "M_pca =  350 , M_lda =  6  --->  Accuracy = 25.96%\n",
      "M_pca =  350 , M_lda =  7  --->  Accuracy = 31.73%\n",
      "M_pca =  350 , M_lda =  8  --->  Accuracy = 33.65%\n",
      "M_pca =  350 , M_lda =  9  --->  Accuracy = 38.46%\n",
      "M_pca =  350 , M_lda =  10  --->  Accuracy = 41.35%\n",
      "M_pca =  350 , M_lda =  11  --->  Accuracy = 42.31%\n",
      "M_pca =  350 , M_lda =  12  --->  Accuracy = 41.35%\n",
      "M_pca =  350 , M_lda =  13  --->  Accuracy = 43.27%\n",
      "M_pca =  350 , M_lda =  14  --->  Accuracy = 44.23%\n",
      "M_pca =  350 , M_lda =  15  --->  Accuracy = 44.23%\n",
      "M_pca =  350 , M_lda =  16  --->  Accuracy = 45.19%\n",
      "M_pca =  350 , M_lda =  17  --->  Accuracy = 46.15%\n",
      "M_pca =  350 , M_lda =  18  --->  Accuracy = 47.12%\n",
      "M_pca =  350 , M_lda =  19  --->  Accuracy = 48.08%\n",
      "M_pca =  350 , M_lda =  20  --->  Accuracy = 48.08%\n",
      "M_pca =  350 , M_lda =  21  --->  Accuracy = 50.00%\n",
      "M_pca =  350 , M_lda =  22  --->  Accuracy = 52.88%\n",
      "M_pca =  350 , M_lda =  23  --->  Accuracy = 53.85%\n",
      "M_pca =  350 , M_lda =  24  --->  Accuracy = 52.88%\n",
      "M_pca =  350 , M_lda =  25  --->  Accuracy = 51.92%\n",
      "M_pca =  350 , M_lda =  26  --->  Accuracy = 53.85%\n",
      "M_pca =  350 , M_lda =  27  --->  Accuracy = 53.85%\n",
      "M_pca =  350 , M_lda =  28  --->  Accuracy = 53.85%\n",
      "M_pca =  350 , M_lda =  29  --->  Accuracy = 53.85%\n",
      "M_pca =  350 , M_lda =  30  --->  Accuracy = 54.81%\n",
      "M_pca =  350 , M_lda =  31  --->  Accuracy = 54.81%\n",
      "M_pca =  350 , M_lda =  32  --->  Accuracy = 56.73%\n",
      "M_pca =  350 , M_lda =  33  --->  Accuracy = 55.77%\n",
      "M_pca =  350 , M_lda =  34  --->  Accuracy = 56.73%\n",
      "M_pca =  350 , M_lda =  35  --->  Accuracy = 56.73%\n",
      "M_pca =  350 , M_lda =  36  --->  Accuracy = 56.73%\n",
      "M_pca =  350 , M_lda =  37  --->  Accuracy = 56.73%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  350 , M_lda =  38  --->  Accuracy = 56.73%\n",
      "M_pca =  350 , M_lda =  39  --->  Accuracy = 56.73%\n",
      "M_pca =  350 , M_lda =  40  --->  Accuracy = 56.73%\n",
      "M_pca =  350 , M_lda =  41  --->  Accuracy = 56.73%\n",
      "M_pca =  350 , M_lda =  42  --->  Accuracy = 56.73%\n",
      "M_pca =  350 , M_lda =  43  --->  Accuracy = 57.69%\n",
      "M_pca =  350 , M_lda =  44  --->  Accuracy = 57.69%\n",
      "M_pca =  350 , M_lda =  45  --->  Accuracy = 57.69%\n",
      "M_pca =  350 , M_lda =  46  --->  Accuracy = 57.69%\n",
      "M_pca =  350 , M_lda =  47  --->  Accuracy = 59.62%\n",
      "M_pca =  350 , M_lda =  48  --->  Accuracy = 59.62%\n",
      "M_pca =  350 , M_lda =  49  --->  Accuracy = 59.62%\n",
      "M_pca =  350 , M_lda =  50  --->  Accuracy = 59.62%\n",
      "M_pca =  350 , M_lda =  51  --->  Accuracy = 59.62%\n",
      "M_pca =  351 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  351 , M_lda =  2  --->  Accuracy = 8.65%\n",
      "M_pca =  351 , M_lda =  3  --->  Accuracy = 13.46%\n",
      "M_pca =  351 , M_lda =  4  --->  Accuracy = 15.38%\n",
      "M_pca =  351 , M_lda =  5  --->  Accuracy = 18.27%\n",
      "M_pca =  351 , M_lda =  6  --->  Accuracy = 24.04%\n",
      "M_pca =  351 , M_lda =  7  --->  Accuracy = 30.77%\n",
      "M_pca =  351 , M_lda =  8  --->  Accuracy = 33.65%\n",
      "M_pca =  351 , M_lda =  9  --->  Accuracy = 38.46%\n",
      "M_pca =  351 , M_lda =  10  --->  Accuracy = 42.31%\n",
      "M_pca =  351 , M_lda =  11  --->  Accuracy = 41.35%\n",
      "M_pca =  351 , M_lda =  12  --->  Accuracy = 41.35%\n",
      "M_pca =  351 , M_lda =  13  --->  Accuracy = 44.23%\n",
      "M_pca =  351 , M_lda =  14  --->  Accuracy = 44.23%\n",
      "M_pca =  351 , M_lda =  15  --->  Accuracy = 45.19%\n",
      "M_pca =  351 , M_lda =  16  --->  Accuracy = 45.19%\n",
      "M_pca =  351 , M_lda =  17  --->  Accuracy = 47.12%\n",
      "M_pca =  351 , M_lda =  18  --->  Accuracy = 48.08%\n",
      "M_pca =  351 , M_lda =  19  --->  Accuracy = 49.04%\n",
      "M_pca =  351 , M_lda =  20  --->  Accuracy = 50.00%\n",
      "M_pca =  351 , M_lda =  21  --->  Accuracy = 50.96%\n",
      "M_pca =  351 , M_lda =  22  --->  Accuracy = 51.92%\n",
      "M_pca =  351 , M_lda =  23  --->  Accuracy = 52.88%\n",
      "M_pca =  351 , M_lda =  24  --->  Accuracy = 55.77%\n",
      "M_pca =  351 , M_lda =  25  --->  Accuracy = 55.77%\n",
      "M_pca =  351 , M_lda =  26  --->  Accuracy = 55.77%\n",
      "M_pca =  351 , M_lda =  27  --->  Accuracy = 55.77%\n",
      "M_pca =  351 , M_lda =  28  --->  Accuracy = 54.81%\n",
      "M_pca =  351 , M_lda =  29  --->  Accuracy = 55.77%\n",
      "M_pca =  351 , M_lda =  30  --->  Accuracy = 55.77%\n",
      "M_pca =  351 , M_lda =  31  --->  Accuracy = 55.77%\n",
      "M_pca =  351 , M_lda =  32  --->  Accuracy = 55.77%\n",
      "M_pca =  351 , M_lda =  33  --->  Accuracy = 55.77%\n",
      "M_pca =  351 , M_lda =  34  --->  Accuracy = 55.77%\n",
      "M_pca =  351 , M_lda =  35  --->  Accuracy = 55.77%\n",
      "M_pca =  351 , M_lda =  36  --->  Accuracy = 55.77%\n",
      "M_pca =  351 , M_lda =  37  --->  Accuracy = 55.77%\n",
      "M_pca =  351 , M_lda =  38  --->  Accuracy = 55.77%\n",
      "M_pca =  351 , M_lda =  39  --->  Accuracy = 55.77%\n",
      "M_pca =  351 , M_lda =  40  --->  Accuracy = 55.77%\n",
      "M_pca =  351 , M_lda =  41  --->  Accuracy = 56.73%\n",
      "M_pca =  351 , M_lda =  42  --->  Accuracy = 56.73%\n",
      "M_pca =  351 , M_lda =  43  --->  Accuracy = 56.73%\n",
      "M_pca =  351 , M_lda =  44  --->  Accuracy = 56.73%\n",
      "M_pca =  351 , M_lda =  45  --->  Accuracy = 57.69%\n",
      "M_pca =  351 , M_lda =  46  --->  Accuracy = 57.69%\n",
      "M_pca =  351 , M_lda =  47  --->  Accuracy = 57.69%\n",
      "M_pca =  351 , M_lda =  48  --->  Accuracy = 57.69%\n",
      "M_pca =  351 , M_lda =  49  --->  Accuracy = 57.69%\n",
      "M_pca =  351 , M_lda =  50  --->  Accuracy = 57.69%\n",
      "M_pca =  351 , M_lda =  51  --->  Accuracy = 57.69%\n",
      "M_pca =  352 , M_lda =  1  --->  Accuracy = 2.88%\n",
      "M_pca =  352 , M_lda =  2  --->  Accuracy = 5.77%\n",
      "M_pca =  352 , M_lda =  3  --->  Accuracy = 13.46%\n",
      "M_pca =  352 , M_lda =  4  --->  Accuracy = 13.46%\n",
      "M_pca =  352 , M_lda =  5  --->  Accuracy = 18.27%\n",
      "M_pca =  352 , M_lda =  6  --->  Accuracy = 21.15%\n",
      "M_pca =  352 , M_lda =  7  --->  Accuracy = 27.88%\n",
      "M_pca =  352 , M_lda =  8  --->  Accuracy = 28.85%\n",
      "M_pca =  352 , M_lda =  9  --->  Accuracy = 32.69%\n",
      "M_pca =  352 , M_lda =  10  --->  Accuracy = 35.58%\n",
      "M_pca =  352 , M_lda =  11  --->  Accuracy = 37.50%\n",
      "M_pca =  352 , M_lda =  12  --->  Accuracy = 43.27%\n",
      "M_pca =  352 , M_lda =  13  --->  Accuracy = 41.35%\n",
      "M_pca =  352 , M_lda =  14  --->  Accuracy = 44.23%\n",
      "M_pca =  352 , M_lda =  15  --->  Accuracy = 45.19%\n",
      "M_pca =  352 , M_lda =  16  --->  Accuracy = 43.27%\n",
      "M_pca =  352 , M_lda =  17  --->  Accuracy = 45.19%\n",
      "M_pca =  352 , M_lda =  18  --->  Accuracy = 47.12%\n",
      "M_pca =  352 , M_lda =  19  --->  Accuracy = 48.08%\n",
      "M_pca =  352 , M_lda =  20  --->  Accuracy = 48.08%\n",
      "M_pca =  352 , M_lda =  21  --->  Accuracy = 49.04%\n",
      "M_pca =  352 , M_lda =  22  --->  Accuracy = 50.00%\n",
      "M_pca =  352 , M_lda =  23  --->  Accuracy = 50.96%\n",
      "M_pca =  352 , M_lda =  24  --->  Accuracy = 51.92%\n",
      "M_pca =  352 , M_lda =  25  --->  Accuracy = 51.92%\n",
      "M_pca =  352 , M_lda =  26  --->  Accuracy = 52.88%\n",
      "M_pca =  352 , M_lda =  27  --->  Accuracy = 52.88%\n",
      "M_pca =  352 , M_lda =  28  --->  Accuracy = 52.88%\n",
      "M_pca =  352 , M_lda =  29  --->  Accuracy = 52.88%\n",
      "M_pca =  352 , M_lda =  30  --->  Accuracy = 53.85%\n",
      "M_pca =  352 , M_lda =  31  --->  Accuracy = 54.81%\n",
      "M_pca =  352 , M_lda =  32  --->  Accuracy = 54.81%\n",
      "M_pca =  352 , M_lda =  33  --->  Accuracy = 54.81%\n",
      "M_pca =  352 , M_lda =  34  --->  Accuracy = 54.81%\n",
      "M_pca =  352 , M_lda =  35  --->  Accuracy = 54.81%\n",
      "M_pca =  352 , M_lda =  36  --->  Accuracy = 53.85%\n",
      "M_pca =  352 , M_lda =  37  --->  Accuracy = 54.81%\n",
      "M_pca =  352 , M_lda =  38  --->  Accuracy = 54.81%\n",
      "M_pca =  352 , M_lda =  39  --->  Accuracy = 54.81%\n",
      "M_pca =  352 , M_lda =  40  --->  Accuracy = 54.81%\n",
      "M_pca =  352 , M_lda =  41  --->  Accuracy = 54.81%\n",
      "M_pca =  352 , M_lda =  42  --->  Accuracy = 54.81%\n",
      "M_pca =  352 , M_lda =  43  --->  Accuracy = 54.81%\n",
      "M_pca =  352 , M_lda =  44  --->  Accuracy = 54.81%\n",
      "M_pca =  352 , M_lda =  45  --->  Accuracy = 54.81%\n",
      "M_pca =  352 , M_lda =  46  --->  Accuracy = 55.77%\n",
      "M_pca =  352 , M_lda =  47  --->  Accuracy = 55.77%\n",
      "M_pca =  352 , M_lda =  48  --->  Accuracy = 55.77%\n",
      "M_pca =  352 , M_lda =  49  --->  Accuracy = 55.77%\n",
      "M_pca =  352 , M_lda =  50  --->  Accuracy = 55.77%\n",
      "M_pca =  352 , M_lda =  51  --->  Accuracy = 55.77%\n",
      "M_pca =  353 , M_lda =  1  --->  Accuracy = 2.88%\n",
      "M_pca =  353 , M_lda =  2  --->  Accuracy = 6.73%\n",
      "M_pca =  353 , M_lda =  3  --->  Accuracy = 13.46%\n",
      "M_pca =  353 , M_lda =  4  --->  Accuracy = 17.31%\n",
      "M_pca =  353 , M_lda =  5  --->  Accuracy = 21.15%\n",
      "M_pca =  353 , M_lda =  6  --->  Accuracy = 20.19%\n",
      "M_pca =  353 , M_lda =  7  --->  Accuracy = 26.92%\n",
      "M_pca =  353 , M_lda =  8  --->  Accuracy = 27.88%\n",
      "M_pca =  353 , M_lda =  9  --->  Accuracy = 29.81%\n",
      "M_pca =  353 , M_lda =  10  --->  Accuracy = 34.62%\n",
      "M_pca =  353 , M_lda =  11  --->  Accuracy = 36.54%\n",
      "M_pca =  353 , M_lda =  12  --->  Accuracy = 37.50%\n",
      "M_pca =  353 , M_lda =  13  --->  Accuracy = 36.54%\n",
      "M_pca =  353 , M_lda =  14  --->  Accuracy = 39.42%\n",
      "M_pca =  353 , M_lda =  15  --->  Accuracy = 39.42%\n",
      "M_pca =  353 , M_lda =  16  --->  Accuracy = 42.31%\n",
      "M_pca =  353 , M_lda =  17  --->  Accuracy = 43.27%\n",
      "M_pca =  353 , M_lda =  18  --->  Accuracy = 43.27%\n",
      "M_pca =  353 , M_lda =  19  --->  Accuracy = 43.27%\n",
      "M_pca =  353 , M_lda =  20  --->  Accuracy = 46.15%\n",
      "M_pca =  353 , M_lda =  21  --->  Accuracy = 46.15%\n",
      "M_pca =  353 , M_lda =  22  --->  Accuracy = 46.15%\n",
      "M_pca =  353 , M_lda =  23  --->  Accuracy = 46.15%\n",
      "M_pca =  353 , M_lda =  24  --->  Accuracy = 46.15%\n",
      "M_pca =  353 , M_lda =  25  --->  Accuracy = 47.12%\n",
      "M_pca =  353 , M_lda =  26  --->  Accuracy = 46.15%\n",
      "M_pca =  353 , M_lda =  27  --->  Accuracy = 47.12%\n",
      "M_pca =  353 , M_lda =  28  --->  Accuracy = 47.12%\n",
      "M_pca =  353 , M_lda =  29  --->  Accuracy = 49.04%\n",
      "M_pca =  353 , M_lda =  30  --->  Accuracy = 49.04%\n",
      "M_pca =  353 , M_lda =  31  --->  Accuracy = 49.04%\n",
      "M_pca =  353 , M_lda =  32  --->  Accuracy = 50.00%\n",
      "M_pca =  353 , M_lda =  33  --->  Accuracy = 51.92%\n",
      "M_pca =  353 , M_lda =  34  --->  Accuracy = 53.85%\n",
      "M_pca =  353 , M_lda =  35  --->  Accuracy = 54.81%\n",
      "M_pca =  353 , M_lda =  36  --->  Accuracy = 53.85%\n",
      "M_pca =  353 , M_lda =  37  --->  Accuracy = 53.85%\n",
      "M_pca =  353 , M_lda =  38  --->  Accuracy = 53.85%\n",
      "M_pca =  353 , M_lda =  39  --->  Accuracy = 54.81%\n",
      "M_pca =  353 , M_lda =  40  --->  Accuracy = 53.85%\n",
      "M_pca =  353 , M_lda =  41  --->  Accuracy = 54.81%\n",
      "M_pca =  353 , M_lda =  42  --->  Accuracy = 54.81%\n",
      "M_pca =  353 , M_lda =  43  --->  Accuracy = 53.85%\n",
      "M_pca =  353 , M_lda =  44  --->  Accuracy = 54.81%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  353 , M_lda =  45  --->  Accuracy = 54.81%\n",
      "M_pca =  353 , M_lda =  46  --->  Accuracy = 53.85%\n",
      "M_pca =  353 , M_lda =  47  --->  Accuracy = 55.77%\n",
      "M_pca =  353 , M_lda =  48  --->  Accuracy = 55.77%\n",
      "M_pca =  353 , M_lda =  49  --->  Accuracy = 53.85%\n",
      "M_pca =  353 , M_lda =  50  --->  Accuracy = 54.81%\n",
      "M_pca =  353 , M_lda =  51  --->  Accuracy = 54.81%\n",
      "M_pca =  354 , M_lda =  1  --->  Accuracy = 2.88%\n",
      "M_pca =  354 , M_lda =  2  --->  Accuracy = 8.65%\n",
      "M_pca =  354 , M_lda =  3  --->  Accuracy = 10.58%\n",
      "M_pca =  354 , M_lda =  4  --->  Accuracy = 13.46%\n",
      "M_pca =  354 , M_lda =  5  --->  Accuracy = 21.15%\n",
      "M_pca =  354 , M_lda =  6  --->  Accuracy = 22.12%\n",
      "M_pca =  354 , M_lda =  7  --->  Accuracy = 26.92%\n",
      "M_pca =  354 , M_lda =  8  --->  Accuracy = 28.85%\n",
      "M_pca =  354 , M_lda =  9  --->  Accuracy = 28.85%\n",
      "M_pca =  354 , M_lda =  10  --->  Accuracy = 32.69%\n",
      "M_pca =  354 , M_lda =  11  --->  Accuracy = 32.69%\n",
      "M_pca =  354 , M_lda =  12  --->  Accuracy = 38.46%\n",
      "M_pca =  354 , M_lda =  13  --->  Accuracy = 37.50%\n",
      "M_pca =  354 , M_lda =  14  --->  Accuracy = 41.35%\n",
      "M_pca =  354 , M_lda =  15  --->  Accuracy = 40.38%\n",
      "M_pca =  354 , M_lda =  16  --->  Accuracy = 41.35%\n",
      "M_pca =  354 , M_lda =  17  --->  Accuracy = 41.35%\n",
      "M_pca =  354 , M_lda =  18  --->  Accuracy = 43.27%\n",
      "M_pca =  354 , M_lda =  19  --->  Accuracy = 44.23%\n",
      "M_pca =  354 , M_lda =  20  --->  Accuracy = 46.15%\n",
      "M_pca =  354 , M_lda =  21  --->  Accuracy = 46.15%\n",
      "M_pca =  354 , M_lda =  22  --->  Accuracy = 46.15%\n",
      "M_pca =  354 , M_lda =  23  --->  Accuracy = 47.12%\n",
      "M_pca =  354 , M_lda =  24  --->  Accuracy = 47.12%\n",
      "M_pca =  354 , M_lda =  25  --->  Accuracy = 48.08%\n",
      "M_pca =  354 , M_lda =  26  --->  Accuracy = 47.12%\n",
      "M_pca =  354 , M_lda =  27  --->  Accuracy = 47.12%\n",
      "M_pca =  354 , M_lda =  28  --->  Accuracy = 47.12%\n",
      "M_pca =  354 , M_lda =  29  --->  Accuracy = 47.12%\n",
      "M_pca =  354 , M_lda =  30  --->  Accuracy = 47.12%\n",
      "M_pca =  354 , M_lda =  31  --->  Accuracy = 47.12%\n",
      "M_pca =  354 , M_lda =  32  --->  Accuracy = 47.12%\n",
      "M_pca =  354 , M_lda =  33  --->  Accuracy = 47.12%\n",
      "M_pca =  354 , M_lda =  34  --->  Accuracy = 48.08%\n",
      "M_pca =  354 , M_lda =  35  --->  Accuracy = 48.08%\n",
      "M_pca =  354 , M_lda =  36  --->  Accuracy = 48.08%\n",
      "M_pca =  354 , M_lda =  37  --->  Accuracy = 48.08%\n",
      "M_pca =  354 , M_lda =  38  --->  Accuracy = 48.08%\n",
      "M_pca =  354 , M_lda =  39  --->  Accuracy = 48.08%\n",
      "M_pca =  354 , M_lda =  40  --->  Accuracy = 48.08%\n",
      "M_pca =  354 , M_lda =  41  --->  Accuracy = 48.08%\n",
      "M_pca =  354 , M_lda =  42  --->  Accuracy = 48.08%\n",
      "M_pca =  354 , M_lda =  43  --->  Accuracy = 49.04%\n",
      "M_pca =  354 , M_lda =  44  --->  Accuracy = 49.04%\n",
      "M_pca =  354 , M_lda =  45  --->  Accuracy = 49.04%\n",
      "M_pca =  354 , M_lda =  46  --->  Accuracy = 48.08%\n",
      "M_pca =  354 , M_lda =  47  --->  Accuracy = 48.08%\n",
      "M_pca =  354 , M_lda =  48  --->  Accuracy = 49.04%\n",
      "M_pca =  354 , M_lda =  49  --->  Accuracy = 50.00%\n",
      "M_pca =  354 , M_lda =  50  --->  Accuracy = 49.04%\n",
      "M_pca =  354 , M_lda =  51  --->  Accuracy = 49.04%\n",
      "M_pca =  355 , M_lda =  1  --->  Accuracy = 2.88%\n",
      "M_pca =  355 , M_lda =  2  --->  Accuracy = 8.65%\n",
      "M_pca =  355 , M_lda =  3  --->  Accuracy = 10.58%\n",
      "M_pca =  355 , M_lda =  4  --->  Accuracy = 16.35%\n",
      "M_pca =  355 , M_lda =  5  --->  Accuracy = 20.19%\n",
      "M_pca =  355 , M_lda =  6  --->  Accuracy = 21.15%\n",
      "M_pca =  355 , M_lda =  7  --->  Accuracy = 24.04%\n",
      "M_pca =  355 , M_lda =  8  --->  Accuracy = 28.85%\n",
      "M_pca =  355 , M_lda =  9  --->  Accuracy = 28.85%\n",
      "M_pca =  355 , M_lda =  10  --->  Accuracy = 35.58%\n",
      "M_pca =  355 , M_lda =  11  --->  Accuracy = 34.62%\n",
      "M_pca =  355 , M_lda =  12  --->  Accuracy = 35.58%\n",
      "M_pca =  355 , M_lda =  13  --->  Accuracy = 37.50%\n",
      "M_pca =  355 , M_lda =  14  --->  Accuracy = 38.46%\n",
      "M_pca =  355 , M_lda =  15  --->  Accuracy = 40.38%\n",
      "M_pca =  355 , M_lda =  16  --->  Accuracy = 42.31%\n",
      "M_pca =  355 , M_lda =  17  --->  Accuracy = 43.27%\n",
      "M_pca =  355 , M_lda =  18  --->  Accuracy = 45.19%\n",
      "M_pca =  355 , M_lda =  19  --->  Accuracy = 45.19%\n",
      "M_pca =  355 , M_lda =  20  --->  Accuracy = 46.15%\n",
      "M_pca =  355 , M_lda =  21  --->  Accuracy = 47.12%\n",
      "M_pca =  355 , M_lda =  22  --->  Accuracy = 48.08%\n",
      "M_pca =  355 , M_lda =  23  --->  Accuracy = 48.08%\n",
      "M_pca =  355 , M_lda =  24  --->  Accuracy = 49.04%\n",
      "M_pca =  355 , M_lda =  25  --->  Accuracy = 48.08%\n",
      "M_pca =  355 , M_lda =  26  --->  Accuracy = 48.08%\n",
      "M_pca =  355 , M_lda =  27  --->  Accuracy = 48.08%\n",
      "M_pca =  355 , M_lda =  28  --->  Accuracy = 48.08%\n",
      "M_pca =  355 , M_lda =  29  --->  Accuracy = 48.08%\n",
      "M_pca =  355 , M_lda =  30  --->  Accuracy = 48.08%\n",
      "M_pca =  355 , M_lda =  31  --->  Accuracy = 49.04%\n",
      "M_pca =  355 , M_lda =  32  --->  Accuracy = 49.04%\n",
      "M_pca =  355 , M_lda =  33  --->  Accuracy = 49.04%\n",
      "M_pca =  355 , M_lda =  34  --->  Accuracy = 49.04%\n",
      "M_pca =  355 , M_lda =  35  --->  Accuracy = 49.04%\n",
      "M_pca =  355 , M_lda =  36  --->  Accuracy = 49.04%\n",
      "M_pca =  355 , M_lda =  37  --->  Accuracy = 49.04%\n",
      "M_pca =  355 , M_lda =  38  --->  Accuracy = 49.04%\n",
      "M_pca =  355 , M_lda =  39  --->  Accuracy = 49.04%\n",
      "M_pca =  355 , M_lda =  40  --->  Accuracy = 49.04%\n",
      "M_pca =  355 , M_lda =  41  --->  Accuracy = 49.04%\n",
      "M_pca =  355 , M_lda =  42  --->  Accuracy = 49.04%\n",
      "M_pca =  355 , M_lda =  43  --->  Accuracy = 49.04%\n",
      "M_pca =  355 , M_lda =  44  --->  Accuracy = 49.04%\n",
      "M_pca =  355 , M_lda =  45  --->  Accuracy = 50.00%\n",
      "M_pca =  355 , M_lda =  46  --->  Accuracy = 50.96%\n",
      "M_pca =  355 , M_lda =  47  --->  Accuracy = 50.96%\n",
      "M_pca =  355 , M_lda =  48  --->  Accuracy = 50.96%\n",
      "M_pca =  355 , M_lda =  49  --->  Accuracy = 50.96%\n",
      "M_pca =  355 , M_lda =  50  --->  Accuracy = 50.96%\n",
      "M_pca =  355 , M_lda =  51  --->  Accuracy = 50.96%\n",
      "M_pca =  356 , M_lda =  1  --->  Accuracy = 2.88%\n",
      "M_pca =  356 , M_lda =  2  --->  Accuracy = 6.73%\n",
      "M_pca =  356 , M_lda =  3  --->  Accuracy = 12.50%\n",
      "M_pca =  356 , M_lda =  4  --->  Accuracy = 16.35%\n",
      "M_pca =  356 , M_lda =  5  --->  Accuracy = 21.15%\n",
      "M_pca =  356 , M_lda =  6  --->  Accuracy = 25.00%\n",
      "M_pca =  356 , M_lda =  7  --->  Accuracy = 28.85%\n",
      "M_pca =  356 , M_lda =  8  --->  Accuracy = 28.85%\n",
      "M_pca =  356 , M_lda =  9  --->  Accuracy = 33.65%\n",
      "M_pca =  356 , M_lda =  10  --->  Accuracy = 33.65%\n",
      "M_pca =  356 , M_lda =  11  --->  Accuracy = 32.69%\n",
      "M_pca =  356 , M_lda =  12  --->  Accuracy = 36.54%\n",
      "M_pca =  356 , M_lda =  13  --->  Accuracy = 39.42%\n",
      "M_pca =  356 , M_lda =  14  --->  Accuracy = 39.42%\n",
      "M_pca =  356 , M_lda =  15  --->  Accuracy = 40.38%\n",
      "M_pca =  356 , M_lda =  16  --->  Accuracy = 41.35%\n",
      "M_pca =  356 , M_lda =  17  --->  Accuracy = 42.31%\n",
      "M_pca =  356 , M_lda =  18  --->  Accuracy = 42.31%\n",
      "M_pca =  356 , M_lda =  19  --->  Accuracy = 43.27%\n",
      "M_pca =  356 , M_lda =  20  --->  Accuracy = 43.27%\n",
      "M_pca =  356 , M_lda =  21  --->  Accuracy = 43.27%\n",
      "M_pca =  356 , M_lda =  22  --->  Accuracy = 43.27%\n",
      "M_pca =  356 , M_lda =  23  --->  Accuracy = 44.23%\n",
      "M_pca =  356 , M_lda =  24  --->  Accuracy = 44.23%\n",
      "M_pca =  356 , M_lda =  25  --->  Accuracy = 44.23%\n",
      "M_pca =  356 , M_lda =  26  --->  Accuracy = 46.15%\n",
      "M_pca =  356 , M_lda =  27  --->  Accuracy = 47.12%\n",
      "M_pca =  356 , M_lda =  28  --->  Accuracy = 48.08%\n",
      "M_pca =  356 , M_lda =  29  --->  Accuracy = 49.04%\n",
      "M_pca =  356 , M_lda =  30  --->  Accuracy = 47.12%\n",
      "M_pca =  356 , M_lda =  31  --->  Accuracy = 47.12%\n",
      "M_pca =  356 , M_lda =  32  --->  Accuracy = 47.12%\n",
      "M_pca =  356 , M_lda =  33  --->  Accuracy = 46.15%\n",
      "M_pca =  356 , M_lda =  34  --->  Accuracy = 46.15%\n",
      "M_pca =  356 , M_lda =  35  --->  Accuracy = 46.15%\n",
      "M_pca =  356 , M_lda =  36  --->  Accuracy = 47.12%\n",
      "M_pca =  356 , M_lda =  37  --->  Accuracy = 47.12%\n",
      "M_pca =  356 , M_lda =  38  --->  Accuracy = 49.04%\n",
      "M_pca =  356 , M_lda =  39  --->  Accuracy = 48.08%\n",
      "M_pca =  356 , M_lda =  40  --->  Accuracy = 48.08%\n",
      "M_pca =  356 , M_lda =  41  --->  Accuracy = 48.08%\n",
      "M_pca =  356 , M_lda =  42  --->  Accuracy = 48.08%\n",
      "M_pca =  356 , M_lda =  43  --->  Accuracy = 49.04%\n",
      "M_pca =  356 , M_lda =  44  --->  Accuracy = 49.04%\n",
      "M_pca =  356 , M_lda =  45  --->  Accuracy = 49.04%\n",
      "M_pca =  356 , M_lda =  46  --->  Accuracy = 49.04%\n",
      "M_pca =  356 , M_lda =  47  --->  Accuracy = 49.04%\n",
      "M_pca =  356 , M_lda =  48  --->  Accuracy = 49.04%\n",
      "M_pca =  356 , M_lda =  49  --->  Accuracy = 49.04%\n",
      "M_pca =  356 , M_lda =  50  --->  Accuracy = 49.04%\n",
      "M_pca =  356 , M_lda =  51  --->  Accuracy = 49.04%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  357 , M_lda =  1  --->  Accuracy = 2.88%\n",
      "M_pca =  357 , M_lda =  2  --->  Accuracy = 4.81%\n",
      "M_pca =  357 , M_lda =  3  --->  Accuracy = 10.58%\n",
      "M_pca =  357 , M_lda =  4  --->  Accuracy = 15.38%\n",
      "M_pca =  357 , M_lda =  5  --->  Accuracy = 23.08%\n",
      "M_pca =  357 , M_lda =  6  --->  Accuracy = 23.08%\n",
      "M_pca =  357 , M_lda =  7  --->  Accuracy = 27.88%\n",
      "M_pca =  357 , M_lda =  8  --->  Accuracy = 32.69%\n",
      "M_pca =  357 , M_lda =  9  --->  Accuracy = 35.58%\n",
      "M_pca =  357 , M_lda =  10  --->  Accuracy = 38.46%\n",
      "M_pca =  357 , M_lda =  11  --->  Accuracy = 39.42%\n",
      "M_pca =  357 , M_lda =  12  --->  Accuracy = 37.50%\n",
      "M_pca =  357 , M_lda =  13  --->  Accuracy = 41.35%\n",
      "M_pca =  357 , M_lda =  14  --->  Accuracy = 44.23%\n",
      "M_pca =  357 , M_lda =  15  --->  Accuracy = 44.23%\n",
      "M_pca =  357 , M_lda =  16  --->  Accuracy = 45.19%\n",
      "M_pca =  357 , M_lda =  17  --->  Accuracy = 45.19%\n",
      "M_pca =  357 , M_lda =  18  --->  Accuracy = 45.19%\n",
      "M_pca =  357 , M_lda =  19  --->  Accuracy = 47.12%\n",
      "M_pca =  357 , M_lda =  20  --->  Accuracy = 47.12%\n",
      "M_pca =  357 , M_lda =  21  --->  Accuracy = 47.12%\n",
      "M_pca =  357 , M_lda =  22  --->  Accuracy = 47.12%\n",
      "M_pca =  357 , M_lda =  23  --->  Accuracy = 47.12%\n",
      "M_pca =  357 , M_lda =  24  --->  Accuracy = 47.12%\n",
      "M_pca =  357 , M_lda =  25  --->  Accuracy = 47.12%\n",
      "M_pca =  357 , M_lda =  26  --->  Accuracy = 47.12%\n",
      "M_pca =  357 , M_lda =  27  --->  Accuracy = 47.12%\n",
      "M_pca =  357 , M_lda =  28  --->  Accuracy = 48.08%\n",
      "M_pca =  357 , M_lda =  29  --->  Accuracy = 47.12%\n",
      "M_pca =  357 , M_lda =  30  --->  Accuracy = 47.12%\n",
      "M_pca =  357 , M_lda =  31  --->  Accuracy = 47.12%\n",
      "M_pca =  357 , M_lda =  32  --->  Accuracy = 47.12%\n",
      "M_pca =  357 , M_lda =  33  --->  Accuracy = 47.12%\n",
      "M_pca =  357 , M_lda =  34  --->  Accuracy = 48.08%\n",
      "M_pca =  357 , M_lda =  35  --->  Accuracy = 48.08%\n",
      "M_pca =  357 , M_lda =  36  --->  Accuracy = 48.08%\n",
      "M_pca =  357 , M_lda =  37  --->  Accuracy = 48.08%\n",
      "M_pca =  357 , M_lda =  38  --->  Accuracy = 48.08%\n",
      "M_pca =  357 , M_lda =  39  --->  Accuracy = 48.08%\n",
      "M_pca =  357 , M_lda =  40  --->  Accuracy = 48.08%\n",
      "M_pca =  357 , M_lda =  41  --->  Accuracy = 48.08%\n",
      "M_pca =  357 , M_lda =  42  --->  Accuracy = 48.08%\n",
      "M_pca =  357 , M_lda =  43  --->  Accuracy = 48.08%\n",
      "M_pca =  357 , M_lda =  44  --->  Accuracy = 48.08%\n",
      "M_pca =  357 , M_lda =  45  --->  Accuracy = 48.08%\n",
      "M_pca =  357 , M_lda =  46  --->  Accuracy = 48.08%\n",
      "M_pca =  357 , M_lda =  47  --->  Accuracy = 49.04%\n",
      "M_pca =  357 , M_lda =  48  --->  Accuracy = 49.04%\n",
      "M_pca =  357 , M_lda =  49  --->  Accuracy = 49.04%\n",
      "M_pca =  357 , M_lda =  50  --->  Accuracy = 49.04%\n",
      "M_pca =  357 , M_lda =  51  --->  Accuracy = 49.04%\n",
      "M_pca =  358 , M_lda =  1  --->  Accuracy = 4.81%\n",
      "M_pca =  358 , M_lda =  2  --->  Accuracy = 5.77%\n",
      "M_pca =  358 , M_lda =  3  --->  Accuracy = 10.58%\n",
      "M_pca =  358 , M_lda =  4  --->  Accuracy = 18.27%\n",
      "M_pca =  358 , M_lda =  5  --->  Accuracy = 19.23%\n",
      "M_pca =  358 , M_lda =  6  --->  Accuracy = 23.08%\n",
      "M_pca =  358 , M_lda =  7  --->  Accuracy = 29.81%\n",
      "M_pca =  358 , M_lda =  8  --->  Accuracy = 28.85%\n",
      "M_pca =  358 , M_lda =  9  --->  Accuracy = 30.77%\n",
      "M_pca =  358 , M_lda =  10  --->  Accuracy = 31.73%\n",
      "M_pca =  358 , M_lda =  11  --->  Accuracy = 32.69%\n",
      "M_pca =  358 , M_lda =  12  --->  Accuracy = 33.65%\n",
      "M_pca =  358 , M_lda =  13  --->  Accuracy = 34.62%\n",
      "M_pca =  358 , M_lda =  14  --->  Accuracy = 37.50%\n",
      "M_pca =  358 , M_lda =  15  --->  Accuracy = 38.46%\n",
      "M_pca =  358 , M_lda =  16  --->  Accuracy = 38.46%\n",
      "M_pca =  358 , M_lda =  17  --->  Accuracy = 40.38%\n",
      "M_pca =  358 , M_lda =  18  --->  Accuracy = 40.38%\n",
      "M_pca =  358 , M_lda =  19  --->  Accuracy = 42.31%\n",
      "M_pca =  358 , M_lda =  20  --->  Accuracy = 41.35%\n",
      "M_pca =  358 , M_lda =  21  --->  Accuracy = 41.35%\n",
      "M_pca =  358 , M_lda =  22  --->  Accuracy = 41.35%\n",
      "M_pca =  358 , M_lda =  23  --->  Accuracy = 41.35%\n",
      "M_pca =  358 , M_lda =  24  --->  Accuracy = 41.35%\n",
      "M_pca =  358 , M_lda =  25  --->  Accuracy = 41.35%\n",
      "M_pca =  358 , M_lda =  26  --->  Accuracy = 41.35%\n",
      "M_pca =  358 , M_lda =  27  --->  Accuracy = 41.35%\n",
      "M_pca =  358 , M_lda =  28  --->  Accuracy = 41.35%\n",
      "M_pca =  358 , M_lda =  29  --->  Accuracy = 41.35%\n",
      "M_pca =  358 , M_lda =  30  --->  Accuracy = 41.35%\n",
      "M_pca =  358 , M_lda =  31  --->  Accuracy = 42.31%\n",
      "M_pca =  358 , M_lda =  32  --->  Accuracy = 43.27%\n",
      "M_pca =  358 , M_lda =  33  --->  Accuracy = 43.27%\n",
      "M_pca =  358 , M_lda =  34  --->  Accuracy = 43.27%\n",
      "M_pca =  358 , M_lda =  35  --->  Accuracy = 43.27%\n",
      "M_pca =  358 , M_lda =  36  --->  Accuracy = 43.27%\n",
      "M_pca =  358 , M_lda =  37  --->  Accuracy = 43.27%\n",
      "M_pca =  358 , M_lda =  38  --->  Accuracy = 43.27%\n",
      "M_pca =  358 , M_lda =  39  --->  Accuracy = 43.27%\n",
      "M_pca =  358 , M_lda =  40  --->  Accuracy = 43.27%\n",
      "M_pca =  358 , M_lda =  41  --->  Accuracy = 43.27%\n",
      "M_pca =  358 , M_lda =  42  --->  Accuracy = 43.27%\n",
      "M_pca =  358 , M_lda =  43  --->  Accuracy = 43.27%\n",
      "M_pca =  358 , M_lda =  44  --->  Accuracy = 43.27%\n",
      "M_pca =  358 , M_lda =  45  --->  Accuracy = 43.27%\n",
      "M_pca =  358 , M_lda =  46  --->  Accuracy = 43.27%\n",
      "M_pca =  358 , M_lda =  47  --->  Accuracy = 43.27%\n",
      "M_pca =  358 , M_lda =  48  --->  Accuracy = 43.27%\n",
      "M_pca =  358 , M_lda =  49  --->  Accuracy = 43.27%\n",
      "M_pca =  358 , M_lda =  50  --->  Accuracy = 43.27%\n",
      "M_pca =  358 , M_lda =  51  --->  Accuracy = 44.23%\n",
      "M_pca =  359 , M_lda =  1  --->  Accuracy = 1.92%\n",
      "M_pca =  359 , M_lda =  2  --->  Accuracy = 4.81%\n",
      "M_pca =  359 , M_lda =  3  --->  Accuracy = 6.73%\n",
      "M_pca =  359 , M_lda =  4  --->  Accuracy = 9.62%\n",
      "M_pca =  359 , M_lda =  5  --->  Accuracy = 15.38%\n",
      "M_pca =  359 , M_lda =  6  --->  Accuracy = 18.27%\n",
      "M_pca =  359 , M_lda =  7  --->  Accuracy = 22.12%\n",
      "M_pca =  359 , M_lda =  8  --->  Accuracy = 22.12%\n",
      "M_pca =  359 , M_lda =  9  --->  Accuracy = 23.08%\n",
      "M_pca =  359 , M_lda =  10  --->  Accuracy = 25.00%\n",
      "M_pca =  359 , M_lda =  11  --->  Accuracy = 26.92%\n",
      "M_pca =  359 , M_lda =  12  --->  Accuracy = 26.92%\n",
      "M_pca =  359 , M_lda =  13  --->  Accuracy = 29.81%\n",
      "M_pca =  359 , M_lda =  14  --->  Accuracy = 29.81%\n",
      "M_pca =  359 , M_lda =  15  --->  Accuracy = 30.77%\n",
      "M_pca =  359 , M_lda =  16  --->  Accuracy = 30.77%\n",
      "M_pca =  359 , M_lda =  17  --->  Accuracy = 32.69%\n",
      "M_pca =  359 , M_lda =  18  --->  Accuracy = 33.65%\n",
      "M_pca =  359 , M_lda =  19  --->  Accuracy = 34.62%\n",
      "M_pca =  359 , M_lda =  20  --->  Accuracy = 34.62%\n",
      "M_pca =  359 , M_lda =  21  --->  Accuracy = 35.58%\n",
      "M_pca =  359 , M_lda =  22  --->  Accuracy = 36.54%\n",
      "M_pca =  359 , M_lda =  23  --->  Accuracy = 37.50%\n",
      "M_pca =  359 , M_lda =  24  --->  Accuracy = 37.50%\n",
      "M_pca =  359 , M_lda =  25  --->  Accuracy = 37.50%\n",
      "M_pca =  359 , M_lda =  26  --->  Accuracy = 37.50%\n",
      "M_pca =  359 , M_lda =  27  --->  Accuracy = 37.50%\n",
      "M_pca =  359 , M_lda =  28  --->  Accuracy = 37.50%\n",
      "M_pca =  359 , M_lda =  29  --->  Accuracy = 38.46%\n",
      "M_pca =  359 , M_lda =  30  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  31  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  32  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  33  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  34  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  35  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  36  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  37  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  38  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  39  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  40  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  41  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  42  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  43  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  44  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  45  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  46  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  47  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  48  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  49  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  50  --->  Accuracy = 39.42%\n",
      "M_pca =  359 , M_lda =  51  --->  Accuracy = 39.42%\n",
      "M_pca =  360 , M_lda =  1  --->  Accuracy = 2.88%\n",
      "M_pca =  360 , M_lda =  2  --->  Accuracy = 3.85%\n",
      "M_pca =  360 , M_lda =  3  --->  Accuracy = 7.69%\n",
      "M_pca =  360 , M_lda =  4  --->  Accuracy = 15.38%\n",
      "M_pca =  360 , M_lda =  5  --->  Accuracy = 19.23%\n",
      "M_pca =  360 , M_lda =  6  --->  Accuracy = 20.19%\n",
      "M_pca =  360 , M_lda =  7  --->  Accuracy = 22.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  360 , M_lda =  8  --->  Accuracy = 24.04%\n",
      "M_pca =  360 , M_lda =  9  --->  Accuracy = 25.96%\n",
      "M_pca =  360 , M_lda =  10  --->  Accuracy = 25.00%\n",
      "M_pca =  360 , M_lda =  11  --->  Accuracy = 28.85%\n",
      "M_pca =  360 , M_lda =  12  --->  Accuracy = 28.85%\n",
      "M_pca =  360 , M_lda =  13  --->  Accuracy = 29.81%\n",
      "M_pca =  360 , M_lda =  14  --->  Accuracy = 31.73%\n",
      "M_pca =  360 , M_lda =  15  --->  Accuracy = 31.73%\n",
      "M_pca =  360 , M_lda =  16  --->  Accuracy = 31.73%\n",
      "M_pca =  360 , M_lda =  17  --->  Accuracy = 32.69%\n",
      "M_pca =  360 , M_lda =  18  --->  Accuracy = 33.65%\n",
      "M_pca =  360 , M_lda =  19  --->  Accuracy = 33.65%\n",
      "M_pca =  360 , M_lda =  20  --->  Accuracy = 35.58%\n",
      "M_pca =  360 , M_lda =  21  --->  Accuracy = 35.58%\n",
      "M_pca =  360 , M_lda =  22  --->  Accuracy = 35.58%\n",
      "M_pca =  360 , M_lda =  23  --->  Accuracy = 36.54%\n",
      "M_pca =  360 , M_lda =  24  --->  Accuracy = 36.54%\n",
      "M_pca =  360 , M_lda =  25  --->  Accuracy = 36.54%\n",
      "M_pca =  360 , M_lda =  26  --->  Accuracy = 37.50%\n",
      "M_pca =  360 , M_lda =  27  --->  Accuracy = 37.50%\n",
      "M_pca =  360 , M_lda =  28  --->  Accuracy = 38.46%\n",
      "M_pca =  360 , M_lda =  29  --->  Accuracy = 38.46%\n",
      "M_pca =  360 , M_lda =  30  --->  Accuracy = 39.42%\n",
      "M_pca =  360 , M_lda =  31  --->  Accuracy = 39.42%\n",
      "M_pca =  360 , M_lda =  32  --->  Accuracy = 38.46%\n",
      "M_pca =  360 , M_lda =  33  --->  Accuracy = 39.42%\n",
      "M_pca =  360 , M_lda =  34  --->  Accuracy = 39.42%\n",
      "M_pca =  360 , M_lda =  35  --->  Accuracy = 40.38%\n",
      "M_pca =  360 , M_lda =  36  --->  Accuracy = 40.38%\n",
      "M_pca =  360 , M_lda =  37  --->  Accuracy = 40.38%\n",
      "M_pca =  360 , M_lda =  38  --->  Accuracy = 40.38%\n",
      "M_pca =  360 , M_lda =  39  --->  Accuracy = 40.38%\n",
      "M_pca =  360 , M_lda =  40  --->  Accuracy = 40.38%\n",
      "M_pca =  360 , M_lda =  41  --->  Accuracy = 40.38%\n",
      "M_pca =  360 , M_lda =  42  --->  Accuracy = 40.38%\n",
      "M_pca =  360 , M_lda =  43  --->  Accuracy = 40.38%\n",
      "M_pca =  360 , M_lda =  44  --->  Accuracy = 40.38%\n",
      "M_pca =  360 , M_lda =  45  --->  Accuracy = 40.38%\n",
      "M_pca =  360 , M_lda =  46  --->  Accuracy = 40.38%\n",
      "M_pca =  360 , M_lda =  47  --->  Accuracy = 40.38%\n",
      "M_pca =  360 , M_lda =  48  --->  Accuracy = 40.38%\n",
      "M_pca =  360 , M_lda =  49  --->  Accuracy = 40.38%\n",
      "M_pca =  360 , M_lda =  50  --->  Accuracy = 40.38%\n",
      "M_pca =  360 , M_lda =  51  --->  Accuracy = 40.38%\n",
      "M_pca =  361 , M_lda =  1  --->  Accuracy = 5.77%\n",
      "M_pca =  361 , M_lda =  2  --->  Accuracy = 9.62%\n",
      "M_pca =  361 , M_lda =  3  --->  Accuracy = 11.54%\n",
      "M_pca =  361 , M_lda =  4  --->  Accuracy = 14.42%\n",
      "M_pca =  361 , M_lda =  5  --->  Accuracy = 17.31%\n",
      "M_pca =  361 , M_lda =  6  --->  Accuracy = 20.19%\n",
      "M_pca =  361 , M_lda =  7  --->  Accuracy = 23.08%\n",
      "M_pca =  361 , M_lda =  8  --->  Accuracy = 26.92%\n",
      "M_pca =  361 , M_lda =  9  --->  Accuracy = 25.96%\n",
      "M_pca =  361 , M_lda =  10  --->  Accuracy = 27.88%\n",
      "M_pca =  361 , M_lda =  11  --->  Accuracy = 28.85%\n",
      "M_pca =  361 , M_lda =  12  --->  Accuracy = 30.77%\n",
      "M_pca =  361 , M_lda =  13  --->  Accuracy = 30.77%\n",
      "M_pca =  361 , M_lda =  14  --->  Accuracy = 30.77%\n",
      "M_pca =  361 , M_lda =  15  --->  Accuracy = 30.77%\n",
      "M_pca =  361 , M_lda =  16  --->  Accuracy = 30.77%\n",
      "M_pca =  361 , M_lda =  17  --->  Accuracy = 30.77%\n",
      "M_pca =  361 , M_lda =  18  --->  Accuracy = 32.69%\n",
      "M_pca =  361 , M_lda =  19  --->  Accuracy = 32.69%\n",
      "M_pca =  361 , M_lda =  20  --->  Accuracy = 32.69%\n",
      "M_pca =  361 , M_lda =  21  --->  Accuracy = 32.69%\n",
      "M_pca =  361 , M_lda =  22  --->  Accuracy = 33.65%\n",
      "M_pca =  361 , M_lda =  23  --->  Accuracy = 33.65%\n",
      "M_pca =  361 , M_lda =  24  --->  Accuracy = 34.62%\n",
      "M_pca =  361 , M_lda =  25  --->  Accuracy = 35.58%\n",
      "M_pca =  361 , M_lda =  26  --->  Accuracy = 34.62%\n",
      "M_pca =  361 , M_lda =  27  --->  Accuracy = 34.62%\n",
      "M_pca =  361 , M_lda =  28  --->  Accuracy = 35.58%\n",
      "M_pca =  361 , M_lda =  29  --->  Accuracy = 35.58%\n",
      "M_pca =  361 , M_lda =  30  --->  Accuracy = 35.58%\n",
      "M_pca =  361 , M_lda =  31  --->  Accuracy = 35.58%\n",
      "M_pca =  361 , M_lda =  32  --->  Accuracy = 35.58%\n",
      "M_pca =  361 , M_lda =  33  --->  Accuracy = 35.58%\n",
      "M_pca =  361 , M_lda =  34  --->  Accuracy = 36.54%\n",
      "M_pca =  361 , M_lda =  35  --->  Accuracy = 36.54%\n",
      "M_pca =  361 , M_lda =  36  --->  Accuracy = 36.54%\n",
      "M_pca =  361 , M_lda =  37  --->  Accuracy = 36.54%\n",
      "M_pca =  361 , M_lda =  38  --->  Accuracy = 36.54%\n",
      "M_pca =  361 , M_lda =  39  --->  Accuracy = 37.50%\n",
      "M_pca =  361 , M_lda =  40  --->  Accuracy = 37.50%\n",
      "M_pca =  361 , M_lda =  41  --->  Accuracy = 37.50%\n",
      "M_pca =  361 , M_lda =  42  --->  Accuracy = 37.50%\n",
      "M_pca =  361 , M_lda =  43  --->  Accuracy = 37.50%\n",
      "M_pca =  361 , M_lda =  44  --->  Accuracy = 37.50%\n",
      "M_pca =  361 , M_lda =  45  --->  Accuracy = 37.50%\n",
      "M_pca =  361 , M_lda =  46  --->  Accuracy = 37.50%\n",
      "M_pca =  361 , M_lda =  47  --->  Accuracy = 37.50%\n",
      "M_pca =  361 , M_lda =  48  --->  Accuracy = 37.50%\n",
      "M_pca =  361 , M_lda =  49  --->  Accuracy = 37.50%\n",
      "M_pca =  361 , M_lda =  50  --->  Accuracy = 37.50%\n",
      "M_pca =  361 , M_lda =  51  --->  Accuracy = 37.50%\n",
      "M_pca =  362 , M_lda =  1  --->  Accuracy = 2.88%\n",
      "M_pca =  362 , M_lda =  2  --->  Accuracy = 9.62%\n",
      "M_pca =  362 , M_lda =  3  --->  Accuracy = 11.54%\n",
      "M_pca =  362 , M_lda =  4  --->  Accuracy = 16.35%\n",
      "M_pca =  362 , M_lda =  5  --->  Accuracy = 17.31%\n",
      "M_pca =  362 , M_lda =  6  --->  Accuracy = 17.31%\n",
      "M_pca =  362 , M_lda =  7  --->  Accuracy = 20.19%\n",
      "M_pca =  362 , M_lda =  8  --->  Accuracy = 21.15%\n",
      "M_pca =  362 , M_lda =  9  --->  Accuracy = 20.19%\n",
      "M_pca =  362 , M_lda =  10  --->  Accuracy = 23.08%\n",
      "M_pca =  362 , M_lda =  11  --->  Accuracy = 23.08%\n",
      "M_pca =  362 , M_lda =  12  --->  Accuracy = 24.04%\n",
      "M_pca =  362 , M_lda =  13  --->  Accuracy = 24.04%\n",
      "M_pca =  362 , M_lda =  14  --->  Accuracy = 23.08%\n",
      "M_pca =  362 , M_lda =  15  --->  Accuracy = 23.08%\n",
      "M_pca =  362 , M_lda =  16  --->  Accuracy = 23.08%\n",
      "M_pca =  362 , M_lda =  17  --->  Accuracy = 24.04%\n",
      "M_pca =  362 , M_lda =  18  --->  Accuracy = 25.00%\n",
      "M_pca =  362 , M_lda =  19  --->  Accuracy = 25.00%\n",
      "M_pca =  362 , M_lda =  20  --->  Accuracy = 25.00%\n",
      "M_pca =  362 , M_lda =  21  --->  Accuracy = 25.00%\n",
      "M_pca =  362 , M_lda =  22  --->  Accuracy = 25.00%\n",
      "M_pca =  362 , M_lda =  23  --->  Accuracy = 25.96%\n",
      "M_pca =  362 , M_lda =  24  --->  Accuracy = 25.00%\n",
      "M_pca =  362 , M_lda =  25  --->  Accuracy = 25.00%\n",
      "M_pca =  362 , M_lda =  26  --->  Accuracy = 25.00%\n",
      "M_pca =  362 , M_lda =  27  --->  Accuracy = 25.00%\n",
      "M_pca =  362 , M_lda =  28  --->  Accuracy = 25.00%\n",
      "M_pca =  362 , M_lda =  29  --->  Accuracy = 25.00%\n",
      "M_pca =  362 , M_lda =  30  --->  Accuracy = 25.96%\n",
      "M_pca =  362 , M_lda =  31  --->  Accuracy = 25.96%\n",
      "M_pca =  362 , M_lda =  32  --->  Accuracy = 26.92%\n",
      "M_pca =  362 , M_lda =  33  --->  Accuracy = 26.92%\n",
      "M_pca =  362 , M_lda =  34  --->  Accuracy = 26.92%\n",
      "M_pca =  362 , M_lda =  35  --->  Accuracy = 26.92%\n",
      "M_pca =  362 , M_lda =  36  --->  Accuracy = 26.92%\n",
      "M_pca =  362 , M_lda =  37  --->  Accuracy = 26.92%\n",
      "M_pca =  362 , M_lda =  38  --->  Accuracy = 26.92%\n",
      "M_pca =  362 , M_lda =  39  --->  Accuracy = 26.92%\n",
      "M_pca =  362 , M_lda =  40  --->  Accuracy = 26.92%\n",
      "M_pca =  362 , M_lda =  41  --->  Accuracy = 26.92%\n",
      "M_pca =  362 , M_lda =  42  --->  Accuracy = 26.92%\n",
      "M_pca =  362 , M_lda =  43  --->  Accuracy = 26.92%\n",
      "M_pca =  362 , M_lda =  44  --->  Accuracy = 26.92%\n",
      "M_pca =  362 , M_lda =  45  --->  Accuracy = 26.92%\n",
      "M_pca =  362 , M_lda =  46  --->  Accuracy = 26.92%\n",
      "M_pca =  362 , M_lda =  47  --->  Accuracy = 26.92%\n",
      "M_pca =  362 , M_lda =  48  --->  Accuracy = 26.92%\n",
      "M_pca =  362 , M_lda =  49  --->  Accuracy = 26.92%\n",
      "M_pca =  362 , M_lda =  50  --->  Accuracy = 26.92%\n",
      "M_pca =  362 , M_lda =  51  --->  Accuracy = 27.88%\n",
      "M_pca =  363 , M_lda =  1  --->  Accuracy = 2.88%\n",
      "M_pca =  363 , M_lda =  2  --->  Accuracy = 4.81%\n",
      "M_pca =  363 , M_lda =  3  --->  Accuracy = 9.62%\n",
      "M_pca =  363 , M_lda =  4  --->  Accuracy = 12.50%\n",
      "M_pca =  363 , M_lda =  5  --->  Accuracy = 14.42%\n",
      "M_pca =  363 , M_lda =  6  --->  Accuracy = 13.46%\n",
      "M_pca =  363 , M_lda =  7  --->  Accuracy = 14.42%\n",
      "M_pca =  363 , M_lda =  8  --->  Accuracy = 15.38%\n",
      "M_pca =  363 , M_lda =  9  --->  Accuracy = 15.38%\n",
      "M_pca =  363 , M_lda =  10  --->  Accuracy = 16.35%\n",
      "M_pca =  363 , M_lda =  11  --->  Accuracy = 19.23%\n",
      "M_pca =  363 , M_lda =  12  --->  Accuracy = 19.23%\n",
      "M_pca =  363 , M_lda =  13  --->  Accuracy = 19.23%\n",
      "M_pca =  363 , M_lda =  14  --->  Accuracy = 19.23%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  363 , M_lda =  15  --->  Accuracy = 19.23%\n",
      "M_pca =  363 , M_lda =  16  --->  Accuracy = 19.23%\n",
      "M_pca =  363 , M_lda =  17  --->  Accuracy = 21.15%\n",
      "M_pca =  363 , M_lda =  18  --->  Accuracy = 21.15%\n",
      "M_pca =  363 , M_lda =  19  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  20  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  21  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  22  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  23  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  24  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  25  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  26  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  27  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  28  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  29  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  30  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  31  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  32  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  33  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  34  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  35  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  36  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  37  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  38  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  39  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  40  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  41  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  42  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  43  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  44  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  45  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  46  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  47  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  48  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  49  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  50  --->  Accuracy = 22.12%\n",
      "M_pca =  363 , M_lda =  51  --->  Accuracy = 22.12%\n",
      "M_pca =  364 , M_lda =  1  --->  Accuracy = 3.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  364 , M_lda =  2  --->  Accuracy = 7.69%\n",
      "M_pca =  364 , M_lda =  3  --->  Accuracy = 7.69%\n",
      "M_pca =  364 , M_lda =  4  --->  Accuracy = 11.54%\n",
      "M_pca =  364 , M_lda =  5  --->  Accuracy = 12.50%\n",
      "M_pca =  364 , M_lda =  6  --->  Accuracy = 12.50%\n",
      "M_pca =  364 , M_lda =  7  --->  Accuracy = 14.42%\n",
      "M_pca =  364 , M_lda =  8  --->  Accuracy = 18.27%\n",
      "M_pca =  364 , M_lda =  9  --->  Accuracy = 21.15%\n",
      "M_pca =  364 , M_lda =  10  --->  Accuracy = 22.12%\n",
      "M_pca =  364 , M_lda =  11  --->  Accuracy = 23.08%\n",
      "M_pca =  364 , M_lda =  12  --->  Accuracy = 23.08%\n",
      "M_pca =  364 , M_lda =  13  --->  Accuracy = 24.04%\n",
      "M_pca =  364 , M_lda =  14  --->  Accuracy = 24.04%\n",
      "M_pca =  364 , M_lda =  15  --->  Accuracy = 24.04%\n",
      "M_pca =  364 , M_lda =  16  --->  Accuracy = 24.04%\n",
      "M_pca =  364 , M_lda =  17  --->  Accuracy = 24.04%\n",
      "M_pca =  364 , M_lda =  18  --->  Accuracy = 25.00%\n",
      "M_pca =  364 , M_lda =  19  --->  Accuracy = 25.96%\n",
      "M_pca =  364 , M_lda =  20  --->  Accuracy = 25.96%\n",
      "M_pca =  364 , M_lda =  21  --->  Accuracy = 25.96%\n",
      "M_pca =  364 , M_lda =  22  --->  Accuracy = 25.96%\n",
      "M_pca =  364 , M_lda =  23  --->  Accuracy = 25.96%\n",
      "M_pca =  364 , M_lda =  24  --->  Accuracy = 25.96%\n",
      "M_pca =  364 , M_lda =  25  --->  Accuracy = 25.96%\n",
      "M_pca =  364 , M_lda =  26  --->  Accuracy = 25.96%\n",
      "M_pca =  364 , M_lda =  27  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  28  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  29  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  30  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  31  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  32  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  33  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  34  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  35  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  36  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  37  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  38  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  39  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  40  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  41  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  42  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  43  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  44  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  45  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  46  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  47  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  48  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  49  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  50  --->  Accuracy = 26.92%\n",
      "M_pca =  364 , M_lda =  51  --->  Accuracy = 26.92%\n",
      "Accuracy is maximum for M__pca =  147 , M_lda =  46  with accuracy of 94.23% .\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# KNN Classifer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "_card = 52\n",
    "D, N = X_train.shape\n",
    "\n",
    "M_pca = 1\n",
    "M_lda = 1\n",
    "\n",
    "M_pca_range = N-_card\n",
    "M_lda_range = _card-1\n",
    "\n",
    "\n",
    "acc_array = np.empty((M_pca_range, M_lda_range))\n",
    "M_pca_array = np.arange(1, M_pca_range+1)\n",
    "M_lda_array = np.arange(1, M_lda_range+1)\n",
    "\n",
    "\n",
    "standard = False\n",
    "\n",
    "M__pca_ideal = None\n",
    "M__lda_ideal = None\n",
    "acc_max = 0\n",
    "\n",
    "while M_pca <= M_pca_range:\n",
    "    M_lda = 1\n",
    "    while M_lda <= M_lda_range:\n",
    "\n",
    "        pca = PCA(n_comps=M_pca, standard=standard)\n",
    "        W_train = pca.fit(X_train)\n",
    "        \n",
    "\n",
    "        lda = LinearDiscriminantAnalysis(n_components=M_lda)\n",
    "        W_train_2 = lda.fit_transform(W_train.T, y_train.T.ravel())\n",
    "\n",
    "        nn = KNeighborsClassifier(n_neighbors=1)\n",
    "        nn.fit(W_train_2, y_train.T.ravel())\n",
    "\n",
    "        W_test = pca.transform(X_test)\n",
    "\n",
    "        W_test_2 = lda.transform(W_test.T)\n",
    "\n",
    "        acc = nn.score(W_test_2, y_test.T.ravel())\n",
    "        \n",
    "        acc_array[M_pca-1, M_lda-1] = acc\n",
    "\n",
    "        print('M_pca = ', M_pca, ', M_lda = ', M_lda,' --->  Accuracy = %.2f%%' % (acc * 100))\n",
    "        \n",
    "        if (acc > acc_max):\n",
    "            M__pca_ideal = M_pca\n",
    "            M__lda_ideal = M_lda\n",
    "            acc_max = acc\n",
    "\n",
    "        M_lda = M_lda + 1\n",
    "        \n",
    "    M_pca = M_pca + 1\n",
    "    \n",
    "print (\"Accuracy is maximum for M__pca = \", M__pca_ideal, \", M_lda = \", M__lda_ideal, \" with accuracy of %.2f%%\"% (acc_max * 100), \".\")\n",
    "\n",
    "#Ideal: M_pca =  147 , M_lda =  46  --->  Accuracy = 94.23%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364, 51)\n",
      "(364, 51)\n",
      "(364, 51)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0d9ae8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "x = np.linspace(1, M_lda_range, M_lda_range)\n",
    "y = np.linspace(1, M_pca_range, M_pca_range)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "print(acc_array.shape)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(X, Y, acc_array, rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "ax.set_title('Accuracy varying M_pca & M_lda');\n",
    "ax.set_xlabel('M_lda')\n",
    "ax.set_ylabel('M_pca')\n",
    "ax.set_zlabel('Accuracy');\n",
    "\n",
    "ax.view_init(30, 220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=90, size=6)\n",
    "        plt.yticks(tick_marks, target_names, size=6)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     size=3,\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     size=3,\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_pca =  147 , M_lda =  46  --->  Accuracy = 94.23%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2173bf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2173bc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "_card = 52\n",
    "D, N = X_train.shape\n",
    "\n",
    "M_pca = 147\n",
    "M_lda = 46\n",
    "\n",
    "standard = False\n",
    "\n",
    "pca = PCA(n_comps=M_pca, standard=standard)\n",
    "W_train = pca.fit(X_train)\n",
    "        \n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=M_lda)\n",
    "W_train_2 = lda.fit_transform(W_train.T, y_train.T.ravel())\n",
    "\n",
    "nn = KNeighborsClassifier(n_neighbors=1)\n",
    "nn.fit(W_train_2, y_train.T.ravel())\n",
    "\n",
    "W_test = pca.transform(X_test)\n",
    "\n",
    "W_test_2 = lda.transform(W_test.T)\n",
    "\n",
    "acc = nn.score(W_test_2, y_test.T.ravel())\n",
    "\n",
    "print('M_pca = ', M_pca, ', M_lda = ', M_lda,' --->  Accuracy = %.2f%%' % (acc * 100))\n",
    "\n",
    "y_hat = nn.predict(W_test_2)\n",
    "\n",
    "cfn_matrix = confusion_matrix(y_test.T, y_hat)\n",
    "\n",
    "class_names = np.arange(1,53)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plot_confusion_matrix(cm           = cfn_matrix, \n",
    "                      normalize    = False,\n",
    "                      target_names = class_names,\n",
    "                      title        = \"Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a183786d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prettify plots\n",
    "plt.rcParams['figure.figsize'] = [12.0, 9.0]\n",
    "sns.set_palette(sns.color_palette(\"muted\"))\n",
    "_palette = sns.color_palette(\"muted\")\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "\n",
    "done = {'success': False, 'failure': False}\n",
    "first_failure = True\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2)\n",
    "\n",
    "for y, t, w, x in zip(y_hat, y_test.T.ravel(), W_test.T, X_test.T):\n",
    "    if y == t and done['success'] is False:\n",
    "        x_hat = pca.reconstruct(w)\n",
    "        axes[0].imshow(x.reshape(46,56).T,\n",
    "                       cmap=plt.get_cmap('gray'))\n",
    "        axes[0].set_title(\n",
    "            'Successful NN Classification\\nPredicted Class: %d, True Class: %d' % (y, t), color=_palette[1])\n",
    "        done['success'] = True\n",
    "    elif y != t and done['failure'] is False and first_failure is True:\n",
    "        first_failure = False\n",
    "    elif y != t and done['failure'] is False and first_failure is False:\n",
    "        x_hat = pca.reconstruct(w)\n",
    "        axes[1].imshow(x.reshape(46,56).T,\n",
    "                       cmap=plt.get_cmap('gray'))\n",
    "        axes[1].set_title(\n",
    "            'Failed NN Classification\\nPredicted Class: %d, True Class: %d' % (y, t), color=_palette[2])\n",
    "        done['failure'] = True\n",
    "    #elif done['failure'] is True and done['success'] is True:\n",
    "     #break\n",
    "\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA-PCA using scikit learn PCA function\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# KNN Classifer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "_card = 52\n",
    "D, N = X_train.shape\n",
    "        \n",
    "    \n",
    "M_pca = 1\n",
    "M_lda = 1\n",
    "\n",
    "\n",
    "standard = False\n",
    "\n",
    "M__pca_ideal = None\n",
    "M__lda_ideal = None\n",
    "acc_max = 0\n",
    "\n",
    "while M_pca <= (N-_card):\n",
    "    M_lda = 1\n",
    "    while M_lda <= (_card-1):\n",
    "\n",
    "        pca = PCA(n_components=M_pca)\n",
    "        W_train = pca.fit_transform(X_train.T)\n",
    "\n",
    "        lda = LinearDiscriminantAnalysis(n_components=M_lda)\n",
    "        W_train_2 = lda.fit_transform(W_train, y_train.T.ravel())\n",
    "\n",
    "        nn = KNeighborsClassifier(n_neighbors=1)\n",
    "        nn.fit(W_train_2, y_train.T.ravel())\n",
    "\n",
    "        W_test = pca.transform(X_test.T)\n",
    "\n",
    "        W_test_2 = lda.transform(W_test)\n",
    "\n",
    "        acc = nn.score(W_test_2, y_test.T.ravel())\n",
    "\n",
    "        print('M_pca = ', M_pca, ', M_lda = ', M_lda,' --->  Accuracy = %.2f%%' % (acc * 100))\n",
    "        \n",
    "        if (acc > acc_max):\n",
    "            M__pca_ideal = M_pca\n",
    "            M__lda_ideal = M_lda\n",
    "            acc_max = acc\n",
    "\n",
    "        M_lda = M_lda + 1\n",
    "        \n",
    "    M_pca = M_pca + 1\n",
    "    \n",
    "print (\"Accuracy is maximum for M__pca = \", M__pca_ideal, \", M_lda = \", M__lda_ideal, \" with accuracy of %.2f%%\"% (acc_max * 100), \".\")\n",
    "\n",
    "#Accuracy is maximum for M__pca =  150 , M_lda =  47  with accuracy of 94.23% ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Draft cell, do not use\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "D, N = X_train.shape\n",
    "\n",
    "standard = False\n",
    "#M__pca_ideal = 147\n",
    "#M__lda_ideal = 46\n",
    "\n",
    "print ('M__pca_ideal = ', M__pca_ideal)\n",
    "print ('M__lda_ideal = ', M__lda_ideal)\n",
    "\n",
    "M_pca_bag = N-1\n",
    "\n",
    "M_pca = 150 #M__pca_ideal\n",
    "M_lda = 47 #M__lda_ideal\n",
    "\n",
    "n_est = 10\n",
    "\n",
    "estimators = [('pca', PCA(n_components=M_pca)), ('lda', LinearDiscriminantAnalysis(n_components=M_lda)), ('knn', KNeighborsClassifier(n_neighbors=1))]\n",
    "\n",
    "base_est = Pipeline (estimators)\n",
    "\n",
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "\n",
    "base_est.fit(X_train.T, y_train.T.ravel())\n",
    "\n",
    "acc = base_est.score(X_test.T, y_test.T.ravel())\n",
    "print ('Accuracy of base estimator with no pre PCA = %.2f%%' % (acc * 100))\n",
    "\n",
    "\n",
    "pca = PCA(n_components=M_pca_bag)\n",
    "W_train = pca.fit_transform(X_train.T)\n",
    "W_test = pca.transform(X_test.T)\n",
    "\n",
    "base_est.fit(W_train, y_train.T.ravel())\n",
    "\n",
    "acc = base_est.score(W_test, y_test.T.ravel())\n",
    "print ('Accuracy of base estimator with pre PCA applied = %.2f%%' % (acc * 100))\n",
    "\n",
    "bagging = BaggingClassifier(base_estimator=base_est,\n",
    "                            max_samples=1.0,\n",
    "                            max_features=1.0,\n",
    "                            bootstrap=True,\n",
    "                            #bootstrap_features=True,\n",
    "                            n_estimators=n_est)\n",
    "\n",
    "print (W_train.shape)\n",
    "\n",
    "bagging = bagging.fit(W_train, y_train.T.ravel())\n",
    "\n",
    "acc = bagging.score(W_test, y_test.T.ravel())\n",
    "print ('Accuracy of ensemble estimator = %.2f%%' % (acc * 100))\n",
    "\n",
    "\n",
    "\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "results = model_selection.cross_val_score(bagging, W_train, y_train.T.ravel(), cv=kfold)\n",
    "print('Cross validation mean accuracy = %.2f%%' % (results.mean() * 100))\n",
    "\n",
    "sub_model_accuracies = []\n",
    "\n",
    "sub_estimators = []\n",
    "\n",
    "for i, estimator in enumerate(bagging.estimators_):\n",
    "    print(estimator)\n",
    "    sub_model_acc = estimator.score(W_test, y_test.T.ravel())\n",
    "    print ('Accuracy of sub model ', i+1, ' = %.2f%%' % (sub_model_acc * 100))\n",
    "    sub_model_accuracies.append(sub_model_acc)\n",
    "    name = 'est'+str(i+1)\n",
    "    sub_estimators.append((name, estimator))\n",
    "    \n",
    "ave_sub_model_acc = sum(sub_model_accuracies)/n_est\n",
    "\n",
    "print ('Average accuracy of sub models = %.2f%%' % (ave_sub_model_acc * 100))\n",
    "\n",
    "\n",
    "voting = VotingClassifier(estimators=sub_estimators, voting='soft')\n",
    "voting = voting.fit(W_train, y_train.T.ravel())\n",
    "acc = voting.score(W_test, y_test.T.ravel())\n",
    "print ('Accuracy of voting = %.2f%%' % (acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Bagging\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "def bagging(n_estimators, max_samples, verbose = False):\n",
    "\n",
    "    D, N = X_train.shape\n",
    "\n",
    "    standard = False\n",
    "    #M__pca_ideal = 147\n",
    "    #M__lda_ideal = 46\n",
    "\n",
    "    if verbose:\n",
    "        print ('M__pca_ideal = ', M__pca_ideal)\n",
    "        print ('M__lda_ideal = ', M__lda_ideal)\n",
    "\n",
    "    M_pca_bag = N-1\n",
    "\n",
    "    M_pca = 150 #M__pca_ideal\n",
    "    M_lda = 47 #M__lda_ideal\n",
    "\n",
    "    estimators = [('pca', PCA(n_components=M_pca)), ('lda', LinearDiscriminantAnalysis(n_components=M_lda)), ('knn', KNeighborsClassifier(n_neighbors=1))]\n",
    "\n",
    "    base_est = Pipeline (estimators)\n",
    "\n",
    "    base_est.fit(X_train.T, y_train.T.ravel())\n",
    "\n",
    "    acc = base_est.score(X_test.T, y_test.T.ravel())\n",
    "    if verbose:\n",
    "        print ('Accuracy of base estimator with no pre PCA = %.2f%%' % (acc * 100))\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=M_pca_bag)\n",
    "    W_train = pca.fit_transform(X_train.T)\n",
    "    W_test = pca.transform(X_test.T)\n",
    "\n",
    "    base_est.fit(W_train, y_train.T.ravel())\n",
    "\n",
    "    acc = base_est.score(W_test, y_test.T.ravel())\n",
    "    if verbose:\n",
    "        print ('Accuracy of base estimator with pre PCA applied = %.2f%%' % (acc * 100))\n",
    "\n",
    "    estimators = []\n",
    "    sub_model_accuracies = []\n",
    "\n",
    "    for i in range (n_estimators):\n",
    "\n",
    "        mask = np.random.choice(np.arange(N), int(max_samples * N), replace=False)\n",
    "\n",
    "        mask = np.array(mask).ravel()\n",
    "\n",
    "        W_bag = W_train[mask, :]\n",
    "        y_bag = y_train[:, mask]\n",
    "    \n",
    "        estimator = clone(base_est)\n",
    "\n",
    "        estimator.fit(W_bag, y_bag.T.ravel())\n",
    "    \n",
    "        name = 'est_'+str(i+1)\n",
    "        estimators.append((name, estimator))\n",
    "    \n",
    "        sub_model_acc = estimator.score(W_test, y_test.T.ravel())\n",
    "        sub_model_accuracies.append(sub_model_acc)\n",
    "        if verbose:\n",
    "            print ('Accuracy of sub model ', i+1, ' = %.2f%%' % (sub_model_acc * 100))\n",
    "    \n",
    "\n",
    "    ave_sub_model_acc = sum(sub_model_accuracies)/n_estimators\n",
    "    if verbose:\n",
    "        print ('Average accuracy of sub models = %.2f%%' % (ave_sub_model_acc * 100))\n",
    "    \n",
    "    y_hat = []\n",
    "\n",
    "    for w in W_test:\n",
    "        prediction_sum = 0\n",
    "        predictions = np.empty(n_estimators, dtype = np.int64)\n",
    "        for i, (name, estimator) in enumerate(estimators):\n",
    "            y = estimator.predict(w.reshape(1, -1))\n",
    "        \n",
    "            prediction_sum = prediction_sum + float(y[0])\n",
    "            predictions[i] = int(y[0])\n",
    "        prediction = round(prediction_sum/n_estimators)\n",
    "        \n",
    "        counts = np.bincount(predictions)\n",
    "        #y_hat.append(prediction)\n",
    "        y_hat.append(np.argmax(counts))\n",
    "    \n",
    "    acc = accuracy_score(y_test.T, y_hat)\n",
    "    if verbose:\n",
    "        print ('Accuracy of ensemble estimator = %.2f%%' % (acc * 100))\n",
    "    \n",
    "    return acc, ave_sub_model_acc\n",
    "    \n",
    "        \n",
    "\n",
    "n_estimators = 50\n",
    "max_samples = 0.8\n",
    "\n",
    "acc, ave_sub_model_acc = bagging(n_estimators, max_samples)\n",
    "\n",
    "n_estimators = 30\n",
    "max_samples = 0.5\n",
    "\n",
    "acc_varying_samples = []\n",
    "acc_varying_samples_ave = []\n",
    "num_samples = []\n",
    "\n",
    "while max_samples <= 1.0:\n",
    "    acc, ave_sub_model_acc = bagging(n_estimators, max_samples)\n",
    "    acc_varying_samples.append(acc*100)\n",
    "    acc_varying_samples_ave.append(ave_sub_model_acc*100)\n",
    "    num_samples.append(max_samples)\n",
    "    max_samples = max_samples + 0.025\n",
    "\n",
    "n_estimators = 1\n",
    "max_samples = 0.8\n",
    "\n",
    "acc_varying_num_est_bag = []\n",
    "num_estimators_list = []\n",
    "n_est_test_range = 60\n",
    "\n",
    "while n_estimators <= n_est_test_range:\n",
    "    acc, ave_sub_model_acc = bagging(n_estimators, max_samples)\n",
    "    acc_varying_num_est_bag.append(acc*100)\n",
    "    num_estimators_list.append(n_estimators)\n",
    "    n_estimators = n_estimators + 1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a14e01fd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1d69c208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(8.0, 6.0))\n",
    "plt.plot(num_samples, acc_varying_samples, color='green', linestyle='dashed', label='Ensemble model accuracy')\n",
    "plt.plot(num_samples, acc_varying_samples_ave, color='blue', linestyle='dashed', label='Average error individual models')\n",
    "plt.title('Accuracy vs Ratio of Samples Drawn for n_estimators=30\\n')\n",
    "plt.xlabel('Ratio of samples drawn to N')\n",
    "plt.ylabel('Recogniton Accuracy / %')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of base estimator with no pre PCA = 92.31%\n",
      "Accuracy of base estimator with pre PCA applied = 91.35%\n",
      "Accuracy of sub model  1  = 83.65%\n",
      "Accuracy of sub model  2  = 84.62%\n",
      "Accuracy of sub model  3  = 77.88%\n",
      "Accuracy of sub model  4  = 77.88%\n",
      "Accuracy of sub model  5  = 83.65%\n",
      "Accuracy of sub model  6  = 81.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sub model  7  = 81.73%\n",
      "Accuracy of sub model  8  = 81.73%\n",
      "Accuracy of sub model  9  = 81.73%\n",
      "Accuracy of sub model  10  = 81.73%\n",
      "Accuracy of sub model  11  = 82.69%\n",
      "Accuracy of sub model  12  = 77.88%\n",
      "Accuracy of sub model  13  = 81.73%\n",
      "Accuracy of sub model  14  = 77.88%\n",
      "Accuracy of sub model  15  = 82.69%\n",
      "Accuracy of sub model  16  = 87.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sub model  17  = 82.69%\n",
      "Accuracy of sub model  18  = 81.73%\n",
      "Accuracy of sub model  19  = 78.85%\n",
      "Accuracy of sub model  20  = 75.96%\n",
      "Accuracy of sub model  21  = 81.73%\n",
      "Accuracy of sub model  22  = 86.54%\n",
      "Accuracy of sub model  23  = 82.69%\n",
      "Accuracy of sub model  24  = 84.62%\n",
      "Accuracy of sub model  25  = 81.73%\n",
      "Accuracy of sub model  26  = 79.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sub model  27  = 85.58%\n",
      "Accuracy of sub model  28  = 83.65%\n",
      "Accuracy of sub model  29  = 84.62%\n",
      "Accuracy of sub model  30  = 82.69%\n",
      "Average accuracy of sub models = 81.99%\n",
      "Accuracy of ensemble estimator = 91.35%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1f7fe3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1f7fe908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "D, N = X_train.shape\n",
    "\n",
    "\n",
    "n_estimators = 30\n",
    "max_samples = 0.8\n",
    "\n",
    "verbose = True\n",
    "\n",
    "standard = False\n",
    "#M__pca_ideal = 147\n",
    "#M__lda_ideal = 46\n",
    "\n",
    "M_pca_bag = N-1\n",
    "\n",
    "M_pca = 150 #M__pca_ideal\n",
    "M_lda = 47 #M__lda_ideal\n",
    "\n",
    "estimators = [('pca', PCA(n_components=M_pca)), ('lda', LinearDiscriminantAnalysis(n_components=M_lda)), ('knn', KNeighborsClassifier(n_neighbors=1))]\n",
    "\n",
    "base_est = Pipeline (estimators)\n",
    "\n",
    "base_est.fit(X_train.T, y_train.T.ravel())\n",
    "\n",
    "acc = base_est.score(X_test.T, y_test.T.ravel())\n",
    "if verbose:\n",
    "    print ('Accuracy of base estimator with no pre PCA = %.2f%%' % (acc * 100))\n",
    "\n",
    "\n",
    "pca = PCA(n_components=M_pca_bag)\n",
    "W_train = pca.fit_transform(X_train.T)\n",
    "W_test = pca.transform(X_test.T)\n",
    "\n",
    "base_est.fit(W_train, y_train.T.ravel())\n",
    "\n",
    "acc = base_est.score(W_test, y_test.T.ravel())\n",
    "if verbose:\n",
    "    print ('Accuracy of base estimator with pre PCA applied = %.2f%%' % (acc * 100))\n",
    "\n",
    "estimators = []\n",
    "sub_model_accuracies = []\n",
    "\n",
    "for i in range (n_estimators):\n",
    "\n",
    "    mask = np.random.choice(np.arange(N), int(max_samples * N), replace=False)\n",
    "\n",
    "    mask = np.array(mask).ravel()\n",
    "\n",
    "    W_bag = W_train[mask, :]\n",
    "    y_bag = y_train[:, mask]\n",
    "    \n",
    "    estimator = clone(base_est)\n",
    "\n",
    "    estimator.fit(W_bag, y_bag.T.ravel())\n",
    "    \n",
    "    name = 'est_'+str(i+1)\n",
    "    estimators.append((name, estimator))\n",
    "    \n",
    "    sub_model_acc = estimator.score(W_test, y_test.T.ravel())\n",
    "    sub_model_accuracies.append(sub_model_acc)\n",
    "    if verbose:\n",
    "        print ('Accuracy of sub model ', i+1, ' = %.2f%%' % (sub_model_acc * 100))\n",
    "    \n",
    "\n",
    "ave_sub_model_acc = sum(sub_model_accuracies)/n_estimators\n",
    "if verbose:\n",
    "    print ('Average accuracy of sub models = %.2f%%' % (ave_sub_model_acc * 100))\n",
    "    \n",
    "y_hat = []\n",
    "\n",
    "for w in W_test:\n",
    "    prediction_sum = 0\n",
    "    predictions = np.empty(n_estimators, dtype = np.int64)\n",
    "    for i, (name, estimator) in enumerate(estimators):\n",
    "        y = estimator.predict(w.reshape(1, -1))\n",
    "        \n",
    "        prediction_sum = prediction_sum + float(y[0])\n",
    "        predictions[i] = int(y[0])\n",
    "    prediction = round(prediction_sum/n_estimators)\n",
    "        \n",
    "    counts = np.bincount(predictions)\n",
    "    #y_hat.append(prediction)\n",
    "    y_hat.append(np.argmax(counts))\n",
    "    \n",
    "acc = accuracy_score(y_test.T, y_hat)\n",
    "if verbose:\n",
    "    print ('Accuracy of ensemble estimator = %.2f%%' % (acc * 100))\n",
    "    \n",
    "    \n",
    "cfn_matrix = confusion_matrix(y_test.T, y_hat)\n",
    "\n",
    "class_names = np.arange(1,53)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plot_confusion_matrix(cm           = cfn_matrix, \n",
    "                      normalize    = False,\n",
    "                      target_names = class_names,\n",
    "                      title        = \"Confusion Matrix\")\n",
    "\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of base estimator with no pre PCA = 91.35%\n",
      "Accuracy of base estimator with pre PCA applied = 23.08%\n",
      "Accuracy of sub model  1  = 92.31%\n",
      "Accuracy of sub model  2  = 89.42%\n",
      "Accuracy of sub model  3  = 90.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sub model  4  = 87.50%\n",
      "Accuracy of sub model  5  = 86.54%\n",
      "Accuracy of sub model  6  = 89.42%\n",
      "Accuracy of sub model  7  = 90.38%\n",
      "Accuracy of sub model  8  = 89.42%\n",
      "Accuracy of sub model  9  = 88.46%\n",
      "Accuracy of sub model  10  = 89.42%\n",
      "Accuracy of sub model  11  = 88.46%\n",
      "Accuracy of sub model  12  = 89.42%\n",
      "Accuracy of sub model  13  = 87.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sub model  14  = 87.50%\n",
      "Accuracy of sub model  15  = 91.35%\n",
      "Accuracy of sub model  16  = 91.35%\n",
      "Accuracy of sub model  17  = 83.65%\n",
      "Accuracy of sub model  18  = 89.42%\n",
      "Accuracy of sub model  19  = 87.50%\n",
      "Accuracy of sub model  20  = 91.35%\n",
      "Accuracy of sub model  21  = 89.42%\n",
      "Accuracy of sub model  22  = 89.42%\n",
      "Accuracy of sub model  23  = 88.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sub model  24  = 85.58%\n",
      "Accuracy of sub model  25  = 85.58%\n",
      "Accuracy of sub model  26  = 90.38%\n",
      "Accuracy of sub model  27  = 86.54%\n",
      "Accuracy of sub model  28  = 92.31%\n",
      "Accuracy of sub model  29  = 90.38%\n",
      "Accuracy of sub model  30  = 92.31%\n",
      "Average accuracy of sub models = 89.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ensemble estimator = 93.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is maximum for M0 =  100 , M1 =  111  with accuracy of 96.15% .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Random subspace\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "def random_subspace(n_estimators, M0, M1, verbose = False):\n",
    "\n",
    "    D, N = X_train.shape\n",
    "\n",
    "    standard = False\n",
    "    #M__pca_ideal = 147\n",
    "    #M__lda_ideal = 46\n",
    "\n",
    "    #if verbose:\n",
    "    #    print ('M__pca_ideal = ', M__pca_ideal)\n",
    "    #    print ('M__lda_ideal = ', M__lda_ideal)\n",
    "\n",
    "    M_pca_bag = N-1\n",
    "\n",
    "    M_pca = 150 #M__pca_ideal\n",
    "    M_lda = 47 #M__lda_ideal\n",
    "\n",
    "    \n",
    "    assert(M1 <= (N-1-M0))\n",
    "    assert(M0+M1 > M_pca)\n",
    "    assert(M_pca > M_lda)\n",
    "\n",
    "    estimators = [('lda', LinearDiscriminantAnalysis(n_components=M_lda)), ('knn', KNeighborsClassifier(n_neighbors=1))]\n",
    "\n",
    "    base_est = Pipeline (estimators)\n",
    "\n",
    "    base_est.fit(X_train.T, y_train.T.ravel())\n",
    "\n",
    "    acc = base_est.score(X_test.T, y_test.T.ravel())\n",
    "    if verbose:\n",
    "        print ('Accuracy of base estimator with no pre PCA = %.2f%%' % (acc * 100))\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=M_pca_bag)\n",
    "    W_train = pca.fit_transform(X_train.T)\n",
    "    W_test = pca.transform(X_test.T)\n",
    "\n",
    "    base_est.fit(W_train, y_train.T.ravel())\n",
    "\n",
    "    acc = base_est.score(W_test, y_test.T.ravel())\n",
    "    if verbose:\n",
    "        print ('Accuracy of base estimator with pre PCA applied = %.2f%%' % (acc * 100))\n",
    "\n",
    "    estimators = []\n",
    "    sub_model_accuracies = []\n",
    "    masks = []\n",
    "\n",
    "    for i in range (n_estimators):\n",
    "\n",
    "        mask0 = np.arange(M0)\n",
    "        mask1 = np.random.choice(np.arange(M0, (N-1)), M1, replace=False)\n",
    "\n",
    "        mask1 = np.array(mask1).ravel()\n",
    "    \n",
    "        mask = np.concatenate((mask0, mask1), axis = None)\n",
    "        masks.append(mask)\n",
    "\n",
    "        W_bag = W_train[:, mask]\n",
    "        y_bag = y_train\n",
    "    \n",
    "        estimator = clone(base_est)\n",
    "\n",
    "        estimator.fit(W_bag, y_bag.T.ravel())\n",
    "    \n",
    "        name = 'est_'+str(i+1)\n",
    "        estimators.append((name, estimator))\n",
    "    \n",
    "        sub_model_acc = estimator.score(W_test[:, mask], y_test.T.ravel())\n",
    "        sub_model_accuracies.append(sub_model_acc)\n",
    "        if verbose:\n",
    "            print ('Accuracy of sub model ', i+1, ' = %.2f%%' % (sub_model_acc * 100))\n",
    "    \n",
    "\n",
    "    ave_sub_model_acc = sum(sub_model_accuracies)/n_estimators\n",
    "    if verbose:\n",
    "        print ('Average accuracy of sub models = %.2f%%' % (ave_sub_model_acc * 100))\n",
    "    \n",
    "    y_hat = []\n",
    "\n",
    "    for w in W_test:\n",
    "        prediction_sum = 0\n",
    "        predictions = np.empty(n_estimators, dtype = np.int64)\n",
    "        for i, (name, estimator) in enumerate(estimators):\n",
    "            y = estimator.predict(w[masks[i]].reshape(1, -1))\n",
    "        \n",
    "            prediction_sum = prediction_sum + float(y[0])\n",
    "            predictions[i] = int(y[0])\n",
    "        prediction = round(prediction_sum/n_estimators)\n",
    "    \n",
    "        counts = np.bincount(predictions)\n",
    "        #y_hat.append(prediction)\n",
    "        y_hat.append(np.argmax(counts))\n",
    "        \n",
    "    acc = accuracy_score(y_test.T, y_hat)\n",
    "    if verbose:\n",
    "        print ('Accuracy of ensemble estimator = %.2f%%' % (acc * 100))\n",
    "        \n",
    "    return acc, ave_sub_model_acc\n",
    "    \n",
    "D, N = X_train.shape      \n",
    "        \n",
    "n_estimators = 30\n",
    "M0 = 120\n",
    "M1 = 60    \n",
    "\n",
    "acc, ave_sub_model_acc = random_subspace(n_estimators, M0, M1, verbose= True)\n",
    "\n",
    "n_estimators = 30\n",
    "M0 = 0\n",
    "M1 = 150-M0+1 \n",
    "\n",
    "acc_varying_subspace = []\n",
    "num_M0 = []\n",
    "num_M1 = []\n",
    "\n",
    "M0_ideal = None\n",
    "M1_ideal = None\n",
    "acc_max = 0\n",
    "\n",
    "while M0 <= N-1:\n",
    "    M1 = max((150-M0+1), 0)\n",
    "    num_M1_i = []\n",
    "    acc_varying_subspace_i = []\n",
    "    while M1 <= (N-1-M0):\n",
    "        acc, ave_sub_model_acc = random_subspace(n_estimators, M0, M1)\n",
    "        acc_varying_subspace_i.append((acc*100))\n",
    "        num_M1_i.append(M1)\n",
    "        \n",
    "        if (acc > acc_max):\n",
    "            M0_ideal = M0\n",
    "            M1_ideal = M1\n",
    "            acc_max = acc\n",
    "        \n",
    "        M1 = M1 + 20\n",
    "        \n",
    "    num_M1.append(num_M1_i)\n",
    "    acc_varying_subspace.append(acc_varying_subspace_i)\n",
    "    num_M0.append(M0)\n",
    "    M0 = M0 + 50\n",
    "\n",
    "print (\"Accuracy is maximum for M0 = \", M0_ideal, \", M1 = \", M1_ideal, \" with accuracy of %.2f%%\"% (acc_max * 100), \".\")\n",
    "\n",
    "# Accuracy is maximum for M0 =  100 , M1 =  111  with accuracy of 96.15% .\n",
    "\n",
    "n_estimators = 1\n",
    "M0 = 120\n",
    "M1 = 60\n",
    "\n",
    "acc_varying_num_est_ran_subsp = []\n",
    "\n",
    "while n_estimators <= n_est_test_range:\n",
    "    acc, ave_sub_model_acc = random_subspace(n_estimators, M0, M1)\n",
    "    acc_varying_num_est_ran_subsp.append(acc*100)\n",
    "    n_estimators = n_estimators + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 21, 41, 61, 81, 101, 121, 141, 161, 181, 201, 221, 241, 261]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a1d09b5c0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAGKCAYAAAAVPNgFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzsnXd8FMUXwL+XBoTepDdBmggICAIJHSmGjoQmiHRFmlR/oCACCtJEUaT3IlWkQygBQui9E0oChJBCSE8u935/TCrkkktIcgns9/O5z93tzs683Z3dN/PmzRudiAgaGhoaGhoamR4LcwugoaGhoaGhkTpoSl1DQ0NDQ+MNQVPqGhoaGhoabwiaUtfQ0NDQ0HhD0JS6hoaGhobGG4Km1DU0NDQ0NN4QNKWuoaGhoaHxhqApdQ0NDQ0NjTcETalraGhoZED27dvHokWLzC2GhhnZuXMnjRs3xs7Ojl27dpl0TIZT6hUqVKBNmza0a9eO9u3b06JFCzp16sTly5fNLRoAly9fZujQoTH/v/zyS3x9fVO1jIiICOzs7OjXr1+q5msuZs6cybFjxwAYP348zZs3Z/DgwURERADg7++Po6Mj4eHhMccEBgbSr18/QkNDU10eDw8PKlSowD///BNv+5IlSxg3blyqlwfwww8/0KRJE+bMmfPKvvSo83v27OHzzz9Ptfzi4uHhQaVKlWjXrh3t2rWjTZs2dO3aNeYl9PIzk96kd/lx63tcjh8/HlPnE2Lfvn0xv8ePH8+8efO4e/duzLaknonE6tjbSGLXI3rfgAEDUq1umPqMmVoP7t27x4wZM1izZg0rV65k2rRpPHv2LGlBJINRvnx58fHxibdt8eLF0qVLFzNJlDgJyfu67Ny5U/r27St16tSRO3fupGre6c358+dl4MCBIiJy/fp1+fLLL0VEZOLEieLk5CQiIpMmTYr5HZetW7fKzz//nOoyubu7S8WKFaVmzZpy9+7dmO2LFy+WsWPHpnp5IiIVKlSQJ0+eJLgvPer87t27pWfPnqmWX1zc3d2levXq8bZ5eHhIs2bNZM+ePWlSZkYlbn1/mdGjR8v58+cT3Ldo0SIZMmRIzH9vb2/ZvHnzK/UxsWcisTr2NpLY9UiLa2XqM2ZqPZg7d67MmDEjZt+0adPk77//TjL/DNdTfxm9Xs+TJ0/InTs3AE5OTnz22We0b9+erl27cv78+Zi0mzZt4tNPP6VNmzb06tWLJ0+eALBhwwYcHBxo27YtX375Jffu3Ys55u+//+aTTz6hQ4cOTJ06lSZNmuDq6krXrl0ZPXo07du3x8HBgbNnzwLg6uqKg4MDoFrTAL179+bJkydGy0ksv4RYt24dTZs2pXXr1qxYsSLePmPnmND2uLLGld3V1ZW2bdvStWtX2rRpQ3h4OD/99BOfffYZrVu3plWrVvHkSyjvCRMmxGsBb9++na+//vqVc5k/fz6Ojo4A2NjYEBYWRnh4OEFBQVhbW3Pjxg08PT1p3LjxK8e2atWKHTt24O3tHW/7t99+y9KlS2P+r127luHDhxMUFMTQoUNp164dHTp0YMKECRgMhgSvcdasWenTpw+jRo2KZyGIJrE6kxgJHde9e3dEhP79+3PmzJkk83i5zhsMhgTvT1L1at68eTRr1ozOnTuzf//+JOV0dXXF0dGR4cOH065dO7p27YqTkxN9+vShUaNGTJs2zaRrAFCsWDGGDh3KkiVL4tXD5JRh7Fk3dt7G7v/Lz0Fyn9Pk1Ku49f1lLl26hKur6yvbDx48yKpVqyhUqFDMtvz58yeYh7Fn4uU6ltg5vvzsR2Osnr1Mct4fSdXRhN6/kPh7Pi7GzjOxZy7uvj/++COmbmzdupVmzZoRFBREcHAwrVq1Ytu2bYnKk9gzZgxT68HNmzf54IMPYvZXr16dmzdvJl2ACQ2QdKV8+fLi4OAgDg4OUr9+fWnSpIlMmTJFvL295d69e+Lg4CC+vr4iInLr1i2pX7++BAUFyfXr16VOnTry+PFjERFZtmyZTJw4UU6cOCHNmjWL6Qlt3rxZWrVqJQaDQY4ePSotWrQQf39/MRgMMn78eGncuLGcPHlSKlWqJNeuXRMRkSVLlkiPHj1EROTkyZPy6aefxpPXx8cn0XISy+9lbt++Le+//774+vrKxYsXpWrVqjHna+wcjW1/Wdbo/ydPnpSKFSuKh4eHiIicO3dOvvnmG4mMjBQRkYULF8brXSeU97Vr16R+/foSEREhIiLdu3eXo0ePxjsXf39/qVatmoSFhcVsmz17trRq1UomTpwokZGR0rt3b7l//77R+jBw4EDZtGlTvG0uLi7i4OAQ879z585y/Phx2bp1a4wlQK/Xy//+978E847uWUZGRkqPHj1iej7RPfXE7mViJHZcYhadxOq8iPH7k1i92r9/v7Ru3VoCAgIkIiJCBgwYENOLMCani4uLVKpUSa5evSoiIn379hVHR0cJCwsTHx8fef/998XT09Po9XyZW7duSbVq1eLVw2iZkyojsWfd2Hkbu/9xy0/Jc2pqvUqovkfj6+srH3/8sXz++efxtl+5ckXWrl0rjo6Osnjx4nj7EuqpiyT8TIiY/i6K++zHJbH3QFyS8/5IrI4ae/8mdu/jktRzmtQz5+Pj88o7cuTIkfLDDz/I+PHjZcKECSIiRuVJ7BkzRnLqwRdffCHHjx+PSePs7Cx9+vRJNH8RESuTmhbpzIoVK8iXLx9Xr15lwIAB1KlTh/z587Nnzx68vLz44osvYtLqdDoePnyIi4sLdnZ2FClSBCAmzYwZM2jdujX58uUDoGPHjkydOhUPDw+OHDlCy5YtyZUrFwA9evTg5MmTABQtWpRKlSoBULlyZbZu3ZqozM7OzkbLSU5+69ato3HjxuTNm5e8efNSvHhxNm7cyMCBA42e47JlyxLcnlBrMJoiRYpQrFgxAD788ENy587N+vXrcXd3x9XVlezZswMYLROgePHiHD58mDJlyuDl5YWdnV28Mh48eEDBggWxsbGJ2TZixAhGjBgBwLZt26hWrRo5cuRgxIgRBAQE0KdPH+rXrx+vjJd7yXXq1CEsLIzLly+TLVs2fH19qVu3Lh4eHsyZM4fPP/+cevXq0bt3b0qVKmX0GlhYWDBz5kzat28fT/bE7mWJEiWM5pdUHUgMY3UeEr8/xuqVi4sLzZs3J0eOHAB06tSJVatWJSrno0ePKF68OJUrVwagZMmS5MyZExsbG/Lly0f27Nnx9/eP16NMDJ1OR9asWV/ZbkoZp0+fNvqsGzvvmjVrJnj/PT09Y/JIyXNqLN+XSai+R3P69Gn69u3L3Llz8fX1JV++fDx9+pSDBw8ydOhQFi5cSOHChU26rgk9E3FJ6hzjPvtxSayevYyp7w8wXkeNvX+PHz9u9N5XrFjRpPNM7DlNjMmTJ9OuXTuyZs3Kli1bAIzKs2LFCqPPmDGSUw9y585NUFBQzLF+fn7Y2tomeQ4Z2vz+/vvvM378eMaNG4eHhwcGg4G6deuyffv2mM/GjRt57733sLS0RKfTxRwbGhrK3bt3EzSTiQh6vR4rKyskzsqzlpaWMb/jvox0Ol28dAmRWDmm5hccHMz27ds5e/YsTZo0oUmTJjx79ozVq1cTERFh9ByNbX+5nLjOGXErx+HDhxk4cCAATZs2pVu3bvGuSUJ5g3oIN2/ezKZNm+jSpUu8dNHnacxMGRgYyJo1axg4cCArVqygYcOGzJ8//xUTr7W1dbz7Ep1v586d2b59O5s3b6Zz587odDpKlCjB/v37GTBgAIGBgfTp0wcnJ6cEy4+mSJEiTJ48mbFjx+Ln5wckfS+NkdLj4vJynYfE709i9cpY3U5MzpcVkpVVytv9ly9fpnz58q9sN6WMxJ51SPi8Tbn/KXlOTa1XidX38+fP07NnT7Jnz862bdsIDg5m2bJlDB48GIPBwLNnz0xuLCX0TCTnHI0phsTq2cuY+v4A43XU2Ps3qXtv6nmmBB8fH8LCwnjx4gVeXl6JylO+fHmjz5gxklMPKleuzJUrV2KOvXr16ivXICEytFIHcHBwoGrVqkyfPp26dety/PjxGKVy5MgR2rZtS2hoKHXq1MHFxSXmRqxfv56ZM2dib2/Prl27YjzUN2/eTJ48eShVqhQNGzZk3759BAQEAGrsOLlYWlqi1+sTLcdUduzYQZ48eXB2dsbJyQknJycOHDhAcHAwe/bsMXqOxrbny5ePx48f4+Pjg4iwc+fOBMs9fvw4jRs3pnv37lSpUoUDBw4QGRkJYDRvgBYtWnD9+nX27t1Lp06dXsm3ZMmSMQ/Jy/z+++/06dMHW1tbwsPDsbKywsLCgpCQkHjpPDw8KFOmzCvHd+jQAScnJ/bu3UvHjh0BNbY+fvx47OzsGD16NHZ2dly7di3J696yZUsaNGgQ47+Q0nuZGnUA4td5SPz+GKNBgwbs2bOHFy9eYDAY2L59e5JylixZMllyJsa9e/dYsGABX375ZYqOT+xZN4Yp9z8l98jUemWsvkdERGBhYUHWrFlp1aoVmzZtYv78+QwaNAhra2uePXuGXq83uadu7Jl4nXOElNWz1znO2PvX1HufWs9bNBEREYwcOZJhw4YxZMgQRowYQUREhFF56tWrZ/QZM5Z/cupBy5Yt2bRpE48fP8bDw4MdO3bQpk2bJM8jQ5rfX2bixIkxjhk//vgjI0eORESwsrLizz//JHv27FSoUIHRo0fHTAMrWLAg06ZNo1ChQnzxxRf07t0bg8FAvnz5WLhwIRYWFtStW5cuXbrg6OhI1qxZee+998iWLVuyZGvZsiWff/458+fPN1qOqaxbt44+ffrEa/HlypWLzz//nOXLl7N582aj52hse9euXenUqRMFCxakUaNGCU6T6tq1K99++y1t2rRBr9dTv3599u3bh8FgMHpdQfW4WrRogbe3d4wJLC65cuWiZs2anDx5koYNG8Zsv3v3Lrdu3YqZPubo6MiwYcP47bffGDx4cEy68PBwLly4wNSpU1/Ju2DBglSuXBm9Xh/Tsm3fvj2nTp2idevWZMuWjSJFipg8jWvChAkxDjz169dP9F7279+frl270rRp03h5JHVccoiu887OzoneH2M0bNiQmzdv0qlTJ3LlykXFihVjLBHG5HydqZmhoaG0a9cOUMMaWbJkYeTIkTRq1CjRYSBjlCtXzuizbgxj9//GjRsxaVJyj0ytVy/X92PHjnHnzh0MBkPMy7hbt27s2rWLLl26kCdPHgCePn0KqN5vWFgYWbJkMSpLYs/E65wjJP4eSOzYlNRPwOj719R7n5rPG8Ds2bMpUKAAn332GQAHDhxgzpw5jBkzJkF5atWqxd27dxN8xuKS0npQsmRJhg8fTpcuXbC0tGT8+PG8++67SZ9IkqPubzCXLl2SFStWxPxfunSpDBs2zIwSZS6CgoKkQ4cORqdniIicPXtW+vfvn6L8N2/enCZT2jQ00oq49X337t1SvXp1WbhwYbw09+7di/c/ICBAevbsKWPHjpWHDx8mmv+b9Ey8Le/ftKgHiaETSWKw+A0mMDCQ7777Djc3N3Q6HUWKFGHKlCkmj229zTg7O/Ptt9/SrVu3GMc3Y0yfPp369evToEEDk/MPCgrim2++4ffffzfJOURDI6OQkvpuCm/aM6G9f9OGt1qpa2hoaGhovElkeEc5DQ0NDQ0NDdPQlLqGhoaGhsYbQob3fg8NDeXKlSsULFjQpHmAGhoaGhoamZnIyEiePXtGlSpVEgzglBgZXqlfuXKFHj16mFsMDQ0NDQ2NdGXNmjXUqlUrWcdkeKVesGBBQJ2cqcEZNDQ0NDQ0Miuenp706NEjRv8lhwyv1KNN7oULF6Z48eJmlkZDQ0NDQyN9SMmQs+Yop6GhoaGh8YagKXUNDQ0NDY03BE2pa2hoaGhovCFoSl1DQ0NDQ+MNQVPqGhoaGhoabwiaUtfQ0NDQ0HhD0JS6hoaGhobGG4Km1DU0NDQ0NN4QNKWuoaGhoaHxhqApdQ0NDQ0NjTcETalraGhoaGi8IWhKXSPZ6MP0PD77OP0KfPYMHB1h0SIQSTCJQW/g8rrLrGu7jpPzThIeFJ5+8mloaGhkEDL8gi4aGQPvm9743PShQtsKXFp1iR39d1D2k7LY/8+ekvYl0el0aVPwo0fQvDlcvw4bN4JOB/36xUtyY9sN9o3ah99dP2wL2nJrxy1u/XuLXgd7pY1MGhoaGhkUTalrJIqIcH7JefYM24NtQVvKtSzH+13eJ9gnmJOzT7K84XJK1C+B/Xf2lGtVLnWV+/370LQpeHmBkxO4uUGPHgCEP3sOtrbYZLchIiSCbHmz8cnWT6jQtgLuLu4Y9AYAQp+HcuLXE9T+pjY5CuVIPdk0NDQ0MiCaUtcwSohvCDv67+D6luuUaVqGDis7YGljiaWNJXZj7agztA7nl57nxIwTOE1wolyrcqkrQGQk2NrCgQNQpw40bkyIXwinftqH6/RD1K1vgf2BH6jiWIUqXavENChK1i8Zk4XbQTecpznjMsuFD/t9SL1R9chTKk/qyqmhoaGRQdCUukaChD4P5a9qfxH4NJBmM5pR79t66Czi98Kts1lT++va1BxQk4DHAeh0OkJ8Q1j1ySo++uojqvasiqVN8tcD5uFDKF4cypaFixfBwoJAz0Bc5rhwZsEZwgPDKV8K3nVeAXX3oFu7FipUSDCryp0qM+TGEI79coyzf53l7F9nqdqzKg5/O2BpnQLZMhCREZGZ/hw0NDRSF81RTiMeEuWIljVPVmoNrkVfl77UH13/FYUeF0try5jeb8CTAMQg/Nv3X34r+1vyndZOn4bq1eHHH9V/C1VFd/TfgcuvLpR3KM+gi4Podn86xbb+rkz0NWok6kSXv3x+2i1px9C7Q6n1VS1C/UNjlKG/u7/pspmZiJCImN8bOmxgmu00ljVYxvMHz80oVdoQEgKHD8OUKfDTT7HbBw+G8eNh927wzzy3TkMj3dCJGHkTZhA8PDxo2rQpBw8epHjx4uYW543G55YP277YRqvfWlG0VtEU5yMi3N17F+dpzjx0fohtQVuG3BhCtnzZEj/Q2Rk+/RQKFODZws0cX/OARpMbkadUHryuemFpY0n+9/LHP+bxY+jVC8LD4dAhsEy65yoi6HQ6nj94zvxy83m32bvYfWdHKftSKT7ntMD/oT8PnB/w0PkhD50fEh4YzrD7w9DpdByZcoQgryAurriIzkKHw18OVOlaxdwivzYLFsDq1XDmDEREKL/IJk3UCIzBAI0agYsL6PWqvVe1Knz99Su+kxoamZrX0Xua+V1DOcMtPc+eoXuwympFsHfwa+Wn0+ko17Ic5VqW4+Gxh9xzuhej0K9suEKZxmXI/k72+Aft3w/t2vH4nWocqziI6y3+xTqbNRXaViBPqTy88/47CRdWtCjs26e6bZaW8PQpXLsGjRsnKh9AtrzZaPRjI07OOcnyBsspaVcSu+/sKNcylR3+TEBE8L7uTf4K+bGwtODA+AMc//k4AFlyZaFEvRKUtC+JQW/A0tqShhMbAlB3ZF229NjC5m6byV0qNyXqlkhXuVPKo0eqDefsrIwzx46BjY0aeQEYMQIaNIB69SBvXrXNwgKOHoWgIHB1jT0+NFTt9/ICOzv1sbdXn7JlVcNAQ+NtQeupv+WE+IawY8AOrm++TpkmZWi/sj25iuVKk7KCngUxu9hsLCwtqNG/BvVG1SN3ydzg64uUKs06XXduBxQha56s1P6mNnWG1sG2gG3yCvnqK/jrLxgzRpnwbWySPCQiOIJzS85xYuYJAp8EMuz+sDS7BtFERkTied4ztid+7CEhPiEMODeAIh8W4eGxhzw594SS9iUpVLUQFpbGR8oMegM3d9ykUodKAAT7BGObP5nXLQ0RUb1sS0vYvl0p7Hv31L4cOaBuXVixAooUeb1y7tyBb79VDQRfX7WtcGHV82/aFMLCwMrKJGOOhoZZ0XrqZsbdxZ1cxXIpBZXJOLfkHDf/vWnUGS4eQQ8gxBPy105R9yd7wewMvjyY4zOOc+bPM5z58wzVv6yOw58O6LZtpeD2YEoVz0etQbXIkitL8jKPDIWnR2DqOOU1/8svyma7di2UL5/ooda21tT5pg61BtbCw9UjRqHv/Gon+SvkJ2uerDFpC1YuSLGPihEZEcnltZfVxiee8OQJlC1L4QblKVy9MBHBEVz952r8ggRKNSjF8Wt5cT90D6/ZawCweicveWpUoHnXkuQumZutW+HFi5KQuyQ3LgGXoFgxaNZMZfPPPxAcz5hiQenSlagEeF3x4q9ai8nduj6529iT/flj8j04T84W9ajdSg1drFjx6jWoVAlq11Ym77VrX91ftSp8+KEa69648dX9NWtClSrw4gVs3aq2+foqBevsDCtXQsuWULCgcpn45hvVk65e6AlWD+5CoXq8rotPuXKq0WAwqLAG0T350qXV/tWrYeRIqF9flV00aoSpe3ewtlYm/6tXX823d2/17eICt27F32dlFTPLUkMjQ6D11FOBHQN3cGXtFVr/0Zqqn1dNd9NtcokMj8TPzY8CFQtg0BvwvuHNO1WMmLejEYE9NcHvPOT7CN7/Doq3BV3KXsT+D/058eVizjkH8aVLf4rUSGE3LSIA7iyE67Mg1BMa7YaiLZVm6ddP2Wa3bVMBbJJBeGA4yxosw/O8Z7ztH39dgxZtsxB+0JnpM15tEzfId4nG7fMQ8EFdZo949Mr+RpMbMWpHQy6dCeM97vCAkgSSE3t7ZVoGqFgRbt6Mf1zr1rBzp/pdvLgyX8fF0RHWrxNCT1/mu3qHyB35nAeUpDuraYYTz7MVJs/2ldC8ORYWr/oUDh8Oc+Yo03aOBKbzT5yoDB+engn3qGfMgNGjVW/5vfdit5curRToN9/ARx+9dNA//8CAAfD8OVSurDzgunZVmjINcHFRDRpnZzVCE82LF5AzJ4waBbNmvXpc9LUaOBD+/jv+vuzZITBQ/V67Ftq2Tfj6aWgkh9fRe5pSTyFPLz1FDELh6oXxvunNtt7beOT6iCpdq/Dpn5/G691lJHxu+7Cl+xZeeLxgyK0hZMmZRI84zAcss4GVLTy/Cl6H4cZsCHSD3JWh5jwo3Cz5gvz2Gwwbhr6lAxb/bsMiuVOzIsPh6jS49RuE+ykZyvSC0j2VFeHiRPC9B+sCYPpSyJ8/6TxfQkR44f4Cw+Mn8PciOH2KLNcuYGsIRCwsef7HGmjxCQQEqq7hhfNkPX+SbKeOEPkikD1/3uP3Jbbkdd1FyazeDFzyEUVaVccn2JbwlyYEZMkS23P08FA95rhky6ZMyaDGnSMj1W8rt1vYHt5F9nNHyXr6GDx7hsHahkNTjuP60350BgP2PUvw8ZFfsLp5DUaO5F7/aarAOOTKpS6RwQAPHrx6LfLkUWPbej24u7+6P29elSYiQskPKsRAoUJGLq5eD7VqqeGRfv1g/ny4ckW5vDdsaPSepBa+vrHe86VKqfF6Hx+l4F+mTBn17e0NAQHx9+l0quFy65Zql9SuDbt2qWuhoZFSXkvvSQbH3d1dypcvL+7u7uYWRUREDJEGcZnrIlOyTJFlDZbFbI/UR8qRn47IZMvJMqfUHHl65an5hEwAg8Eg55ack6nZp8rPeX+Wq5uuJn3QkwMiW4qKnPoq/vbICJF7a0T+qyLyeJ/aFvZcRB9imjBTp4qASIcOIqGhyTuRiGD1bTCI7P5I5Eh7kWeur6Y7N0pknY3IWguRY91Fnp1T5Tk5Gc/bYBBxcxNZsUKkf3/1LSLi6SmSLZtIw4YiEyaI7Nsn8uKF0WyuX42UdlXuCIgUKyZys1pndb4gkju3SOvWIr/9lrzzFhEJDhY5dEjkxx9FvL3Vtp9/VvmWKSPSq5fIokUiN26IGAzie9dXFn+8WPaN3icSFCTy1VcilpYip04lv+zU4swZkefP1e9Hj0TCw9XvyEiRgwfVPRBR5zhzZqLXOaOxZYuItbVI9eoiXl7mlkYjM/M6ek9T6skg4EmArGqxSiYxSda2WSuBXoGvpHE/6S4rm6+UUP9kKqs0JCIkQjZ+tlEmMUmWN14u/u7+iR+gDxM5N1pkjU5kR0URn3MJpzNExr6Ez44U2VxY5NpMkXAjL2KDQWT8eKWEevQQiYgw/SQC7oq4DhTZlF8kNEqhRSt4YwQ9Usp9Q3aRNYj0LiCi04mMGxerTKLl6tVLaeBo5Zsnj8iUKbFp4qZPgPBwkXv31O/nz0Vq1VL6NTQ0Kv9790RWrlSNhYoVRVq2jD24b1/VWNi791Uldv++yNixIvXqKY0B6hz271f7vbxEPDyMyhUZESn6ML2IiDw88VDc/zkRu/PEidj7l9bo9SLTp4tYWYkMG5Z4WoNBpG1bda5584r88ENsIyaDs3u3SNasIpUqqTaLhkZK0JR6OvDs+jOZUXCG/JT1Jzm14JQYTHgZRoREyLY+28T3rq+JhbiInB4i8mCTUpivSbSMBoNBNnTaIM4/O0ukPol8/W+J7KqhlKDrQJGIINMK8zwscrCZOu6fvCIXfxAJ9Xk13cSJIgMGqJ6ZKfhdFjneQ2Stpep5uw4SCfaMl0SvFzl3TmTePJEvvhBZsOClPEJ9RC5NEnnkItKvn0ghRJoXEWnXNjZNhw4ijo4iv/8ucvGiyfKFhKjySpcWqVLF9NOSsDD1HR4uUru26kGDiIWFyIcfimzfrvZfvaqUed26ImPGiOzYIeJrYn16iaX2S2Wy5WQ58tMRiTxxUpXXrp3Is2cpys9k3N1FGjVS5XXpYrr8rq4i7dur47JnF1m3Lm3lfAmvQC8Zt3+c7L69O1nHHT4skjOnyJo1aSSYxhuPptTTgciISNneb7t4XTXdrvbozCOZnnu6TMs5TS6uuph4YpcvlEJca6G+d1QUebg1RbJGhEbI2UVnZX6F+eJzWylWUxohIiLy4rbIttIpLlueuSqT+BpETvRW2/R6kbt3JUoQ03uHgfeVtWBDdpGz36qed1R20QweLJIrV2wHu0ABkc6dY/c7Oop8953qQflHGyjWtVDy/fWOiPu2FDWgXrwQmTFDpHBhVW6dOiL//vsaHd8XL5RZf+JEpQB//VVtNxiU6TxGo50RAAAgAElEQVQVCPELkU1dN8kkJslS+6XyfOKvIjY2IkWKxPb8U5tDh1RvO3t2kWXLUnaBLl9Wlp1r19T/O3di61MasffOXin8a2FhErLj5g4REfEP9Zfg8CSsQ1E8jTP6Ft1+09AwFU2ppxGeFz1lZbOVEvQs5S9Vv/t+stRuqUxikmzuvllCnkeNOxsilUKJNiHfWytyfbZIuL/I/Q0iO6uJ3P5b7dOHJG1qFpGwwDBxmeMis4rNkklMkoU1F8qj0ybYAEO9Ra79GvvCjUzc1GwSfpdFXtxRPdH+LUQGZxG5n8RYrsEg4ukkcvWX2G1uq8Tfy1t27VKWezs7pYOie8RTpogMHCiyerXIgwdqW7RVPzBQ5KOPXu0Eb1gbInLrL5FtZZRy/+99kQcbk3V6K1aoPJs1U8P06WXFfl0MBoNcWHFBpuWYJtNzT5dnW44qWzGoIYDU5uFDkRYtRG7fTr08HR3VTe3RQyn8VCQ0IlRG7BkhTEIq/1FZLjy5ENMgHrd/nBSaWUh+OfaLvAg1baz/yBHl7nDpUqqKqfGGoyn1VMZgiHWGm1lopnicMj5maQqR+kg5MkU50a1vv1rEbZXIf5WVQrmzxJgQIpFRXdIbv4lsLiRy9Wel9BMgIjQiRpkvb7Rc7uy7Y1rv/MlBkS3FRNZZi/il8psnJESkTRuRhoistlRWiOM9lMKPiyFSxP1fkT0fi6xB9JuKS1iQ8leYPVspY1DDsbVri3z7rVLYphIQoDqi338v0rhxrBX3yuUIGdlxtXgsfF+urBwud+4oR0jRv+oP8eiRKvePP9T/8HCR06dTclEyBj53fGTPyD3qfIOCxDBocOzJvS6nT6uWlsljEckk+mZkzx47hJBKzn9zXeYKk5Cvd379Sq/86P2j0nxlc2ESkufnPPK90/fiHZT4WP/168pVI1++zF1fNNIXTamnIgGeAbK65WrlDOeQsDNcijBEiu/e6aL/p5TIGiTy3/cl8s4q5UmeFF4nRJyiTMYb84hcmCAS8kwCPAPk1ILYl9npP0/Lw+MPTZNHHyZybkyUM1wFEZ+zKTsvYwQGijRvrl66f/yhTOdnv411WjveQ0REDN5nJHTLByJrEK/FpWVi1z8li3WIHD2qsnFxUX5SBw4kT5GbwoULqs2RL1+kZLMJEhDpbH9QwjYUFbk2S4JfBMitW8oFwMZGdQ5HjkxdGTIC/h7+sqjOIvFwjWq8btggsnBh8s0PcZ3hihWLNZ2kFd7eqnLkzaucCUWSN7wj0YcYxMNfnXu4PlwOuh1MNP0pj1PSYX0HYRLSbVO3JPN3c1O99Zw5JaZea2gkhqbUU5GtvbbKT1l/EtffXU0fh06M6N62wSCyp476uG+XTV03ypJ6S8TXLRlOT96nRY52FFmDPPujmvyU9SeZpJsk3jdT4Bns1CrKGW6ASEQqaEuDQXVL/PzU/7/+Ul3s5cvjpwv1Vk50l5Vn+ZmjHnL2pw+lR/1VUrBAhLRtq2YyPTSxbZIaREYqK+6CBSLfDTot4bubiKxBAlYWkpIF7ouNjcigQWk+jGs2Hp99LLNLzJbJlpPl2uZrIp06xU45NNXrPK4zXOfOIj4JOEmmFS9exNa7nTtVzz3EtOmVXoFe0nZdWyk2q5j4hfglq9irXlfllvctERG55nVNBvw7QO743Ekwrbu7SIUKambk65jiH714JOsvrxdXDzWN8+Hzh2I71faVzx+n/oiRMaH9Ky6o6ZquHq7xtjv+4yghESZOTdVIM15H72nBZwB9qJ7Q56HkKJyDoGdBBHkFGV9AxFTCfODmfHBbAi3PQdaCKkiKdR7Q6biy/gr/DfoPBFovaE3VHlWTzDLIK4j9Y/bz5NBBrGz0FGrYCrsR5ckXNBcqjYKc5RLPQAQQFQXu8V6IDIYSHVJ2fno9nD8fG4vz2DEVnWPVKujZUwX3vnEDWrVKNJuwMFi+XEUdq1gxZqVV8/PsOPoDrXgS+iFWLZwoUvTNDhge4hfC2tZr8bzoyZdHv6DIkfUqwlvBgirGa9Omxg8WUTFk79xRQYX69DHfKiqrVqm4ro0bq5ixiYR32393P7229cI3xJdfmv3C0DpDsUhhhMSVF1cyYMcAIgwRdK3SlXH1x/FBoQ/ipfHygj/+gO+/Nz3+vEEMLDu/DOeHzjg/dMbNzw2AQTUH8afDn/iF+DHNedorx7Wr2A67knZ4Bnoy68SrYfI+e/8zaherzYPnD/j91O8APA99zuLzi2n2bjN2dNtBVquMGUDrbUALPvMaeF7ylAVVFsiS+ktSp2f+spn5SDuRALcEkxp1onuJ6DnvYQFhMrvEbNk9fHfsXHP3bSLrskQFWekq4mvEyz7UR+RoJ5HLP6XsvKIDn7hGBXpxd491OY8b+CSROdOZjrvL1HV9+nbYTAM8A2ROyTkyq+gsefHohZonWLGimhefkENaYGCsa/fJkyK3bqWvwMZYuVJZierVi+3BxyFcHy4j94yM5wyXGjx+8VhG7xstOablECYhjv84Gn2nPHggsnlz/G36SL2cfXxW5rrMlV+P/xqzvczcMlJgRgHpsL6DzD4xW04/Oi0RpgzbpYDl55fLgH8HSGQqTKnVSDma+T0FGAwGOTnvZIwz3O3dqeCdG/JUZH1W4w5hCRAZESmHfzwsMwvNFH+PWCc4g8Eg94/cl1UtVsnvFX+PmV+uD9e/mknwEzU+viFHbEMi7kPv6RTrDHdtlunns2uXmhtdt25s4JO488W2bHmzlPjLGAwiz6+ZW4p0xfOip2zouEFC/KIamEFBIqtWxSaIDo5z5oxI+fKxY9kZjU2bVJ398MM4cxkVBoNBWq5uKV/995UEhafOdMG4+AT7yOTDk+V7p+9jynNxd4mn4Pv0UW2lxYtFlp1fJi1WtZCc03IKkxAmIXUW1YlJ6xngmTodjmTi5uuWpCOgRtqgmd+TSbBPMNt6beP2rtu89+l7tFva7tX1vU3BEAl+58DnFJT/Wm27/RcUbg45yyYrq7CAMLLkzIIYBKcJTjw4+gD34+5kfyc7H4/8mI+Hf4xVlpcWurh7N3YBagBDAARtg0JWUOdvtSrI9XEQvB0si0HeCWBTARo1UumvX1crdETz9KmyEQ4dqv7XrAmXL6sY3fb2ry5w/Tbx9AgUqAOWb49JUh+qx9LGMnblvosXlVm7Y0dlkn/nHbX0WXR9ymjs3q1WwZk/HwEWn1tMi3ItKJm7JBGREVhbWqeLGEfuH6HRikbULlab/jX6c9f3Li73LpJ183/s3WtBw0Fb8an6PfYl7dWnlD3Fc5l3nQu9QU/VP6tiaWHJ/s/3UzhHYbPK87ahmd+TSVhAmPxZ9c+UOcM9vypyZaqIU0uRjbmiPNJziYSlLMrXy9zccVMmMUlml5gtrvNdJTw4kTnj48bFmsDjfqJNoqO6i6xCpB8iWaL22djEHt+r16vHFioUOxXpzp1UC3ySqfG/oWYJnBlubknSjbCAMFlUZ5EcnBDHE/zRI5GmTVU96dQpfZ3hXoNnQc9kwNxmUnI4Mm7/uHQvPzQiVBaeWSjvzntXmIRY/WgldRbVkbteHtKhg7qcU6emu1hJ4uTmJNmnZpdyv5WTB8/TeCaDRjy0nnoKMOgNWFgl4RQT7g/eJ8DLGcoPAduiyvnt7FC1QllBe/Up2hKyJH8VMGP43fMjV7FcWNok4U3j5pbwkln29srj7OZV8LgMVnHWytTpVI8blCPb06ex+3Llgg8+SLOlLzM1Z76BW79Dk/0pW5UukyEi7Oi/g/NLztNhdYdYR87oxcorVzafM1wyOOB2gF5bPmfn7KeUNeQmx9GTWJSvYBZZ9AY9V7yuUD5/eWytbdU2vfIrvHoVjh9Xq/FlJFzcXWi1phW5s+bmwOcHeC//e0kfpPHaaEuvpiZBD9Xa3M+c4flFEAPorKDhv1C0FYQ/B4lMVSWukQnQB6v15CMCoPUlyJLP3BKlOZHhkaz6ZBUeJz3ofag3JeqWMLdIyWLDlQ103dyVSgUqsbXCD1ToNkS5nR84AFWqmFu8GAwGteRrnjxqNoi1dQaaBQKcf3KeT1Z/Qv0S9dnWdZu5xXkreB29l4GqTjojAgF34O4yOPkl3F8fvQPuLgabvPD+RGhyAD57rhQ6gE0eTaG/jVjZQr01EPoUTg+Omh74ZmNpY0mXzV3IVTwXG9pv4PmD5+YWySQMYgCg1XutmGA/gTMDzlChmSMcPaqUesOGcPasmaWMxcJCKXS9Hjp1gv79ITLS3FLF8mGRD3Hu48yydsvMLYqGCaSJnTU8PJzx48fj7u5Ojhw5+P7773n+/DlTp07F0tISOzs7hgwZkhZFJ40Y4EQP8DoCIU/UNpt8ypwOkL2UUuIW6eNEkymIBC4Dx4AywKdAMPB9AmlbAs0AP2BqAvvbAfaAJ/Ar0A2omfoipwn5akD1X94qZznb/LZ0/68723pvIzI8A2malwiPDOfM4zPsv7ufPXf3cKj3IXJlycWUJlNiE1WqpGIqNG0K330He/eaT+AEsLRUvqk//giBgbBsGdjamlsqRcUCFQEI1YfSc0tPRtYdSb0S9cwslUZCpIlS37hxI7a2tmzcuBE3NzemTJmCt7c38+fPp0SJEgwYMICrV6/y/vvvp0XxiaOzUGPl7zSGd6LGxHNXUtuj0RQ6GIBfAGfgBOAftX0CSqmHAn8lcNw7KKUeaGR/WZRS9wPmAvuAi0DGH55VVBppbgnSnQIVC9D3ZF90Oh0iEhW/KGPcsINuB5lydAquj1wJ1YcC0LJcSwLDAxMOnvLuu0qxZ4+a7SKSYXwDdDqYPFnFyxkzBi5dgrVrVVyfjIJfiB+Xnl6i+arm/Nv1X5q+m0hQIg2zkCbm9zt37tAgyhnr3Xff5fLly4SHh1OyZEl0Oh12dna4uLikRdGm0XgX1F8D7w2CPO/HV+hvIy+APcD/iO19WwBLgQdAV2B11O/ojk8+lOJ++TMman8JI/sHR+2vBCxBWQB2p81ppSkPNsDR9sry8xag0+kwRBrY/sV29o/Zn+7lPwt6xtbrWxm5dyQfLfqIw/cPAyAIgeGBDKo5iM1dNvN01FN299hNAdsCxjMrXlxNywwNhTZtYMeO9DkJExk9GvbtA39/+OwzZZbPKBTJWYSjfY7ybt53+XTtp/x36z9zi6TxEmnSU69UqRKHDh2iWbNmXLx4kYCAAEqUiHWyyZ49O+4JeG1v2LCBDRs2xNsWHh6eFiJqAMwDVqB6ygbAEmgRZ/8lIC29cbuhev6/AK3TsJy0QB8EHtvhxmwVovctwMLSApucNrjMcqFApQLU6FsjTcoRESIMEdhY2vDg+QNarG7BTZ+bAGS1ykqdYnWI9u9t9m4zzgw4k7KCQkJUXIaOHdV8e0fH1DqF16Z5c9VTd3dXk1HCw8HXFwpngOnihXMU5nDvw7Rc05IOGzqwofMGOlbqaG6xNKJIE6XeqVMn7t69S69evahRowYVK1YkJCQkZn9QUBC5cuV65ThHR0ccX3qwor0ANVKIAG4oM7ozcAY4DdgA3kAelGK1Bz4G4obKTuvpNTbAyKiPC1A3jctLTd7tA492wMX/QeFPIG/SsfvfBFrObYnvbV92DtpJvrL5KN2o9GvnaRAD155dw/mBc0yM844VOzKv1TyK5ixKpYKV6FO9D/al7KlZpCZZrLK8/omA6q0fOKB66926QVAQfPll6uSdChQooD6gzPILF8LSpdC2rXnlAshvm5+DvQ7Se1tvyucvb25xNOKQJnbny5cvU7NmTVatWkWzZs0oXbo01tbWPHz4EBHh2LFj1KpVKy2KztwcA+oRa44+gTJTv/w5GrV/v5H90Y6924EiQDmgD7AVKAX4Ru2fAjgBk1Hj4MbXvkg7+gPzgcymE3U6qP23miVxogdEhppbonTBwsqCzhs7k++9fGzstBHfO75JH5QI4ZHhlP2tLB/8+QFf7fqKIw+OUL9EfexL2QNgbWnNVsetjLUbS70S9VJPoUeTK5eKPNe8OfTtC4sXp27+qUTPnlCiBLRrB199BcHB5pYIcmXJxVbHrVR5pwoiwvGHx80tkgZp1FMvVaoU8+bNY+nSpeTMmZOpU6fy5MkTRo0aRWRkJHZ2dlSrVi0tis6c6IEfUd7iRVG9Z4CcJKzsckZ95zayPzribR6UN3odVE+8MhlvEmMOwEwTIV6brAWhzlI48qkyxZfKOObbtCRr7qx029GN1S1W4+/uT75yyZuzf+3ZNVZfWs3UJlOxsbRhWpNphEeGY1/KnjJ5yqBLb8c1W1v4918YPBg+/jh9yzaRSpXg5EmYMAF+/RUOH4YNG1SsqIzA+ivr6b6lO780+4Ux9cckfYBGmqEFnzE394AeKPNzb1SvNWeiR7yZrALuApPMLEdK8LsIed++RmpkRCSW1qYvSXv60WmmH5vO1htbsbW25eyAszFTpTIUIrBnD7RsmWE84+Oyfz8MGKBWlq2aQSxcEZER9NrWi/VX1jOxwUQmN5qc/o2zNwgt+Exm5h/gGrAeWM7bqdABTgHTAA9zC5ICohW63yUI9zOvLOlItEJ3me3Crm92GU33OOAxn6z6hNqLa3Po/iG+b/A9D4Y/yJgKHZQ3fOvWMGJEhgwy1Lw53L4dq9B/+w2ePDGvTNaW1qzusJq+H/ZlytEpfLvvWzJ4f/GNRVPq5sAf5awG8C1wFXg7LLfG+RblgT/X3IKkkDAf2F8PTn9tbkleISAsIE3zD/QM5PTvpzn1+6mYbSLCg+cPAChgW4Dnoc+Z0WwGD4Y/YHLjyYlPOTM3bdrAsGEwb57qEmek8G5RRC/PcP8+jBunFPx/Zp5dZmlhyd9t/mZo7aHMc53H2ScZJ2rf24Sm1NOb40A1VGS1UNQ0smJmlShjUBrVsFmICkyT2ciSHyqPgwfr4P46c0sTw6lHp3DcFNtiXHxuMYfuHSI4IvU8rZpOb0qFthXYM2wPt/bcYv2V9VRfWJ36S+sTpg/DxtIG136ujK4/mlxZXp31kuHQ6WDOHDWAvXixUvAZlNKlVcTbYsVUW+Trr9VMPXNhobNgbsu5nOl/hlpFNWdoc6Ap9fRCD/wANEAp8i3A2xNt1DTGogLULDC3ICmk8jgoUFfFhg96mHT6NMbd352269oSEB5ASEQIofpQhuwaQpOVTcjzcx7qLqnLmP1jOPXoVNKZJYKFpQWfrvgUy3KWrOiwgm/++obwyHCmNZ2GpYUy0We68VWdDqZMgVGj4M8/4fJlc0tklEqVwNVVjRYsWKCi4JrT8q3T6fiwiAqDt+PmDs0rPp3RlHp6EIBS5j8CPYHzqDnhGvGpipqznkGcf5KNhRXUXaVW8Tv5hVmjzQWGB9JmXRtC9CEsdFhINutsZLXKiucoT/7r9h8j645UvaqTc3F+4AyAV5AXX+38inWX1+HxInnODS4+LsxsPZPIrJFMLzydq19dpVe1XlhZZPJlfH/+WbmdZxQ3cyNkyQKzZ6tw9qNGqTaJiFoBzlyE6cMYvnc4Pbf25EXYC/MJ8paheb+nBwL0Q80F72ZmWTTSnrvLIOA2VJ1slnUEDGKg44aO7Li1g53dd9KyXEujaUMiQtAb9OTMkhPnB860XtuawPBAAErnKY19SXv+Z/8/KhSIvwa5X4gff5z+A0udJePtxyMiOD90pnbe2mTN9YaaoHbuVLHjK1UytyQm8ccfyudv+XLzRaI74X4C+2X29KrWS1vlLRlo3u8ZEX+UIr+NWqxkCZpCNxU/YA5qyCIzUrYPVJ9mtoWBrnpdZb/bfua2mJuoQgfIZp2NnFnUlAv7Uvb4jfXjTP8zzGkxhxpFarDnzp4Y0/nGqxvpuKEjX+/8mlJzSzHx0EQueV0ClMm1QakGMQr9zp477Px6JxHBEWl4pulIcLBaE7VNG/DxMbc0JpElCxw5opzo9u0zjwz1StRjvN14ll9YzpbrW8wjxFuGptTTghNAddQUtWPmFSVTcgRlhv/H3IK8Jk+PwOFP0z3a3AeFPuD619cZUjv5UX2sLKyoWbQmwz8eHrNAynv53gPgRdgLLnhe4K+zf/Fp+U+5MPAC6zol7BT46NQjziw4w9zSc3Ge7kyofyaPuGdrC1u2gIeHihWfCdak6NdPOdG9845aGMb39YL/pZgfGv5AzSI1GbBjAD7BmaNBlJnRlHpqokeFXG2A6p07o8KzaiSPtkBF1EIvGXpwKAn0gfB4F1yckC7FOT9w5u+zfwNQMnfJVHFO0+l0Mfn0q9EPt2FuhPwvhHWd1lGtsPGAOw2/b8gXR7+gaK2iOH3nxNySczn952mj6TMFH3+sgq8fPaqiz2XskUsAKleGdesgIABmzDCPDNaW1qzuuJqZzWeSL1vyog9qJB9Nqacm81AR0boBF8hcC5RkJCxQS7heRK23nlkp9imUG6RWcnt6KE2LcvNzo8OGDsxymUVIRNrOabKxtDEpXSn7UvTY1YMB5wZQtkVZsuZRpvmwgDD8H/qnpYhpR/fuMHGiUu5795pbGpP44AMYO9a867JXLFCRPh/2QafTpep0So1X0ZR6ahA9r3owaqraKiATTMfN0PRAzd//xdyCvCY1foWc5cClN4Q/T5Mi/EP9cVjrgEEM/NftP7JZp/XyesmjyIdF+GzjZ3zQTXmQn15wmt/K/sb2vtvxuZUJzbGTJqkYrS1aJJk0ozB9esZYWXbPnT2UmluKG943zC3KG4um1FOCAbXW+B/Ap6gFUwIBW6DD62edUV9zG4GZ6VVY9LKsWYHM3LC3yg51V0PIY7jzd6pnrzfocdzkyG3f22zuspn38r+X6mWkNh90+4Bag2txZe0Vfq/4O5scN+F5wdPcYpmOhYVa/1Sng2vX1MLnmYDgYJg5E9zczCdDtULVEBF6bulJeGTG90vIjGhK3RTCgehIkYuB/KiocENQJuLPSbVAMp1QweYy2mjdI1TAt3QNIzEC2IVqLKUnj1CzFwTVynpdCtSGT1yg0ij1Xx+UCpkqDrodZO/dvSxovYDGZRqnWr5pSe6SuWn1WyuG3R+G3Tg77uy5w/7R+80tVvIxGJQHmoMDeGb8RomfH3z/vVqb3VwUyVmERW0WcfbJWX488qP5BHmD0ZR6QgSgxnInAo1QS5xGB916F+gMrADcAPeodK8RY+M2qoPvD7RBKc5VKc8uTRgFZAFmp2eh0X5e91DXOT0IAFoDBVBL2KbWUHj+j0BnAcGP4N9ycG1GqgSnaVGuBecHnqd/zf6pIGT6kqNQDppOa8rwB8NxWOgAgL+7PyubruTO3jsZf0EQCwtYtUpNcWvf3rzxWU2gWDEYMkSJfPWq+eToUKkDfar3Yfqx6ZxwP2E+Qd5QNKUO4AVEN7TPoNYhb4FaNSwINVYe7bTZBFgE9ALKEKt4UsgVlLP8MZTe+gJlzR8NpM0IbPI5hFpEbhzKEn4gPQsPQllF0qN3EYkay78K/AaEkPqrxllmg4L14cJYcGqulHwKcLrnxJH7RwCoXrh6akqY7mTNk5W87+YFwM/ND59bPqxpuYZFtRZxbfM1xJCBlXuNGkpLurpC374Z3iN+7FjIkUP12M3JvJbzKJ2nNAfdDppXkDeQt0+pC6rntxLoD1QACqE81wHeB74D9qK06mlU97TCKzm9NmdRhgAdamp2FdQNWQA8Q4WKNzcRqFGGMqjQ7ONQbZx0IztqeGMlyiyelowDdqDqwhdR21JbqWfJB3b/QJ3F4H0SdlUF963JyuKm9006bezEyH0jMZgxFG1aULphaYbeHUqbxW0IexHGP53/4a9qfxEZnvFWSouhY0eYNk3NHVuWsaOmFSigwshu2QKnzTjDMGeWnJwfeJ6JDSeaT4g3lEwemDkFCPAhytadB7AD+gKtovZnA6akvRgnUcaAvMBBoGycfTWAQajh5J+jRDIXguq8VouSowWwE7hLfJnTlG+Bv1DLsqaVp94q4Ffg66gPKOtMWjQkdDoo2xcK2sOJ7vBwI5QwzcPSJ9gHh3UOWFtYs7nLZix0b1673NLGkhp9a1D9i+pc23QNn5s+WNpYmlusxBk3DgoWhB49zC1JkowYAWfOxC7fai6iV+w79egUfiF+tCiXeWYTZGTePqVuAawGSqF65WZ6JxYBagNLgRIJ7P8FmIV5FTooJ/Tv4vyPDjq6F/gqvYR4l9hlWf+HaoylNo2BYSjFHk1xUr+nHpdc5aH5CTCEqf8vbionunw1EkweHhlO538689D/IYd6H6J0ntJpKJz5sbC0oIpjFQD87vnhfcOb91plUO9+nU6FcAMVuu3Rowy7CEzOnPDvv+aWQiEiDN09lDu+d7g8+DJFchYxt0iZnjevmW8KDsAHmOXsz6EcqksB+0lYoQPkRCn0EFQcG3PwLbDtpW3lUDp2T3oLMwYII/XD7j5FjaUXR1kC4jZzexNrwUkrLG3AWsVe59wo2PcxXJuZoBPd8gvLOXz/MEvbLqVeiXppLFjG4sLyC6z9dC0GfSYYbujWTc1h90jLFuHr4+mppriZe5nWZe2WERQRRN9/+2Z858hMwNup1M3ERpQT3K9JJYxDb1TvOL3jbx1CuRKcf2m7DmWCP0Y6r7dSHWUKd0jFPJ+jnBr6Gdk/kvR1IKi7HIq1gQtjwOmTV5zo+tXox/7P99OjasY38aY2OYvmBIHAp4HmFiVpZs2CwEA1lz0o9aYvpjb//Qdjxqhvc1KpYCVmNp/J7ju7+fPMn+YV5g1AU+rpxDJU9NiPUePlpjIW5Zyfnk5z0c5xpVG+Yy/zPfAAM4zdFIj69ks0lWnogS4o54AvjKQRVCSg9PLRypIf7DZB7UXg7aKc6Pwu4HTPifvP72Ohs6DZu83SSZiMRc4iypoR+CQTKPUqVWD9erh4EXr1Mu+i5onQuze89x7873/mF/Hrj76mRdkWjNo3iru+d80rTCZHU+rpwO/Al0BTlNk6ORFkawIDo/K4nPqiJRU9I2QAACAASURBVMh84BrKCTyhMf3CqOEBszAcqMXrmwmGo8Y//gIaGkmzDNWQSE8rqk4H5fpBq3NQtDVXQvS0W9+OwTvTdc5BhiNnUVXjAh4HmFkSE2ndWvXYt2wx30oqSWBtDT/+CJcvqzaIOdHpdCxtt5QfGv5AqTylzCtMJkdT6mmMO2rOeTvUbKnsKchjKso37GvSPtJctFXgU1QgHGOsxUwL0DVEBf3Z/Bp5LECF+B2Fam0Zo1jUtzmGRnNVwKvaLBw2dqZIluxsLRQOvi8Phrw95CiSA8hESh1g2DD49Vf44gtzS2KULl2gWjU1bz0iwryyFM1ZlLF2Y7GysCJMH2ZeYTIxmlJPY0qgxp//QUVkSwn5UFPbIkkdy3NiFEQ5mc8j8bg67qjl4p+ksTyv0A4VM+B1lmX9EKXMf04iXbRST+v58QkQqg+l/fr2eAV5sdVhDlkDbsC+OnB9VqpEosts5CiUg577elKxfUVzi2I6Oh18+y0ULgx6Pdy+bW6JXsHCQk2x//hjtTxrRuDck3OU/a0sLu4u5hYlU6Ip9TRAUJ7jS6P+1wSsXzPPL1HLs6flasSCUuTdSXoOevTUtnRfGdUCZfo4T/JD20W/tOoCS4Ckpj4Xj/o2Q099mvM0XDxcWNlhJe+X7watL0FRBzg/Cg61gODH6S+UGbGwsqBs87LkKJzD3KKkjG++gfr14d49c0vyCq1bw+rVkC+DLHVeLl85rC2t+Xzr5wSEZZCWRiZCU+qpTCRqDHw2qTsGbhH1eQqsS8V8o4kA6hHbEEmKqqix9XSf2gbQEyiKcjQwFR9UDz05w5u5UYvJmKGnPqb+GP757B86V+6sNmTJD/abofbf8OwEnBmS/kKZmXuH7nHrv1vmFiNljBih7NsODhAaam5pEuTSJbWirLnJlSUXK9uvxM3PjRF7R5hbnEyHptRTET0qJPwiVIyUtFj8ZBoqampqO83NR0W5K5BUwih0wCeonnq6B/DMgppAb+qqN+FAR1SPu0EyytGhHBrSeq56HDwDPQnVh5LDJkesQo+RRwfl+isnuprzEs7gDcZllguHvk+tFXbSmfLlYcECtVSrOeOzJsKYMSp8/YsX5pYE7EvZM7b+WJacX8K2Gy9Hy9BIDE2ppxIG1AyptSjF+xOvvdZLgnxP6jvNPQYmoRYnS8w57mXaAh8BvqkkR7L4CDWNIKmLIKi55kdRZoiPk1nOcCCdZpGJCL229sJuqV3iQThyVYDsJSAiEE5/BaFe6SOgmclRJEfmmNJmjKpV1fcjM5h+TOCnn9SCc3PmmFsSxeTGk/mw8IfsuLnD3KJkKjSlnkpYoMbOfwPGp2E5+YHpqPH1NamU52hUsLaknONephPK/F4wleRINudQQWkSs8jOQinziShngeTij1q1LR3YfH0z+93207tab3Q6E+5E4B1wWw5H20NkxjTppiY5i+Yk8Glg5ogqlxDFojwvfXzMK4cRatVSa9PMmgXe3uaWBmwsbTjY6yCL2y42tyiZCk2pvyYvgItRv/8HfJMOZfZFdVRH8/qR5m6ixujHoELApoT0jnYXQzHUCSQWoq8gagx+UgrL+BnVcEhjPRIUHsSIvSOoVqgagz8ycU563upQd6UKVOPaP8Mv+/m6ZKqocgmROzeEhcHXXyed1kxMmaKC4P2c1MyQdCJvtrzodDrc/NzYfiMDDPhnAjSlngIeonrJg1AOY82B1HjN3L59mzp16nD27NlE01mgplk3QTm4vQ4VgOOk3LrwJ2ocPq2n2iVIIdRk+RW8Orcu+sL0Ro29p7SmF0M5SzxL4fEm8tPRn/B44cEfrf/AyiIZsfpKdoaqU+D+arg2Pe0EzABER5XLVHPV46LTgY2NuaVIlMqVYdAg1f7ISIzeP5pum7tx+Wl6heDKvGhKPQkEFV0tJOr/DNRiLD1RPdxKKJ3xuhNt/Pz8cHBw4NSpUzg5OSWZ/iNUw8JUx7YEy4z6roty8k4J1fg/e+cdHlWV/vHPZNILhCSkh5QJRRAIvUqRsGoEiYAkoCgg8NsFCwqoBEVWpAm6umJhXXcVBEwUVBCNLgoiEEroAQFDk1ACJKGkkDbz++OSmNCSTDtzJvfzPPcJuXPn3u+QmXnvOed9368S8+paXWY2plwX8HaVfdkohj11sym/NVYoa9Mb9GzJ2sITbZ+gR5MedT9Bq+kQPgIOvwMll8wv0EaI6BPBhIMTCGgTIFqK8fzzn0pfVhvmvffgFRuzOV/0wCK8Xb0ZuGIg5wvqRw6JsahB/QZKge0oS7HxKLO3rVBGs6CYmbyDspybC3x/fZ+p/N///R/Hjx/H1dWVY8eO1fp5+1Fq4us68XoWxW1tcR2fdyOdUSq/fjDxPEajAx5Bafd6GbiG8oc7hXL3ZSpWaEDjoHFg/RPreS/uPeNOoNFA14/hvu3gbAlfWtvApYELje9qjKOLxI7R27bBCksUpZoXgwHWroU6fBVZlCCvIFYPX835gvM8nPww18rsP4fEWOp9UC8EfubPXKg9KE5qU4AMlGzwj1EGfqCMTJ9BKXmuqXdJXZgzZw6ff/45y5YtY/z48bV+XhpK6Vxdvyamorz2fnV83o04oiSHp2L5Fra3ZTpKzbobSpeerSjTJ7e2Ja8bFh6pbz+9nfMF53HQOODhbEwT4etoXcEjXOk2d/CNmxze7IXti7Zz9H8SG36EhMCZMzaf/3DxIjzyiNI+1lboGNyRJQ8vYcupLczfNF+0HJul3gV1PbAaJah1RRll9gP+df3xdkAyysAsE8XTYwzK8q0l2LFjBwaDgejoaAYPHszgwYNp165drZ9fkTQ3GSVprzZsRJm6NyU5rir3o/x/HTTDuYyiNUrx/nyUu5s5KHXp5sAfZRbgXjOdrwoFJQUMTRnKsC+GmfGkJyFjFmwcBGWF5juvjfDr7F85kGKlcgRLEBKiJMvZaAZ8BY0bK63rly9XDF9shaEth7Jq2Cqm9pgqWorNUu+Cugal49s/UUaZU4C1wN+vP+6IUm8ebAUtqampdO3alXfffbdy3+nTp1m1ahVlZbWzIdOiJM1l8+druBOlKDXu4Ziv9O7B6xqErnSWo4ymn+DWfrHGokV5w1ig5fjsX2dz6sopXr/3dfOd1DMSui+H3F2Q9oTd9YmXvla9oqzNRmvVqzJ1KjRoAC+/LFpJdR6+62Hcndy5UnyFjSc3ipZjc9TLoP4zyvLrJpSa7ziUhi7W5ODBgyQkJNC6dWvGjPnTKuyHH35gyJAh/PHHH7U+VydgHMpaf0YNx+5CmYF4G+OT424kCJiAaUl7JqNFWRf5N+bv+nMEZZ3DnKfMOcLCLQt5vO3j9GzS07wnDx0I7RbAqS9h36vmPbdgvIK95M1+BwgNVQxebMU95Q74+CiBffVq2LpVtJqbeTb1WR5Y9gC7zu4SLcWmqHdBHZSMdVeB179w4QIDBgzA3d2dNWvW4On5Z+68TqdYqdQlWQ6UGedXUJLf7kQXFOfSQXU6e83koLi2FZj5vHWiFcpUi7mZjll9Zg0GA09//zRuTm68EWshr+0Wz0PUGPhtPuTbnomIsXgGecod1Lt2hbNnoaeZb+QsxLPPQvv2trlaMK/fPPzc/Ri4YiBnrtYvg6M7US+DukgMBgMJCQmcPXuWb775hrCwsGqPR0UpYfno0bolA/mi+KDfafSdjpLMFoT5B7O7UOLeL2Y+r00QijK1b6bcpmtl1/Bx82FW31kEeFpo0UKjgU4fQP/NypS8neAV7EXB+QJ5u8pJhqcnpKfDgw+KVnIzAZ4BrBm+hivFV3hoxUMUltpfDokxqEHdymg0GpKSkli6dCmdO3e+6fGQkBCcnZ3rHNQr+BXFs+TGpLmNKNP0nxh11pq5ByX5XIhrm6UJRZmCMFPrPDcnN1YMWcHTnS3cf1DrDL6dlH+fWqUk0UlO98ndeenySzg4SvzV9eSTMFeeRkEaDZSUKJV4tpa03yagDcsHL2fX2V1M/mGyaDk2gcQFn/Jx9OhRdDodsbG3dwhxcHAgMjLS6KDugpIr8HeUWntQerM8BTQBEow6a824An2w06BetVbdxOSLT/d8SsfgjrTyb1W7/u7moCQPto0F91Bl5O7kZZ3rWgCXBi6iJZjO7t1w7pxoFXXiiy/gscfA1RUefli0muoMbD6QT+M/pU9EH9FSbAKL3O6WlpYyefJkEhMTGTFiBEePHuXkyZMMHz6cESNG8Oqrr6LX16/ps6+//prmzZuzevXqGo9dtmwZb775Zo3H3YrOwFiUpLmKwp/3UJrUmDM57lbcD/yOsmZvV5ipVv1IzhHGfzueBVsWmCypTjg3gh7JcPkgbB4Bequb5ZqNgvMF/Dj1R87uurEvsEQEByu16hKRkAAtWiiZ8OU2+PYZ2XYkYQ3DKNeX1/vEOYsE9V9++YWysjI+//xzJk6cyNtvv83cuXOZNGkSy5cvx2Aw8NNPP1ni0jbJnj17ePTRR+nQoQP9+/ev8fgOHToQERFh9PXmoNTfP4XSOW4GSsCNN/qMtaOis94WC1/H6rQGvgM6Gn8Kg8HAM98/g6ujK/NiBbhlBPWHDv+EM9/CXnPW/FmX8tJy0hamcXqH7ZeE3ZaQEClK2qri6KiYvRw8qNSu2yqzNs6i+8fdSTtl5nIVibBIUI+MjKS8vBy9Xk9+fj6Ojo4cOHCgcg25V69ebNlid1/9t+Ts2bMMHDgQHx8fvv76a9zc3Gp8zrFjx3jnnXe4fNm4RVw/lMC+AaUe3/v6T0tP9jZD6c76mIWvY3UaAg+gZCMaydeHvuaHoz/wWp/XCPQMNJeyutFsAjSdCL8thAtyful5BniCRmJTF1CC+oULShMaiRg8WMmEf/VVZY3dFnm689OENgglPjmek5fkzyExBousqbu7u3P69GkeeOAB8vLy+PDDD9mxY0flGqKHhwdXb1GnmZycTHJycrV9Jbb67qkFJSUlxMfHk5eXx6ZNmwgKCqrV8w4cOMCkSZPo2rUrXbp0MeraY1Fi0GBgFtZJntDw50y13fE/wBnoXfenFpQUMOmHSbT2b83EzoJtNzu8rYzaG3cTq8NIHBwd8PD3kLsBTfPminn5lStK6zZJcHCA2bMVP5qzZyHcHN4KZsbX3ZdvR3xL1393ZeCKgWwesxkvF3lzSIzBIt/1n3zyCT179mTy5MmcPXuWJ554gtLSP01CCwoKaNCgwU3PS0hIICGheipXVlYW/fqZ2qFcDE5OTjz66KOEh4cTExNT6+dV1KofPXrU6KCuBYZe/7c184RPAs+hdOrrbsXrWpwXUdoMGhHUNRoNj7Z+lPuj76+braolcHCE0OtdCnJ3K0lzXuZoFmw9pG9Ak5CgbBJy333KZq0cT2No4deClEdSiFsWx+hvRvPlsC9FS7IqFvmGadCgAU5OTgA0bNiQsrIyWrZsybZt2+jSpQsbN26ka9eulri0zXDx4kX8/Px45pln6vzcyEilrriuDWhsgUbAGhSfdrsK6qFA7Zv8VcPdyZ05/eaYVY7JlJfArw+D1g3+kiaVu5tXkBfFV+SaurYXKoK5Xq+M3G2Vv+j+wkcDP6KFnwX6O9s4FvmzjBo1igMHDjBixAieeOIJnnvuOWbMmMG7775LQkICpaWl3HefOQxLbZPPP/8cnU7H7t27jXq+m5sbwcHBRpe1iaQBSjAXZsVqKUKos/2qwWBgwtoJ/O/o/ywiySS0ztBtCeQfhU3DQF87rwFbIPGbREZvNGOLP2tTUKBMv3/8sWglRvHccxAtweTO6Haj6RamLDMdz7Ofroo1YZGRuoeHB++8885N+z/77DNLXM6m2LZtG6NGjaJz5860atXK6PNERUVJGdRBybRPAs4BglLCzE8ocBHFr72WPYa/PvQ1H6R/QDPfZvTX1Vz1YHX8e0GnD2Hbk7DzWehkpJ+7lZG68QyAuztkZMChQ6KVGIWXF5w8qSTLOTuLVlMzS/cu5cnVT/LjyB/rRS275J8O2+LUqVMMGjSI4OBgVq1ahbMJ7/jk5GRSU+Vs5XL/9Z8/ClVhZioa0NSyvLiwtLAyOe6pzk9ZTJbJ6MbAXVPgyiEovyZaTa04lXaKlcNXUnBeqNOA8Wg0Upa1VRAerky/Z5nYt8FaDGw+EJ2PjiEpQ8jMzRQtx+KoQd1M5OfnM3DgQIqKivj222/x8zPNsyw4OBh3d0u2irEcbYFYlO52dsMAYB+1Tu+f8+sc/rj8B4viFolPjquJtvOgbypoRdoc1Z7CC4VkfJ7B5T/M1LdXBBIH9YoWGiclqRjzdvXm2+HfokHDgOUDuHTtkmhJFkUN6mbC2dmZzp07k5ycTMuWLU0+3++//86UKVPqZMFqKzigVIDJmd97G/xQmtDUYvLleN5xFmxZwGNtHqNXeC9LKzMdBy04OIlWUWs8gxRXw6tnJc6At4OgfuKESBV1Q+ejY1XCKo7lHWPYF8PQG+y3o6mNDyHkoKioCDc3N/71r3+Z7Zw5OTm8+eab9OnThyZNmpjtvNak+Pp2c/GihOiBD4G7URxz7kCThk1Y9MAiBjQbYAVh9Q+vYKXuWOqytu7dbbsu7A6EhcHYsXC98lYaeoX34l8Dle9oB439jmft95VZiU8++YTWrVuTZeYFpqq16jKSjzK4/adoIebCAXgJWHnnwwwGA1oHLeM6jCPIq3bNhlTqhl10lXv6advut3oHnJ3ho4+glwSTUDcyKmYUo2JGAZBblCtWjIVQg7oJGAwGpk6dSkhICAEB5vXF9vPzw9PTU9qg7gm0wM5K22ooayssLaTjRx358mD9anZhbRwcHfBr4Wc2f3uVuqPXQ06OaBXG8/3v39PyvZYYbM1L1gyoQd0Ejhw5wsWLF3niiScqm+2YC41Gg06nk7IBTQX3AWmA3aSlhHJHp7a5v85l19ld+Hv4W01SfWXiwYn0fa2vaBnGs2cPBAbCj3LWiIwapZTay8qxvGNkF2RzLl8uC9zaoAZ1E9i6dSuAxbrj6XQ6ciS+Hb4fKAfsxo/vDiP1zNxM3tjyBo+2flSO5DgVsXh7Q3Y2nDolWolRhIUp0svk6VlUjWgfpXuOPZa4qUHdBNLS0mjYsCEtWlimFeHnn39OWpqcbloAXVCS5OxmCj4Uxcv2Bj/pCltVF60LC/pb2Su9npK+OJ3PB30uWobxVJg7SearXkFEhOKrLql8uw7qtc5+T0tLo6CggJ49e+LqKkc9q6VJSEigQ4cOOFioCbK5p/StjROwGMWS1S6YjOJUc8Ofe8eZHXyf+T1v/eUtNTnOSlw9c5XDaw6jL9PL2WHOxQX8/OyirE3G4pwmDZug1WjtMqjX6tPwj3/8g0OHDnHq1CkmThRsHWlD9O3bl3Hjxlns/EePHiUhIYFdu3ZZ7BqWJhFoL1qEuWiEYk5/QyVS55DObHhig213jrMzvIK8wIC8XeVA6lr1CttVWRrQ3IiT1onH2jyGzkeyurxacNugPmfOHHJzlZT/y5cv07lzZ7p27XpLH/T6yMmTJ9m8eXM1S1lzo9FoSElJYe/evRa7hqUxAN8D60ULMQc5wDQg/eaHekf0xkkr98yKTNhFrfqwYXLWhaGMzmfNgrZtRSsxnk/iP2FMuzGiZZid206/jxw5koULFxIREcHYsWNJSUnh2rVrvPbaa9bUZ7MsW7aM6dOnk5ubS6NGjSxyjbCwMLRarbRlbaAMaicDYYDEucoK5cA8FF91iTN/7QG76CqXlCRagdG4usLLL4tWYTpl+jK0Gi0aSRsB3YrbjtTDwsKYM2cOHTt2ZMGCBTRt2pSkpCSLJYXJRlpaGi1atLBYQAdlTT08PFzqoA5KFvwvQKFoIabih9ImVhIjC3umQWgDAtoEoHGQ/Mu4pEQp+paQCxfgt99EqzCej3d9jNtsN3KK5K0wuhW3DeppaWlMmDCB5cuXM2nSJDQaDc888wzp6beYe6xnGAwGtm7dSrdu3Sx+LZktWCu4D6Vd7EbRQkzFAWWULucyqF3hFeTFX/f+lWYPSpyGuWSJkjAni93ZDTz9NDz0kGgVxuPv4U+ZvszukuVuG9Tffvtt5s+fz9SpU3n77bcZMGAACxYskDppy1wcPXqUixcvWqw+vSpt27bFy8vL4texJL1QLMjlNJK9gRoa0Kio1JoKJ0dJk+UiIpREOUknGirL2o7myj1oupHbrqn7+fmxaNEiioqKaNq0KQAuLi6MHz/eauJslYqmM9YYqS9cuNDi17A0bkBvbplfJh+hwAHRIlQAvhn9DRqthof+LelwMSRE+SlpUA8Ph9JSOHv2z5ciE5GNItGgsbuR+m2D+qJFi/jtt99wd3cnoqIoUQWAIUOGEBERYRaL1frCMpSKMOn5FKUAX0U4BecLyD+XL1qG8Uge1Kv6qssY1F0dXQlrGEZmnn0F9dtOv2s0Glq2bKkG9Fvg5uZGz5490Wq1Fr/WqVOn6N69O2vXrrX4tSyJL3bSvtCZm+rUVcTgGeQpd0mbr69ieSZ5UJfJV/1Gnu78NH+J+otoGWbFLr5nrUlBQQEvvfQSBw8etMr1GjZsSFpaGhkZGVa5niWZCTwtWoSp7AdGAvZ1cy8lXsFeFJwvQF8m6aKuRgPTpklbqx4ZCf/9r2INLytTuk9hZNuRomWYldsG9e3bt1NeXn67h+st6enpzJ8/n+PHj1vleg0aNMDPz09qt7YKzqLMXluuXY8VyAc+A46IFqLiGeSJQW+Qu6vczJkwYIBoFUbh6qq4tck8mas36Mm6kkVJeYloKWbjtkH9wIEDPPvss7z44ousXr2aS5fsxkDTJCztzHYrdDqd9GVtoNSrX0WxY5WW0Os/5ZwxtSsat2xM07imlJdKPPgoLpbWqQ3gwAHYKHGt6teHvibsH2FknJd/JrSC2ybKjR49mtGjR5Ofn8/GjRuZP38+V69epU2bNvU6Az4tLY2mTZvi6+trtWtGRUVJ7dZWwb2AFsW1Tc4JRyAQZU1dLWsTTkTvCCJ6R4iWYRrTpsHixZCfr0zHS8bMmbB/Pxw6JFqJcVR1a2sfZB8uFTW6tHl6ehIXF0dcXBwGg4E9e/ZYQ5dNUtF05r777rPqdXv06MG1a9cwGAxStzNsCHRHqVefLViL0TihBHY1qKuYg5AQKCyEy5cVj3XJCA+Hb78Fg0HKexKiGkUB9mXBWqdEOY1GQ7t27Sylxea5cOECxcXFVp16B5g4cSKrVq2SOqBXMBxox02W5HLRAjUD3gYw6A28HfE2G2dLPP9rB2Vt167B+fOilRiHp7MngZ6BdtWAptZ+6irg7+9PTk4OZWVloqVIy99ECzAHP4sWoAKgcdBQVlTG5ZOXRUsxnqpBvVUrsVqMoMKC9cQJCAgQKsVoon2i7apWvcaR+qxZs/hN5q79ZsbBwQFnZ2erXvPixYuEhYWxePFiq17XUhhQ88xUzINXsBf5Z9UGNKKo2oBGViZ3m8xzXZ8TLcNs1BjUe/fuzYcffkhiYiLLly8nP1/iD5CJPProo7z55ptWv66Pjw8XLlzg999/t/q1LcFTKFPwklYXw2qgDyBxJZW9IH0DmpAQWLAAOnUSrcQomjaFdeugXz/RSownvkU88S3iRcswGzUG9V69evHOO+/w/vvvs3PnTnr27MlLL73EaUnvLI2lqKiIlJQUcnKsb9Pn4OBgF25tFXQDLgC7RQsxlssoXrL16yNgk3gFe8kd1F1cYMoUuPtu0UqMwtVVCehWLAYyO4WlhaSdSiO3KFe0FLNQY1A/evQoCxYs4LHHHsPLy4vly5czYsQInn5a+t5gdWLXrl2UlZVZPUmuAp1OZxcNaAAqmjL+IFSFCVT0uVaDunAi742kxcMtMBgMoqUYz6lTSsG3pPz8M6xaJVqF8Ry8cJDu/+nOLyd+ES3FLNSYKDd9+nQSEhJ4+umncXV1rdw/ZMgQiwqzNSrqxEUF9aioKNavXy99WRuAP9AepbQtSbAWo6hoQKOWtQmn9YjWtB7RWrQM0xg/Hi5cgHQ5fQzffReOHIHBg0UrMQ5dIx0AR/PsYya0xpH6/PnzcXJywtXVlTfffJOsLOWb7NFHH7W4OFsiLS2NqKgo/P39hVy/X79+PPHEExQXFwu5vrm5H9iCMpMtHepI3abQl+vl7f8Oyrq6xMuZERFK9ruskyWN3Brh6+ZrN7XqNQb1F198kcaNGwPK+vr06dMtLsoWCQ8PFzo78dBDD/Hee+9Vmy2RmceBLwEX0UKMwQPofP2nilDO7TnH6y6v8/v3EieRhoRAdrZiTi4hERFK/xwB6UZmI9on2m6Ceq3q1Lt06QJAp06d0OslviM2gbfeeku0BMrKyigpKcHd3V20FJNpfn2Tlm2iBagAuPu5Yyg3yJ0sFxKiDHPPnYOwMNFq6kxVC1Y/P5FKjCfaJ5rNpzaLlmEWahypN2jQgOTkZA4fPswXX3yBh0f9G55UtGgVSXFxMe7u7ixcuFCoDhUVW8IjwAM0qLXqAqnagEZWJnebzJL4JaJlmIUag/q8efPIzMxkwYIFHD16lDlz5lhDl02RlJREVFSU0FkKFxcX/P397aasTXreQGlkryIUrZMWj8Yeco/UO3aEzz+H6GjRSozirrvg8GEYOFC0EuNpF9SOe8LvES3DLNQ4/e7j48O4ceMoKyvDYDBw8uRJfHx8rKHNZkhLSyM0NBQHhzq1yjc79mLBahcUAFtRzOGdBGup50jfVS4gABISRKswGhcXaNZMtArTKCgpYO3va2kX2I6mvk1FyzGJGoP6tGnT2Lt3L0VFRVy7do2wsDBSUlKsoc0mKC4uZteuXTz77LOipaDT6UhNTRUtQwWUsjYDcBZoIlhLPafd2HY4ukpuY/Hrr+DlBTExopUYxYoVUFAAY8eKVmIchaWFJHyZwDv3vyN9UK9x6Hn8+HHWrl1Lz549Wbt2LS4uUuYrG83u3bspKSkRVp9eFZ1Ox9mzZyksLBQtD0hUwwAAIABJREFURUUta7MZOk/sTPsnJffCHjkSBLSgNheffw7//KdoFcbj5+5HA5cGdpEBX+PtrYeHBxqNhsLCQnx8fCiVtOzCWCqaznTr1k2wEujfvz9arVZ1ibMF1AY0NoO+TE/B+QI8Az3ROEjamEnyWvXwcNiwQV5fdY1Gg66Rzi6Ceo0j9VatWvHxxx/j7+/Pc889R3m51E7YdaZr1668+uqrBAUFiZZC586deemll2jQoIFoKSphKP1uG4oWorLzo528FfIW+dkSr6sHB8OZM6JVGE1EBFy5ApcuiVZiPPZSq17jSD0+Ph5/f39cXV3ZuHEjbdq0qfGkq1at4quvvgKUNenffvuNpUuXMnv2bLRaLT179uSpp54yXb0V6Natm02M0gEMBgOnT59Go9EQUlEGoyKGRkjcvN6+8Ar2AuDqmat4BXkJVmMkISEgcb5M1bK2Ro2ESjGaaJ9ovjr0FWX6Mhwd5M3RqHGkPn36dDw9PXF0dOTee+/FrxbdBQYPHszSpUtZunQprVq14uWXX+bVV1/lzTffZMWKFezdu5cDEhgYXL58me3bt1NSUiJaSiWtWrVi7ty5omWoqNgMFYFc6gz4kBDIz1eGuxJS0YBG4hUEnur8FIefOoxWoxUtxSRqDOru7u7MmTOHFStWkJycTHJycq1Pvn//fjIzM3nwwQcpKSmhSZMmaDQaevbsWblWbcusW7eOLl26sHu3bZiEajQau3Jrk54RQKxoESpVR+rSkpAAmzYpXqYS0ratkv0+YIBoJcYT7BVMVKMo6Q2zapxjaNeuHYBRPuKLFy9m4sSJ5Ofn4+npWbnfw8ODU6dO3XT8rW4aRI6St27dirOzMzE2VGYSFRXF/v37RctQAeWWWG0bIJyKrnJSB/UmTZRNUhwdlU1mSspLWLR9ER2DO9IrvJdoOUZT459hsJF+eleuXOHYsWN07dqV/Px8CgoKKh8rKCi4ZbJXQkICCTc0YcjKyqJfv35GaTCVtLQ0OnToYFNlfDqdjtWrV1NeXo5WK/c0kfSEAGcAPbWY81KxFFonLX9Z+BdCu4bWfLCtcu0afPmlUqd+992i1RjFm2+CXg9Tp4pWYhxODk68/PPL/K3j3+w7qD/33HNoNBr0ej1ZWVmEh4ezYsWKGk+8Y8cOundX+mh6enri5OTEH3/8QVhYGJs2bbL5RLmSkhLS09OZOHGiaCnV0Ol0lJaWcvr0aZpIfGdvF4QCJcBFFJN4FWF0e942klmNRq9XatVnz5Y2qP/8M5w9K29Q12g06Hx0ZObJnQFfY1CvOh1+5coVZsyYUasTHz9+nNDQP++c//73vzNlyhTKy8vp2bMnbdu2NUKu9di7dy/FxcU20XSmKrGxsXz22Wc0bKjWUgmn4u19GjWoC6bgfAEF5wvwv1vSP4S7O3h7S51pFhEBEqRK3ZFon2iO5BwRLcMk6rQK4uXlxR9//FGrY8fe0C8wJiZGqvayrVq14ueff7a5m4+oqCiioqJEy1ABaAmMAeR3wpWeddPWkfl9JpPPTBYtxXjsoAFNXp6SwC9rK43oRtGkZqaiN+hx0Mi5plZjUE9ISKjMBszJybGZmm1L4+7uTt++fUXLuCXbtm3DxcXFphL46iXNgY9Fi1ABJQO+ILsAfbkeB62cX8ayB/WKsraTJ6F1a6FSjCbaJ5rismLO5Z8j2CtYtByjqDGov/XWWxgMBjQaDRqNhuBgOV9oXVm4cCF9+/alQ4cOoqXcxKOPPkqHDh3qVF6oYiEMwDXATbSQ+o1XkBcGvYGC8wVyN6CRuLIlPBx8fSE3V7QS4xnZdiRPxDyBq6OcpYVQi5zdzZs3s2TJEkJCQnj55Zf5+uuvraFLKNnZ2UydOpUNGzaIlnJLVAtWG6IpMEG0CBW7qFV/7TXYulW0CqPp3BkuXoTevUUrMR53J3epAzrUIqivWLGCyZOVdarFixfXKvNddrZe/2DZ6lKD2oDGhmiM6tRmA9hFUA8NlbpWXfKeLZW8+L8XWbJ3iWgZRlNjUHdwcKis03ZycpK+205tSEtLw8nJifbtbdPOMSoqiry8PPLy8kRLUQlBdWqzAXyb+RK/JJ6gduKNl4wmKwvmzoXjx0UrMZrJkyEpSbQK0/jm8DesObJGtAyjqXFNvV+/fowYMYI2bdpw4MAB7r33XmvoEsrWrVtp164drjbaslGn0wFw9OhROnbsKFhNPScU+FG0CBVXb1fajrStSpU6c/68EhFbtIDISNFqjCIjQ1lTnzNHtBLjkd2trcagPmHCBPr27cvx48eJi4urlUubzOj1eg4fPsywYcNES7ktvXr1YsOGDbRo0UK0FJUQ4CpwBZC0jMdeOJN+Bo2DhqD2ko7WK5wXJc+AtxGrDKOJ9onml5O/VCaIy0aNQT0lJYXMzEySkpIYM2YMDz30EPHx8dbQJgQHBweysrIoLCwULeW2+Pr60lvmbBR7ohfwKkoWvIpQVo9dTcOwhgxfM1y0FONo3FhpoC55UL9wQTF38fAQrcY4dI105Jfkc77gPAGeAaLl1Bk1Ue4WaLVavLxsuyzm22+/5bvvvhMtQ6ULMBNQG/wJxyvYS+5EOQcHCAqCM2dEKzGaCl/1WvYos0mifaIJ8AgguyBbtBSjqHGkXt8S5V599VX0ej2zZs0SLeWOzJ49Gzc3N+Li4kRLqd8YgPOAE+AjWEs9xzPIk3N7zomWYRqSN6Bp2lTxpLHhic4auT/6fs5Nkfd9pCbK3cDy5ctpLUE7JJ1Ox6ZNm0TLUCkGAoFZwMuCtdRz7KKr3Nq1YOOzhHeiUyf519RlH7jWKVEuPj6eRo0aWUOXEC5cuEBmZibjxo0TLaVGdDodK1asoKSkBGdnZ9Fy6i+ugC9qrboN4BVsB13lfNTpHlvg6e+exsvFizn95Evjr9Xt7F133YWPjw/vvfee0f7qMrBt2zYAm3NmuxVRUVHo9XpOnjwpWopKKGqtug3QbEAzHv/pcVy9bbMUtVakpcGECZCfL1qJ0SQmgo05VteZwzmHWXdsnWgZRnHHoF5YWMiyZcsYMGAAzz77LPfddx/r16+3ljark5aWhlarlaL2u2qtuopgQlBH6jZAw7CGRN4biZObk2gpxnP0KHzwgdTr6jk5sHOnaBWmIXOt+m2D+qxZs3jkkUc4f/487733Hq1bt2bAgAF2PdXr4eHBgw8+iLu77XtpduzYkaNHjxIbGytaioo6UrcJykvKOZBygPMZ50VLMR47qVU/cUK0CtOI9okm71oeuUXyudPcNqjv3LmTVq1a0bZtW8LCwqRPHqgNSUlJfPPNN6Jl1ApXV1eioqJwdKwxLULF0owA5qLWqotGA18mfMnBlQdFKzEeOwjq4eGQnQ1FRaKVGE+0TzSAlKP12wb1r7/+msTERP73v/9x//33c+LECbue6i0vLxctoc4sXbqUDz/8ULQMld7Ak4D93/faNFonLR7+HnLXqttBUK/wVZe5Vr25b3M6BnektLxUtJQ6c8dhXvv27Wnfvj35+fmsXr2aqVOnArBq1SqriLMm//73v5k1axa7d++mcePGouXUii+++ILjx4/z17/+VbSU+s014AAQgZIJryIMzyBP8s/Km2SGh4eSAX9V3huTli1h4EAwSDxz1dyvOTvG7RAtwyhqNXfr6enJiBEjGDFiBL/99pulNQkhLS2NkpIS/Pz8REupNTqdjp9++knaHsV2w1GgI7ACSBSspZ4jfVc5UPqsOkhaZw+0bw+rV4tWUX+p8zvnrrvusoQO4WzdupWuXbtKFRx1Oh2FhYVkZ8vZztBuCL3+U02WE470I3WQOqBXReaROsDEtRMZsHyAaBl1xj7ePSaSm5vL4cOH6datm2gpdUIta7MRGgAeqGVtNkDvV3rzxIYnRMswjSVLYPRo0SpMokcPePxx0SpMo6S8hB1n5JuCr1VQz8nJ4cyZM5WbvSFT05mqREVFodFo7PJvIhUa1LI2G8E7whvfppInNhw+DEuXgoTJuxW4uMCxY6JVmEa0TzTnC85ztViu5Zwa19RnzpzJxo0b8ff3r1y7/fzzz62hzWoEBwczceJEOnXqJFpKnWjatClFRUWVhjsqAglFHanbAFeyrnAg5QAtH2lJwzBJrfNCQpSAfv684tomIeHh8L//iVZhGhVlbUfzjhITGCNYTe2pMajv27ePdevW4WAn6zy3om3btixatEi0jDpT1UFPRTAzRAtQAbhy+go/Tv4R32a+cgd1UMraJA3qERGKg2xJCcjar0znoyxvZuZmShXUa4zU4eHhFBcXW0OLEPR6PXv27KGsrEy0FKN4//33eeGFF0TLUOl1fVMRilewYuRy9axcU6bVsINa9fBwJVHu1CnRSoxH10hHfIt4fNzkMtmpMaifPXuWvn37kpCQQEJCAomJ9lWzc/DgQdq1a8fy5ctFSzGKXbt2sWTJEtEyVLKBrwGJY0lhYSH5tzESyc7OpqysjBdeeIHBgwczY8YM9Hp9na+h1+uZMWMGCQkJjBw50uyGRJ4BngByl7WFhipbqXyNTypo317xpXGSuA2/l4sXXyV8xb2RctmN1zj9/uabb1pDhzC2bt0KyJckV4FOpyM7O5v8/Hw8PT1Fy6m/bAMeBnag1KxLyPbt27l8+TKDBg26af/atWtp3rw5Op2ON954g0WLFpGamkpcXFydrrFu3TpKSkpITk5mz549zJs3jw8++MBsr0HrrMW9sbvcZW2BgXIPcYE2beC990SrMA8l5SU4a+VZQ6hxpK7Vapk/fz7jx49nzpw5GGQvPryBrVu34uPjQ9OmTUVLMYqoqCgAjh8/LlhJPef6jKnMyXIZGRmVlSAVnDx5knnz5uHj48PevXuJj48HYMiQIWzYsKHasampqYwcObLatm/fvmrH7Ny5k3vuuQeAmJgYMjIyzP46vILsoAGNHVBWBleuiFZhGs98/wy6f+pEy6gTNY7UX375ZYYPH06nTp3Yvn0706dP59NPP7WGNquQlpYmXdOZqlStVW/durVgNfUYMzSg6fNJn5v2DWs1jAmdJlBYWkjcsptHxaNiRjEqZhQXCy8yNGVotcc2jNpQp+vn5eWxZcuWyt8vX77Mpk2biI6OJigoiH379uHjo6wv+vr6kpOTU+35999/P/fff/8dr3HjjJJWq6WsrMysxkSP/fAYLg0kTyCdOhUKCuD990UrMZqmTeGee5Sye1nx9/An60oWRaVFuDm5iZZTK2ocqRcXF9OvXz8aNGhAbGystAllt+LSpUscPHhQuqYzVdHpdAQEBFBYWChaSv2mMeCEtCP1kpISmjRpglarJT09ndLSUlJSUkhMTOTcuXMEBATg7e1Nbq5iRZmTk4O/v3+1c9RmpO7p6UlBQUHl73q93uxOg56Bnji5S7yYC4qv+i+/iFZhEmFhYOaUCauja6QMmo7lyVN0X+Onqby8nMOHD9O8eXMOHz4s7Yj2Vri5uZGamlo52pWRRo0ace7cOdEyVByAYEwaqd9pZO3u5H7Hx/3c/eo8Mq/Kli1b6N69O6dPn2blypXs37+fxMREtFot2dnZBAYG0qNHD9asWcPYsWNZuXIlMTHVy3xqM1Jv374969evJy4ujj179tCsWTOjNd+OPzb9wW+rfqP/gv44aCUtxQ0JgZ9/Fq3CJCIipL8vqWbB2sq/lWA1taPGoP7KK6+QlJTE+fPnCQgI4PXXX7eGLqvg4uLCfffdJ1qGir2QgjJil4j09HScnJw4cOAAffr0ISEhgccff5wJEybg5aWUh2VnZ9OwYUMGDBhAUlIS8fHx6HQ6o9wB+/fvz+bNm0lMTMRgMDBnzhxzvySy92Wz9R9b6T61O15BXmY/v1UICYHLl5UpeA8P0WqMIjxcqcorKwMzT8ZYDRl91Wv8rz537hwrV66s/P27776jRYsWFhVlLZYtW4ZOp5M2872Ct956i19++YVvvvlGtJT6TWfRAurOpUuX+Pjjj5k/fz6gLOckJycTGhpaecyQIUNYsWIFY8eOZeHChSZdz8HBgddee82kc9RERa16/tl8uYM6KFHRArMZ1iAiQmmMl5X1p8e6bDRya8SUblNoH9RetJRac9ugvn79enbt2sXatWvZvXs3oKx//fTTT3UuY7FF9Ho9Tz31FI888oj0Qf3ChQt89913lJeXo9VqRcupv+wHfgX+htIPXgJiY2OJjY2ttq9qQAdltk4mPIP+rFUPai9nRzZ0OujSRWnJJindu8PcueDuLlqJaSz4ywLREurEbYN6ixYtuHTpEi4uLkRGRgKg0Wh48MEHrSbOkhw5coRLly5JnSRXgU6no6ysjFOnThEh6y2xPfA/YDIwAvAWrKUeYxdd5bp3h+s9NGTlrruUTXZKykvIupJFVKMo0VJqxW2DeuPGjXn44Yd54IEH7LLve1paGiBv05mqVNSqHzt2TA3qIqmoVc9CDeoC8Qz0BA0U5RSJllLvqeihExYmVocpvL7xdWb/Opui6UVSNKG5bbR+8cUXAYiLi+OBBx6ozGx94IEHrCbOkmzduhVvb2+aN28uWorJqL7qNoIZatVVTEfrpGV60XR6vtRTtBTT6N0bZsjtFNS1K7z6qmgVphHtE43eoOfEpROipdSK247UK9rD/ix5WcXt2L17N126dLGLWYjQ0FC6du2Kh6RZsnaDHXSVsxccXSRNt67K+fNw8KBoFSYRHg4nTohWYRoVtepHc4/SzNf2kxZrfOdv3ryZTz75pJpTmz0YiGzevLmykYbsaLXayuUEFYEEX/+pjtSFk744nbxjefSf31+0FOMJCZHaqQ2UrPcbOg9Lh2xlbTUG9blz55KUlERgYKA19FgNJycnAgICRMtQsSecgUP8OQ2vIozT209zNPWo3EE9OFj67i0REfDFF0ppm6yFOf4e/ng6e9pPUA8KCqJ79+51PvHixYv5+eefKS0tZfjw4XTu3JmXXnoJjUZD06ZNefXVV4VNfX/66afs3r2bt956yy6m3wHeeOMNFi9eTGZmpl11/ZMO+VM07AKvIC/yz+WjL9fL3VXuzBnQ60HS76nwcKX5zNmzipusjGg0Gv55/z9p7ifHh7vGoO7r68uMGTNo2bJlZbBISEi443O2bdvG7t27WbFiBUVFRfznP/9h7ty5TJo0iS5dujBjxgx++ukn+vcXcxf9xRdfcOzYMbsJ6ACOjo4cO3aM3NxcfH19Rcupv6wFDgPPixZSv/EK9sKgN1B4oVDJhpeRjh0hPh6KiqTtKhcbC599Bg0aiFZiGqPbjRYtodbUGNQrGlFcvHix1ifdtGkTzZo1Y+LEieTn5/PCCy+QkpJC585Ky61evXqxefNmIUHdYDCwdetWHnroIatf25JUZMAfO3ZMDeoiWQskI2VQLywsRK/XV3NRqyA7OxtfX1+SkpLIzMzk7rvvZubMmUbdGMfHx1e2oA0NDWX27NnMnDmTw4cP4+zszOuvv054eLhJr6VqAxppg/qQIcomMTqdsslOTmEOe87toU9EH7QOtr2OUGNQ79KlS/UnODpy7ty5O66x5+XlcebMGT788EOysrL429/+hsFgqBzpe3h4cPWqmMYQmZmZ5OTk2EXTmapULWvr1KmTYDX1mFAgFygC5HBqrGT79u1cvnyZQYMG3bR/7dq1NG/eHJ1OxxtvvMGiRYtITU2tc3fJioTbpUuXVu778ccfKSkpITk5mT179jBv3jw++OADk15Lg5AGuDd2p/hqcc0H2zoGA0i8pJaWpozUW8nhh3JLvjr0FePWjOP4s8eJ8I4QLeeO1BjU3377bS5evEirVq04ePAgTk5OlJSU8MgjjzB27NhbPsfb25uoqCicnZ2JiorCxcWlmpNYQUEBDW4xH5OcnExycnK1fSVmbpNYkSVub0G9ouvfsWPyWATaJVXL2qJFCqk7GRkZnDlzplpQP3nyJPPmzaN3797s3buX559XpiCGDBnCP/7xj2pBPTU1lWXLllU759SpU2nTpk3l74cOHaKoqIgxY8ZQVlbG888/z86dO7nnnnsAiImJISMjw+TXEtI5hKnnp5p8HqGcPw8tW8Ls2fB//ydajdE8/DAMHAgffSRaifFUzYCXPqi7urqyevVqXFxcKCkp4emnn+bdd9/lscceu21Q79ChA0uWLGH06NGcP3+eoqIiunXrxrZt2+jSpQsbN268ZSe3hISEm9brs7Ky6Nevn5Ev72auXbtG8+bNucse+hdWwcPDg1GjRtG0aVPRUuo3VRvQ1DGo9+lz875hw2DCBCgshFsNikeNUraLF2Ho0OqPbdhQt+vn5eWxZcuWyt8vX77Mpk2biI6OJigoiH379uHj4wMouTY5OTnVnl8b61VXV1eefPJJHnnkEU6cOMG4cePo0qVLtSl/rVZLWVmZ2X3WpcPHB/Ly7KKsTfZa9apBPTYqtoajxVLjpyYvLw8XFxcAnJ2dycvLw9nZGb1ef9vn9O3blx07djB06FAMBgMzZswgNDSUV155hbfeeouoqChhlqfjx49n/PjxQq5taf773/+KlqBSMVI/K1RFnSkpKaFJkyZotVrS09Np27YtKSkpjBkzhh9++IGAgAC8vb3Jzc0lICCAnJwc/P39q52jNiP1yMhIwsPD0Wg0REZG4u3tjV6vp6CgoPIYvV5vloC+euxqfJv70mNqD5PPJQRHRwgIkD6oh4fDrl2iVZhGsFcwLloXKcraavzk9OvXj+HDh9OmTRv279/Pvffey/Lly2scEb7wwgs37fvss8+MV6pSK4qKinBzk2wx155oClwBjHD8vNPI2t39zo/7+dV9ZF6VLVu20L17d06fPs3KlSvZv38/iYmJaLVasrOzCQwMpEePHqxZs4axY8eycuVKYmJiqp2jNiP1L7/8kiNHjjBz5kyys7PJz8/nnnvuYePGjcTFxbFnzx6amclq9MyOMxReKASZZ+HtpAHN119LXZmHg8YBnY/OPoL6xIkT6devH8eOHWPo0KE0bdqU3Nxchg8fbg19KnVgwYIFvPTSSxQUFODq6ipaTv1Ei1EBXRTp6ek4OTlx4MAB+vTpQ0JCAo8//jgTJkyozFDPzs6mYcOGDBgwgKSkJOLj49HpdPz1r3+t8/WGDh3KtGnTGD58OBqNhjlz5hATE8PWrVtJTEzEYDAwZ84cs7w2r2Avrp6R2KkNlKAuuadDRITiIHvunNJPR1Y+ePADfNx8RMuokRqD+rlz53j//ffJzMwkMjKSadOm3eS3rGIbBAYGotfrOXHiBC1atBAtp/7yj+s/nxOqolZcunSJjz/+mPnz5wNKFUVycnK1z/iQIUNYsWIFY8eOZeHChSZdz9nZudJXoiqvvfaaSee9FZ5BnmTvzzb7ea3KQw9JvyA9cKCS+e5j+/HwjvQK7yVaQq2oMai//PLLDB8+nE6dOrF9+3amT5/Op59+ag1tKnWkaq26GtQFkgrkIUVQj42NJTa2euLPjTftr7zyijUlmQ2vYDvoKjdmjGgFJhMaKm83uaqcuXqGH4/+yKDmg2jk1ki0nNtS4zu9uLiYfv360aBBA2JjYykvL7eGLhUjUC1YbYQQVKc2G8C3mS+BbQMpuWreslirU1QEpaWiVRiNwQDJybB1q2glppFxPoPR34xmX/Y+0VLuSI1Bvby8nMOHDwNU/lSxTfz9/fHw8FBr1UUTCpwDykQLqd+0fbwt43eOx9Vb4vyS9euVLMkqpYayodHAU0/BJ5+IVmIasri11Wr6PSkpiQsXLuDv78+sWbOsoUvFCDQaDdOnT6d169aipdRvQgE9SmC3g2lHFYFUdO6UPAPeHnzVmzRsgqODo/xBPTo6mlmzZtGyZUvWrVtHdLRkbbLqGdOmTRMtQSUEaAhcRA3qAinMKWR53HK6Pt+VuxPuFi3HOEKuNz6QPKhHRMCBA6JVmIajgyOR3pEczbPt5c0ap9+nTJnC3r17ATh+/DgvvfSSxUWpGE9JSQlHjhy5Y3MgFQsTB1wCYmo6UMWSuHi5cHr7aXIO59R8sK3i5aU4tJ05I1qJSUREwMmTyvq6zET7RNv8SL3GoJ6dnV1Zkz5u3DjOnz9vcVEqxvPvf/+b5s2bV+u1r2Jl5PXesCu0zlrc/dzlrlXXaOyiAU14uJLvd+GCaCWm8V7ce3z/6PeiZdyRWtV5HD9+HIA//vhDHQHaOGoGvI0wBvhQtAgVr2Av8s/mi5ZhGpMmSW/BOnw4HDsGsrtCRzaKJMAzQLSMO1LjmnpSUhKTJk2q7PX897//3Rq6VIwkKioKUIJ6hfOVigB+AYqBujddUzEjdtFV7m9/E63AZPz8lE12zlw9w392/4dhrYbRzNc87YzNTY0j9bZt2/LZZ5/x73//m6VLl6qZ1TZOeHg4Dg4OalmbaEJRnNokorCwkPz8W49qs7OzKSsr44UXXmDw4MHMmDHDpFm7vXv3MnLkSEAxcJkxYwYJCQmMHDmSkydP3nF/XQjrEYZ/G/+aD7Rlrl2D339XmqdLil4PCxfCTz+JVmIaV4uv8sr6V9iWtU20lNtSY1D/4YcfGDlyJFOnTuWTTz7h/ffft4YuFSNxdnamSZMm6vS7aCRsQLN9+3Z+usW37vbt23n//fdJSUlBp9OxatUq/P39SU1NNeo6H330ES+//DLFxcUArFu3jpKSEpKTk5k8eTLz5s274/660OvlXgz6eFDNB9oyH30EzZop/rqS4uCg2MJ/9ZVoJaYR4R2Bg8bBppPlagzq//3vf0lJScHb25sJEyawbt06a+hSMYF58+Yxbtw40TLqNyEoI/W6ZPv26XPzVnETXVh468crOnpcvHjzY3UkIyODbduqj0BOnjzJvHnz8PHxYe/evcTHxwNKP/gNN9jCpaamMnLkyGrbvn03d99q0qQJ7777buXvO3furFwqiomJISMj44776x0VLih2kAEve626i6MLYQ3CyMyz3aBe45q6g4PIs9AiAAAgAElEQVQDzs7OaDQaNBqNauspAQkJCaIlqDS9vuUjjWtbXl4eW6p0Lrt8+TKbNm0iOjqaoKAg9u3bh891Vw5fX19ycqqXitXGehXgvvvuIyvrz7WJ/Px8PD09K3/XarWUlZXddn9dvNaPrz/OV499xYi1IwiMCaz182yKqrXqMfLWSYaHQ6btxsJaE+0TzdFc250JrfHT0bFjRyZPnkx2djYzZsxQ19QlIDc3l927d9O9e3f1JkwU469vdUGgoXpJSQlNmjRBq9WSnp5O27ZtSUlJYcyYMfzwww8EBATg7e1Nbm4uAQEBlYmzVUlNTWXZsmXV9k2dOpU2bdrc8dqenp4UFBRU/q7X63F0dLzt/rrg5O7E1TNXuXL6in0EdYmJiFDW1A0GpVJPVqJ9oll9eLVoGbelxk/I888/z8aNG7nrrruIiori3nvvtYYuFRP46aefGDZsGLt37yZG4jt7FeuxZcsWunfvzunTp1m5ciX79+8nMTERrVZLdnY2gYGB9OjRgzVr1jB27FhWrlx503urtiP1G2nfvj3r168nLi6OPXv20KxZszvurwteQco0idRlbYGBShS0g6Cenw95eXLbsC78y0Lei3tPtIzbcts19bKyMn788Ue2bt1Kr169GDt2LK1bt2bSpEnW1KdiBFUtWFUEkQfcA3wuWsidSU9PZ+/evRw4cICmTZuSkJDAxo0biY2NxctLCYjZ2dk0bNiQAQMGcOjQIeLj4zl+/DhDzFQ73b9/f5ydnUlMTGTu3LmVrY5vt78ueAYq0/dSl7U5OcEHHyjG5BIzfrySyC9zQAfwdPZE66AVLeO23HakPmXKFLRaLRcuXCAzM5PQ0FCmT5/O448/bk19KkagNqCxAbyALUBf0ULuzKVLl/j444+ZP38+oLx3kpOTq3mqDxkyhBUrVjB27FgWLlxoluuGhoaSkpICKHk7r7322k3H3G5/XbCLrnIA//d/ohWYjLu7aAXmIacwh2k/TWP43cPpG2l7H/DbBvU//viDVatWUVJSwpAhQ3BycmLJkiWVAUPFdmnYsCE+Pj7qSF0kjkAgNl+rHhsbS2xsbLV9VQM6wCuvvGJNSWan9aOt8btL8s4nWVlK9nvnzqKVGE1pKUyZAv36wUMPiVZjPG5Obny06yOaNGwiV1CvyDp1dnZGr9fzn//8B29vb6sJUzENnU6njtRFI2Gtuj1y/9t1X+e3OWbPhi++kLpW3dER/vtfJVFO5qDu7uROsFewzdaq1yqV1NfXVw3okvHOO+/g4eEhWkb9JhQ4LFqECoC+XI+DtlZWF7ZJSAjk5CiL0q6uotUYhUajlLUZ0RjQ5oj2ibZZC9bbBvXMzEwmT56MwWCo/HcFb775plXEqRhPt27dREtQ6QI4iRah8uucX/nl77+QVJgkb2CvKGs7cwau+zvIiD00oAGIbhTNd5nfiZZxS24b1N9+++3KfycmJlpFjIr5OHfuHKmpqQwYMAA/e3BSkJEXRQtQAXBp6EJ5STmFFwvxDPCs+Qm2SNVadYmDeng4bNwoWoXpNPdrzoaTGyguK8bF0UW0nGrcNqh3ljghQwUOHTrE6NGj+fHHH+nfv79oOSoqwqioVb965qr8QV3yVrGRkeDmptSre0r6pwB4occLvNDjBdEybomkc1EqNaHWqtsAu4EIYL1gHfUcr2A7aEATGakkyvXsKVqJSTz/PJw7J3dAt3XUoG6nhISE4OLiombAi8QLOAn8IVpI/aYiqEtdq+7uDkOH/jlilxSZ28NWpbS8lLhlcfxn939ES7kJNajbKQ4ODkRGRqojdZFUfP+qZW1C8Qz0pNNTnfBrIXluydat0i9IFxXB4MHwuY13WqwJJ60T6WfSbdJXvW7uCCpSERUVpY7UReIG+GDzDWgqKCwsRK/XV3NGqyA7OxtfX1+SkpLIzMzk7rvvZubMmTg4GDcu2Lt3LwsXLmTp0qUAxMfHV7alDQ0NZe7cuej1embOnMnhw4dxdnbm9ddfJzw8vM7X0jpriXs3ziidNsW0aUoHl02bRCsxGldX+OEHJQte9vzraJ9om7RgVYO6HbNo0SLc7aU3o6xI1IBm+/btXL58mUGDBt20f+3atTRv3hydTscbb7zBokWLSE1NJS6u7sHyo48+YvXq1ZUOgsXFxQCVAb6CdevWUVJSQnJyMnv27GHevHl88MEHRr228pJyiq8U4+4n8echOBjS0kSrMAmNxo7K2nyi+eXkL6Jl3IQa1O2YyMhI0RJU4oFaVrx80ueTm/a1GtaKThM6UVpYyrK4ZTc9HjMqhphRMRReLCRlaEq1x0ZtGFUnqRkZGZw5c6ZaUD958iTz5s2jd+/e7N27l+effx5Q+sH/4x//qBbUa2u92qRJE959911eeEHJHj506BBFRUWMGTOGsrIynn/+eWJiYti5cyf33HOP8jpjYsjIyKjT66nKiodWUJRbxLjt44w+h3BCQpTsd8m9S8PD7SOo6xrp+GzfZ1wru4aro+00BFKDuoqKJTHNj8Sq5OXlsWXLlsrfL1++zKZNm4iOjiYoKIh9+/bhc91iy9fXl5ycnGrPr6316n333UdW1p9rEq6urjz55JM88sgjnDhxgnHjxpGamkp+fn61pQCtVktZWVmdPdVBSZY7n3G+zs+zKUJCoLhY6Swnce+JiAjYZntL0XUmJjCGe8Lv4dK1SwR6BoqWU4ka1FVULI0e0Fzf7sCdRtZO7k53fNzdz73OI/OqlJSU0KRJE7RaLenp6bRt25aUlBTGjBnDDz/8QEBAAN7e3uTm5hIQEEBOTg7+/v7VzlHbkfqNREZGEh4ejkajITIyEm9vby5cuICnpycFBQWVx+n1eqMCOoBnkCf55/Ix6A1oHCQd5VZtQCNxUL/7btixQ7k/cbGtvi11YlCLQQxqMajmA62MGtRVVCzJCuBxIBOoe46X1diyZQvdu3fn9OnTrFy5kv3795OYmIhWqyU7O5vAwEB69OjBmjVrGDt2LCtXriQmJqbaOWo7Ur+RL7/8kiNHjjBz5kyys7PJz8+ncePGtG/fnvXr1xMXF8eePXto1qyZ0a/PK9gLQ7mBggsF8jag6dtXyYBv2lS0EpOYMEHZVCyDWtKmomJJGgFl2GyyXHp6Onv37uXAgQM0bdqUhIQENm7cSGxsbGU2enZ2Ng0bNmTAgAEcOnSI+Ph4jh8/zpAhQ8yiYejQoVy9epXhw4fz3HPPMWfOHBwdHenfvz/Ozs4kJiYyd+5cpk2bZvQ17KJW3dcXunSxH2NyO+Ce/97DlB+niJZRDXWkrqJiSSqsyW20rO3SpUt8/PHHzJ8/H1A6ESYnJ1fzVB8yZAgrVqxg7NixLFy40CzXDQ0NJSVFSexzdna+pUmUg4MDr71mnqSEwJhA+s3rh4e/5M6FS5Yo3eWuJxDKyJUriqf6xIkwapRoNaZRVFpExnnjEzgtgRrUVVQsiY03oImNjSU2NrbavqoBHeCVV16xpiSL0CiyET1flLvFKgBTp8KgQVIHdS8vyMiAAwdEKzGdaJ9o0s+ki5ZRDXX6XUXFkngD7tjsSL0+cenEJa5kXREtwzRCQpREOYnRaKBJE/vxVT9x6QSl5aWipVSiBnUVFUuiAZ4DuosWovJRp4/YOFvuNqv2ENTBvhrQlBvKOXnZdu5Q1KCuomJpXgfMk1OmYgJewV7kn5HYqQ3sJqjbSwOamMAYHm39KJqa6lWtiLqmrqJiacqBHMC/pgNVLIlnkCdXz0qc/Q5Kq9iLF6Uv8u7WTemhU14OWq1oNcYTExjDZ4M/Ey2jGhYL6jcaNCQkJDB79my0Wi09e/bkqaeestSlVVRsi5eBN4FrqHNjArGLrnITJsDYseDsLFqJSYwerWz2gMFgoLi82GZaxVokqN/KoGHQoEG8++67hIWFMX78eA4cOECrVq0scXkVFdsiBCgFLgABgrXUY+yiq5zEneRuheRt7AGlVr2RWyPWDF8jWgpgoXFDVYOGxx9/nB07dlS2odRoNPTs2ZM0yd2GVFRqTUWFmPxLoVLTcmhLHl7yMPpyvWgpxnPpEsyaBTt3ilZiEhcuQGAg/OtfopWYToBnAJm5tmPBapGR+q0MGho0aFD5uIeHB6dOnbLEpVVUbI+KWvUsoL1IIXfGGn7qpaWlJCUlcfr0aUpKSvjb3/5G3759b+mbbi4/9QqC2gUR1C7I6OfbBHo9zJgBnp7QoYNoNUbj6wu5ufaRLBfdKJpvj3xLub4crYP4BAGLBPUbDRq8vLy4dOlS5eMFBQXVgnwFycnJJCcnV9tXUlJiCYkqKtbDxrvKVWANP/XVq1fj7e3NggULyMvL4+GHH6a8vPyWvunm9FMHKC0q5Uz6GXx0PpVtY6WjUSMlQe7MGdFKTMLBQalVt4ug7hNNSXkJp6+epknDJqLlWGb6/csvv2TevHmAcodfVFSEu7s7f/zxBwaDgU2bNtGxY8ebnpeQkMCqVauqbR9++KElJKqoWA9/YBbQRbSQO5ORkcG2GzwxK/zUfXx82Lt3L/Hx8YDSOnbDhg3Vjk1NTWXkyJHVtn379lU75v777+fZZ5+t/F2r1d7WN92cfuoABecL+KTXJ/z+3e8mnUcoGo1a1mZjRPtEA9jMFLxFRupDhw5l2rRpDB8+HI1Gw5w5c3BwcGDKlCmUl5fTs2dP2rZta4lLq6jYHlqUDPiaWNfn5n1NhkGzCVBWCBtuMSqOGqVs1y7CpqHVH4vdUCeZ1vBT9/BQeq/n5+fzzDPPMGnSJLZu3XpL33Rz+qkDeAYq55K+rM1OgnpEBHz/vWgVptPKvxUv9XiJYK9g0VIACwX12xk0VBg4qKjUOy4AuUBz0UJujTX91M+ePcvEiRMZMWIEAwcOJCMj45a+6eb0UwdwdHHEzddNbqc2UIL6rl2iVZjMffdBgwbyZ8D7e/gzN3auaBmVqM1nVFSswXKUsrY7BfU7jawd3e/8uKtfnUfmVbGWn/rFixcZM2YMM2bMoFu3bgC39U03p596BV7BXuSflbyr3EcfgZubaBUmM2yYsqmYFzWoq6hYg2drPkQE6enpODk5ceDAAfr06UNCQgKPP/44EyZMuKWfelJSEvHx8eh0Ov7617/W+XoffvghV65c4f333+f9998HYPHixWzevJnExEQMBgNz5swBoH///rfcbwpeQV7yj9RvUZ0gK8XFSkK/Hdyj2Awag8FgEC3iTmRlZdGvXz9++umnmywhVVRUTGPdunWVfupNmiiZu1lZWdU+a7NmzcLT05OxY8dWBnpZOb1dWYsO6RxSw5E2zMGD8M47MG2asjAtKVlZSgb84sUwbpxoNbaFKXFPHamrqNRj6oufegVSB/MK8vKUri2DB0sd1AMDlb7v9pABb0uonahVVFTqDVeyrrB/+X6KrxaLlmI8IddvTCTPgHd0hNBQ+/BVtyXUoK6iolJvOL39NKseXUXe0TzRUown+HrplORBHezHV92WUIO6iopKvcEz6HqtuszJcs7O0LixXQR1e2lAY0uoa+oqKir1hor2sNI3oImIUFLHJWfYMFD7kJkXNairqKjUGyq7ysk8UgfYtk3uji3XiYtTNhXzoU6/q6io1BvspqucHQR0gPJyJVGuSuNAFRNRg7qKikq9YuSPI+k9o7doGaaxZg08+CBI7mJpMCh5f9ctAVTMwP+3d/dBUd1n/8ffyyI3qRgNGNHGwVGU1paJ1HpHo1Fsgg9j9NaiyKKutWgqsanxKaKoZFtRINraSaxJTU1r1ERQSCb+TDGaaBkl0cGpKCRK8IEasStBalyM8rD7+8O6cXUhEtGF5fOaYcb9fvecc53z9ey152HPpaQuIq1Kl75daNelZT9EB6sV3n8fzp/3dCR3xdcX2rTxdBTeRdfURQSAK1euYLfbXSqj3WC1WgkKCiIpKYmSkhLCw8OxWCz4+DTuuKCmpoakpCTOnTtHdXU1zz77LE899RTjxo1zPq2ua9eupKamYrfbsVgsnDhxAj8/P1JSUujWrdtdr+fZj8/y73/+m/+d9b93PS+PufGztrKy67eQi/yXkrqIAHDo0CEuXbrE2LFjb2vfuXMnP/jBDwgNDeWll15i7dq15OTkMKqRdzm99957dOjQgVWrVlFZWcnPf/5znnjiCQA2bdrk8t49e/ZQXV1NRkYGR44cIS0tjVdfffXuVhIo/n/FHEg/QL+Efhh8Wui1aS95AI00PZ1+FxEACgsLOXjwoEtbaWkpaWlpBAYGUlBQwLhx4wAYP348+/btc3lvTk4OZrPZ5e/o0aMu7xk5ciTPP/9NdRuj0cjx48f5+uuviY+PZ+rUqRw5cgSAw4cPM3jwYAAiIiIoLCxskvVs16UdjjoHVeUt+O4sJXWph47URZqLoW7aJgKzgCuAu4Piaf/9+xKYcEvfvsYtvrKykry8POfrS5cusX//fnr27EmXLl04evQogYGBAAQFBVFRUeEy/Z2UXm373zuibDYbs2fPZs6cOfj7+zN9+nRiYmI4c+YMzzzzDDk5OdhsNpdLAUajkdra2ruqqQ7f/Fbddt5GQHALrXgWFAS9el2/KC1yE/2PEBGqq6sJCQnBaDSSn59Pnz59yMzMJD4+nl27dhEcHEyHDh24ePEiwcHBVFRU0KlTJ5d55OTksGXLFpe2F154gUcffdSl7fz58/z6179m0qRJjBkzhurqarp164bBYKB79+506NCB8vJyAgICqLrpt052u/2uEzq4PlWuc0Tnu56fRxgMUFzs6SikGVJSF2ku9jXQ971v6e/4Lf3fIi8vj4EDB3Lu3DmysrI4duwYJpMJo9GI1Wqlc+fODBo0iB07djBjxgyysrKIiIhwmcedHKl/+eWXxMfHk5yczOOPPw7A9u3bKS4uxmKxYLVasdlsPPzww/Tt25e9e/cyatQojhw5QlhY2HdfwZt4zVPlRNzQNXWRViw/P5+CggKKioro1asXsbGx5ObmEhUV5bwb3Wq10r59e0aPHs3x48cZN24cp0+fZvz48Y1e3muvvcZXX33FunXrnNfdx4wZw+XLl4mLi2Pu3LmsXLkSX19fhg0bhp+fHyaTidTUVBYvXtwk6/xg1wd5/szz9DG38OeTpqXB//2fp6OQZsbgcDgcng6iIXdTLF5EGrZnzx42bNhAeno6ISEhwPV97uZ9bfny5QQEBDBjxgxnopdmYPduuHABJk/2dCTSxO4m7+n0u0grFhUVRVRUlEvbrR8iy5Ytu58hyZ0aNszTEUgzpNPvIiIiXkJJXURExEsoqYuIiHgJJXUREREvoaQuIiLiJZTURUREvISSuoiIiJdQUhcREfESeviMiABw5coV7Ha7S2W0G6xWK0FBQSQlJVFSUkJ4eDgWiwUfn8YdF9TV1bF06VJOnz6N0WgkNTWVrl27YrFYOHHiBH5+fqSkpNCtWzfsdrvbdhGpn47URQSAQ4cO8eGHH7ptX7duHZmZmYSGhpKdnU2nTp3Iyclp9DL27t0LwNatW5k9ezapqans2bOH6upqMjIymD9/PmlpaQD1totI/XSkLtJMDHXTdh/LqVNYWEhZWRljx451tpWWlpKWlkZkZCQFBQXMmzcPgPHjx7NmzRpGjfomqjspvRoVFcXQoUMBKCsro2PHjhw+fJjBgwcDEBERQWFhIUC97SJSPyV1EQGgsrKSvLw85+tLly6xf/9+evbsSZcuXTh69CiBgYEABAUFUVFR4TL9nZReBfD19SUxMZHdu3fz8ssv8/e//93llL/RaKS2thabzea2vSlqqot4K+0dIs3Evgb67nE5daqrqwkJCcFoNJKfn0+fPn3IzMwkPj6eXbt2ERwcTIcOHbh48SLBwcFUVFTQqVMnl3ncyZH6Denp6SxYsICJEycybNgwqqqqnH12ux1fX18CAgLctotI/bSHiAh5eXkMHDiQc+fOkZWVxbFjxzCZTBiNRqxWK507d2bQoEHs2LGDGTNmkJWVRUREhMs87uRI/d1338VqtTJz5kweeOABDAYD4eHh5ObmMmrUKI4cOUJYWBgAffv2Ze/evbe1i0j9lNRFWrH8/HzatGlDUVERQ4cOJTY2lqlTpzJr1ixn7XSr1Ur79u0ZPXo0SUlJjBs3jtDQUBISEhq9vOHDh7N48WImT55MbW0tSUlJPPnkk+Tn52MymXA4HKxcuRKAYcOGceDAgdvaRaR+BofD4fB0EA25m2LxItKwPXv2sGHDBtLT0wkJCQGu73M372vLly8nICCAGTNmOBO9iNw7d5P3dKQu0opFRUURFRXl0nbrh8iyZcvuZ0gichf0O3UREREvoaQuIiLiJZTURUREvMQ9S+oVFRVERkZy8uRJSktLiYuLY9KkSbz44ovY7fZ7tVgREZFW654k9ZqaGpKTk/H39wcgNTWVOXPm8NZbb+FwONw+X1pERETuzj1J6unp6ZhMJucTp4qKinjssccAGDJkiMujKEVERKRpNHlSz87OJjAw0FmIAcDhcGAwGABo27Ytly9fburFioiItHpN/jv1rKwsDAYDH3/8MZ999hmJiYlcvHjR2V9VVcWDDz7odtqMjAwyMjJc2qqrq5s6RBEREa/U5En95oIOZrMZi8XCqlWrOHjwIP379yc3N5cBAwa4nTY2NpbY2FiXthtP1hGRe+vKlSvY7XaXymg3WK1WgoKCSEpKoqSkhPDwcCwWCz4+jTvZV1dXx9KlSzl9+jRGo5HU1FRCQkIYN26c82l1Xbt2JTU1FbvdjsVi4cSJE/j5+ZGSkkK3bt2aZF1FvNV9+UlbYmIir7zyCrGxsdTU1DBixIj7sVgRaYRDhw65vYn10KFDrFu3jszMTEJDQ8nOzqZTp07k5OQ0ehl79+4FYOvWrcyePZvU1FSuXbsGwKZNm9i0aROpqanA9UfYVldXk5GRwfz580lLS7uLtRNpHe7pY2I3bdrk/PfmzZvv5aJEWryhQ4fe1jZx4kRmzZrFlStXGDVq1G3906ZNY9q0aXz55ZdMmDDBpW/fvn2NWn5hYSFlZWWMHTvW2VZaWkpaWhqRkZEUFBQwb948AMaPH8+aNWtcYrqT0qtRUVHO9SwrK6Njx44cP36cr7/+mvj4eGpra5k3bx4REREcPnzYeW9OREQEhYWFjVofkdZIz34XEQAqKytdfply6dIl9u/fT8+ePenSpQtHjx4lMDAQgKCgICoqKlymv5PSqwC+vr4kJiaye/duXn75Zfz9/Zk+fToxMTGcOXOGZ555hpycHGw2m8ulAKPRSG1trWqqizRAe4dIM9HQkfX3vve9Bvs7duzY6CPzm1VXVxMSEoLRaCQ/P58+ffqQmZlJfHw8u3btIjg4mA4dOnDx4kWCg4OpqKhw/mT1hjs5Ur8hPT2dBQsWMHHiRN577z26deuGwWCge/fudOjQgfLycgICAqiqqnJOY7fbldBFvoX2EBEhLy+PgQMHcu7cObKysjh27Bgmkwmj0YjVaqVz584MGjSIHTt2MGPGDLKysoiIiHCZx50cqb/77rtYrVZmzpzJAw88gMFgYMeOHRQXF2OxWLBardhsNh5++GH69u3L3r17GTVqFEeOHCEsLOxebgIRr6Bnv4u0Yvn5+RQUFFBUVESvXr2IjY0lNzeXqKgo593oVquV9u3bM3r0aI4fP864ceM4ffo048ePb/Tyhg8fzqeffsrkyZOZPn06SUlJTJgwgcuXLxMXF8fcuXNZuXIlvr6+DBs2DD8/P0wmE6mpqSxevLipV1/E6xgcDofD00E05G6KxYtIw/bs2cOGDRtIT08nJCQEuL7P3byvLV++nICAAGbMmOFM9CJy79xN3tPpd5FWLCoqiqioKJe2Wz9Eli1bdj9DEpG7oNPvIiIiXkJJXURExEsoqYuIiHgJJXUREREvoaQuIiLiJZTURUREvISSuoiIiJdQUhcR4Ho9dZvN5rbParVSW1vLwoULiY6OJjk5Gbvd/p2XVVFRQWRkJCdPnsRut5OcnExsbCxms5nS0lKAettFpH5K6iIC3J966gA1NTUkJyfj7+8P1F83XfXURRpPSV1EgOv11A8ePOjSdqOeemBgIAUFBYwbNw64Xk/91qpwOTk5mM1ml7+jR4/etpz09HRMJpOzylt9ddNVT12k8fSYWJFmonjFitvaHurfn4ejorBfu0bJ6tW39QcNHkzQkCHUXr7MqZdfdukLW7KkUcu/H/XUs7OzCQwMZPDgwaxfvx6g3rrpqqcu0njaO0TkvtVTz8rKwmAw8PHHH/PZZ5+RmJhIr1693NZNVz11kcbTHiLSTDR0ZO3zP//TYL9vu3aNPjK/2f2qp35z0jebzVgsFkpKStzWTVc9dZHG0zV1kVbsftdTd6e+uumqpy7SeKqnLtKKqZ66SPOjeuoi8p2onrqId9HpdxERES+hpC4iIuIllNRFRES8hJK6iIiIl1BSFxER8RJK6iIiIl5CSV1ERMRLKKmLiIh4CSV1ERERL9HsnyhXV1cHwL///W8PRyIiInLv3ch3N/JfYzT7pF5eXg7A5MmTPRyJiIjI/VNeXk63bt0aNU2zL+hy9epVCgsLefjhhzEajU0yz4SEBF577bUmmZfcHY1F86GxaB40Ds2Hp8airq6O8vJywsPD8ff3b9S0zf5I3d/fn379+jXpPP38/FTxrZnQWDQfGovmQePQfHhyLBp7hH6DbpQTERHxEkrqIiIiXkJJXURExEsYLRaLxdNBeEJ4eLinQ5D/0lg0HxqL5kHj0Hy0tLFo9ne/i4iIyJ3R6XcREREvoaQuIiLiJZr979Sbkt1ux2KxcOLECfz8/EhJSfnOvwWUxikoKGD16tVs2rSJ0tJSFi1ahMFgoFevXrz44ov4+Piwdu1a9u3bh6+vL0lJSTz66KOeDtur1NTUkJSUxLlz56iurubZZ5+lZ8+eGov7rK6ujqVLl3L69GmMRiOpqak4HA6NgwdVVCDGkYUAAAsoSURBVFQQHR3NG2+8ga+vb8seC0crsmvXLkdiYqLD4XA4/vnPfzoSEhI8HFHrsH79esfo0aMdMTExDofD4Zg5c6bjk08+cTgcDseyZcscH3zwgaOwsNBhNpsddrvdce7cOUd0dLQnQ/ZK27dvd6SkpDgcDofj4sWLjsjISI2FB+zevduxaNEih8PhcHzyySeOhIQEjYMHVVdXO2bNmuUYPny4o6SkpMWPRas6/X748GEGDx4MQEREBIWFhR6OqHUICQnhlVdecb4uKiriscceA2DIkCHk5eVx+PBhnnjiCQwGA9///vepq6vj4sWLngrZK40cOZLnn3/e+dpoNGosPCAqKorly5cDUFZWRseOHTUOHpSeno7JZKJTp05Ay/98alVJ3WazERAQ4HxtNBqpra31YEStw4gRI/D1/eZKj8PhwGAwANC2bVsuX75829jcaJem07ZtWwICArDZbMyePZs5c+ZoLDzE19eXxMREli9fzogRIzQOHpKdnU1gYKDzYA9a/udTq0rqAQEBVFVVOV/b7XaXZCP3h4/PN//tqqqqePDBB28bm6qqKtq1a+eJ8Lza+fPnmTp1KmPHjmXMmDEaCw9KT09n165dLFu2jGvXrjnbNQ73T1ZWFnl5eZjNZj777DMSExNdjsBb4li0qqTet29fcnNzAThy5AhhYWEejqh1+tGPfsTBgwcByM3NpV+/fvTt25f9+/djt9spKyvDbrcTGBjo4Ui9y5dffkl8fDwvvPACEyZMADQWnvDuu+/y5z//GYAHHngAg8FAeHi4xsEDtmzZwubNm9m0aRO9e/cmPT2dIUOGtOixaFWHqcOGDePAgQOYTCYcDgcrV670dEitUmJiIsuWLeMPf/gDPXr0YMSIERiNRvr160dsbCx2u53k5GRPh+l1XnvtNb766ivWrVvHunXrAFiyZAkpKSkai/to+PDhLF68mMmTJ1NbW0tSUhKhoaHaJ5qJlv75pCfKiYiIeIlWdfpdRETEmympi4iIeAkldRERES+hpC4iIuIllNRFRES8hJK6iIiIl1BSFxER8RJK6iIizUhxcbGnQ5AWTEldWoSDBw/Sr18/zp8/72xbvXo12dnZdz3vuro6pk+fTlxcHJcuXXJZ5uOPP47ZbMZsNhMdHc3s2bOprq7+zsu6du0aTz755F3Fm52dzerVq+/ovevXr2fatGnEx8czffr0BisTNma+N1y7do1t27bd8XtvXfebt/GUKVMwmUy8//77zv7c3FwyMjIaFdN3ca+Xc+XKFWw2m9s+q9Xq/HdKSgqxsbH3LA7xfq3qMbHSsrVp04bFixfz17/+1VlFqSmUl5dTWVnp9gvCgAEDWLNmjfP1/Pnz+eijjxg5cmSTLf9eKSkp4aOPPuLtt9/GYDA4C1a89957TbaM8vJytm3bRkxMzHeex83buKqqCrPZTPfu3enduzdDhgxpqlAbdK+Xc+jQIS5dusTYsWNva9+5cye//e1vATCZTJw4ceKexiLeTUldWowBAwZgt9vZsmULU6ZMcbbX1NSQlJTE2bNnqaur45e//CWjRo1yOw93733nnXc4c+YMycnJ/O53v6t3+dXV1Vy4cIH27dtjs9lYsmQJly9fprKykpiYGCZNmkR2djb/+Mc/uHr1Kv/617945plnGDFiBAsWLOCrr74iJCSkwViuXr3K3r17uXr1KuXl5UydOpUPP/yQzz//nIULFxIVFeWcfv78+YwZM4ahQ4dy8uRJ0tPTWb9+vbM/MDCQsrIytm/fzpAhQ+jduzfbt2+npqaGF198kdLSUux2O3PmzKF///4ucbnrv3r1KosXL6asrIyamhqWLVtGVlYWJSUlrF27lpkzZ942XXh4uNt1r0/btm2JjY0lJyeH3r17k52dzalTp+jRo0eD2yUyMtJtzO7G4yc/+QmLFy/G19cXo9HISy+9xIEDBzh16hQLFiyod1xunU90dDSnT5++bV7BwcG3rVdhYSFlZWUuSb20tJS0tDQiIyOdbT179vzWbSTSECV1aVEsFgsxMTE88cQTzraMjAweeughVq1ahc1mIzo6mgEDBritouTuvb///e9Zvny524T+ySefYDabqaiowMfHh4kTJ/L4449TVFTE008/zfDhw7FarZjNZiZNmgSAzWZjw4YNnDlzhoSEBK5cuUJYWBhz586loKDAWQHKXSyxsbFUVVXxxhtvsHPnTv72t7+RmZnJwYMHefPNN12SekxMDG+//TZDhw5l+/btzsprNwQGBvLqq6+yefNm/vSnP+Hv78/cuXOpqKjgoYceYuXKlVRWVjJlyhR27tzpnG7btm1u+7du3cojjzzCmjVrKC4uJi8vj4SEBIqLi3nuued46623bpsuLi7O7bo3JCgoiKKiotvaG9ouFy5cqHedbh0Ps9nMj3/8YxYtWkR+fr7LJZeGxuXW+URHR5OXl3fbvNwl9crKSvLy8pyvL126xP79++nZsyddunT51m0icqeU1KVFeeihh0hKSmLRokX07dsXgJMnTzJw4EAAAgICCA0N5ezZs26Turv32u32epd349RwZWUl8fHxdO3aFYCOHTuyceNGPvjgAwICAqitrXVO88Mf/hCALl26UF1dzeeff87gwYMB6NOnD76+vvXGUldXR+/evQFo164doaGhGAwG2rdv71JzG6B///6sWLGCiooKDhw4wLx581z6S0tLCQgIIDU1FYBjx47xq1/9ihEjRnD48GGOHj0KQG1tLZWVlc7piouL3fafOnXKeZo6LCyMsLAwvvjiiwanq2/dG1JWVkbnzp1va29ou9QXs7vxmDBhAq+//jozZsygXbt2zJ0712U59Y3LrfMBvnVecP0MT0hICEajkfz8fPr06UNmZibx8fHs2rXL7ZcAke9KN8pJi/Pkk0/SvXt33nnnHQBCQ0PJz88Hrh+VFRcXO5Pvrdy9906uz984clu6dCkXLlzgjTfeICIigtWrVzNy5EhuLnZ46/x69OjBkSNHAPj000+dXwDqi+VO7xcwGAyMGTOGFStWMGjQINq0aePSf+LECSwWi/PLQPfu3WnXrh3du3fn6aefZtOmTbz++uuMHDmS9u3bu8Trrj80NJRjx44BcPbsWebPn4+Pj4/zS5G76epb9/rYbDa2bdvm9p6FhrZLfTG7m+7DDz/kpz/9KRs3bmTkyJH85S9/celvzLh827wA8vLyGDhwIE899RRZWVls3rwZk8mE0WjEarW6/QIj8l0pqUuLtGTJEvz9/QGYOHEi//nPf4iLi2Pq1Kk899xzGI1Gnnvuudumc/ded0f07vTs2ROz2UxKSgo/+9nPePPNN4mLi2Pjxo0YjcZ674qfPHkyVquVuLg4tmzZ4ky+7mIJCgpq1HaIjo7mgw8+uO3UO1yv2/3YY48RExODyWRi+vTpLFy4kLi4OE6dOuW82/yRRx7Bx+ebjwKTyeS232Qy8cUXXzBlyhQWLlzItGnTCAoKoqamhlWrVrmdrr51v9mNSxy/+MUvSEhI4De/+Q09evRo1HaoL2Z3wsPD+eMf/8ikSZPYunWry/0Z0LhxaWhe+fn5FBQUUFRURK9evYiNjSU3N5eoqCjatWsHXL/zvX379t/6ZUfkTqmeukgLZrVaWbhwIRs3bvR0KHKLPXv2sGHDBtLT0503CX7xxRcuZ5GWL19OQECA8/S9yN1SUhdpoXbt2sXatWtZsWIFjz76qKfDEZFmQEldRETES+iauoiIiJdQUhcREfESSuoiIiJeQkldRETESyipi4iIeAkldRERES+hpC4iIuIllNRFRES8xP8H2CIBVx/SruwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1af7d860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (num_M1[3])\n",
    "plt.figure(figsize=(8.0, 6.0))\n",
    "color_list = ['green', 'blue', 'red', 'purple', 'orange', 'magenta', 'cyan', 'black', 'indianred', 'lightseagreen', 'gold']\n",
    "for i in range(len(num_M0)):\n",
    "    plt.plot(num_M1[i], acc_varying_subspace[i], color=color_list[i], linestyle='dashed', label='$\\mathcal{M0}$ = '+str(num_M0[i]))\n",
    "\n",
    "plt.title('Recogniton Accuracy (%) vs No. of Random Dimensions ($\\mathcal{M1}$) for a range of fixed $\\mathcal{M0}$')\n",
    "plt.xlabel('No. of Randomly Selected Dimensions $\\mathcal{M1}$')\n",
    "plt.ylabel('Recogniton Accuracy / %')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a21218ef0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a185fb668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8.0, 6.0))\n",
    "plt.plot(num_estimators_list, acc_varying_num_est_bag, color='green', linestyle='dashed', label='Bagging')\n",
    "plt.plot(num_estimators_list, acc_varying_num_est_ran_subsp, color='blue', linestyle='dashed', label='Random Subspace')\n",
    "plt.title('Accuracy vs number of estimators\\n')\n",
    "plt.xlabel('Number of estimators')\n",
    "plt.ylabel('Recogniton Accuracy / %')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of base estimator with no pre PCA = 91.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of base estimator with pre PCA applied = 23.08%\n",
      "Accuracy of sub model  1  = 88.46%\n",
      "Accuracy of sub model  2  = 87.50%\n",
      "Accuracy of sub model  3  = 91.35%\n",
      "Accuracy of sub model  4  = 89.42%\n",
      "Accuracy of sub model  5  = 87.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sub model  6  = 90.38%\n",
      "Accuracy of sub model  7  = 91.35%\n",
      "Accuracy of sub model  8  = 88.46%\n",
      "Accuracy of sub model  9  = 92.31%\n",
      "Accuracy of sub model  10  = 85.58%\n",
      "Accuracy of sub model  11  = 85.58%\n",
      "Accuracy of sub model  12  = 87.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sub model  13  = 84.62%\n",
      "Accuracy of sub model  14  = 88.46%\n",
      "Accuracy of sub model  15  = 85.58%\n",
      "Accuracy of sub model  16  = 86.54%\n",
      "Accuracy of sub model  17  = 84.62%\n",
      "Accuracy of sub model  18  = 85.58%\n",
      "Accuracy of sub model  19  = 82.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sub model  20  = 88.46%\n",
      "Accuracy of sub model  21  = 87.50%\n",
      "Accuracy of sub model  22  = 83.65%\n",
      "Accuracy of sub model  23  = 88.46%\n",
      "Accuracy of sub model  24  = 89.42%\n",
      "Accuracy of sub model  25  = 90.38%\n",
      "Accuracy of sub model  26  = 89.42%\n",
      "Accuracy of sub model  27  = 87.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sub model  28  = 89.42%\n",
      "Accuracy of sub model  29  = 88.46%\n",
      "Accuracy of sub model  30  = 87.50%\n",
      "Accuracy of sub model  31  = 85.58%\n",
      "Accuracy of sub model  32  = 86.54%\n",
      "Accuracy of sub model  33  = 88.46%\n",
      "Accuracy of sub model  34  = 86.54%\n",
      "Accuracy of sub model  35  = 91.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sub model  36  = 86.54%\n",
      "Accuracy of sub model  37  = 87.50%\n",
      "Accuracy of sub model  38  = 82.69%\n",
      "Accuracy of sub model  39  = 86.54%\n",
      "Accuracy of sub model  40  = 88.46%\n",
      "Accuracy of sub model  41  = 90.38%\n",
      "Accuracy of sub model  42  = 87.50%\n",
      "Accuracy of sub model  43  = 90.38%\n",
      "Accuracy of sub model  44  = 88.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sub model  45  = 86.54%\n",
      "Accuracy of sub model  46  = 86.54%\n",
      "Accuracy of sub model  47  = 87.50%\n",
      "Accuracy of sub model  48  = 83.65%\n",
      "Accuracy of sub model  49  = 91.35%\n",
      "Accuracy of sub model  50  = 87.50%\n",
      "Average accuracy of sub models = 87.67%\n",
      "Accuracy of ensemble estimator = 95.19%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1e3e64a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1e3e6d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "D, N = X_train.shape      \n",
    "        \n",
    "n_estimators = 50\n",
    "M0 = M0_ideal\n",
    "M1 = M1_ideal  \n",
    "\n",
    "verbose = True\n",
    "\n",
    "standard = False\n",
    "#M__pca_ideal = 147\n",
    "#M__lda_ideal = 46\n",
    "\n",
    "#if verbose:\n",
    "#    print ('M__pca_ideal = ', M__pca_ideal)\n",
    "#    print ('M__lda_ideal = ', M__lda_ideal)\n",
    "\n",
    "M_pca_bag = N-1\n",
    "\n",
    "M_pca = 150 #M__pca_ideal\n",
    "M_lda = 47 #M__lda_ideal\n",
    "\n",
    "    \n",
    "assert(M1 <= (N-1-M0))\n",
    "assert(M0+M1 > M_pca)\n",
    "assert(M_pca > M_lda)\n",
    "\n",
    "estimators = [('lda', LinearDiscriminantAnalysis(n_components=M_lda)), ('knn', KNeighborsClassifier(n_neighbors=1))]\n",
    "\n",
    "base_est = Pipeline (estimators)\n",
    "\n",
    "base_est.fit(X_train.T, y_train.T.ravel())\n",
    "\n",
    "acc = base_est.score(X_test.T, y_test.T.ravel())\n",
    "if verbose:\n",
    "    print ('Accuracy of base estimator with no pre PCA = %.2f%%' % (acc * 100))\n",
    "\n",
    "\n",
    "pca = PCA(n_components=M_pca_bag)\n",
    "W_train = pca.fit_transform(X_train.T)\n",
    "W_test = pca.transform(X_test.T)\n",
    "\n",
    "base_est.fit(W_train, y_train.T.ravel())\n",
    "\n",
    "acc = base_est.score(W_test, y_test.T.ravel())\n",
    "if verbose:\n",
    "    print ('Accuracy of base estimator with pre PCA applied = %.2f%%' % (acc * 100))\n",
    "\n",
    "estimators = []\n",
    "sub_model_accuracies = []\n",
    "masks = []\n",
    "\n",
    "for i in range (n_estimators):\n",
    "\n",
    "    mask0 = np.arange(M0)\n",
    "    mask1 = np.random.choice(np.arange(M0, (N-1)), M1, replace=False)\n",
    "\n",
    "    mask1 = np.array(mask1).ravel()\n",
    "    \n",
    "    mask = np.concatenate((mask0, mask1), axis = None)\n",
    "    masks.append(mask)\n",
    "\n",
    "    W_bag = W_train[:, mask]\n",
    "    y_bag = y_train\n",
    "    \n",
    "    estimator = clone(base_est)\n",
    "\n",
    "    estimator.fit(W_bag, y_bag.T.ravel())\n",
    "    \n",
    "    name = 'est_'+str(i+1)\n",
    "    estimators.append((name, estimator))\n",
    "    \n",
    "    sub_model_acc = estimator.score(W_test[:, mask], y_test.T.ravel())\n",
    "    sub_model_accuracies.append(sub_model_acc)\n",
    "    if verbose:\n",
    "        print ('Accuracy of sub model ', i+1, ' = %.2f%%' % (sub_model_acc * 100))\n",
    "    \n",
    "\n",
    "ave_sub_model_acc = sum(sub_model_accuracies)/n_estimators\n",
    "if verbose:\n",
    "    print ('Average accuracy of sub models = %.2f%%' % (ave_sub_model_acc * 100))\n",
    "    \n",
    "y_hat = []\n",
    "\n",
    "for w in W_test:\n",
    "    prediction_sum = 0\n",
    "    predictions = np.empty(n_estimators, dtype = np.int64)\n",
    "    for i, (name, estimator) in enumerate(estimators):\n",
    "        y = estimator.predict(w[masks[i]].reshape(1, -1))\n",
    "        \n",
    "        prediction_sum = prediction_sum + float(y[0])\n",
    "        predictions[i] = int(y[0])\n",
    "    prediction = round(prediction_sum/n_estimators)\n",
    "    \n",
    "    counts = np.bincount(predictions)\n",
    "    #y_hat.append(prediction)\n",
    "    y_hat.append(np.argmax(counts))\n",
    "        \n",
    "acc = accuracy_score(y_test.T, y_hat)\n",
    "if verbose:\n",
    "    print ('Accuracy of ensemble estimator = %.2f%%' % (acc * 100))\n",
    "\n",
    "cfn_matrix = confusion_matrix(y_test.T, y_hat)\n",
    "\n",
    "class_names = np.arange(1,53)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plot_confusion_matrix(cm           = cfn_matrix, \n",
    "                      normalize    = False,\n",
    "                      target_names = class_names,\n",
    "                      title        = \"Confusion Matrix\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0db589e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_hat = pca.inverse_transform(W_test)     \n",
    "\n",
    "col_index = 0\n",
    "\n",
    "# prettify plots\n",
    "plt.rcParams['figure.figsize'] = [14.0, 6.0]\n",
    "sns.set_palette(sns.color_palette(\"muted\"))\n",
    "_palette = sns.color_palette(\"muted\")\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(ncols=5, nrows=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for y, y_, x_, x in zip(y_hat, y_test.T.ravel(), X_hat, X_test.T):\n",
    "    if (y != y_):\n",
    "        axes[0,col_index].imshow(x.reshape(46,56).T,\n",
    "                       cmap=plt.get_cmap('gray'))\n",
    "        axes[0,col_index].set_title(\n",
    "            'Predicted Class: %d, True Class: %d' % (y, y_) + '\\nOriginal Image', color=_palette[2])\n",
    "        axes[1,col_index].imshow(x_.reshape(46,56).T,\n",
    "                       cmap=plt.get_cmap('gray'))\n",
    "        axes[1,col_index].set_title(\n",
    "            'Reconstructed Image', color=_palette[2])\n",
    "        col_index = col_index + 1\n",
    "\n",
    "fig.tight_layout()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
